{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api/blocks/","title":"Block system","text":"<p><code>qadence</code> offers a block-based system to construct quantum circuits in a flexible manner.</p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock","title":"<code>AbstractBlock(tag=None, __array_priority__=1000)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for both primitive and composite blocks.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>A human-readable name attached to the block type. Notice, this is the same for all the class instances so it cannot be used for identifying different blocks</p> <p> TYPE: <code>str</code> </p> <code>qubit_support</code> <p>The qubit support of the block expressed as a tuple of integers</p> <p> TYPE: <code>tuple[int, ...]</code> </p> <code>tag</code> <p>A tag identifying a particular instance of the block which can be used for identification and pretty printing</p> <p> TYPE: <code>str | None</code> </p> <code>eigenvalues</code> <p>The eigenvalues of the matrix representing the block. This is used mainly for primitive blocks and it's needed for generalized parameter shift rule computations. Currently unused.</p> <p> TYPE: <code>list[float] | None</code> </p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.is_identity","title":"<code>is_identity</code>  <code>property</code>","text":"<p>Identity predicate for blocks.</p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.n_qubits","title":"<code>n_qubits()</code>","text":"<p>The number of qubits in the whole system.</p> <p>A block acting on qubit N would has at least n_qubits &gt;= N + 1.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_qubits(self) -&gt; int:\n    \"\"\"The number of qubits in the whole system.\n\n    A block acting on qubit N would has at least n_qubits &gt;= N + 1.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.n_supports","title":"<code>n_supports()</code>","text":"<p>The number of qubits the block is acting on.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_supports(self) -&gt; int:\n    \"\"\"The number of qubits the block is acting on.\"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.qubit_support","title":"<code>qubit_support()</code>","text":"<p>The indices of the qubit(s) the block is acting on.</p> <p>Qadence uses the ordering [0..,N-1] for qubits.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef qubit_support(self) -&gt; Tuple[int, ...]:\n    \"\"\"The indices of the qubit(s) the block is acting on.\n\n    Qadence uses the ordering [0..,N-1] for qubits.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#primitive-blocks","title":"Primitive blocks","text":""},{"location":"api/blocks/#qadence.blocks.primitive.ControlBlock","title":"<code>ControlBlock(control, target_block, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The abstract ControlBlock.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    control: tuple[int, ...],\n    target_block: PrimitiveBlock,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.control = control\n    self.blocks = (target_block,)\n    self.target = target_block.qubit_support\n\n    # using tuple expansion because some control operations could\n    # have multiple targets, e.g. CSWAP\n    super().__init__((*control, *self.target), noise=noise)  # target_block.qubit_support[0]))\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricBlock","title":"<code>ParametricBlock(qubit_support, noise=None)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>Parameterized primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    qubit_support: tuple[int, ...],\n    noise: NoiseHandler | None = None,\n):\n    self._qubit_support = qubit_support\n    self._noise = noise\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricBlock.num_parameters","title":"<code>num_parameters()</code>  <code>abstractmethod</code>","text":"<p>The number of parameters required by the block.</p> <p>This is a class property since the number of parameters is defined automatically before instantiating the operation. Also, this could correspond to a larger number of actual user-facing parameters since any parameter expression is allowed</p> <p>Examples: - RX operation has 1 parameter - U operation has 3 parameters - HamEvo has 2 parameters (generator and time evolution)</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>@abstractmethod\ndef num_parameters(cls) -&gt; int:\n    \"\"\"The number of parameters required by the block.\n\n    This is a class property since the number of parameters is defined\n    automatically before instantiating the operation. Also, this could\n    correspond to a larger number of actual user-facing parameters\n    since any parameter expression is allowed\n\n    Examples:\n    - RX operation has 1 parameter\n    - U operation has 3 parameters\n    - HamEvo has 2 parameters (generator and time evolution)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricControlBlock","title":"<code>ParametricControlBlock(control, target_block, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The abstract parametrized ControlBlock.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    control: tuple[int, ...],\n    target_block: ParametricBlock,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.blocks = (target_block,)\n    self.control = control\n    self.parameters = target_block.parameters\n    super().__init__((*control, *target_block.qubit_support), noise=noise)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.PrimitiveBlock","title":"<code>PrimitiveBlock(qubit_support, noise=None)</code>","text":"<p>               Bases: <code>AbstractBlock</code></p> <p>Primitive blocks represent elementary unitary operations.</p> <p>Examples are single/multi-qubit gates or Hamiltonian evolution. See <code>qadence.operations</code> for a full list of primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    qubit_support: tuple[int, ...],\n    noise: NoiseHandler | None = None,\n):\n    self._qubit_support = qubit_support\n    self._noise = noise\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.PrimitiveBlock.digital_decomposition","title":"<code>digital_decomposition()</code>","text":"<p>Decomposition into purely digital gates.</p> <p>This method returns a decomposition of the Block in a combination of purely digital single-qubit and two-qubit 'gates', by manual/custom knowledge of how this can be done efficiently. :return:</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def digital_decomposition(self) -&gt; AbstractBlock:\n    \"\"\"Decomposition into purely digital gates.\n\n    This method returns a decomposition of the Block in a\n    combination of purely digital single-qubit and two-qubit\n    'gates', by manual/custom knowledge of how this can be done efficiently.\n    :return:\n    \"\"\"\n    return self\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ProjectorBlock","title":"<code>ProjectorBlock(ket, bra, qubit_support, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The abstract ProjectorBlock.</p> <p>Arguments:</p> <pre><code>ket (str): The ket given as a bitstring.\nbra (str): The bra given as a bitstring.\nqubit_support (int | tuple[int]): The qubit_support of the block.\n</code></pre> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    ket: str,\n    bra: str,\n    qubit_support: int | tuple[int, ...],\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    \"\"\"\n    Arguments:\n\n        ket (str): The ket given as a bitstring.\n        bra (str): The bra given as a bitstring.\n        qubit_support (int | tuple[int]): The qubit_support of the block.\n    \"\"\"\n    if isinstance(qubit_support, int):\n        qubit_support = (qubit_support,)\n    if len(bra) != len(ket):\n        raise ValueError(\n            \"Bra and ket must be bitstrings of same length in the 'Projector' definition.\"\n        )\n    elif len(bra) != len(qubit_support):\n        raise ValueError(\"Bra or ket must be of same length as the 'qubit_support'\")\n    for wf in [bra, ket]:\n        if not all(int(item) == 0 or int(item) == 1 for item in wf):\n            raise ValueError(\n                \"All qubits must be either in the '0' or '1' state\"\n                \" in the 'ProjectorBlock' definition.\"\n            )\n\n    self.ket = ket\n    self.bra = bra\n    super().__init__(qubit_support, noise=noise)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ScaleBlock","title":"<code>ScaleBlock(block, parameter)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>Scale blocks are created when multiplying a block by a number or parameter.</p> <p>Example: <pre><code>from qadence import X\n\nprint(X(0) * 2)\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 X(0)\n</code></pre> </p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, block: AbstractBlock, parameter: Any):\n    self.block = block\n    # TODO: more meaningful name like `scale`?\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    super().__init__(block.qubit_support)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.TimeEvolutionBlock","title":"<code>TimeEvolutionBlock(qubit_support, noise=None)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>Simple time evolution block with time-independent Hamiltonian.</p> <p>This class is just a convenience class which is used to label blocks which contains simple time evolution with time-independent Hamiltonian operators</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    qubit_support: tuple[int, ...],\n    noise: NoiseHandler | None = None,\n):\n    self._qubit_support = qubit_support\n    self._noise = noise\n</code></pre>"},{"location":"api/blocks/#analog-blocks","title":"Analog blocks","text":"<p>To learn how to use analog blocks and how to mix digital &amp; analog blocks, check out the digital-analog section of the documentation.</p> <p>Examples on how to use digital-analog blocks can be found in the *examples folder of the qadence repo:</p> <ul> <li>Fit a simple sinus: <code>examples/digital-analog/fit-sin.py</code></li> <li>Solve a QUBO: <code>examples/digital-analog/qubo.py</code></li> </ul>"},{"location":"api/blocks/#qadence.blocks.analog.AnalogChain","title":"<code>AnalogChain(blocks)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogComposite</code></p> <p>A chain of analog blocks.</p> <p>Needed because analog blocks require stricter validation than the general <code>ChainBlock</code>.</p> <p><code>AnalogChain</code>s can only be constructed from <code>AnalogKron</code> blocks or globally supported, primitive, analog blocks (like <code>InteractionBlock</code>s and <code>ConstantAnalogRotation</code>s).</p> <p>Automatically constructed by the <code>chain</code> function if only analog blocks are given.</p> <p>Example: <pre><code>from qadence import X, chain, AnalogInteraction\n\nb = chain(AnalogInteraction(200), AnalogInteraction(200))\nprint(type(b))  # this is an `AnalogChain`\n\nb = chain(X(0), AnalogInteraction(200))\nprint(type(b))  # this is a general `ChainBlock`\n</code></pre> <pre><code>&lt;class 'qadence.blocks.analog.AnalogChain'&gt;\n&lt;class 'qadence.blocks.composite.ChainBlock'&gt;\n</code></pre> </p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...]):\n    \"\"\"A chain of analog blocks.\n\n    Needed because analog blocks require\n    stricter validation than the general `ChainBlock`.\n\n    `AnalogChain`s can only be constructed from `AnalogKron` blocks or\n    _**globally supported**_, primitive, analog blocks (like `InteractionBlock`s and\n    `ConstantAnalogRotation`s).\n\n    Automatically constructed by the [`chain`][qadence.blocks.utils.chain]\n    function if only analog blocks are given.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, chain, AnalogInteraction\n\n    b = chain(AnalogInteraction(200), AnalogInteraction(200))\n    print(type(b))  # this is an `AnalogChain`\n\n    b = chain(X(0), AnalogInteraction(200))\n    print(type(b))  # this is a general `ChainBlock`\n    ```\n    \"\"\"\n    for b in blocks:\n        if not (isinstance(b, AnalogKron) or b.qubit_support.is_global):\n            raise ValueError(\"Only KronBlocks or global blocks can be chain'ed.\")\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.analog.AnalogKron","title":"<code>AnalogKron(blocks, interaction=Interaction.NN)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogComposite</code></p> <p>Stack analog blocks vertically (i.e. in time).</p> <p>Needed because analog require stricter validation than the general <code>KronBlock</code>.</p> <p><code>AnalogKron</code>s can only be constructed from non-global, analog blocks with the same duration.</p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...], interaction: Interaction = Interaction.NN):\n    \"\"\"Stack analog blocks vertically (i.e. in time).\n\n    Needed because analog require\n    stricter validation than the general `KronBlock`.\n\n    `AnalogKron`s can only be constructed from _**non-global**_, analog blocks\n    with the _**same duration**_.\n    \"\"\"\n    if len(blocks) == 0:\n        raise NotImplementedError(\"Empty KronBlocks not supported\")\n\n    self.blocks = blocks\n    self.interaction = interaction\n\n    qubit_support = QubitSupport()\n    duration = blocks[0].duration\n    for b in blocks:\n        if not isinstance(b, AnalogBlock):\n            raise ValueError(\"Can only kron `AnalgoBlock`s with other `AnalgoBlock`s.\")\n\n        if b.qubit_support == QubitSupport(\"global\"):\n            raise ValueError(\"Blocks with global support cannot be kron'ed.\")\n\n        if not qubit_support.is_disjoint(b.qubit_support):\n            raise ValueError(\"Make sure blocks act on distinct qubits!\")\n\n        if not np.isclose(evaluate(duration), evaluate(b.duration)):\n            raise ValueError(\"Kron'ed blocks have to have same duration.\")\n\n        qubit_support += b.qubit_support\n\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.analog.ConstantAnalogRotation","title":"<code>ConstantAnalogRotation(tag=None, __array_priority__=1000, _eigenvalues_generator=None, parameters=ParamMap(alpha=0.0, duration=1000.0, omega=0.0, delta=0.0, phase=0.0), qubit_support=QubitSupport('global'), add_pattern=True)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogBlock</code></p> <p>Implements a constant analog rotation with interaction dictated by the chosen Hamiltonian.</p> <pre><code>H/h = \u2211\u1d62(\u03a9/2 cos(\u03c6)*X\u1d62 - sin(\u03c6)*Y\u1d62 - \u03b4n\u1d62) + H\u1d62\u2099\u209c.\n</code></pre> <p>To construct this block you can use of the following convenience wrappers: - The general rotation operation <code>AnalogRot</code> - Shorthands for rotatins around an axis:   <code>AnalogRX</code>,   <code>AnalogRY</code>,   <code>AnalogRZ</code></p> <p>WARNING: do not use <code>ConstantAnalogRotation</code> with <code>alpha</code> as differentiable parameter - use the convenience wrappers mentioned above.</p>"},{"location":"api/blocks/#qadence.blocks.analog.InteractionBlock","title":"<code>InteractionBlock(tag=None, __array_priority__=1000, _eigenvalues_generator=None, parameters=ParamMap(duration=1000.0), qubit_support=QubitSupport('global'), add_pattern=True)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogBlock</code></p> <p>Free-evolution for the Hamiltonian interaction term of a register of qubits.</p> <p>In real interacting quantum devices, it means letting the system evolve freely according to the time-dependent Schrodinger equation. With emulators, this block is translated to an appropriate interaction Hamiltonian, for example, an Ising interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n</code></pre> <p>or an XY-interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2083/r\u2c7c\u2c7c\u00b3 (X\u1d62X\u2c7c + Z\u1d62Z\u2c7c)\n</code></pre> <p>with <code>n\u1d62 = (1-Z\u1d62)/2</code>.</p> <p>To construct, use the <code>AnalogInteraction</code> function.</p>"},{"location":"api/blocks/#composite-blocks","title":"Composite blocks","text":""},{"location":"api/blocks/#qadence.blocks.utils.chain","title":"<code>chain(*args)</code>","text":"<p>Chain blocks sequentially.</p> <p>On digital backends this can be interpreted loosely as a matrix mutliplication of blocks. In the analog case it chains blocks in time.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to chain. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator, List[AbstractBlock]]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>ChainBlock</p> <p>Example: <pre><code>from qadence import X, Y, chain\n\nb = chain(X(0), Y(0))\n\n# or use a generator\nb = chain(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def chain(*args: Union[AbstractBlock, Generator, List[AbstractBlock]]) -&gt; ChainBlock:\n    \"\"\"Chain blocks sequentially.\n\n    On digital backends this can be interpreted\n    loosely as a matrix mutliplication of blocks. In the analog case it chains\n    blocks in time.\n\n    Arguments:\n        *args: Blocks to chain. Can also be a generator.\n\n    Returns:\n        ChainBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, chain\n\n    b = chain(X(0), Y(0))\n\n    # or use a generator\n    b = chain(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    # ugly hack to use `AnalogChain` if we are dealing only with analog blocks\n    if len(args) and all(\n        isinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n    ):\n        return analog_chain(*args)  # type: ignore[return-value,arg-type]\n    return _construct(ChainBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.utils.kron","title":"<code>kron(*args)</code>","text":"<p>Stack blocks vertically.</p> <p>On digital backends this can be intepreted loosely as a kronecker product of blocks. In the analog case it executes blocks parallel in time.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to kron. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>KronBlock</p> <p>Example: <pre><code>from qadence import X, Y, kron\n\nb = kron(X(0), Y(1))\n\n# or use a generator\nb = kron(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def kron(*args: Union[AbstractBlock, Generator]) -&gt; KronBlock:\n    \"\"\"Stack blocks vertically.\n\n    On digital backends this can be intepreted\n    loosely as a kronecker product of blocks. In the analog case it executes\n    blocks parallel in time.\n\n    Arguments:\n        *args: Blocks to kron. Can also be a generator.\n\n    Returns:\n        KronBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, kron\n\n    b = kron(X(0), Y(1))\n\n    # or use a generator\n    b = kron(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    # ugly hack to use `AnalogKron` if we are dealing only with analog blocks\n    if len(args) and all(\n        isinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n    ):\n        return analog_kron(*args)  # type: ignore[return-value,arg-type]\n    return _construct(KronBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.utils.add","title":"<code>add(*args)</code>","text":"<p>Sums blocks.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to add. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>AddBlock</code> <p>AddBlock</p> <p>Example: <pre><code>from qadence import X, Y, add\n\nb = add(X(0), Y(0))\n\n# or use a generator\nb = add(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def add(*args: Union[AbstractBlock, Generator]) -&gt; AddBlock:\n    \"\"\"Sums blocks.\n\n    Arguments:\n        *args: Blocks to add. Can also be a generator.\n\n    Returns:\n        AddBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, add\n\n    b = add(X(0), Y(0))\n\n    # or use a generator\n    b = add(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    return _construct(AddBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.AddBlock","title":"<code>AddBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Adds blocks.</p> <p>Constructed via <code>add</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.ChainBlock","title":"<code>ChainBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Chains blocks sequentially.</p> <p>Constructed via <code>chain</code></p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.CompositeBlock","title":"<code>CompositeBlock(tag=None, __array_priority__=1000)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractBlock</code></p> <p>Block which composes multiple blocks into one larger block (which can again be composed).</p> <p>Composite blocks are constructed via <code>chain</code>, <code>kron</code>, and <code>add</code>.</p>"},{"location":"api/blocks/#qadence.blocks.composite.KronBlock","title":"<code>KronBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Stacks blocks horizontally.</p> <p>Constructed via <code>kron</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    if len(blocks) == 0:\n        raise NotImplementedError(\"Empty KronBlocks not supported\")\n\n    qubit_support = QubitSupport()\n    for b in blocks:\n        assert (\n            QubitSupportType.GLOBAL,\n        ) != b.qubit_support, \"Blocks with global support cannot be kron'ed.\"\n        assert qubit_support.is_disjoint(\n            b.qubit_support\n        ), \"Make sure blocks act on distinct qubits!\"\n        qubit_support += b.qubit_support\n\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#converting-blocks-to-matrices","title":"Converting blocks to matrices","text":""},{"location":"api/blocks/#qadence.blocks.block_to_tensor.block_to_tensor","title":"<code>block_to_tensor(block, values={}, qubit_support=None, use_full_support=False, tensor_type=TensorType.DENSE, endianness=Endianness.BIG, device=None)</code>","text":"<p>Convert a block into a torch tensor.</p> PARAMETER DESCRIPTION <code>block</code> <p>The block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>values</code> <p>A optional dict with values for parameters.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>qubit_support</code> <p>The qubit_support of the block.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>use_full_support</code> <p>True infers the total number of qubits.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tensor_type</code> <p>the target tensor type.</p> <p> TYPE: <code>TensorType</code> DEFAULT: <code>DENSE</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n\nblock = hea(2,2)\nprint(block_to_tensor(block))\n\n# In case you have a diagonal observable, you can use\nobs = hamiltonian_factory(2, detuning = Z)\nprint(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n</code></pre> <pre><code>tensor([[[-0.2008+0.3230j, -0.2182-0.7227j, -0.1047+0.1998j, -0.0938+0.4752j],\n         [ 0.2443-0.3459j, -0.1302+0.2333j, -0.7366+0.2874j, -0.1422+0.3224j],\n         [-0.3314-0.5466j, -0.4928-0.3127j, -0.0738+0.0088j, -0.0230-0.4947j],\n         [-0.3654-0.3659j, -0.0407+0.1283j,  0.0824-0.5583j,  0.2571+0.5744j]]],\n       grad_fn=&lt;UnsafeViewBackward0&gt;)\ntensor(indices=tensor([[0, 3],\n                       [0, 3]]),\n       values=tensor([ 2.+0.j, -2.+0.j]),\n       size=(4, 4), nnz=2, layout=torch.sparse_coo)\n</code></pre> </p> Source code in <code>qadence/blocks/block_to_tensor.py</code> <pre><code>def block_to_tensor(\n    block: AbstractBlock,\n    values: dict[str, TNumber | torch.Tensor] = {},\n    qubit_support: tuple | None = None,\n    use_full_support: bool = False,\n    tensor_type: TensorType = TensorType.DENSE,\n    endianness: Endianness = Endianness.BIG,\n    device: torch.device = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Convert a block into a torch tensor.\n\n    Arguments:\n        block (AbstractBlock): The block to convert.\n        values (dict): A optional dict with values for parameters.\n        qubit_support (tuple): The qubit_support of the block.\n        use_full_support (bool): True infers the total number of qubits.\n        tensor_type (TensorType): the target tensor type.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n\n    block = hea(2,2)\n    print(block_to_tensor(block))\n\n    # In case you have a diagonal observable, you can use\n    obs = hamiltonian_factory(2, detuning = Z)\n    print(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n    ```\n    \"\"\"\n    from qadence.blocks import embedding\n\n    (ps, embed) = embedding(block)\n    values = embed(ps, values)\n    if tensor_type == TensorType.DENSE:\n        return _block_to_tensor_embedded(\n            block,\n            values,\n            qubit_support,\n            use_full_support,\n            endianness=endianness,\n            device=device,\n        )\n\n    elif tensor_type == TensorType.SPARSEDIAGONAL:\n        t = block_to_diagonal(block, values, endianness=endianness)\n        indices, values, size = torch.nonzero(t), t[t != 0], len(t)\n        indices = torch.stack((indices.flatten(), indices.flatten()))\n        return torch.sparse_coo_tensor(indices, values, (size, size))\n</code></pre>"},{"location":"api/constructors/","title":"Constructors for common quantum circuits","text":""},{"location":"api/constructors/#qadence.constructors.feature_maps.exp_fourier_feature_map","title":"<code>exp_fourier_feature_map(n_qubits, support=None, param='x', feature_range=None)</code>","text":"<p>Exponential fourier feature map.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the feature</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>name of feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'x'</code> </p> <code>feature_range</code> <p>min and max value of the feature, as floats in a Tuple</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def exp_fourier_feature_map(\n    n_qubits: int,\n    support: tuple[int, ...] = None,\n    param: str = \"x\",\n    feature_range: tuple[float, float] = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Exponential fourier feature map.\n\n    Args:\n        n_qubits: number of qubits in the feature\n        support: qubit support\n        param: name of feature `Parameter`\n        feature_range: min and max value of the feature, as floats in a Tuple\n    \"\"\"\n\n    if feature_range is None:\n        feature_range = (0.0, 2.0**n_qubits)\n\n    support = tuple(range(n_qubits)) if support is None else support\n    hlayer = kron(H(qubit) for qubit in support)\n    rlayer = feature_map(\n        n_qubits,\n        support=support,\n        param=param,\n        op=RZ,\n        fm_type=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.EXP,\n        feature_range=feature_range,\n        target_range=(0.0, 2 * PI),\n    )\n    rlayer.tag = None\n    return tag(chain(hlayer, rlayer), f\"ExpFourierFM({param})\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.feature_maps.feature_map","title":"<code>feature_map(n_qubits, support=None, param='phi', op=RX, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multiplier=None, param_prefix=None)</code>","text":"<p>Construct a feature map of a given type.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Number of qubits the feature map covers. Results in <code>support=range(n_qubits)</code>.</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>Puts one feature-encoding rotation gate on every qubit in <code>support</code>. n_qubits in this case specifies the total overall qubits of the circuit, which may be wider than the support itself, but not narrower.</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>Parameter of the feature map; you can pass a string or Parameter; it will be set as non-trainable (FeatureParameter) regardless.</p> <p> TYPE: <code>Parameter | str</code> DEFAULT: <code>'phi'</code> </p> <code>op</code> <p>Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.</p> <p> TYPE: <code>RotationTypes</code> DEFAULT: <code>RX</code> </p> <code>fm_type</code> <p>Basis set for data encoding; choose from <code>BasisSet.FOURIER</code> for Fourier encoding, or <code>BasisSet.CHEBYSHEV</code> for Chebyshev polynomials of the first kind.</p> <p> TYPE: <code>BasisSet | Callable | str</code> DEFAULT: <code>FOURIER</code> </p> <code>reupload_scaling</code> <p>how the feature map scales the data that is re-uploaded for each qubit. choose from <code>ReuploadScaling</code> enumeration or provide your own function with a single int as input and int or float as output.</p> <p> TYPE: <code>ReuploadScaling | Callable | str</code> DEFAULT: <code>CONSTANT</code> </p> <code>feature_range</code> <p>range of data that the input data provided comes from. Used to map input data to the correct domain of the feature-encoding function.</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>target_range</code> <p>range of data the data encoder assumes as the natural range. For example, in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*PI). Used to map data to the correct domain of the feature-encoding function.</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>multiplier</code> <p>overall multiplier; this is useful for reuploading the feature map serially with different scalings; can be a number or parameter/expression.</p> <p> TYPE: <code>Parameter | TParameter | None</code> DEFAULT: <code>None</code> </p> <code>param_prefix</code> <p>string prefix to create trainable parameters multiplying the feature parameter inside the feature-encoding function. Note that currently this does not take into account the domain of the feature-encoding function.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Example: <pre><code>from qadence import feature_map, BasisSet, ReuploadScaling\n\nfm = feature_map(3, fm_type=BasisSet.FOURIER)\nprint(f\"{fm = }\")\n\nfm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\nprint(f\"{fm = }\")\n\nfm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\nprint(f\"{fm = }\")\n</code></pre> <pre><code>fm = KronBlock(0,1,2) [tag: Constant Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nfm = KronBlock(0,1,2) [tag: Constant Chebyshev FM]\n\u251c\u2500\u2500 RX(0) [params: ['acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['acos(phi)']]\nfm = KronBlock(0,1,2) [tag: Tower Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['1_0*phi']]\n\u251c\u2500\u2500 RX(1) [params: ['2_0*phi']]\n\u2514\u2500\u2500 RX(2) [params: ['3_0*phi']]\n</code></pre> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def feature_map(\n    n_qubits: int,\n    support: tuple[int, ...] | None = None,\n    param: Parameter | str = \"phi\",\n    op: RotationTypes = RX,\n    fm_type: BasisSet | Callable | str = BasisSet.FOURIER,\n    reupload_scaling: ReuploadScaling | Callable | str = ReuploadScaling.CONSTANT,\n    feature_range: tuple[float, float] | None = None,\n    target_range: tuple[float, float] | None = None,\n    multiplier: Parameter | TParameter | None = None,\n    param_prefix: str | None = None,\n) -&gt; KronBlock:\n    \"\"\"Construct a feature map of a given type.\n\n    Arguments:\n        n_qubits: Number of qubits the feature map covers. Results in `support=range(n_qubits)`.\n        support: Puts one feature-encoding rotation gate on every qubit in `support`. n_qubits in\n            this case specifies the total overall qubits of the circuit, which may be wider than the\n            support itself, but not narrower.\n        param: Parameter of the feature map; you can pass a string or Parameter;\n            it will be set as non-trainable (FeatureParameter) regardless.\n        op: Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.\n        fm_type: Basis set for data encoding; choose from `BasisSet.FOURIER` for Fourier\n            encoding, or `BasisSet.CHEBYSHEV` for Chebyshev polynomials of the first kind.\n        reupload_scaling: how the feature map scales the data that is re-uploaded for each qubit.\n            choose from `ReuploadScaling` enumeration or provide your own function with a single\n            int as input and int or float as output.\n        feature_range: range of data that the input data provided comes from. Used to map input data\n            to the correct domain of the feature-encoding function.\n        target_range: range of data the data encoder assumes as the natural range. For example,\n            in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*PI).\n            Used to map data to the correct domain of the feature-encoding function.\n        multiplier: overall multiplier; this is useful for reuploading the feature map serially with\n            different scalings; can be a number or parameter/expression.\n        param_prefix: string prefix to create trainable parameters multiplying the feature parameter\n            inside the feature-encoding function. Note that currently this does not take into\n            account the domain of the feature-encoding function.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import feature_map, BasisSet, ReuploadScaling\n\n    fm = feature_map(3, fm_type=BasisSet.FOURIER)\n    print(f\"{fm = }\")\n\n    fm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\n    print(f\"{fm = }\")\n\n    fm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\n    print(f\"{fm = }\")\n    ```\n    \"\"\"\n\n    # Process input\n    if support is None:\n        support = tuple(range(n_qubits))\n    elif len(support) != n_qubits:\n        raise ValueError(\"Wrong qubit support supplied\")\n\n    if op not in ROTATIONS:\n        raise ValueError(\n            f\"Operation {op} not supported. \"\n            f\"Please provide one from {[rot.__name__ for rot in ROTATIONS]}.\"\n        )\n\n    scaled_fparam = fm_parameter_scaling(\n        fm_type, param, feature_range=feature_range, target_range=target_range\n    )\n\n    transform_func = fm_parameter_func(fm_type)\n\n    basis_tag = fm_type.value if isinstance(fm_type, BasisSet) else str(fm_type)\n    rs_func, rs_tag = fm_reupload_scaling_fn(reupload_scaling)\n\n    # Set overall multiplier\n    multiplier = 1 if multiplier is None else Parameter(multiplier)\n\n    # Build feature map\n    op_list = []\n    fparam = scaled_fparam\n    for i, qubit in enumerate(support):\n        if param_prefix is not None:\n            train_param = VariationalParameter(param_prefix + f\"_{i}\")\n            fparam = train_param * scaled_fparam\n        op_list.append(op(qubit, multiplier * rs_func(i) * transform_func(fparam)))\n    fm = kron(*op_list)\n\n    fm.tag = rs_tag + \" \" + basis_tag + \" FM\"\n\n    return fm\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hea.hea","title":"<code>hea(n_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the Hardware Efficient Ansatz (HEA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the HEA is applied</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy for the ansatz. One of the Strategy variants.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital and DigitalAnalog HEA.</p> <p> TYPE: <code>list</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c. Valid for only for Digital HEA.</p> <p> TYPE: <code>bool</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>SDAQC | Analog: Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The Hardware Efficient Ansatz (HEA) circuit.</p> <p>Examples: <pre><code>from qadence import RZ, RX\nfrom qadence import hea\n\n# create the circuit\nn_qubits, depth = 2, 4\nansatz = hea(\n    n_qubits=n_qubits,\n    depth=depth,\n    strategy=\"sDAQC\",\n    operations=[RZ,RX,RZ]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/constructors/hea.py</code> <pre><code>def hea(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    strategy: Strategy = Strategy.DIGITAL,\n    **strategy_args: Any,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Factory function for the Hardware Efficient Ansatz (HEA).\n\n    Args:\n        n_qubits: number of qubits in the circuit\n        depth: number of layers of the HEA\n        param_prefix: the base name of the variational parameters\n        support: qubit indices where the HEA is applied\n        strategy: Strategy for the ansatz. One of the Strategy variants.\n        **strategy_args: see below\n\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital and DigitalAnalog HEA.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c. Valid for only\n            for Digital HEA.\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - SDAQC | Analog: Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n\n    Returns:\n        The Hardware Efficient Ansatz (HEA) circuit.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import RZ, RX\n    from qadence import hea\n\n    # create the circuit\n    n_qubits, depth = 2, 4\n    ansatz = hea(\n        n_qubits=n_qubits,\n        depth=depth,\n        strategy=\"sDAQC\",\n        operations=[RZ,RX,RZ]\n    )\n    ```\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    hea_func_dict = {\n        Strategy.DIGITAL: hea_digital,\n        Strategy.SDAQC: hea_sDAQC,\n        Strategy.BDAQC: hea_bDAQC,\n        Strategy.ANALOG: hea_analog,\n    }\n\n    try:\n        hea_func = hea_func_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    hea_block: AbstractBlock = hea_func(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        **strategy_args,\n    )  # type: ignore\n\n    return hea_block\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hea.hea_digital","title":"<code>hea_digital(n_qubits, depth=1, param_prefix='theta', support=None, periodic=False, operations=[RX, RY, RX], entangler=CNOT)</code>","text":"<p>Construct the Digital Hardware Efficient Ansatz (HEA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the cricuit.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The digital Hardware Efficient Ansatz (HEA) circuit.</p> Source code in <code>qadence/constructors/hea.py</code> <pre><code>def hea_digital(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    periodic: bool = False,\n    operations: list[type[AbstractBlock]] = [RX, RY, RX],\n    entangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the Digital Hardware Efficient Ansatz (HEA).\n\n    Args:\n        n_qubits (int): number of qubits in the cricuit.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        support (tuple): qubit indices where the HEA is applied.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n\n    Returns:\n        The digital Hardware Efficient Ansatz (HEA) circuit.\n    \"\"\"\n    try:\n        if entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\n            raise ValueError(\n                \"Please provide a valid two-qubit entangler operation for digital HEA.\"\n            )\n    except TypeError:\n        raise ValueError(\"Please provide a valid two-qubit entangler operation for digital HEA.\")\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        periodic=periodic,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n    return tag(chain(*layers), \"HEA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hea.hea_sDAQC","title":"<code>hea_sDAQC(n_qubits, depth=1, param_prefix='theta', support=None, operations=[RX, RY, RX], entangler=None)</code>","text":"<p>Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers.</p> <p>It uses step-wise digital-analog computation.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>entangler</code> <p>Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The step-wise digital-analog Hardware Efficient Ansatz (sDA HEA) circuit.</p> Source code in <code>qadence/constructors/hea.py</code> <pre><code>def hea_sDAQC(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    operations: list[type[AbstractBlock]] = [RX, RY, RX],\n    entangler: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers.\n\n    It uses step-wise digital-analog computation.\n\n    Args:\n        n_qubits (int): number of qubits in the circuit.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        support (tuple): qubit indices where the HEA is applied.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        entangler (AbstractBlock): Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n\n    Returns:\n        The step-wise digital-analog Hardware Efficient Ansatz (sDA HEA) circuit.\n    \"\"\"\n\n    # TODO: Add qubit support\n    if entangler is None:\n        entangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n    try:\n        if not block_is_qubit_hamiltonian(entangler):\n            raise ValueError(\n                \"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n            )\n    except NotImplementedError:\n        raise ValueError(\n            \"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n        )\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_analog(\n        depth=depth,\n        param_prefix=param_prefix,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n    return tag(chain(*layers), \"HEA-sDA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.iia.identity_initialized_ansatz","title":"<code>identity_initialized_ansatz(n_qubits, depth=1, param_prefix='iia', strategy=Strategy.DIGITAL, rotations=[RX, RY], entangler=None, periodic=False)</code>","text":"<p>Identity block for barren plateau mitigation.</p> <p>The initial configuration of this block is equal to an identity unitary but can be trained in the same fashion as other ansatzes, reaching same level of expressivity.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>The base name of the variational parameter. Defaults to \"iia\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'iia'</code> </p> <code>strategy</code> <p>(Strategy) Strategy.DIGITAL for fully digital or Strategy.SDAQC for digital-analog.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>rotations</code> <p>single-qubit rotations with trainable parameters</p> <p> TYPE: <code>list of AbstractBlocks</code> DEFAULT: <code>[RX, RY]</code> </p> <code>entangler</code> <p>For Digital:     2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE.     Controlled rotations will have variational parameters on the rotation angles.     Defaults to CNOT. For Digital-analog:     Hamiltonian generator for the analog entangling layer.     Time parameter is considered variational.     Defaults to a global NN Hamiltonain.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. Valid only for digital.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The identity initialized ansatz circuit.</p> Source code in <code>qadence/constructors/iia.py</code> <pre><code>def identity_initialized_ansatz(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"iia\",\n    strategy: Strategy = Strategy.DIGITAL,\n    rotations: Any = [RX, RY],\n    entangler: Any = None,\n    periodic: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Identity block for barren plateau mitigation.\n\n    The initial configuration of this block is equal to an identity unitary\n    but can be trained in the same fashion as other ansatzes, reaching same level\n    of expressivity.\n\n    Args:\n        n_qubits: number of qubits in the block\n        depth: number of layers of the HEA\n        param_prefix (str):\n            The base name of the variational parameter. Defaults to \"iia\".\n        strategy: (Strategy)\n            Strategy.DIGITAL for fully digital or Strategy.SDAQC for digital-analog.\n        rotations (list of AbstractBlocks):\n            single-qubit rotations with trainable parameters\n        entangler (AbstractBlock):\n            For Digital:\n                2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE.\n                Controlled rotations will have variational parameters on the rotation angles.\n                Defaults to CNOT.\n            For Digital-analog:\n                Hamiltonian generator for the analog entangling layer.\n                Time parameter is considered variational.\n                Defaults to a global NN Hamiltonain.\n        periodic (bool): if the qubits should be linked periodically. Valid only for digital.\n\n    Returns:\n        The identity initialized ansatz circuit.\n    \"\"\"\n    initialized_layers = []\n    for layer in range(depth):\n        alpha = 2 * PI * torch.rand(n_qubits * len(rotations))\n        gamma = torch.zeros(n_qubits)\n        beta = -alpha\n\n        left_rotations = _rotations(\n            n_qubits=n_qubits,\n            layer=layer,\n            side=\"left\",\n            param_str=f\"{param_prefix}_\u03b1\",\n            values=alpha,\n            ops=rotations,\n        )\n\n        if strategy == Strategy.DIGITAL:\n            if entangler is None:\n                entangler = CNOT\n\n            if entangler not in [CNOT, CZ, CRZ, CRY, CRX, CPHASE]:\n                raise ValueError(\n                    \"Please provide a valid two-qubit entangler operation for digital IIA.\"\n                )\n\n            ent_param_prefix = f\"{param_prefix}_\u03b8_ent_\"\n            if not periodic:\n                left_entanglers = [\n                    chain(\n                        _entangler(\n                            control=n,\n                            target=n + 1,\n                            param_str=ent_param_prefix + f\"_{layer}{n}\",\n                            entangler=entangler,\n                        )\n                        for n in range(n_qubits - 1)\n                    )\n                ]\n            else:\n                left_entanglers = [\n                    chain(\n                        _entangler(\n                            control=n,\n                            target=(n + 1) % n_qubits,\n                            param_str=ent_param_prefix + f\"_{layer}{n}\",\n                            entangler=entangler,\n                        )\n                        for n in range(n_qubits)\n                    )\n                ]\n\n        elif strategy == Strategy.SDAQC:\n            if entangler is None:\n                entangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n\n            if not block_is_qubit_hamiltonian(entangler):\n                raise ValueError(\n                    \"Please provide a valid Pauli Hamiltonian generator for digital-analog IIA.\"\n                )\n\n            ent_param_prefix = f\"{param_prefix}_ent_t\"\n\n            left_entanglers = [\n                chain(\n                    _entangler_analog(\n                        param_str=f\"{ent_param_prefix}_{layer}\",\n                        generator=entangler,\n                    )\n                )\n            ]\n\n        else:\n            raise NotImplementedError\n\n        centre_rotations = [\n            kron(\n                RX(\n                    target=n,\n                    parameter=Parameter(name=f\"{param_prefix}_\u03b3\" + f\"_{layer}{n}\", value=gamma[n]),\n                )\n                for n in range(n_qubits)\n            )\n        ]\n\n        right_entanglers = reversed(*left_entanglers)\n\n        right_rotations = _rotations(\n            n_qubits=n_qubits,\n            layer=layer,\n            side=\"right\",\n            param_str=f\"{param_prefix}_\u03b2\",\n            values=beta,\n            ops=rotations,\n        )\n\n        krons = [\n            *left_rotations,\n            *left_entanglers,\n            *centre_rotations,\n            *right_entanglers,\n            *right_rotations,\n        ]\n\n        initialized_layers.append(tag(chain(*krons), tag=f\"BPMA-{layer}\"))\n\n    return chain(*initialized_layers)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.ala.ala","title":"<code>ala(n_qubits, m_block_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the alternating layer ansatz (ala).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit</p> <p> TYPE: <code>int</code> </p> <code>m_block_qubits</code> <p>number of qubits in the local entangling block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the alternating layer ansatz</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the ala is applied</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy for the ansatz. One of the Strategy variants.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital .</p> <p> TYPE: <code>list</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>SDAQC | BDAQC: Hamiltonian generator for the analog entangling     layer. Must be an m-qubit operator where m is the size of the     local entangling block. Defaults to a ZZ interaction.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The Alternating Layer Ansatz (ALA) circuit.</p> Source code in <code>qadence/constructors/ala.py</code> <pre><code>def ala(\n    n_qubits: int,\n    m_block_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    strategy: Strategy = Strategy.DIGITAL,\n    **strategy_args: Any,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Factory function for the alternating layer ansatz (ala).\n\n    Args:\n        n_qubits: number of qubits in the circuit\n        m_block_qubits: number of qubits in the local entangling block\n        depth: number of layers of the alternating layer ansatz\n        param_prefix: the base name of the variational parameters\n        support: qubit indices where the ala is applied\n        strategy: Strategy for the ansatz. One of the Strategy variants.\n        **strategy_args: see below\n\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital .\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - SDAQC | BDAQC: Hamiltonian generator for the analog entangling\n                layer. Must be an m-qubit operator where m is the size of the\n                local entangling block. Defaults to a ZZ interaction.\n\n    Returns:\n        The Alternating Layer Ansatz (ALA) circuit.\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    ala_func_dict = {\n        Strategy.DIGITAL: ala_digital,\n        Strategy.SDAQC: ala_sDAQC,\n        Strategy.BDAQC: ala_bDAQC,\n        Strategy.ANALOG: ala_analog,\n    }\n\n    try:\n        ala_func = ala_func_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    ala_block: AbstractBlock = ala_func(\n        n_qubits=n_qubits,\n        m_block_qubits=m_block_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        **strategy_args,\n    )  # type: ignore\n\n    return ala_block\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.ala.ala_digital","title":"<code>ala_digital(n_qubits, m_block_qubits, depth=1, param_prefix='theta', support=None, operations=[RX, RY], entangler=CNOT)</code>","text":"<p>Construct the digital alternating layer ansatz (ALA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit.</p> <p> TYPE: <code>int</code> </p> <code>m_block_qubits</code> <p>number of qubits in the local entangling block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the ALA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the ALA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY]</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The digital Alternating Layer Ansatz (ALA) circuit.</p> Source code in <code>qadence/constructors/ala.py</code> <pre><code>def ala_digital(\n    n_qubits: int,\n    m_block_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    operations: list[type[AbstractBlock]] = [RX, RY],\n    entangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the digital alternating layer ansatz (ALA).\n\n    Args:\n        n_qubits (int): number of qubits in the circuit.\n        m_block_qubits (int): number of qubits in the local entangling block.\n        depth (int): number of layers of the ALA.\n        param_prefix (str): the base name of the variational parameters\n        support (tuple): qubit indices where the ALA is applied.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n\n    Returns:\n        The digital Alternating Layer Ansatz (ALA) circuit.\n    \"\"\"\n\n    try:\n        if entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\n            raise ValueError(\n                \"Please provide a valid two-qubit entangler operation for digital ALA.\"\n            )\n    except TypeError:\n        raise ValueError(\"Please provide a valid two-qubit entangler operation for digital ALA.\")\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        support=support,\n        param_prefix=param_prefix,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_ala_block_digital(\n        n_qubits,\n        m_block_qubits,\n        param_prefix=param_prefix + \"_ent\",\n        depth=depth,\n        support=support,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n\n    return tag(chain(*layers), \"ALA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig","title":"<code>ObservableConfig(interaction=None, detuning=None, scale=1.0, shift=0.0, trainable_transform=None, tag=None)</code>  <code>dataclass</code>","text":"<p>ObservableConfig is a configuration class for defining the parameters of an observable Hamiltonian.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.detuning","title":"<code>detuning = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Single qubit detuning of the observable Hamiltonian.</p> <p>Accepts single-qubit operator N, X, Y, or Z.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.interaction","title":"<code>interaction = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The type of interaction.</p> Available options from the Interaction enum are <ul> <li>Interaction.ZZ</li> <li>Interaction.NN</li> <li>Interaction.XY</li> <li>Interaction.XYZ</li> </ul> <p>Alternatively, a custom interaction function can be defined.         Example:</p> <pre><code>        def custom_int(i: int, j: int):\n            return X(i) @ X(j) + Y(i) @ Y(j)\n\n        n_qubits = 2\n\n        observable_config = ObservableConfig(interaction=custom_int, scale = 1.0, shift = 0.0)\n        observable = create_observable(register=4, config=observable_config)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.scale","title":"<code>scale = 1.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The scale by which to multiply the output of the observable.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.shift","title":"<code>shift = 0.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The shift to add to the output of the observable.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the observable.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.trainable_transform","title":"<code>trainable_transform = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to have a trainable transformation on the output of the observable.</p> <p>If None, the scale and shift are numbers. If True, the scale and shift are VariationalParameter. If False, the scale and shift are FeatureParameter.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.hamiltonian_factory","title":"<code>hamiltonian_factory(register, interaction=None, detuning=None, interaction_strength=None, detuning_strength=None, random_strength=False, use_all_node_pairs=False)</code>","text":"<p>General Hamiltonian creation function.</p> <p>Can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings, both with arbitrary strength or parameterized.</p> PARAMETER DESCRIPTION <code>register</code> <p>register of qubits with a specific graph topology, or number of qubits. When passing a number of qubits a register with all-to-all connectivity is created.</p> <p> TYPE: <code>Register | int</code> </p> <code>interaction</code> <p>Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.</p> <p> TYPE: <code>Interaction | Callable | None</code> DEFAULT: <code>None</code> </p> <code>detuning</code> <p>single-qubit operator N, X, Y, or Z.</p> <p> TYPE: <code>TDetuning | None</code> DEFAULT: <code>None</code> </p> <code>interaction_strength</code> <p>list of values to be used as the interaction strength for each pair of qubits. Should be ordered following the order of <code>Register(n_qubits).edges</code>. Alternatively, some string \"x\" can be passed, which will create a parameterized interactions for each pair of qubits, each labelled as <code>\"x_ij\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>detuning_strength</code> <p>list of values to be used as the detuning strength for each qubit. Alternatively, some string \"x\" can be passed, which will create a parameterized detuning for each qubit, each labelled as <code>\"x_i\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>random_strength</code> <p>set random interaction and detuning strengths between -1 and 1.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_all_node_pairs</code> <p>computes an interaction term for every pair of nodes in the graph, independent of the edge topology in the register. Useful for defining Hamiltonians where the interaction strength decays with the distance.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>from qadence import hamiltonian_factory, Interaction, Register, Z\n\nn_qubits = 3\n\n# Constant total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n\n# Parameterized total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n\n# Random all-to-all XY Hamiltonian generator:\ngenerator = hamiltonian_factory(\n    n_qubits,\n    interaction = Interaction.XY,\n    random_strength = True,\n    )\n\n# Parameterized NN Hamiltonian generator with a square grid interaction topology:\nregister = Register.square(qubits_side = n_qubits)\ngenerator = hamiltonian_factory(\n    register,\n    interaction = Interaction.NN,\n    interaction_strength = \"theta\"\n    )\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def hamiltonian_factory(\n    register: Register | int,\n    interaction: Interaction | Callable | None = None,\n    detuning: TDetuning | None = None,\n    interaction_strength: TArray | str | None = None,\n    detuning_strength: TArray | str | None = None,\n    random_strength: bool = False,\n    use_all_node_pairs: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    General Hamiltonian creation function.\n\n    Can be used to create Hamiltonians with 2-qubit\n    interactions and single-qubit detunings, both with arbitrary strength or parameterized.\n\n    Arguments:\n        register: register of qubits with a specific graph topology, or number of qubits.\n            When passing a number of qubits a register with all-to-all connectivity\n            is created.\n        interaction: Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.\n        detuning: single-qubit operator N, X, Y, or Z.\n        interaction_strength: list of values to be used as the interaction strength for each\n            pair of qubits. Should be ordered following the order of `Register(n_qubits).edges`.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            interactions for each pair of qubits, each labelled as `\"x_ij\"`.\n        detuning_strength: list of values to be used as the detuning strength for each qubit.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            detuning for each qubit, each labelled as `\"x_i\"`.\n        random_strength: set random interaction and detuning strengths between -1 and 1.\n        use_all_node_pairs: computes an interaction term for every pair of nodes in the graph,\n            independent of the edge topology in the register. Useful for defining Hamiltonians\n            where the interaction strength decays with the distance.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import hamiltonian_factory, Interaction, Register, Z\n\n        n_qubits = 3\n\n        # Constant total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z)\n\n        # Parameterized total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n\n        # Random all-to-all XY Hamiltonian generator:\n        generator = hamiltonian_factory(\n            n_qubits,\n            interaction = Interaction.XY,\n            random_strength = True,\n            )\n\n        # Parameterized NN Hamiltonian generator with a square grid interaction topology:\n        register = Register.square(qubits_side = n_qubits)\n        generator = hamiltonian_factory(\n            register,\n            interaction = Interaction.NN,\n            interaction_strength = \"theta\"\n            )\n        ```\n    \"\"\"\n\n    if interaction is None and detuning is None:\n        raise ValueError(\"Please provide an interaction and/or detuning for the Hamiltonian.\")\n\n    # If number of qubits is given, creates all-to-all register\n    register = Register(register) if isinstance(register, int) else register\n\n    # Get interaction function\n    if interaction is not None:\n        if callable(interaction):\n            int_fn = interaction\n            try:\n                if not block_is_qubit_hamiltonian(interaction(0, 1)):\n                    raise ValueError(\"Custom interactions must be composed of Pauli operators.\")\n            except TypeError:\n                raise TypeError(\n                    \"Please use a custom interaction function signed with two integer parameters.\"\n                )\n        else:\n            int_fn = INTERACTION_DICT.get(interaction, None)  # type: ignore [arg-type]\n            if int_fn is None:\n                raise KeyError(f\"Interaction {interaction} not supported.\")\n\n    # Check single-qubit detuning\n    if (detuning is not None) and (detuning not in DETUNINGS):\n        raise TypeError(f\"Detuning of type {type(detuning)} not supported.\")\n\n    # Pre-process detuning and interaction strengths and update register\n    detuning_strength_array = _preprocess_strengths(\n        register, detuning_strength, \"nodes\", random_strength\n    )\n\n    edge_str = \"all_node_pairs\" if use_all_node_pairs else \"edges\"\n    interaction_strength_array = _preprocess_strengths(\n        register, interaction_strength, edge_str, random_strength\n    )\n\n    # Create single-qubit detunings:\n    single_qubit_terms: List[AbstractBlock] = []\n    if detuning is not None:\n        for strength, node in zip(detuning_strength_array, register.nodes):\n            single_qubit_terms.append(strength * detuning(node))\n\n    # Create two-qubit interactions:\n    two_qubit_terms: List[AbstractBlock] = []\n    edge_data = register.all_node_pairs if use_all_node_pairs else register.edges\n    if interaction is not None and int_fn is not None:\n        for strength, edge in zip(interaction_strength_array, edge_data):\n            two_qubit_terms.append(strength * int_fn(*edge))\n\n    return add(*single_qubit_terms, *two_qubit_terms)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_nn","title":"<code>interaction_nn(i, j)</code>","text":"<p>Ising NN interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_nn(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Ising NN interaction.\"\"\"\n    return N(i) @ N(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_xy","title":"<code>interaction_xy(i, j)</code>","text":"<p>XY interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xy(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"XY interaction.\"\"\"\n    return X(i) @ X(j) + Y(i) @ Y(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_xyz","title":"<code>interaction_xyz(i, j)</code>","text":"<p>Heisenberg XYZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xyz(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Heisenberg XYZ interaction.\"\"\"\n    return X(i) @ X(j) + Y(i) @ Y(j) + Z(i) @ Z(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_zz","title":"<code>interaction_zz(i, j)</code>","text":"<p>Ising ZZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_zz(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Ising ZZ interaction.\"\"\"\n    return Z(i) @ Z(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.qft.qft","title":"<code>qft(n_qubits, support=None, inverse=False, reverse_in=False, swaps_out=False, strategy=Strategy.DIGITAL, gen_build=None)</code>","text":"<p>The Quantum Fourier Transform.</p> <p>Depending on the application, user should be careful with qubit ordering in the input and output. This can be controlled with reverse_in and swaps_out arguments.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the QFT</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support to use</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>inverse</code> <p>True performs the inverse QFT</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reverse_in</code> <p>Reverses the input qubits to account for endianness</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>swaps_out</code> <p>Performs swaps on the output qubits to match the \"textbook\" QFT.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.sDAQC</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>gen_build</code> <p>building block Ising Hamiltonian for the DAQC transform. Defaults to constant all-to-all Ising.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import qft\n\nn_qubits = 3\n\nqft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/qft.py</code> <pre><code>def qft(\n    n_qubits: int,\n    support: tuple[int, ...] = None,\n    inverse: bool = False,\n    reverse_in: bool = False,\n    swaps_out: bool = False,\n    strategy: Strategy = Strategy.DIGITAL,\n    gen_build: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    The Quantum Fourier Transform.\n\n    Depending on the application, user should be careful with qubit ordering\n    in the input and output. This can be controlled with reverse_in and swaps_out\n    arguments.\n\n    Args:\n        n_qubits: number of qubits in the QFT\n        support: qubit support to use\n        inverse: True performs the inverse QFT\n        reverse_in: Reverses the input qubits to account for endianness\n        swaps_out: Performs swaps on the output qubits to match the \"textbook\" QFT.\n        strategy: Strategy.Digital or Strategy.sDAQC\n        gen_build: building block Ising Hamiltonian for the DAQC transform.\n            Defaults to constant all-to-all Ising.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import qft\n\n        n_qubits = 3\n\n        qft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n        ```\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    assert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\n\n    if reverse_in:\n        support = support[::-1]\n\n    qft_layer_dict = {\n        Strategy.DIGITAL: _qft_layer_digital,\n        Strategy.SDAQC: _qft_layer_sDAQC,\n        Strategy.BDAQC: _qft_layer_bDAQC,\n        Strategy.ANALOG: _qft_layer_analog,\n    }\n\n    try:\n        layer_func = qft_layer_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    qft_layers = reversed(range(n_qubits)) if inverse else range(n_qubits)\n\n    qft_circ = chain(\n        layer_func(\n            n_qubits=n_qubits, support=support, layer=layer, inverse=inverse, gen_build=gen_build\n        )  # type: ignore\n        for layer in qft_layers\n    )\n\n    if swaps_out:\n        swap_ops = [SWAP(support[i], support[n_qubits - i - 1]) for i in range(n_qubits // 2)]\n        qft_circ = chain(*swap_ops, qft_circ) if inverse else chain(qft_circ, *swap_ops)\n\n    return tag(qft_circ, tag=\"iQFT\") if inverse else tag(qft_circ, tag=\"QFT\")\n</code></pre>"},{"location":"api/constructors/#hardware-efficient-ansatz-for-rydberg-atom-arrays","title":"Hardware efficient ansatz for Rydberg atom arrays","text":""},{"location":"api/constructors/#qadence.constructors.rydberg_hea.rydberg_hea","title":"<code>rydberg_hea(register, n_layers=1, addressable_detuning=True, addressable_drive=False, tunable_phase=False, additional_prefix=None)</code>","text":"<p>Hardware efficient ansatz for neutral atom (Rydberg) platforms.</p> <p>This constructor implements a variational ansatz which is very close to what is implementable on 2nd generation PASQAL quantum devices. In particular, it implements evolution over a specific Hamiltonian which can be realized on the device. This Hamiltonian contains:</p> <ul> <li> <p>an interaction term given by the standard NN interaction and determined starting     from the positions in the input register: H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c</p> </li> <li> <p>a detuning term which corresponding to a n_i = (1+sigma_i^z)/2 applied to     all the qubits. If the <code>addressable_detuning</code> flag is set to True, the routine     effectively a local n_i = (1+sigma_i^z)/2 term in the     evolved Hamiltonian with a different coefficient for each atom. These     coefficients determine a local addressing pattern for the detuning on a subset     of the qubits. In this routine, the coefficients are variational parameters     and they will therefore be optimized at each optimizer step</p> </li> <li> <p>a drive term which corresponding to a sigma^x evolution operation applied to     all the qubits. If the <code>addressable_drive</code> flag is set to True, the routine     effectively a local sigma_i^x term in the evolved Hamiltonian with a different     coefficient for each atom. These coefficients determine a local addressing pattern     for the drive on a subset of the qubits. In this routine, the coefficients are     variational parameters and they will therefore be optimized at each optimizer step</p> </li> <li> <p>if the <code>tunable_phase</code> flag is set to True, the drive term is modified in the following     way: drive = cos(phi) * sigma^x - sin(phi) * sigma^y     The addressable pattern above is maintained and the phase is considered just as an     additional variational parameter which is optimized with the rest</p> </li> </ul> <p>Notice that, on real devices, the coefficients assigned to each qubit in both the detuning and drive patterns should be non-negative and they should always sum to 1. This is not the case for the implementation in this routine since the coefficients (weights) do not have any constraint. Therefore, this HEA is not completely realizable on neutral atom devices.</p> PARAMETER DESCRIPTION <code>register</code> <p>the input atomic register with Cartesian coordinates.</p> <p> TYPE: <code>Register</code> </p> <code>n_layers</code> <p>number layers in the HEA, each layer includes a drive, detuning and pure interaction pulses whose is a variational parameter</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>addressable_detuning</code> <p>whether to turn on the trainable semi-local addressing pattern on the detuning (n_i terms in the Hamiltonian)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>addressable_drive</code> <p>whether to turn on the trainable semi-local addressing pattern on the drive (sigma_i^x terms in the Hamiltonian)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tunable_phase</code> <p>whether to have a tunable phase to get both sigma^x and sigma^y rotations in the drive term. If False, only a sigma^x term will be included in the drive part of the Hamiltonian generator</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>additional_prefix</code> <p>an additional prefix to attach to the parameter names</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>The Rydberg HEA block</p> Source code in <code>qadence/constructors/rydberg_hea.py</code> <pre><code>def rydberg_hea(\n    register: qd.Register,\n    n_layers: int = 1,\n    addressable_detuning: bool = True,\n    addressable_drive: bool = False,\n    tunable_phase: bool = False,\n    additional_prefix: str = None,\n) -&gt; qd.blocks.ChainBlock:\n    \"\"\"Hardware efficient ansatz for neutral atom (Rydberg) platforms.\n\n    This constructor implements a variational ansatz which is very close to\n    what is implementable on 2nd generation PASQAL quantum devices. In particular,\n    it implements evolution over a specific Hamiltonian which can be realized on\n    the device. This Hamiltonian contains:\n\n    * an interaction term given by the standard NN interaction and determined starting\n        from the positions in the input register: H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n\n    * a detuning term which corresponding to a n_i = (1+sigma_i^z)/2 applied to\n        all the qubits. If the `addressable_detuning` flag is set to True, the routine\n        effectively a local n_i = (1+sigma_i^z)/2 term in the\n        evolved Hamiltonian with a different coefficient for each atom. These\n        coefficients determine a local addressing pattern for the detuning on a subset\n        of the qubits. In this routine, the coefficients are variational parameters\n        and they will therefore be optimized at each optimizer step\n\n    * a drive term which corresponding to a sigma^x evolution operation applied to\n        all the qubits. If the `addressable_drive` flag is set to True, the routine\n        effectively a local sigma_i^x term in the evolved Hamiltonian with a different\n        coefficient for each atom. These coefficients determine a local addressing pattern\n        for the drive on a subset of the qubits. In this routine, the coefficients are\n        variational parameters and they will therefore be optimized at each optimizer step\n\n    * if the `tunable_phase` flag is set to True, the drive term is modified in the following\n        way: drive = cos(phi) * sigma^x - sin(phi) * sigma^y\n        The addressable pattern above is maintained and the phase is considered just as an\n        additional variational parameter which is optimized with the rest\n\n    Notice that, on real devices, the coefficients assigned to each qubit in both the detuning\n    and drive patterns should be non-negative and they should always sum to 1. This is not the\n    case for the implementation in this routine since the coefficients (weights) do not have any\n    constraint. Therefore, this HEA is not completely realizable on neutral atom devices.\n\n    Args:\n        register: the input atomic register with Cartesian coordinates.\n        n_layers: number layers in the HEA, each layer includes a drive, detuning and\n            pure interaction pulses whose is a variational parameter\n        addressable_detuning: whether to turn on the trainable semi-local addressing pattern\n            on the detuning (n_i terms in the Hamiltonian)\n        addressable_drive: whether to turn on the trainable semi-local addressing pattern\n            on the drive (sigma_i^x terms in the Hamiltonian)\n        tunable_phase: whether to have a tunable phase to get both sigma^x and sigma^y rotations\n            in the drive term. If False, only a sigma^x term will be included in the drive part\n            of the Hamiltonian generator\n        additional_prefix: an additional prefix to attach to the parameter names\n\n    Returns:\n        The Rydberg HEA block\n    \"\"\"\n    n_qubits = register.n_qubits\n    prefix = \"\" if additional_prefix is None else \"_\" + additional_prefix\n\n    detunings = None\n    # add a detuning pattern locally addressing the atoms\n    if addressable_detuning:\n        detunings = [qd.VariationalParameter(f\"detmap_{j}\") for j in range(n_qubits)]\n\n    drives = None\n    # add a drive pattern locally addressing the atoms\n    if addressable_drive:\n        drives = [qd.VariationalParameter(f\"drivemap_{j}\") for j in range(n_qubits)]\n\n    phase = None\n    if tunable_phase:\n        phase = qd.VariationalParameter(\"phase\")\n\n    return chain(\n        rydberg_hea_layer(\n            register,\n            VariationalParameter(f\"At{prefix}_{layer}\"),\n            VariationalParameter(f\"Omega{prefix}_{layer}\"),\n            VariationalParameter(f\"wait{prefix}_{layer}\"),\n            detunings=detunings,\n            drives=drives,\n            phase=phase,\n        )\n        for layer in range(n_layers)\n    )\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.rydberg_hea.rydberg_hea_layer","title":"<code>rydberg_hea_layer(register, tevo_drive, tevo_det, tevo_wait, phase=None, detunings=None, drives=None, drive_scaling=1.0)</code>","text":"<p>A single layer of the Rydberg hardware efficient ansatz.</p> PARAMETER DESCRIPTION <code>register</code> <p>the input register with atomic coordinates needed to build the interaction.</p> <p> TYPE: <code>Register</code> </p> <code>tevo_drive</code> <p>a variational parameter for the duration of the drive term of the Hamiltonian generator, including optional semi-local addressing</p> <p> TYPE: <code>Parameter | float</code> </p> <code>tevo_det</code> <p>a variational parameter for the duration of the detuning term of the Hamiltonian generator, including optional semi-local addressing</p> <p> TYPE: <code>Parameter | float</code> </p> <code>tevo_wait</code> <p>a variational parameter for the duration of the waiting time with interaction only</p> <p> TYPE: <code>Parameter | float</code> </p> <code>phase</code> <p>a variational parameter representing the global phase. If None, the global phase is set to 0 which results in a drive term in sigma^x only. Otherwise both sigma^x and sigma^y terms will be present</p> <p> TYPE: <code>Parameter | float | None</code> DEFAULT: <code>None</code> </p> <code>detunings</code> <p>a list of parameters with the weights of the locally addressed detuning terms. These are variational parameters which are tuned by the optimizer</p> <p> TYPE: <code>list[Parameter] | list[float] | None</code> DEFAULT: <code>None</code> </p> <code>drives</code> <p>a list of parameters with the weights of the locally addressed drive terms. These are variational parameters which are tuned by the optimizer</p> <p> TYPE: <code>list[Parameter] | list[float] | None</code> DEFAULT: <code>None</code> </p> <code>drive_scaling</code> <p>a scaling term to be added to the drive Hamiltonian generator</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A block with a single layer of Rydberg HEA</p> Source code in <code>qadence/constructors/rydberg_hea.py</code> <pre><code>def rydberg_hea_layer(\n    register: qd.Register,\n    tevo_drive: Parameter | float,\n    tevo_det: Parameter | float,\n    tevo_wait: Parameter | float,\n    phase: Parameter | float | None = None,\n    detunings: list[Parameter] | list[float] | None = None,\n    drives: list[Parameter] | list[float] | None = None,\n    drive_scaling: float = 1.0,\n) -&gt; ChainBlock:\n    \"\"\"A single layer of the Rydberg hardware efficient ansatz.\n\n    Args:\n        register: the input register with atomic coordinates needed to build the interaction.\n        tevo_drive: a variational parameter for the duration of the drive term of\n            the Hamiltonian generator, including optional semi-local addressing\n        tevo_det: a variational parameter for the duration of the detuning term of the\n            Hamiltonian generator, including optional semi-local addressing\n        tevo_wait: a variational parameter for the duration of the waiting\n            time with interaction only\n        phase: a variational parameter representing the global phase. If None, the\n            global phase is set to 0 which results in a drive term in sigma^x only. Otherwise\n            both sigma^x and sigma^y terms will be present\n        detunings: a list of parameters with the weights of the locally addressed\n            detuning terms. These are variational parameters which are tuned by the optimizer\n        drives: a list of parameters with the weights of the locally addressed\n            drive terms. These are variational parameters which are tuned by the optimizer\n        drive_scaling: a scaling term to be added to the drive Hamiltonian generator\n\n    Returns:\n        A block with a single layer of Rydberg HEA\n    \"\"\"\n    n_qubits = register.n_qubits\n\n    drive_x = _amplitude_map(n_qubits, qd.X, weights=drives)\n    drive_y = _amplitude_map(n_qubits, qd.Y, weights=drives)\n    detuning = _amplitude_map(n_qubits, qd.N, weights=detunings)\n    interaction = hamiltonian_factory(register, qd.Interaction.NN)\n\n    # drive and interaction are not commuting thus they need to be\n    # added directly into the final Hamiltonian generator\n    if phase is not None:\n        generator = (\n            drive_scaling * sympy.cos(phase) * drive_x\n            - drive_scaling * sympy.sin(phase) * drive_y\n            + interaction\n        )\n    else:\n        generator = drive_scaling * drive_x + interaction\n\n    return chain(\n        qd.HamEvo(generator, tevo_drive),\n        # detuning and interaction are commuting, so they\n        # can be ordered arbitrarily and treated separately\n        qd.HamEvo(interaction, tevo_wait),\n        qd.HamEvo(detuning, tevo_det),\n    )\n</code></pre>"},{"location":"api/constructors/#the-daqc-transform","title":"The DAQC Transform","text":""},{"location":"api/constructors/#qadence.constructors.daqc.daqc.daqc_transform","title":"<code>daqc_transform(n_qubits, gen_target, t_f, gen_build=None, zero_tol=1e-08, strategy=Strategy.SDAQC, ignore_global_phases=False)</code>","text":"<p>Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian.</p> <p>The result is another fixed 2-body Hamiltonian.</p> <p>Reference for universality of 2-body Hamiltonians:</p> <p>-- https://arxiv.org/abs/quant-ph/0106064</p> <p>Based on the transformation for Ising (ZZ) interactions, as described in the paper</p> <p>-- https://arxiv.org/abs/1812.03637</p> <p>The transform translates a target weighted generator of the type:</p> <pre><code>`gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>To a circuit using analog evolutions with a fixed building block generator:</p> <pre><code>`gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>where <code>op = Z</code> or <code>op = N</code>.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>total number of qubits to use.</p> <p> TYPE: <code>int</code> </p> <code>gen_target</code> <p>target generator built with the structure above. The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>t_f</code> <p>total time for the gen_target evolution.</p> <p> TYPE: <code>float</code> </p> <code>gen_build</code> <p>fixed generator to act as a building block. Defaults to constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>zero_tol</code> <p>default \"zero\" for a missing interaction. Included for numerical reasons, see notes below.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>strategy</code> <p>sDAQC or bDAQC, following definitions in the reference paper.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>SDAQC</code> </p> <code>ignore_global_phases</code> <p>if <code>True</code> the transform does not correct the global phases coming from the mapping between ZZ and NN interactions.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Notes:</p> <pre><code>The paper follows an index convention of running from 1 to N. A few functions\nhere also use that convention to be consistent with the paper. However, for qadence\nrelated things the indices are converted to [0, N-1].\n\nThe case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\nThere is a workaround for this described in the paper, but it is currently not implemented.\n\nThe current implementation may result in evolution times that are both positive or\nnegative. In practice, both can be represented by simply changing the signs of the\ninteractions. However, for a real implementation where the interactions should remain\nfixed, the paper discusses a workaround that is not currently implemented.\n\nThe transformation works by representing each interaction in the target hamiltonian by\na set of evolutions using the build hamiltonian. As a consequence, some care must be\ntaken when choosing the build hamiltonian. Some cases:\n\n- The target hamiltonian can have any interaction, as long as it is sufficiently\nrepresented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\nis in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\nneeds to be in the build hamiltonian. This is checked when the generators are parsed.\n\n- The build hamiltonian can have any interaction, irrespectively of it being needed\nfor the target hamiltonian. This is especially useful for designing local operations\nthrough the repeated evolution of a \"global\" hamiltonian.\n\n- The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\nAny interaction strength smaller than `zero_tol` in the build hamiltonian will not be\nconsidered, and thus that interaction is missing.\n\n- The various ratios `g_jk / f_jk` will influence the time parameter for the various\nevolution slices, meaning that if there is a big discrepancy in the interaction strength\nfor a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\nevolutions with very large times.\n\n- A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\ntimes smaller than `zero_tol` will not be represented.\n</code></pre> <p>Examples:</p> <pre><code>from qadence import Z, N, daqc_transform\n\nn_qubits = 3\n\ngen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n\ngen_target = 0.1 * (Z(1)@Z(2))\n\nt_f = 2.0\n\ntransformed_circuit = daqc_transform(\n    n_qubits = n_qubits,\n    gen_target = gen_target,\n    t_f = t_f,\n    gen_build = gen_build,\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/daqc/daqc.py</code> <pre><code>def daqc_transform(\n    n_qubits: int,\n    gen_target: AbstractBlock,\n    t_f: float,\n    gen_build: AbstractBlock | None = None,\n    zero_tol: float = 1e-08,\n    strategy: Strategy = Strategy.SDAQC,\n    ignore_global_phases: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian.\n\n    The result is another fixed 2-body Hamiltonian.\n\n    Reference for universality of 2-body Hamiltonians:\n\n    -- https://arxiv.org/abs/quant-ph/0106064\n\n    Based on the transformation for Ising (ZZ) interactions, as described in the paper\n\n    -- https://arxiv.org/abs/1812.03637\n\n    The transform translates a target weighted generator of the type:\n\n        `gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n\n    To a circuit using analog evolutions with a fixed building block generator:\n\n        `gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n\n    where `op = Z` or `op = N`.\n\n    Args:\n        n_qubits: total number of qubits to use.\n        gen_target: target generator built with the structure above. The type\n            of the generator will be automatically evaluated when parsing.\n        t_f (float): total time for the gen_target evolution.\n        gen_build: fixed generator to act as a building block. Defaults to\n            constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type\n            of the generator will be automatically evaluated when parsing.\n        zero_tol: default \"zero\" for a missing interaction. Included for\n            numerical reasons, see notes below.\n        strategy: sDAQC or bDAQC, following definitions in the reference paper.\n        ignore_global_phases: if `True` the transform does not correct the global\n            phases coming from the mapping between ZZ and NN interactions.\n\n    Notes:\n\n        The paper follows an index convention of running from 1 to N. A few functions\n        here also use that convention to be consistent with the paper. However, for qadence\n        related things the indices are converted to [0, N-1].\n\n        The case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\n        There is a workaround for this described in the paper, but it is currently not implemented.\n\n        The current implementation may result in evolution times that are both positive or\n        negative. In practice, both can be represented by simply changing the signs of the\n        interactions. However, for a real implementation where the interactions should remain\n        fixed, the paper discusses a workaround that is not currently implemented.\n\n        The transformation works by representing each interaction in the target hamiltonian by\n        a set of evolutions using the build hamiltonian. As a consequence, some care must be\n        taken when choosing the build hamiltonian. Some cases:\n\n        - The target hamiltonian can have any interaction, as long as it is sufficiently\n        represented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\n        is in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\n        needs to be in the build hamiltonian. This is checked when the generators are parsed.\n\n        - The build hamiltonian can have any interaction, irrespectively of it being needed\n        for the target hamiltonian. This is especially useful for designing local operations\n        through the repeated evolution of a \"global\" hamiltonian.\n\n        - The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\n        Any interaction strength smaller than `zero_tol` in the build hamiltonian will not be\n        considered, and thus that interaction is missing.\n\n        - The various ratios `g_jk / f_jk` will influence the time parameter for the various\n        evolution slices, meaning that if there is a big discrepancy in the interaction strength\n        for a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\n        evolutions with very large times.\n\n        - A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\n        times smaller than `zero_tol` will not be represented.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import Z, N, daqc_transform\n\n        n_qubits = 3\n\n        gen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n\n        gen_target = 0.1 * (Z(1)@Z(2))\n\n        t_f = 2.0\n\n        transformed_circuit = daqc_transform(\n            n_qubits = n_qubits,\n            gen_target = gen_target,\n            t_f = t_f,\n            gen_build = gen_build,\n        )\n        ```\n    \"\"\"\n\n    ##################\n    # Input controls #\n    ##################\n\n    if strategy != Strategy.SDAQC:\n        raise NotImplementedError(\"Currently only the sDAQC transform is implemented.\")\n\n    if n_qubits == 4:\n        raise NotImplementedError(\"DAQC transform 4-qubit edge case not implemented.\")\n\n    if gen_build is None:\n        gen_build = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n\n    try:\n        if (not block_is_qubit_hamiltonian(gen_target)) or (\n            not block_is_qubit_hamiltonian(gen_build)\n        ):\n            raise ValueError(\n                \"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n            )\n    except NotImplementedError:\n        # Happens when block_is_qubit_hamiltonian is called on something that is not a block.\n        raise TypeError(\n            \"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n        )\n\n    #####################\n    # Generator parsing #\n    #####################\n\n    g_jk_target, mat_jk_target, target_type = _parse_generator(n_qubits, gen_target, 0.0)\n    g_jk_build, mat_jk_build, build_type = _parse_generator(n_qubits, gen_build, zero_tol)\n\n    # Get the global phase hamiltonian and single-qubit detuning hamiltonian\n    if build_type == GenDAQC.NN:\n        h_phase_build, h_sq_build = _nn_phase_and_detunings(n_qubits, mat_jk_build)\n\n    if target_type == GenDAQC.NN:\n        h_phase_target, h_sq_target = _nn_phase_and_detunings(n_qubits, mat_jk_target)\n\n    # Time re-scalings\n    if build_type == GenDAQC.ZZ and target_type == GenDAQC.NN:\n        t_star = t_f / 4.0\n    elif build_type == GenDAQC.NN and target_type == GenDAQC.ZZ:\n        t_star = 4.0 * t_f\n    else:\n        t_star = t_f\n\n    # Check if target Hamiltonian can be mapped with the build Hamiltonian\n    assert _check_compatibility(g_jk_target, g_jk_build, zero_tol)\n\n    ##################\n    # DAQC Transform #\n    ##################\n\n    # Section III A of https://arxiv.org/abs/1812.03637:\n\n    # Matrix M for the linear system, exemplified in Table I:\n    matrix_M = _build_matrix_M(n_qubits)\n\n    # Linear system mapping interaction ratios -&gt; evolution times.\n    t_slices = torch.linalg.solve(matrix_M, g_jk_target / g_jk_build) * t_star\n\n    # ZZ-DAQC with ZZ or NN build Hamiltonian\n    daqc_slices = []\n    for m in range(2, n_qubits + 1):\n        for n in range(1, m):\n            alpha = _ix_map(n_qubits, n, m)\n            t = t_slices[alpha - 1]\n            if abs(t) &gt; zero_tol:\n                if abs(t) &gt; (1 / (zero_tol**0.5)):\n                    logger.warning(\n                        \"\"\"\nTransformed circuit with very long evolution time.\nMake sure your target interactions are sufficiently\nrepresented in the build Hamiltonian.\"\"\"\n                    )\n                x_gates = kron(X(n - 1), X(m - 1))\n                analog_evo = HamEvo(gen_build, t)\n                # TODO: Fix repeated X-gates\n                if build_type == GenDAQC.NN:\n                    # Local detuning at each DAQC layer for NN build Hamiltonian\n                    sq_detuning_build = HamEvo(h_sq_build, t)\n                    daqc_slices.append(chain(x_gates, sq_detuning_build, analog_evo, x_gates))\n                elif build_type == GenDAQC.ZZ:\n                    daqc_slices.append(chain(x_gates, analog_evo, x_gates))\n\n    daqc_circuit = chain(*daqc_slices)\n\n    ########################\n    # Phases and Detunings #\n    ########################\n\n    if target_type == GenDAQC.NN:\n        # Local detuning given a NN target Hamiltonian\n        sq_detuning_target = HamEvo(h_sq_target, t_f).dagger()\n        daqc_circuit = chain(sq_detuning_target, daqc_circuit)\n\n    if not ignore_global_phases:\n        if build_type == GenDAQC.NN:\n            # Constant global phase given a NN build Hamiltonian\n            global_phase_build = HamEvo(h_phase_build, t_slices.sum())\n            daqc_circuit = chain(global_phase_build, daqc_circuit)\n\n        if target_type == GenDAQC.NN:\n            # Constant global phase and given a NN target Hamiltonian\n            global_phase_target = HamEvo(h_phase_target, t_f).dagger()\n            daqc_circuit = chain(global_phase_target, daqc_circuit)\n\n    return daqc_circuit\n</code></pre>"},{"location":"api/constructors/#some-utility-functions","title":"Some utility functions","text":""},{"location":"api/constructors/#qadence.constructors.utils.build_idx_fms","title":"<code>build_idx_fms(basis, fm_pauli, multivariate_strategy, n_features, n_qubits, reupload_scaling)</code>","text":"<p>Builds the index feature maps based on the given parameters.</p> PARAMETER DESCRIPTION <code>basis</code> <p>Type of basis chosen for the feature map.</p> <p> TYPE: <code>BasisSet</code> </p> <code>fm_pauli</code> <p>The chosen Pauli rotation type.</p> <p> TYPE: <code>PrimitiveBlock type</code> </p> <code>multivariate_strategy</code> <p>The strategy used for encoding the multivariate feature map.</p> <p> TYPE: <code>MultivariateStrategy</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>reupload_scaling</code> <p>The chosen scaling for the reupload.</p> <p> TYPE: <code>ReuploadScaling</code> </p> RETURNS DESCRIPTION <code>list[KronBlock]</code> <p>List[KronBlock]: The list of index feature maps.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def build_idx_fms(\n    basis: BasisSet,\n    fm_pauli: Type[RY],\n    multivariate_strategy: MultivariateStrategy,\n    n_features: int,\n    n_qubits: int,\n    reupload_scaling: ReuploadScaling,\n) -&gt; list[KronBlock]:\n    \"\"\"Builds the index feature maps based on the given parameters.\n\n    Args:\n        basis (BasisSet): Type of basis chosen for the feature map.\n        fm_pauli (PrimitiveBlock type): The chosen Pauli rotation type.\n        multivariate_strategy (MultivariateStrategy): The strategy used for encoding\n            the multivariate feature map.\n        n_features (int): The number of features.\n        n_qubits (int): The number of qubits.\n        reupload_scaling (ReuploadScaling): The chosen scaling for the reupload.\n\n    Returns:\n        List[KronBlock]: The list of index feature maps.\n    \"\"\"\n    idx_fms = []\n    for i in range(n_features):\n        target_qubits = get_fm_qubits(multivariate_strategy, i, n_qubits, n_features)\n        param = FeatureParameter(f\"x{i}\")\n        block = kron(\n            *[\n                fm_pauli(qubit, generator_prefactor(reupload_scaling, j) * basis_func(basis, param))\n                for j, qubit in enumerate(target_qubits)\n            ]\n        )\n        idx_fm = block\n        idx_fms.append(idx_fm)\n    return idx_fms\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.utils.generator_prefactor","title":"<code>generator_prefactor(reupload_scaling, qubit_index)</code>","text":"<p>Converts a spectrum string, e.g. tower or exponential.</p> <p>The result is the correct generator prefactor.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def generator_prefactor(reupload_scaling: ReuploadScaling, qubit_index: int) -&gt; float | int:\n    \"\"\"Converts a spectrum string, e.g. tower or exponential.\n\n    The result is the correct generator prefactor.\n    \"\"\"\n    conversion_dict: dict[str, float | int] = {\n        ReuploadScaling.CONSTANT: 1,\n        ReuploadScaling.TOWER: qubit_index + 1,\n        ReuploadScaling.EXP: 2 * PI / (2 ** (qubit_index + 1)),\n    }\n    return conversion_dict[reupload_scaling]\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.utils.get_fm_qubits","title":"<code>get_fm_qubits(multivariate_strategy, i, n_qubits, n_features)</code>","text":"<p>Returns the list of target qubits for the given feature map strategy and feature index.</p> PARAMETER DESCRIPTION <code>multivariate_strategy</code> <p>The strategy used for encoding the multivariate feature map.</p> <p> TYPE: <code>MultivariateStrategy</code> </p> <code>i</code> <p>The feature index.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Iterable</code> <p>List[int]: The list of target qubits.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the feature map strategy is not implemented.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def get_fm_qubits(\n    multivariate_strategy: MultivariateStrategy, i: int, n_qubits: int, n_features: int\n) -&gt; Iterable:\n    \"\"\"Returns the list of target qubits for the given feature map strategy and feature index.\n\n    Args:\n        multivariate_strategy (MultivariateStrategy): The strategy used for encoding\n            the multivariate feature map.\n        i (int): The feature index.\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of features.\n\n    Returns:\n        List[int]: The list of target qubits.\n\n    Raises:\n        ValueError: If the feature map strategy is not implemented.\n    \"\"\"\n    if multivariate_strategy == MultivariateStrategy.PARALLEL:\n        n_qubits_per_feature = int(n_qubits / n_features)\n        target_qubits = range(i * n_qubits_per_feature, (i + 1) * n_qubits_per_feature)\n    elif multivariate_strategy == MultivariateStrategy.SERIES:\n        target_qubits = range(0, n_qubits)\n    else:\n        raise ValueError(f\"Multivariate strategy {multivariate_strategy} not implemented.\")\n    return target_qubits\n</code></pre>"},{"location":"api/draw/","title":"Drawing","text":""},{"location":"api/draw/#drawing","title":"Drawing","text":""},{"location":"api/draw/#qadence.draw.display","title":"<code>display(x, qcd=None, layout='LR', theme='light', fill=True, **kwargs)</code>","text":"<p>Display a block, circuit, or quantum model.</p> <p>The <code>kwargs</code> are forwarded to the underlying <code>nx.Graph</code>, so you can e.g. specify the size of the resulting plot via <code>size=\"2,2\"</code> (see examples)</p> PARAMETER DESCRIPTION <code>x</code> <p><code>AbstractBlock</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <p> TYPE: <code>Any</code> </p> <code>qcd</code> <p>Circuit diagram to plot the block into.</p> <p> TYPE: <code>QuantumCircuitDiagram | Cluster | None</code> DEFAULT: <code>None</code> </p> <code>layout</code> <p>Can be either \"LR\" (left-right), or \"TB\" (top-bottom).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'LR'</code> </p> <code>theme</code> <p>Available themes are: [\"light\", \"dark\", \"black\", \"white\"].</p> <p> TYPE: <code>str</code> DEFAULT: <code>'light'</code> </p> <code>fill</code> <p>Whether to fill the passed <code>x</code> with identities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>kwargs</code> <p>Passed on to <code>nx.Graph</code></p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples: <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\ndisplay(b, size=\"1,1\", theme=\"dark\")\n</code></pre> </p> Source code in <code>qadence/draw/__init__.py</code> <pre><code>def display(\n    x: Any,\n    qcd: QuantumCircuitDiagram | Cluster | None = None,\n    layout: str = \"LR\",\n    theme: str = \"light\",\n    fill: bool = True,\n    **kwargs: Any,\n) -&gt; Graph:\n    \"\"\"Display a block, circuit, or quantum model.\n\n    The `kwargs` are forwarded to\n    the underlying `nx.Graph`, so you can e.g. specify the size of the resulting plot via\n    `size=\"2,2\"` (see examples)\n\n    Arguments:\n        x: `AbstractBlock`, `QuantumCircuit`, or `QuantumModel`.\n        qcd: Circuit diagram to plot the block into.\n        layout: Can be either \"LR\" (left-right), or \"TB\" (top-bottom).\n        theme: Available themes are: [\"light\", \"dark\", \"black\", \"white\"].\n        fill: Whether to fill the passed `x` with identities.\n        kwargs: Passed on to `nx.Graph`\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from qadence import X, Y, kron\n    from qadence.draw import display\n\n    b = kron(X(0), Y(1))\n    def display(*args, **kwargs): return args # markdown-exec: hide\n    display(b, size=\"1,1\", theme=\"dark\")\n    ```\n    \"\"\"\n    return make_diagram(x, **kwargs).show()\n</code></pre>"},{"location":"api/draw/#qadence.draw.savefig","title":"<code>savefig(x, filename, *args, **kwargs)</code>","text":"<p>Save a block, circuit, or quantum model to file. Accepts the same args/kwargs as <code>display</code>.</p> PARAMETER DESCRIPTION <code>x</code> <p><code>AbstractBlock</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <p> TYPE: <code>Any</code> </p> <code>filename</code> <p>Should end in svg/png.</p> <p> TYPE: <code>str</code> </p> <code>args</code> <p>Same as in <code>display</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>kwargs</code> <p>Same as in <code>display</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples: <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\nsavefig(b, \"test.svg\", size=\"1,1\", theme=\"dark\")\n</code></pre> </p> Source code in <code>qadence/draw/__init__.py</code> <pre><code>def savefig(x: Any, filename: str, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Save a block, circuit, or quantum model to file. Accepts the same args/kwargs as `display`.\n\n    Arguments:\n        x: `AbstractBlock`, `QuantumCircuit`, or `QuantumModel`.\n        filename: Should end in svg/png.\n        args: Same as in `display`.\n        kwargs: Same as in `display`.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from qadence import X, Y, kron\n    from qadence.draw import display\n\n    b = kron(X(0), Y(1))\n    def savefig(*args, **kwargs): return args # markdown-exec: hide\n    savefig(b, \"test.svg\", size=\"1,1\", theme=\"dark\")\n    ```\n    \"\"\"\n    make_diagram(x, *args, **kwargs).savefig(filename)\n</code></pre>"},{"location":"api/execution/","title":"Execution","text":""},{"location":"api/execution/#qadence.execution.expectation","title":"<code>expectation(x, observable, values=None, state=None, backend=BackendName.PYQTORCH, diff_mode=None, noise=None, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.expectation</code> method.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>observable</code> <p>Observable(s) w.r.t. which the expectation is computed.</p> <p> TYPE: <code>Union[list[AbstractBlock], AbstractBlock]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>Union[dict, None]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>Which differentiation mode to use.</p> <p> TYPE: <code>Union[DiffMode, str, None]</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> <pre><code>from qadence import RX, Z, Register, QuantumCircuit, expectation\n\nreg = Register(1)\nblock = RX(0, 0.5)\nobservable = Z(0)\ncirc = QuantumCircuit(reg, block)\n\n# You can compute the expectation for a\n# QuantumCircuit with a given observable.\nexpectation(circ, observable)\n\n# You can also use only a block.\n# In this case the register is constructed automatically to\n# Register.line(block.n_qubits)\nexpectation(block, observable)\n\n# Or a register and block\nexpectation(reg, block, observable)\n</code></pre> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef expectation(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    observable: Union[list[AbstractBlock], AbstractBlock],\n    values: Union[dict, None] = None,\n    state: Tensor = None,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: Union[DiffMode, str, None] = None,\n    noise: Union[NoiseHandler, None] = None,\n    endianness: Endianness = Endianness.BIG,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n    \"\"\"Convenience wrapper for the `QuantumModel.expectation` method.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        observable: Observable(s) w.r.t. which the expectation is computed.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        diff_mode: Which differentiation mode to use.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n\n    Returns:\n        A wavefunction\n\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import RX, Z, Register, QuantumCircuit, expectation\n\n    reg = Register(1)\n    block = RX(0, 0.5)\n    observable = Z(0)\n    circ = QuantumCircuit(reg, block)\n\n    # You can compute the expectation for a\n    # QuantumCircuit with a given observable.\n    expectation(circ, observable)\n\n    # You can also use only a block.\n    # In this case the register is constructed automatically to\n    # Register.line(block.n_qubits)\n    expectation(block, observable)\n\n    # Or a register and block\n    expectation(reg, block, observable)\n    ```\n    \"\"\"\n\n    raise ValueError(f\"Cannot execute {type(x)}\")\n</code></pre>"},{"location":"api/execution/#qadence.execution.run","title":"<code>run(x, *args, values=None, state=None, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.run</code> method.</p> <p>This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>Union[dict, None]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef run(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    *args: Any,\n    values: Union[dict, None] = None,\n    state: Tensor = None,\n    backend: BackendName = BackendName.PYQTORCH,\n    endianness: Endianness = Endianness.BIG,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n    \"\"\"Convenience wrapper for the `QuantumModel.run` method.\n\n     This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n\n    Returns:\n        A wavefunction\n    \"\"\"\n    raise ValueError(f\"Cannot run {type(x)}\")\n</code></pre>"},{"location":"api/execution/#qadence.execution.sample","title":"<code>sample(x, *args, values=None, state=None, n_shots=100, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, noise=None, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.sample</code> method.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>Union[dict, None]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Union[Tensor, None]</code> DEFAULT: <code>None</code> </p> <code>n_shots</code> <p>Number of shots per element in the batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>noise</code> <p>The noise model to use if any.</p> <p> TYPE: <code>Union[NoiseHandler, None]</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef sample(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    *args: Any,\n    values: Union[dict, None] = None,\n    state: Union[Tensor, None] = None,\n    n_shots: int = 100,\n    backend: BackendName = BackendName.PYQTORCH,\n    endianness: Endianness = Endianness.BIG,\n    noise: Union[NoiseHandler, None] = None,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; list[Counter]:\n    \"\"\"Convenience wrapper for the `QuantumModel.sample` method.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        n_shots: Number of shots per element in the batch.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        noise: The noise model to use if any.\n        configuration: The backend configuration.\n\n    Returns:\n        A list of Counter instances with the sample results\n    \"\"\"\n    raise ValueError(f\"Cannot sample from {type(x)}\")\n</code></pre>"},{"location":"api/ml_tools/","title":"QML tools","text":""},{"location":"api/ml_tools/#ml-tools","title":"ML Tools","text":"<p>This module implements a <code>Trainer</code> class for torch <code>Modules</code> and <code>QuantumModel</code>. It also implements the <code>QNN</code> class and callbacks that can be used with the trainer module.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer","title":"<code>Trainer(model, optimizer, config, loss_fn='mse', train_dataloader=None, val_dataloader=None, test_dataloader=None, optimize_step=optimize_step, max_batches=None)</code>","text":"<p>               Bases: <code>BaseTrainer</code></p> <p>Trainer class to manage and execute training, validation, and testing loops for a model (eg.</p> <p>QNN).</p> <p>This class handles the overall training process, including: - Managing epochs and steps - Handling data loading and batching - Computing and updating gradients - Logging and monitoring training metrics</p> ATTRIBUTE DESCRIPTION <code>current_epoch</code> <p>The current epoch number.</p> <p> TYPE: <code>int</code> </p> <code>global_step</code> <p>The global step across all epochs.</p> <p> TYPE: <code>int</code> </p> Inherited Attributes <p>use_grad (bool): Indicates if gradients are used for optimization. Default is True.</p> <p>model (nn.Module): The neural network model. optimizer (optim.Optimizer | NGOptimizer | None): The optimizer for training. config (TrainConfig): The configuration settings for training. train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data. val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data. test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.</p> <p>optimize_step (Callable): Function for performing an optimization step. loss_fn (Callable): loss function to use.</p> <p>num_training_batches (int): Number of training batches. num_validation_batches (int): Number of validation batches. num_test_batches (int): Number of test batches.</p> <p>state (str): Current state in the training process</p> <p>Default training routine <pre><code>for epoch in max_iter + 1:\n    # Training\n    for batch in train_batches:\n        train model\n    # Validation\n    if val_every % epoch == 0:\n        for batch in val_batches:\n            train model\n</code></pre></p> Notes <ul> <li>In case of InfiniteTensorDataset, number of batches = 1.</li> <li>In case of TensorDataset, number of batches are default.</li> <li>Training is run for max_iter + 1 epochs. Epoch 0 logs untrained model.</li> <li>Please look at the CallbackManager initialize_callbacks method to review the default     logging behavior.</li> </ul> <p>Examples:</p> <pre><code>import torch\nfrom torch.optim import SGD\nfrom qadence import (\n    feature_map,\n    hamiltonian_factory,\n    hea,\n    QNN,\n    QuantumCircuit,\n    TrainConfig,\n    Z,\n)\nfrom qadence.ml_tools.trainer import Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\n\n# Initialize the model\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=2)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\n\n# Set up the optimizer\noptimizer = SGD(model.parameters(), lr=0.001)\n\n# Use TrainConfig for configuring the training process\nconfig = TrainConfig(\n    max_iter=100,\n    print_every=10,\n    write_every=10,\n    checkpoint_every=10,\n    val_every=10\n)\n\n# Create the Trainer instance with TrainConfig\ntrainer = Trainer(\n    model=model,\n    optimizer=optimizer,\n    config=config,\n    loss_fn=\"mse\",\n    optimize_step=optimize_step\n)\n\nbatch_size = 25\nx = torch.linspace(0, 1, 32).reshape(-1, 1)\ny = torch.sin(x)\ntrain_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\nval_loader = to_dataloader(x, y, batch_size=batch_size, infinite=False)\n\n# Train the model\nmodel, optimizer = trainer.fit(train_loader, val_loader)\n</code></pre> <p>This also supports both gradient based and gradient free optimization. The default support is for gradient based optimization.</p> <p>Notes:</p> <ul> <li>set_use_grad() (class level):This method is used to set the global <code>use_grad</code> flag,     controlling whether the trainer uses gradient-based optimization. <pre><code># gradient based\nTrainer.set_use_grad(True)\n\n# gradient free\nTrainer.set_use_grad(False)\n</code></pre></li> <li>Context Managers (instance level):  <code>enable_grad_opt()</code> and <code>disable_grad_opt()</code> are     context managers that temporarily switch the optimization mode for specific code blocks.     This is useful when you want to mix gradient-based and gradient-free optimization     in the same training process. <pre><code># gradient based\nwith trainer.enable_grad_opt(optimizer):\n    trainer.fit()\n\n# gradient free\nwith trainer.disable_grad_opt(ng_optimizer):\n    trainer.fit()\n</code></pre></li> </ul> <p>Examples</p> <p>Gradient based optimization example Usage: <pre><code>from torch import optim\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nTrainer.set_use_grad(True)\ntrainer = Trainer(\n    model=model,\n    optimizer=optimizer,\n    config=config,\n    loss_fn=\"mse\"\n)\ntrainer.fit(train_loader, val_loader)\n</code></pre> or <pre><code>trainer = Trainer(\n    model=model,\n    config=config,\n    loss_fn=\"mse\"\n)\nwith trainer.enable_grad_opt(optimizer):\n    trainer.fit(train_loader, val_loader)\n</code></pre></p> <p>Gradient free optimization example Usage: <pre><code>import nevergrad as ng\nfrom qadence.ml_tools.parameters import num_parameters\nng_optimizer = ng.optimizers.NGOpt(\n                budget=config.max_iter, parametrization= num_parameters(model)\n                )\n\nTrainer.set_use_grad(False)\ntrainer = Trainer(\n    model=model,\n    optimizer=ng_optimizer,\n    config=config,\n    loss_fn=\"mse\"\n)\ntrainer.fit(train_loader, val_loader)\n</code></pre> or <pre><code>import nevergrad as ng\nfrom qadence.ml_tools.parameters import num_parameters\nng_optimizer = ng.optimizers.NGOpt(\n        budget=config.max_iter, parametrization= num_parameters(model)\n        )\n\ntrainer = Trainer(\n    model=model,\n    config=config,\n    loss_fn=\"mse\"\n)\nwith trainer.disable_grad_opt(ng_optimizer):\n    trainer.fit(train_loader, val_loader)\n</code></pre></p> <p>Initializes the Trainer class.</p> PARAMETER DESCRIPTION <code>model</code> <p>The PyTorch model to train.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The optimizer for training.</p> <p> TYPE: <code>Optimizer | Optimizer | None</code> </p> <code>config</code> <p>Training configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>Loss function used for training. If not specified, default mse loss will be used.</p> <p> TYPE: <code>str | Callable</code> DEFAULT: <code>'mse'</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for test data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>optimize_step</code> <p>Function to execute an optimization step.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>optimize_step</code> </p> <code>max_batches</code> <p>Maximum number of batches to process per epoch. This is only valid in case of finite TensorDataset dataloaders. if max_batches is not None, the maximum number of batches used will be min(max_batches, len(dataloader.dataset)) In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def __init__(\n    self,\n    model: nn.Module,\n    optimizer: optim.Optimizer | NGOptimizer | None,\n    config: TrainConfig,\n    loss_fn: str | Callable = \"mse\",\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n    optimize_step: Callable = optimize_step,\n    max_batches: int | None = None,\n):\n    \"\"\"\n    Initializes the Trainer class.\n\n    Args:\n        model (nn.Module): The PyTorch model to train.\n        optimizer (optim.Optimizer | NGOptimizer | None): The optimizer for training.\n        config (TrainConfig): Training configuration object.\n        loss_fn (str | Callable ): Loss function used for training.\n            If not specified, default mse loss will be used.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for test data.\n        optimize_step (Callable): Function to execute an optimization step.\n        max_batches (int | None): Maximum number of batches to process per epoch.\n            This is only valid in case of finite TensorDataset dataloaders.\n            if max_batches is not None, the maximum number of batches used will\n            be min(max_batches, len(dataloader.dataset))\n            In case of InfiniteTensorDataset only 1 batch per epoch is used.\n    \"\"\"\n    super().__init__(\n        model=model,\n        optimizer=optimizer,\n        config=config,\n        loss_fn=loss_fn,\n        optimize_step=optimize_step,\n        train_dataloader=train_dataloader,\n        val_dataloader=val_dataloader,\n        test_dataloader=test_dataloader,\n        max_batches=max_batches,\n    )\n    self.current_epoch: int = 0\n    self.global_step: int = 0\n    self._stop_training: torch.Tensor = torch.tensor(0, dtype=torch.int)\n    self.progress: Progress | None = None\n\n    # Integration with Accelerator:\n    self.accelerator = Accelerator(\n        backend=config.backend,\n        nprocs=config.nprocs,\n        compute_setup=config.compute_setup,\n        dtype=config.dtype,\n        log_setup=config.log_setup,\n    )\n    # Decorate the unbound Trainer.fit method with accelerator.distribute.\n    # We use __get__ to bind the decorated method to the current instance,\n    # ensuring that 'self' is passed only once when self.fit is called.\n    self.fit = self.accelerator.distribute(Trainer.fit).__get__(self, Trainer)  # type: ignore[method-assign]\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.build_optimize_result","title":"<code>build_optimize_result(result)</code>","text":"<p>Builds and stores the optimization result by calculating the average loss and metrics.</p> <p>Result (or loss_metrics) can have multiple formats: - <code>None</code> Indicates no loss or metrics data is provided. - <code>tuple[torch.Tensor, dict[str, Any]]</code> A single tuple containing the loss tensor     and metrics dictionary - at the end of batch. - <code>list[tuple[torch.Tensor, dict[str, Any]]]</code> A list of tuples for     multiple batches. - <code>list[list[tuple[torch.Tensor, dict[str, Any]]]]</code> A list of lists of tuples, where each inner list represents metrics across multiple batches within an epoch.</p> PARAMETER DESCRIPTION <code>result</code> <p>(None |     tuple[torch.Tensor, dict[Any, Any]] |     list[tuple[torch.Tensor, dict[Any, Any]]] |     list[list[tuple[torch.Tensor, dict[Any, Any]]]])         The loss and metrics data, which can have multiple formats</p> <p> TYPE: <code>None | tuple[Tensor, dict[Any, Any]] | list[tuple[Tensor, dict[Any, Any]]] | list[list[tuple[Tensor, dict[Any, Any]]]]</code> </p> RETURNS DESCRIPTION <code>None</code> <p>This method does not return anything. It sets <code>self.opt_result</code> with</p> <p> TYPE: <code>None</code> </p> <code>None</code> <p>the computed average loss and metrics.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def build_optimize_result(\n    self,\n    result: (\n        None\n        | tuple[torch.Tensor, dict[Any, Any]]\n        | list[tuple[torch.Tensor, dict[Any, Any]]]\n        | list[list[tuple[torch.Tensor, dict[Any, Any]]]]\n    ),\n) -&gt; None:\n    \"\"\"\n    Builds and stores the optimization result by calculating the average loss and metrics.\n\n    Result (or loss_metrics) can have multiple formats:\n    - `None` Indicates no loss or metrics data is provided.\n    - `tuple[torch.Tensor, dict[str, Any]]` A single tuple containing the loss tensor\n        and metrics dictionary - at the end of batch.\n    - `list[tuple[torch.Tensor, dict[str, Any]]]` A list of tuples for\n        multiple batches.\n    - `list[list[tuple[torch.Tensor, dict[str, Any]]]]` A list of lists of tuples,\n    where each inner list represents metrics across multiple batches within an epoch.\n\n    Args:\n        result: (None |\n                tuple[torch.Tensor, dict[Any, Any]] |\n                list[tuple[torch.Tensor, dict[Any, Any]]] |\n                list[list[tuple[torch.Tensor, dict[Any, Any]]]])\n                    The loss and metrics data, which can have multiple formats\n\n    Returns:\n        None: This method does not return anything. It sets `self.opt_result` with\n        the computed average loss and metrics.\n    \"\"\"\n    loss_metrics = result\n    if loss_metrics is None:\n        loss = None\n        metrics: dict[Any, Any] = {}\n    elif isinstance(loss_metrics, tuple):\n        # Single tuple case\n        loss, metrics = loss_metrics\n    else:\n        last_epoch: list[tuple[torch.Tensor, dict[Any, Any]]] = []\n        if isinstance(loss_metrics, list):\n            # Check if it's a list of tuples\n            if all(isinstance(item, tuple) for item in loss_metrics):\n                last_epoch = cast(list[tuple[torch.Tensor, dict[Any, Any]]], loss_metrics)\n            # Check if it's a list of lists of tuples\n            elif all(isinstance(item, list) for item in loss_metrics):\n                last_epoch = cast(\n                    list[tuple[torch.Tensor, dict[Any, Any]]],\n                    loss_metrics[-1] if loss_metrics else [],\n                )\n            else:\n                raise ValueError(\n                    \"Invalid format for result: Expected None, tuple, list of tuples,\"\n                    \" or list of lists of tuples.\"\n                )\n\n        if not last_epoch:\n            loss, metrics = None, {}\n        else:\n            # Compute the average loss over the batches\n            loss_tensor = torch.stack([loss_batch for loss_batch, _ in last_epoch])\n            avg_loss = loss_tensor.mean()\n\n            # Collect and average metrics for all batches\n            metric_keys = last_epoch[0][1].keys()\n            metrics_stacked: dict = {key: [] for key in metric_keys}\n\n            for _, metrics_batch in last_epoch:\n                for key in metric_keys:\n                    value = metrics_batch[key]\n                    metrics_stacked[key].append(value)\n\n            avg_metrics = {key: torch.stack(metrics_stacked[key]).mean() for key in metric_keys}\n\n            loss, metrics = avg_loss, avg_metrics\n\n    # Store the optimization result\n    self.opt_result = OptimizeResult(\n        self.current_epoch,\n        self.model,\n        self.optimizer,\n        loss,\n        metrics,\n        rank=self.accelerator.rank,\n        device=self.accelerator.execution.device,\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.fit","title":"<code>fit(train_dataloader=None, val_dataloader=None)</code>","text":"<p>Fits the model using the specified training configuration.</p> <p>The dataloaders can be provided to train on new datasets, or the default dataloaders provided in the trainer will be used.</p> PARAMETER DESCRIPTION <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple[Module, Optimizer]</code> <p>tuple[nn.Module, optim.Optimizer]: The trained model and optimizer.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def fit(\n    self,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; tuple[nn.Module, optim.Optimizer]:\n    \"\"\"\n    Fits the model using the specified training configuration.\n\n    The dataloaders can be provided to train on new datasets, or the default dataloaders\n    provided in the trainer will be used.\n\n    Args:\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n\n    Returns:\n        tuple[nn.Module, optim.Optimizer]: The trained model and optimizer.\n    \"\"\"\n    if train_dataloader is not None:\n        self.train_dataloader = train_dataloader\n    if val_dataloader is not None:\n        self.val_dataloader = val_dataloader\n\n    self._fit_setup()\n    self._train()\n    self._fit_end()\n    self.training_stage = TrainingStage(\"idle\")\n    return self.model, self.optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.get_ic_grad_bounds","title":"<code>get_ic_grad_bounds(eta, epsilons, variation_multiple=20, dataloader=None)</code>","text":"<p>Calculate the bounds on the gradient norm of the loss using Information Content.</p> PARAMETER DESCRIPTION <code>eta</code> <p>The sensitivity IC.</p> <p> TYPE: <code>float</code> </p> <code>epsilons</code> <p>The epsilons to use for thresholds to for discretization of the finite derivatives.</p> <p> TYPE: <code>Tensor</code> </p> <code>variation_multiple</code> <p>The number of sets of variational parameters to generate per each variational parameter. The number of variational parameters required for the statisctiacal analysis scales linearly with the amount of them present in the model. This is that linear factor.</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>dataloader</code> <p>The dataloader for training data. A new dataloader can be provided, or the dataloader provided in the trinaer will be used. In case no dataloaders are provided at either places, it assumes that the model does not require any input data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple[float, float, float]</code> <p>tuple[float, float, float]: The max IC lower bound, max IC upper bound, and sensitivity IC upper bound.</p> <p>Examples:</p> <pre><code>import torch\nfrom torch.optim.adam import Adam\n\nfrom qadence.constructors import ObservableConfig\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig, TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\nfrom qadence.ml_tools.models import QNN\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools.trainer import Trainer\nfrom qadence.operations.primitive import Z\n\nfm_config = FeatureMapConfig(num_features=1)\nansatz_config = AnsatzConfig(depth=4)\nobs_config = ObservableConfig(detuning=Z)\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=obs_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n)\n\noptimizer = Adam(qnn.parameters(), lr=0.001)\n\nbatch_size = 25\nx = torch.linspace(0, 1, 32).reshape(-1, 1)\ny = torch.sin(x)\ntrain_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\ntrain_config = TrainConfig(max_iter=100)\n\ntrainer = Trainer(\n    model=qnn,\n    optimizer=optimizer,\n    config=train_config,\n    loss_fn=\"mse\",\n    train_dataloader=train_loader,\n    optimize_step=optimize_step,\n)\n\n# Perform exploratory landscape analysis with Information Content\nic_sensitivity_threshold = 1e-4\nepsilons = torch.logspace(-2, 2, 10)\n\nmax_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound = (\n    trainer.get_ic_grad_bounds(\n        eta=ic_sensitivity_threshold,\n        epsilons=epsilons,\n    )\n)\n\n# Resume training as usual...\n\ntrainer.fit(train_loader)\n</code></pre> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def get_ic_grad_bounds(\n    self,\n    eta: float,\n    epsilons: torch.Tensor,\n    variation_multiple: int = 20,\n    dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; tuple[float, float, float]:\n    \"\"\"\n    Calculate the bounds on the gradient norm of the loss using Information Content.\n\n    Args:\n        eta (float): The sensitivity IC.\n        epsilons (torch.Tensor): The epsilons to use for thresholds to for discretization of the\n            finite derivatives.\n        variation_multiple (int): The number of sets of variational parameters to generate per\n            each variational parameter. The number of variational parameters required for the\n            statisctiacal analysis scales linearly with the amount of them present in the\n            model. This is that linear factor.\n        dataloader (DataLoader | DictDataLoader | None): The dataloader for training data. A\n            new dataloader can be provided, or the dataloader provided in the trinaer will be\n            used. In case no dataloaders are provided at either places, it assumes that the\n            model does not require any input data.\n\n    Returns:\n        tuple[float, float, float]: The max IC lower bound, max IC upper bound, and sensitivity\n            IC upper bound.\n\n    Examples:\n        ```python\n        import torch\n        from torch.optim.adam import Adam\n\n        from qadence.constructors import ObservableConfig\n        from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig, TrainConfig\n        from qadence.ml_tools.data import to_dataloader\n        from qadence.ml_tools.models import QNN\n        from qadence.ml_tools.optimize_step import optimize_step\n        from qadence.ml_tools.trainer import Trainer\n        from qadence.operations.primitive import Z\n\n        fm_config = FeatureMapConfig(num_features=1)\n        ansatz_config = AnsatzConfig(depth=4)\n        obs_config = ObservableConfig(detuning=Z)\n\n        qnn = QNN.from_configs(\n            register=4,\n            obs_config=obs_config,\n            fm_config=fm_config,\n            ansatz_config=ansatz_config,\n        )\n\n        optimizer = Adam(qnn.parameters(), lr=0.001)\n\n        batch_size = 25\n        x = torch.linspace(0, 1, 32).reshape(-1, 1)\n        y = torch.sin(x)\n        train_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\n        train_config = TrainConfig(max_iter=100)\n\n        trainer = Trainer(\n            model=qnn,\n            optimizer=optimizer,\n            config=train_config,\n            loss_fn=\"mse\",\n            train_dataloader=train_loader,\n            optimize_step=optimize_step,\n        )\n\n        # Perform exploratory landscape analysis with Information Content\n        ic_sensitivity_threshold = 1e-4\n        epsilons = torch.logspace(-2, 2, 10)\n\n        max_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound = (\n            trainer.get_ic_grad_bounds(\n                eta=ic_sensitivity_threshold,\n                epsilons=epsilons,\n            )\n        )\n\n        # Resume training as usual...\n\n        trainer.fit(train_loader)\n        ```\n    \"\"\"\n    if not self._use_grad:\n        logger.warning(\n            \"Gradient norm bounds are only relevant when using a gradient based optimizer. \\\n                Currently the trainer is set to use a gradient-free optimizer.\"\n        )\n\n    dataloader = dataloader if dataloader is not None else self.train_dataloader\n\n    batch = next(iter(self._batch_iter(dataloader, num_batches=1)))\n\n    ic = InformationContent(self.model, self.loss_fn, batch, epsilons)\n\n    max_ic_lower_bound, max_ic_upper_bound = ic.get_grad_norm_bounds_max_IC()\n    sensitivity_ic_upper_bound = ic.get_grad_norm_bounds_sensitivity_IC(eta)\n\n    return max_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_test_batch","title":"<code>run_test_batch(batch)</code>","text":"<p>Runs a single test batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Batch of data from the DataLoader.</p> <p> TYPE: <code>tuple[Tensor, ...]</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, dict[str, Any]]</code> <p>tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"test_batch\")\ndef run_test_batch(\n    self, batch: tuple[torch.Tensor, ...]\n) -&gt; tuple[torch.Tensor, dict[str, Any]]:\n    \"\"\"\n    Runs a single test batch.\n\n    Args:\n        batch (tuple[torch.Tensor, ...]): Batch of data from the DataLoader.\n\n    Returns:\n        tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.\n    \"\"\"\n    with torch.no_grad():\n        loss_metrics = self.loss_fn(self.model, batch)\n    return self._modify_batch_end_loss_metrics(loss_metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_train_batch","title":"<code>run_train_batch(batch)</code>","text":"<p>Runs a single training batch, performing optimization.</p> <p>We use the step function to optimize the model based on use_grad.     use_grad = True entails gradient based optimization, for which we use     optimize_step function.     use_grad = False entails gradient free optimization, for which we use     update_ng_parameters function.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Batch of data from the DataLoader.</p> <p> TYPE: <code>tuple[Tensor, ...]</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, dict[str, Any]]</code> <p>tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch. tuple of (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"train_batch\")\ndef run_train_batch(\n    self, batch: tuple[torch.Tensor, ...]\n) -&gt; tuple[torch.Tensor, dict[str, Any]]:\n    \"\"\"\n    Runs a single training batch, performing optimization.\n\n    We use the step function to optimize the model based on use_grad.\n        use_grad = True entails gradient based optimization, for which we use\n        optimize_step function.\n        use_grad = False entails gradient free optimization, for which we use\n        update_ng_parameters function.\n\n    Args:\n        batch (tuple[torch.Tensor, ...]): Batch of data from the DataLoader.\n\n    Returns:\n        tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.\n            tuple of (loss, metrics)\n    \"\"\"\n\n    if self.use_grad:\n        # Perform gradient-based optimization\n        loss_metrics = self.optimize_step(\n            model=self.model,\n            optimizer=self.optimizer,\n            loss_fn=self.loss_fn,\n            xs=batch,\n            device=self.accelerator.execution.device,\n            dtype=self.accelerator.execution.data_dtype,\n        )\n    else:\n        # Perform optimization using Nevergrad\n        loss, metrics, ng_params = update_ng_parameters(\n            model=self.model,\n            optimizer=self.optimizer,\n            loss_fn=self.loss_fn,\n            data=batch,\n            ng_params=self.ng_params,  # type: ignore[arg-type]\n        )\n        self.ng_params = ng_params\n        loss_metrics = loss, metrics\n\n    return self._modify_batch_end_loss_metrics(loss_metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_training","title":"<code>run_training(dataloader)</code>","text":"<p>Runs the training for a single epoch, iterating over multiple batches.</p> PARAMETER DESCRIPTION <code>dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader</code> </p> RETURNS DESCRIPTION <code>list[tuple[Tensor, dict[str, Any]]]</code> <p>list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch. list                  -&gt; tuples Training Batches      -&gt; (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"train_epoch\")\ndef run_training(self, dataloader: DataLoader) -&gt; list[tuple[torch.Tensor, dict[str, Any]]]:\n    \"\"\"\n    Runs the training for a single epoch, iterating over multiple batches.\n\n    Args:\n        dataloader (DataLoader): DataLoader for training data.\n\n    Returns:\n        list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch.\n            list                  -&gt; tuples\n            Training Batches      -&gt; (loss, metrics)\n    \"\"\"\n    self.model.train()\n    train_epoch_loss_metrics = []\n\n    for batch in self._batch_iter(dataloader, self.num_training_batches):\n        self.on_train_batch_start(batch)\n        train_batch_loss_metrics = self.run_train_batch(batch)\n        if self.config.all_reduce_metrics:\n            train_batch_loss_metrics = self._aggregate_result(train_batch_loss_metrics)\n        train_epoch_loss_metrics.append(train_batch_loss_metrics)\n        self.on_train_batch_end(train_batch_loss_metrics)\n\n    return train_epoch_loss_metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_val_batch","title":"<code>run_val_batch(batch)</code>","text":"<p>Runs a single validation batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Batch of data from the DataLoader.</p> <p> TYPE: <code>tuple[Tensor, ...]</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, dict[str, Any]]</code> <p>tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"val_batch\")\ndef run_val_batch(self, batch: tuple[torch.Tensor, ...]) -&gt; tuple[torch.Tensor, dict[str, Any]]:\n    \"\"\"\n    Runs a single validation batch.\n\n    Args:\n        batch (tuple[torch.Tensor, ...]): Batch of data from the DataLoader.\n\n    Returns:\n        tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.\n    \"\"\"\n    with torch.no_grad():\n        loss_metrics = self.loss_fn(self.model, batch)\n    return self._modify_batch_end_loss_metrics(loss_metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_validation","title":"<code>run_validation(dataloader)</code>","text":"<p>Runs the validation loop for a single epoch, iterating over multiple batches.</p> PARAMETER DESCRIPTION <code>dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader</code> </p> RETURNS DESCRIPTION <code>list[tuple[Tensor, dict[str, Any]]]</code> <p>list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch. list                  -&gt; tuples Validation Batches      -&gt; (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"val_epoch\")\ndef run_validation(self, dataloader: DataLoader) -&gt; list[tuple[torch.Tensor, dict[str, Any]]]:\n    \"\"\"\n    Runs the validation loop for a single epoch, iterating over multiple batches.\n\n    Args:\n        dataloader (DataLoader): DataLoader for validation data.\n\n    Returns:\n        list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch.\n            list                  -&gt; tuples\n            Validation Batches      -&gt; (loss, metrics)\n    \"\"\"\n    self.model.eval()\n    val_epoch_loss_metrics = []\n\n    for batch in self._batch_iter(dataloader, self.num_validation_batches):\n        self.on_val_batch_start(batch)\n        val_batch_loss_metrics = self.run_val_batch(batch)\n        if self.config.all_reduce_metrics:\n            val_batch_loss_metrics = self._aggregate_result(val_batch_loss_metrics)\n        val_epoch_loss_metrics.append(val_batch_loss_metrics)\n        self.on_val_batch_end(val_batch_loss_metrics)\n\n    return val_epoch_loss_metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.stop_training","title":"<code>stop_training()</code>","text":"<p>Helper function to indicate if the training should be stopped.</p> <p>We all_reduce the indicator across all processes to ensure all processes are stopped.</p> Notes <p>self._stop_training indicator indicates if the training should be stopped. 0 is continue. 1 is stop.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def stop_training(self) -&gt; bool:\n    \"\"\"\n    Helper function to indicate if the training should be stopped.\n\n    We all_reduce the indicator across all processes to ensure all processes are stopped.\n\n    Notes:\n        self._stop_training indicator indicates if the training should be stopped.\n        0 is continue. 1 is stop.\n    \"\"\"\n    _stop_training = self.accelerator.all_reduce_dict(\n        {\"indicator\": self._stop_training}, op=\"max\"\n    )\n    return bool(_stop_training[\"indicator\"] &gt; 0)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.test","title":"<code>test(test_dataloader=None)</code>","text":"<p>Runs the testing loop if a test DataLoader is provided.</p> <p>if the test_dataloader is not provided, default test_dataloader defined in the Trainer class is used.</p> PARAMETER DESCRIPTION <code>test_dataloader</code> <p>DataLoader for test data.</p> <p> TYPE: <code>DataLoader</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[tuple[Tensor, dict[str, Any]]]</code> <p>list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch. list                    -&gt; tuples Test Batches            -&gt; (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def test(self, test_dataloader: DataLoader = None) -&gt; list[tuple[torch.Tensor, dict[str, Any]]]:\n    \"\"\"\n    Runs the testing loop if a test DataLoader is provided.\n\n    if the test_dataloader is not provided, default test_dataloader defined\n    in the Trainer class is used.\n\n    Args:\n        test_dataloader (DataLoader): DataLoader for test data.\n\n    Returns:\n        list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch.\n            list                    -&gt; tuples\n            Test Batches            -&gt; (loss, metrics)\n    \"\"\"\n    if test_dataloader is not None:\n        self.test_dataloader = test_dataloader\n\n    self.model.eval()\n    test_loss_metrics = []\n\n    for batch in self._batch_iter(test_dataloader, self.num_training_batches):\n        self.on_test_batch_start(batch)\n        loss_metrics = self.run_test_batch(batch)\n        test_loss_metrics.append(loss_metrics)\n        self.on_test_batch_end(loss_metrics)\n\n    return test_loss_metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig","title":"<code>AnsatzConfig(depth=1, ansatz_type=AnsatzType.HEA, ansatz_strategy=Strategy.DIGITAL, strategy_args=dict(), m_block_qubits=None, param_prefix='theta', tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.ansatz_strategy","title":"<code>ansatz_strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ansatz strategy.</p> <p><code>Strategy.DIGITAL</code> for fully digital ansatz. Required if <code>ansatz_type</code> is <code>AnsatzType.ALA</code>. <code>Strategy.SDAQC</code> for analog entangling block. Only available for <code>AnsatzType.HEA</code> or <code>AnsatzType.ALA</code>. <code>Strategy.RYDBERG</code> for fully rydberg hea ansatz. Only available for <code>AnsatzType.HEA</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.ansatz_type","title":"<code>ansatz_type = AnsatzType.HEA</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>What type of ansatz.</p> <p><code>AnsatzType.HEA</code> for Hardware Efficient Ansatz. <code>AnsatzType.IIA</code> for Identity Intialized Ansatz. <code>AnsatzType.ALA</code> for Alternating Layer Ansatz.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.depth","title":"<code>depth = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of layers of the ansatz.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.m_block_qubits","title":"<code>m_block_qubits = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The number of qubits in the local entangling block of an Alternating Layer Ansatz (ALA).</p> <p>Only used when <code>ansatz_type</code> is <code>AnsatzType.ALA</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.param_prefix","title":"<code>param_prefix = 'theta'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The base bame of the variational parameter.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.strategy_args","title":"<code>strategy_args = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A dictionary containing keyword arguments to the function creating the ansatz.</p> <p>Details about each below.</p> <p>For <code>Strategy.DIGITAL</code> strategy, accepts the following:     periodic (bool): if the qubits should be linked periodically.         periodic=False is not supported in emu-c.     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): 2-qubit entangling operation.         Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlld rotations         will have variational parameters on the rotation angles.         Defaults to CNOT</p> <p>For <code>Strategy.SDAQC</code> strategy, accepts the following:     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): Hamiltonian generator for the         analog entangling layer. Time parameter is considered variational.         Defaults to NN interaction.</p> <p>For <code>Strategy.RYDBERG</code> strategy, accepts the following:     addressable_detuning: whether to turn on the trainable semi-local addressing pattern         on the detuning (n_i terms in the Hamiltonian).         Defaults to True.     addressable_drive: whether to turn on the trainable semi-local addressing pattern         on the drive (sigma_i^x terms in the Hamiltonian).         Defaults to False.     tunable_phase: whether to have a tunable phase to get both sigma^x and sigma^y rotations         in the drive term. If False, only a sigma^x term will be included in the drive part         of the Hamiltonian generator.         Defaults to False.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the ansatz.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig","title":"<code>FeatureMapConfig(num_features=0, basis_set=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multivariate_strategy=MultivariateStrategy.PARALLEL, feature_map_strategy=Strategy.DIGITAL, param_prefix=None, num_repeats=0, operation=None, inputs=None, tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.basis_set","title":"<code>basis_set = BasisSet.FOURIER</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basis set for feature encoding.</p> <p>Takes qadence.BasisSet. Give a single BasisSet to use the same for all features. Give a dict of (str, BasisSet) where the key is the name of the variable and the value is the BasisSet to use for encoding that feature. BasisSet.FOURIER for Fourier encoding. BasisSet.CHEBYSHEV for Chebyshev encoding.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.feature_map_strategy","title":"<code>feature_map_strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Strategy for feature map.</p> <p>Accepts DIGITAL, ANALOG or RYDBERG. Defaults to DIGITAL. If the strategy is incompatible with the <code>operation</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.feature_range","title":"<code>feature_range = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data that the input data is assumed to come from.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the feature range to use for that feature.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.inputs","title":"<code>inputs = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List that indicates the order of variables of the tensors that are passed.</p> <p>Optional if a single feature is being encoded, required otherwise. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.multivariate_strategy","title":"<code>multivariate_strategy = MultivariateStrategy.PARALLEL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The encoding strategy in case of multi-variate function.</p> <p>Takes qadence.MultivariateStrategy. If PARALLEL, the features are encoded in one block of rotation gates with the register being split in sub-registers for each feature. If SERIES, the features are encoded sequentially using the full register for each feature, with an ansatz block between them. PARALLEL is allowed only for DIGITAL <code>feature_map_strategy</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.num_features","title":"<code>num_features = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature parameters to be encoded.</p> <p>Defaults to 0. Thus, no feature parameters are encoded.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.num_repeats","title":"<code>num_repeats = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature map layers repeated in the data reuploading step.</p> <p>If all features are to be repeated the same number of times, then can give a single <code>int</code>. For different number of repetitions for each feature, provide a dict of (str, int) where the key is the name of the variable and the value is the number of repetitions for that feature. This amounts to the number of additional reuploads. So if <code>num_repeats</code> is N, the data gets uploaded N+1 times. Defaults to no repetition.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.operation","title":"<code>operation = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of operation.</p> <p>Choose among the analog or digital rotations or a custom callable function returning an AnalogBlock instance. If the type of operation is incompatible with the <code>strategy</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.param_prefix","title":"<code>param_prefix = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String prefix to create trainable parameters in Feature Map.</p> <p>A string prefix to create trainable parameters multiplying the feature parameter inside the feature-encoding function. Note that currently this does not take into account the domain of the feature-encoding function. Defaults to <code>None</code> and thus, the feature map is not trainable. Note that this is separate from the name of the parameter. The user can provide a single prefix for all features, and it will be appended by appropriate feature name automatically.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.reupload_scaling","title":"<code>reupload_scaling = ReuploadScaling.CONSTANT</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Scaling for encoding the same feature on different qubits.</p> <p>Scaling used to encode the same feature on different qubits in the same layer of the feature maps. Takes qadence.ReuploadScaling. Give a single ReuploadScaling to use the same for all features. Give a dict of (str, ReuploadScaling) where the key is the name of the variable and the value is the ReuploadScaling to use for encoding that feature. ReuploadScaling.CONSTANT for constant scaling. ReuploadScaling.TOWER for linearly increasing scaling. ReuploadScaling.EXP for exponentially increasing scaling.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the feature map.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.target_range","title":"<code>target_range = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data the data encoder assumes as natural range.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the target range to use for that feature.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig","title":"<code>TrainConfig(max_iter=10000, print_every=0, write_every=0, checkpoint_every=0, plot_every=0, callbacks=lambda: list()(), log_model=False, root_folder=Path('./qml_logs'), create_subfolder_per_run=False, log_folder=Path('./'), checkpoint_best_only=False, val_every=0, val_epsilon=1e-05, validation_criterion=None, trainstop_criterion=None, batch_size=1, verbose=True, tracking_tool=ExperimentTrackingTool.TENSORBOARD, hyperparams=dict(), plotting_functions=tuple(), _subfolders=list(), nprocs=1, compute_setup='cpu', backend='gloo', log_setup='cpu', dtype=None, all_reduce_metrics=False)</code>  <code>dataclass</code>","text":"<p>Default configuration for the training process.</p> <p>This class provides default settings for various aspects of the training loop, such as logging, checkpointing, and validation. The default values for these fields can be customized when an instance of <code>TrainConfig</code> is created.</p> <p>Example: <pre><code>from qadence.ml_tools import TrainConfig\nc = TrainConfig(root_folder=\"/tmp/train\")\n</code></pre> <pre><code>TrainConfig(max_iter=10000, print_every=0, write_every=0, checkpoint_every=0, plot_every=0, callbacks=[], log_model=False, root_folder='/tmp/train', create_subfolder_per_run=False, log_folder=PosixPath('.'), checkpoint_best_only=False, val_every=0, val_epsilon=1e-05, validation_criterion=None, trainstop_criterion=None, batch_size=1, verbose=True, tracking_tool=&lt;ExperimentTrackingTool.TENSORBOARD: 'tensorboard'&gt;, hyperparams={}, plotting_functions=(), _subfolders=[], nprocs=1, compute_setup='cpu', backend='gloo', log_setup='cpu', dtype=None, all_reduce_metrics=False)\n</code></pre> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.all_reduce_metrics","title":"<code>all_reduce_metrics = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to aggregate metrics (e.g., loss, accuracy) across processes.</p> <p>When True, metrics from different training processes are averaged to provide a consolidated metrics. Note: Since aggregation requires synchronization/all_reduce operation, this can increase the  computation time significantly.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.backend","title":"<code>backend = 'gloo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Backend used for distributed training communication.</p> <p>The default is \"gloo\". Other options may include \"nccl\" - which is optimized for GPU-based training or \"mpi\", depending on your system and requirements. It should be one of the backends supported by <code>torch.distributed</code>. For further details, please look at torch backends</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.batch_size","title":"<code>batch_size = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The batch size to use when processing a list or tuple of torch.Tensors.</p> <p>This specifies how many samples are processed in each training iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.callbacks","title":"<code>callbacks = field(default_factory=lambda: list())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of callbacks to execute during training.</p> <p>Callbacks can be used for custom behaviors, such as early stopping, custom logging, or other actions triggered at specific events.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_best_only","title":"<code>checkpoint_best_only = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If <code>True</code>, checkpoints are only saved if there is an improvement in the.</p> <p>validation metric. This conserves storage by only keeping the best models.</p> <p>validation_criterion is required when this is set to True.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_every","title":"<code>checkpoint_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for saving model and optimizer checkpoints during training.</p> <p>Set to 0 to disable checkpointing. This helps in resuming training or recovering models. Note that setting checkpoint_best_only = True will disable this and only best checkpoints will be saved.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.compute_setup","title":"<code>compute_setup = 'cpu'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute device setup; options are \"auto\", \"gpu\", or \"cpu\".</p> <ul> <li>\"auto\": Automatically uses GPU if available; otherwise, falls back to CPU.</li> <li>\"gpu\": Forces GPU usage, raising an error if no CUDA device is available.</li> <li>\"cpu\": Forces the use of CPU regardless of GPU availability.</li> </ul>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.create_subfolder_per_run","title":"<code>create_subfolder_per_run = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to create a subfolder for each run, named <code>&lt;id&gt;_&lt;timestamp&gt;_&lt;PID&gt;</code>.</p> <p>This ensures logs and checkpoints from different runs do not overwrite each other, which is helpful for rapid prototyping. If <code>False</code>, training will resume from the latest checkpoint if one exists in the specified log folder.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.dtype","title":"<code>dtype = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Data type (precision) for computations.</p> <p>Both model parameters, and dataset will be of the provided precision.</p> <p>If not specified or None, the default torch precision (usually torch.float32) is used. If provided dtype is torch.complex128, model parameters will be torch.complex128, and data parameters will be torch.float64</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.hyperparams","title":"<code>hyperparams = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A dictionary of hyperparameters to be tracked.</p> <p>This can include learning rates, regularization parameters, or any other training-related configurations.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.log_folder","title":"<code>log_folder = Path('./')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The log folder for saving checkpoints and tensorboard logs.</p> <p>This stores the path where all logs and checkpoints are being saved for this training session. <code>log_folder</code> takes precedence over <code>root_folder</code>, but it is ignored if <code>create_subfolders_per_run=True</code> (in which case, subfolders will be spawned in the root folder).</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.log_model","title":"<code>log_model = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to log a serialized version of the model.</p> <p>When set to <code>True</code>, the model's state will be logged, useful for model versioning and reproducibility.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.log_setup","title":"<code>log_setup = 'cpu'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Logging device setup; options are \"auto\" or \"cpu\".</p> <ul> <li>\"auto\": Uses the same device for logging as for computation.</li> <li>\"cpu\": Forces logging to occur on the CPU. This can be useful to avoid potential conflicts with GPU processes.</li> </ul>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.max_iter","title":"<code>max_iter = 10000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of training iterations (epochs) to perform.</p> <p>This defines the total number of times the model will be updated.</p> <p>In case of InfiniteTensorDataset, each epoch will have 1 batch. In case of TensorDataset, each epoch will have len(dataloader) batches.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.nprocs","title":"<code>nprocs = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The number of processes to use for training when spawning subprocesses.</p> <p>For effective parallel processing, set this to a value greater than 1. - In case of Multi-GPU or Multi-Node-Multi-GPU setups, nprocs should be equal to the total number of GPUs across all nodes (world size), or total number of GPU to be used.</p> <p>If nprocs &gt; 1, multiple processes will be spawned for training. The training framework will launch additional processes (e.g., for distributed or parallel training). - For CPU setup, this will launch a true parallel processes - For GPU setup, this will launch a distributed training routine. This uses the DistributedDataParallel framework from PyTorch.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.plot_every","title":"<code>plot_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for generating and saving figures during training.</p> <p>Set to 0 to disable plotting.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.plotting_functions","title":"<code>plotting_functions = field(default_factory=tuple)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Functions used for in-training plotting.</p> <p>These are called to generate plots that are logged or saved at specified intervals.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.print_every","title":"<code>print_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for printing loss and metrics to the console during training.</p> <p>Set to 0 to disable this output, meaning that metrics and loss will not be printed during training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.root_folder","title":"<code>root_folder = Path('./qml_logs')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The root folder for saving checkpoints and tensorboard logs.</p> <p>The default path is \"./qml_logs\"</p> <p>This can be set to a specific directory where training artifacts are to be stored. Checkpoints will be saved inside a subfolder in this directory. Subfolders will be created based on <code>create_subfolder_per_run</code> argument.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.tracking_tool","title":"<code>tracking_tool = ExperimentTrackingTool.TENSORBOARD</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The tool used for tracking training progress and logging metrics.</p> <p>Options include tools like TensorBoard, which help visualize and monitor model training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.trainstop_criterion","title":"<code>trainstop_criterion = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A function to determine if the training process should stop based on a.</p> <p>specific stopping metric. If <code>None</code>, training continues until <code>max_iter</code> is reached.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.val_epsilon","title":"<code>val_epsilon = 1e-05</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A small safety margin used to compare the current validation loss with the.</p> <p>best previous validation loss. This is used to determine improvements in metrics.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.val_every","title":"<code>val_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for performing validation.</p> <p>If set to 0, validation is not performed. Note that metrics from validation are always written, regardless of the <code>write_every</code> setting. Note that initial validation happens at the start of training (when val_every &gt; 0)     For initial validation  - initial metrics are written.                             - checkpoint is saved (when checkpoint_best_only = False)</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.validation_criterion","title":"<code>validation_criterion = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A function to evaluate whether a given validation metric meets a desired condition.</p> <p>The validation_criterion has the following format: def validation_criterion(val_loss: float, best_val_loss: float, val_epsilon: float) -&gt; bool:     # process</p> <p>If <code>None</code>, no custom validation criterion is applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.verbose","title":"<code>verbose = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to print metrics and status messages during training.</p> <p>If <code>True</code>, detailed metrics and status updates will be displayed in the console.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.write_every","title":"<code>write_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for writing loss and metrics using the tracking tool during training.</p> <p>Set to 0 to disable this logging, which prevents metrics from being logged to the tracking tool. Note that the metrics will always be written at the end of training regardless of this setting.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.get_parameters","title":"<code>get_parameters(model)</code>","text":"<p>Retrieve all trainable model parameters in a single vector.</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a 1-dimensional tensor with the parameters</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def get_parameters(model: Module) -&gt; Tensor:\n    \"\"\"Retrieve all trainable model parameters in a single vector.\n\n    Args:\n        model (Module): the input PyTorch model\n\n    Returns:\n        Tensor: a 1-dimensional tensor with the parameters\n    \"\"\"\n    ps = [p.reshape(-1) for p in model.parameters() if p.requires_grad]\n    return torch.concat(ps)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.num_parameters","title":"<code>num_parameters(model)</code>","text":"<p>Return the total number of parameters of the given model.</p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def num_parameters(model: Module) -&gt; int:\n    \"\"\"Return the total number of parameters of the given model.\"\"\"\n    return len(get_parameters(model))\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.set_parameters","title":"<code>set_parameters(model, theta)</code>","text":"<p>Set all trainable parameters of a model from a single vector.</p> <p>Notice that this function assumes prior knowledge of right number of parameters in the model</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> <code>theta</code> <p>the parameters to assign</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def set_parameters(model: Module, theta: Tensor) -&gt; None:\n    \"\"\"Set all trainable parameters of a model from a single vector.\n\n    Notice that this function assumes prior knowledge of right number\n    of parameters in the model\n\n    Args:\n        model (Module): the input PyTorch model\n        theta (Tensor): the parameters to assign\n    \"\"\"\n\n    with torch.no_grad():\n        idx = 0\n        for ps in model.parameters():\n            if ps.requires_grad:\n                n = torch.numel(ps)\n                if ps.ndim == 0:\n                    ps[()] = theta[idx : idx + n]\n                else:\n                    ps[:] = theta[idx : idx + n].reshape(ps.size())\n                idx += n\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.optimize_step.optimize_step","title":"<code>optimize_step(model, optimizer, loss_fn, xs, device=None, dtype=None)</code>","text":"<p>Default Torch optimize step with closure.</p> <p>This is the default optimization step.</p> PARAMETER DESCRIPTION <code>model</code> <p>The input model to be optimized.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The chosen Torch optimizer.</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function that returns the loss value and a dictionary of metrics.</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>The input data. If None, it means the given model does not require any input data.</p> <p> TYPE: <code>dict | list | Tensor | None</code> </p> <code>device</code> <p>A target device to run computations on.</p> <p> TYPE: <code>device</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Data type for <code>xs</code> conversion.</p> <p> TYPE: <code>dtype</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor | float, dict | None]</code> <p>tuple[Tensor | float, dict | None]: A tuple containing the computed loss value and a dictionary with collected metrics.</p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def optimize_step(\n    model: Module,\n    optimizer: Optimizer,\n    loss_fn: Callable,\n    xs: dict | list | torch.Tensor | None,\n    device: torch.device = None,\n    dtype: torch.dtype = None,\n) -&gt; tuple[torch.Tensor | float, dict | None]:\n    \"\"\"Default Torch optimize step with closure.\n\n    This is the default optimization step.\n\n    Args:\n        model (Module): The input model to be optimized.\n        optimizer (Optimizer): The chosen Torch optimizer.\n        loss_fn (Callable): A custom loss function\n            that returns the loss value and a dictionary of metrics.\n        xs (dict | list | Tensor | None): The input data. If None, it means\n            the given model does not require any input data.\n        device (torch.device): A target device to run computations on.\n        dtype (torch.dtype): Data type for `xs` conversion.\n\n    Returns:\n        tuple[Tensor | float, dict | None]: A tuple containing the computed loss value\n            and a dictionary with collected metrics.\n    \"\"\"\n\n    loss, metrics = None, {}\n\n    def closure() -&gt; Any:\n        # NOTE: We need the nonlocal as we can't return a metric dict and\n        # because e.g. LBFGS calls this closure multiple times but for some\n        # reason the returned loss is always the first one...\n        nonlocal metrics, loss\n        optimizer.zero_grad()\n        loss, metrics = loss_fn(model, xs)\n        loss.backward(retain_graph=True)\n        return loss.item()\n\n    optimizer.step(closure)\n    # return the loss/metrics that are being mutated inside the closure...\n    return loss, metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.optimize_step.update_ng_parameters","title":"<code>update_ng_parameters(model, optimizer, loss_fn, data, ng_params)</code>","text":"<p>Update the model parameters using Nevergrad.</p> <p>This function integrates Nevergrad for derivative-free optimization.</p> PARAMETER DESCRIPTION <code>model</code> <p>The PyTorch model to be optimized.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>A Nevergrad optimizer instance.</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function that returns the loss value and a dictionary of metrics.</p> <p> TYPE: <code>Callable[[Module, Tensor | None], tuple[float, dict]]</code> </p> <code>data</code> <p>Input data for the model. If None, it means the model does not require input data.</p> <p> TYPE: <code>Tensor | None</code> </p> <code>ng_params</code> <p>The current set of parameters managed by Nevergrad.</p> <p> TYPE: <code>Array</code> </p> RETURNS DESCRIPTION <code>tuple[float, dict, Array]</code> <p>tuple[float, dict, ng.p.Array]: A tuple containing the computed loss value, a dictionary of metrics, and the updated Nevergrad parameters.</p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def update_ng_parameters(\n    model: Module,\n    optimizer: ng.optimizers.Optimizer,\n    loss_fn: Callable[[Module, torch.Tensor | None], tuple[float, dict]],\n    data: torch.Tensor | None,\n    ng_params: ng.p.Array,\n) -&gt; tuple[float, dict, ng.p.Array]:\n    \"\"\"Update the model parameters using Nevergrad.\n\n    This function integrates Nevergrad for derivative-free optimization.\n\n    Args:\n        model (Module): The PyTorch model to be optimized.\n        optimizer (ng.optimizers.Optimizer): A Nevergrad optimizer instance.\n        loss_fn (Callable[[Module, Tensor | None], tuple[float, dict]]): A custom loss function\n            that returns the loss value and a dictionary of metrics.\n        data (Tensor | None): Input data for the model. If None, it means the model does\n            not require input data.\n        ng_params (ng.p.Array): The current set of parameters managed by Nevergrad.\n\n    Returns:\n        tuple[float, dict, ng.p.Array]: A tuple containing the computed loss value,\n            a dictionary of metrics, and the updated Nevergrad parameters.\n    \"\"\"\n    loss, metrics = loss_fn(model, data)  # type: ignore[misc]\n    optimizer.tell(ng_params, float(loss))\n    ng_params = optimizer.ask()  # type: ignore[assignment]\n    params = promote_to_tensor(ng_params.value, requires_grad=False)\n    set_parameters(model, params)\n    return loss, metrics, ng_params\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.DictDataLoader","title":"<code>DictDataLoader(dataloaders)</code>  <code>dataclass</code>","text":"<p>This class only holds a dictionary of <code>DataLoader</code>s and samples from them.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.InfiniteTensorDataset","title":"<code>InfiniteTensorDataset(*tensors)</code>","text":"<p>               Bases: <code>IterableDataset</code></p> <p>Randomly sample points from the first dimension of the given tensors.</p> <p>Behaves like a normal torch <code>Dataset</code> just that we can sample from it as many times as we want.</p> <p>Examples: <pre><code>import torch\nfrom qadence.ml_tools.data import InfiniteTensorDataset\n\nx_data, y_data = torch.rand(5,2), torch.ones(5,1)\n# The dataset accepts any number of tensors with the same batch dimension\nds = InfiniteTensorDataset(x_data, y_data)\n\n# call `next` to get one sample from each tensor:\nxs = next(iter(ds))\n</code></pre> <pre><code>(tensor([0.1525, 0.2433]), tensor([1.]))\n</code></pre></p> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>def __init__(self, *tensors: Tensor):\n    \"\"\"Randomly sample points from the first dimension of the given tensors.\n\n    Behaves like a normal torch `Dataset` just that we can sample from it as\n    many times as we want.\n\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    import torch\n    from qadence.ml_tools.data import InfiniteTensorDataset\n\n    x_data, y_data = torch.rand(5,2), torch.ones(5,1)\n    # The dataset accepts any number of tensors with the same batch dimension\n    ds = InfiniteTensorDataset(x_data, y_data)\n\n    # call `next` to get one sample from each tensor:\n    xs = next(iter(ds))\n    print(str(xs)) # markdown-exec: hide\n    ```\n    \"\"\"\n    self.tensors = tensors\n    self.indices = list(range(self.tensors[0].size(0)))\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult","title":"<code>OptimizeResult(iteration, model, optimizer, loss=None, metrics=lambda: dict()(), extra=lambda: dict()(), rank=0, device='cpu')</code>  <code>dataclass</code>","text":"<p>OptimizeResult stores many optimization intermediate values.</p> <p>We store at a current iteration, the model, optimizer, loss values, metrics. An extra dict can be used for saving other information to be used for callbacks.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.device","title":"<code>device = 'cpu'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Device on which this result for calculated.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.extra","title":"<code>extra = field(default_factory=lambda: dict())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Extra dict for saving anything else to be used in callbacks.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.iteration","title":"<code>iteration</code>  <code>instance-attribute</code>","text":"<p>Current iteration number.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.loss","title":"<code>loss = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Loss value.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.metrics","title":"<code>metrics = field(default_factory=lambda: dict())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Metrics that can be saved during training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.model","title":"<code>model</code>  <code>instance-attribute</code>","text":"<p>Model at iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.optimizer","title":"<code>optimizer</code>  <code>instance-attribute</code>","text":"<p>Optimizer at iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.rank","title":"<code>rank = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rank of the process for which this result was generated.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.data_to_device","title":"<code>data_to_device(xs, *args, **kwargs)</code>","text":"<p>Utility method to move arbitrary data to 'device'.</p> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>@singledispatch\ndef data_to_device(xs: Any, *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"Utility method to move arbitrary data to 'device'.\"\"\"\n    raise ValueError(f\"Unable to move {type(xs)} with input args: {args} and kwargs: {kwargs}.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.to_dataloader","title":"<code>to_dataloader(*tensors, batch_size=1, infinite=False)</code>","text":"<p>Convert torch tensors an (infinite) Dataloader.</p> PARAMETER DESCRIPTION <code>*tensors</code> <p>Torch tensors to use in the dataloader.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>()</code> </p> <code>batch_size</code> <p>batch size of sampled tensors</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>infinite</code> <p>if <code>True</code>, the dataloader will keep sampling indefinitely even after the whole dataset was sampled once</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>import torch\nfrom qadence.ml_tools import to_dataloader\n\n(x, y, z) = [torch.rand(10) for _ in range(3)]\nloader = iter(to_dataloader(x, y, z, batch_size=5, infinite=True))\nprint(next(loader))\nprint(next(loader))\nprint(next(loader))\n</code></pre> <pre><code>[tensor([0.0755, 0.1879, 0.5966, 0.9069, 0.3805]), tensor([0.2353, 0.3706, 0.6665, 0.4887, 0.1360]), tensor([0.4474, 0.0525, 0.7524, 0.9236, 0.6251])]\n[tensor([0.4993, 0.3688, 0.2488, 0.1881, 0.5465]), tensor([0.7988, 0.7930, 0.5057, 0.5055, 0.7528]), tensor([0.5153, 0.2946, 0.7875, 0.9052, 0.4109])]\n[tensor([0.0755, 0.1879, 0.5966, 0.9069, 0.3805]), tensor([0.2353, 0.3706, 0.6665, 0.4887, 0.1360]), tensor([0.4474, 0.0525, 0.7524, 0.9236, 0.6251])]\n</code></pre> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>def to_dataloader(*tensors: Tensor, batch_size: int = 1, infinite: bool = False) -&gt; DataLoader:\n    \"\"\"Convert torch tensors an (infinite) Dataloader.\n\n    Arguments:\n        *tensors: Torch tensors to use in the dataloader.\n        batch_size: batch size of sampled tensors\n        infinite: if `True`, the dataloader will keep sampling indefinitely even after the whole\n            dataset was sampled once\n\n    Examples:\n\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    import torch\n    from qadence.ml_tools import to_dataloader\n\n    (x, y, z) = [torch.rand(10) for _ in range(3)]\n    loader = iter(to_dataloader(x, y, z, batch_size=5, infinite=True))\n    print(next(loader))\n    print(next(loader))\n    print(next(loader))\n    ```\n    \"\"\"\n    ds = InfiniteTensorDataset(*tensors) if infinite else TensorDataset(*tensors)\n    return DataLoader(ds, batch_size=batch_size)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN","title":"<code>QNN(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, inputs=None, input_diff_mode=InputDiffMode.AD)</code>","text":"<p>               Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs.</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN, Z\nfrom qadence import hea, feature_map, hamiltonian_factory, kron\n\n# create the circuit\nn_qubits, depth = 2, 4\nfm = kron(\n    feature_map(1, support=(0,), param=\"x\"),\n    feature_map(1, support=(1,), param=\"y\")\n)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning=Z)\n\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n\n# initialize and use the model\nqnn = QNN(circuit, obs, inputs=[\"x\", \"y\"])\ny = qnn(torch.rand(3, 2))\n</code></pre> <pre><code>tensor([[2.4425, 4.8850],\n        [1.7416, 3.4832],\n        [1.3288, 2.6576]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN.</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>The observable.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>inputs</code> <p>List that indicates the order of variables of the tensors that are passed to the model. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p> <p> TYPE: <code>list[Basic | str] | None</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode | str</code> DEFAULT: <code>AD</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    inputs: list[sympy.Basic | str] | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n):\n    \"\"\"Initialize the QNN.\n\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        observable: The observable.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        configuration: optional configuration for the backend\n        inputs: List that indicates the order of variables of the tensors that are passed\n            to the model. Given input tensors `xs = torch.rand(batch_size, input_size:=2)` a QNN\n            with `inputs=[\"t\", \"x\"]` will assign `t, x = xs[:,0], xs[:,1]`.\n        input_diff_mode: The differentiation mode for the input tensor.\n    \"\"\"\n    super().__init__(\n        circuit,\n        observable=observable,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        configuration=configuration,\n        noise=noise,\n    )\n    if self._observable is None:\n        raise ValueError(\"You need to provide at least one observable in the QNN constructor\")\n    if (inputs is not None) and (len(self.inputs) == len(inputs)):\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in inputs]  # type: ignore[union-attr]\n    elif (inputs is None) and len(self.inputs) &lt;= 1:\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in self.inputs]  # type: ignore[union-attr]\n    else:\n        raise ValueError(\n            \"\"\"\n            Your QNN has more than one input. Please provide a list of inputs in the order of\n            your tensor domain. For example, if you want to pass\n            `xs = torch.rand(batch_size, input_size:=3)` to you QNN, where\n            ```\n            t = x[:,0]\n            x = x[:,1]\n            y = x[:,2]\n            ```\n            you have to specify\n            ```\n            QNN(circuit, observable, inputs=[\"t\", \"x\", \"y\"])\n            ```\n            You can also pass a list of sympy symbols.\n        \"\"\"\n        )\n    self.format_to_dict = format_to_dict_fn(self.inputs)  # type: ignore[arg-type]\n    self.input_diff_mode = InputDiffMode(input_diff_mode)\n    if self.input_diff_mode == InputDiffMode.FD:\n        from qadence.backends.utils import finitediff\n\n        self.__derivative = finitediff\n    elif self.input_diff_mode == InputDiffMode.AD:\n        self.__derivative = _torch_derivative  # type: ignore[assignment]\n    else:\n        raise ValueError(f\"Unkown forward diff mode: {self.input_diff_mode}\")\n\n    self._model_configs: dict = dict()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of a QNN.</p> <p>When creating a QNN from a set of configurations, we print the configurations used. Otherwise, we use the default printing.</p> RETURNS DESCRIPTION <code>str | Any</code> <p>str | Any: A string representation of a QNN.</p> <p>Example: <pre><code>from qadence import QNN\nfrom qadence.constructors.hamiltonians import Interaction\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools.constructors import (\n    ObservableConfig,\n)\nfrom qadence.operations import Z\nfrom qadence.types import BackendName\n\nbackend = BackendName.PYQTORCH\nfm_config = FeatureMapConfig(num_features=1)\nansatz_config = AnsatzConfig()\nobservable_config = ObservableConfig(detuning=Z, interaction=Interaction.ZZ, scale=2)\n\nqnn = QNN.from_configs(\n    register=2,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=backend,\n)\n</code></pre> <pre><code>QNN(\nansatz_config = AnsatzConfig(depth=1, ansatz_type=&lt;AnsatzType.HEA: 'hea'&gt;, ansatz_strategy=&lt;Strategy.DIGITAL: 'Digital'&gt;, strategy_args={}, m_block_qubits=None, param_prefix='theta', tag=None)\nfm_config = FeatureMapConfig(num_features=1, basis_set={'x': &lt;BasisSet.FOURIER: 'Fourier'&gt;}, reupload_scaling={'x': &lt;ReuploadScaling.CONSTANT: 'Constant'&gt;}, feature_range={'x': None}, target_range={'x': None}, multivariate_strategy=&lt;MultivariateStrategy.PARALLEL: 'Parallel'&gt;, feature_map_strategy=&lt;Strategy.DIGITAL: 'Digital'&gt;, param_prefix=None, num_repeats={'x': 0}, operation=&lt;class 'qadence.operations.parametric.RX'&gt;, inputs=['x'], tag=None)\nregister = 2\nobservable_config = {'Obs.': '(2 * (Z(0) + Z(1) + (Z(0) \u2297 Z(1))))'}\n)\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def __str__(self) -&gt; str | Any:\n    \"\"\"Return a string representation of a QNN.\n\n    When creating a QNN from a set of configurations,\n    we print the configurations used. Otherwise, we use the default printing.\n\n    Returns:\n        str | Any: A string representation of a QNN.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import QNN\n    from qadence.constructors.hamiltonians import Interaction\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools.constructors import (\n        ObservableConfig,\n    )\n    from qadence.operations import Z\n    from qadence.types import BackendName\n\n    backend = BackendName.PYQTORCH\n    fm_config = FeatureMapConfig(num_features=1)\n    ansatz_config = AnsatzConfig()\n    observable_config = ObservableConfig(detuning=Z, interaction=Interaction.ZZ, scale=2)\n\n    qnn = QNN.from_configs(\n        register=2,\n        obs_config=observable_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n    )\n    print(qnn) # markdown-exec: hide\n    ```\n    \"\"\"\n    if bool(self._model_configs):\n        configs_str = \"\\n\".join(\n            (\n                k + \" = \" + str(self._model_configs[k])\n                for k in sorted(self._model_configs.keys())\n                if k != \"observable_config\"\n            )\n        )\n        observable_str = \"\"\n        if self._observable:\n            observable_str = f\"observable_config = {self.observables_to_expression()}\"\n\n        return f\"{type(self).__name__}(\\n{configs_str}\\n{observable_str}\\n)\"\n\n    return super().__str__()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.forward","title":"<code>forward(values=None, state=None, measurement=None, noise=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model.</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def forward(\n    self,\n    values: dict[str, Tensor] | Tensor = None,\n    state: Tensor | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    \"\"\"Forward pass of the model.\n\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n\n    Args:\n        values: the values of the feature parameters\n        state: Initial state.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\n    return self.expectation(\n        values, state=state, measurement=measurement, noise=noise, endianness=endianness\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.from_configs","title":"<code>from_configs(register, obs_config, fm_config=FeatureMapConfig(), ansatz_config=AnsatzConfig(), backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, input_diff_mode=InputDiffMode.AD)</code>  <code>classmethod</code>","text":"<p>Create a QNN from a set of configurations.</p> PARAMETER DESCRIPTION <code>register</code> <p>The number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>obs_config</code> <p>The configuration(s) for the observable(s).</p> <p> TYPE: <code>list[ObservableConfig] | ObservableConfig</code> </p> <code>fm_config</code> <p>The configuration for the feature map. Defaults to no feature encoding block.</p> <p> TYPE: <code>FeatureMapConfig</code> DEFAULT: <code>FeatureMapConfig()</code> </p> <code>ansatz_config</code> <p>The configuration for the ansatz. Defaults to a single layer of hardware efficient ansatz.</p> <p> TYPE: <code>AnsatzConfig</code> DEFAULT: <code>AnsatzConfig()</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices are 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Optional backend configuration.</p> <p> TYPE: <code>BackendConfiguration | dict</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode</code> DEFAULT: <code>AD</code> </p> RETURNS DESCRIPTION <code>QNN</code> <p>A QNN object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the observable configuration is not provided.</p> <p>Example: <pre><code>import torch\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools import QNN\nfrom qadence.constructors import ObservableConfig\nfrom qadence.operations import Z\nfrom qadence.types import (\n    AnsatzType, BackendName, BasisSet, ReuploadScaling, Strategy\n)\n\nregister = 4\nobs_config = ObservableConfig(\n    detuning=Z,\n    scale=5.0,\n    shift=0.0,\n    trainable_transform=None,\n)\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs=[\"x\", \"y\"],\n    basis_set=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.CONSTANT,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nqnn = QNN.from_configs(\n    register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n)\n\nx = torch.rand(2, 2)\ny = qnn(x)\n</code></pre> <pre><code>tensor([[-2.6743],\n        [ 0.8359]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>@classmethod\ndef from_configs(\n    cls,\n    register: int | Register,\n    obs_config: Any,\n    fm_config: Any = FeatureMapConfig(),\n    ansatz_config: Any = AnsatzConfig(),\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n) -&gt; QNN:\n    \"\"\"Create a QNN from a set of configurations.\n\n    Args:\n        register (int | Register): The number of qubits or a register object.\n        obs_config (list[ObservableConfig] | ObservableConfig): The configuration(s)\n            for the observable(s).\n        fm_config (FeatureMapConfig): The configuration for the feature map.\n            Defaults to no feature encoding block.\n        ansatz_config (AnsatzConfig): The configuration for the ansatz.\n            Defaults to a single layer of hardware efficient ansatz.\n        backend (BackendName): The chosen quantum backend.\n        diff_mode (DiffMode): The differentiation engine to use. Choices are\n            'gpsr' or 'ad'.\n        measurement (Measurements): Optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator.\n        noise (Noise): A noise model to use.\n        configuration (BackendConfiguration | dict): Optional backend configuration.\n        input_diff_mode (InputDiffMode): The differentiation mode for the input tensor.\n\n    Returns:\n        A QNN object.\n\n    Raises:\n        ValueError: If the observable configuration is not provided.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools import QNN\n    from qadence.constructors import ObservableConfig\n    from qadence.operations import Z\n    from qadence.types import (\n        AnsatzType, BackendName, BasisSet, ReuploadScaling, Strategy\n    )\n\n    register = 4\n    obs_config = ObservableConfig(\n        detuning=Z,\n        scale=5.0,\n        shift=0.0,\n        trainable_transform=None,\n    )\n    fm_config = FeatureMapConfig(\n        num_features=2,\n        inputs=[\"x\", \"y\"],\n        basis_set=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.CONSTANT,\n        feature_range={\n            \"x\": (-1.0, 1.0),\n            \"y\": (0.0, 1.0),\n        },\n    )\n    ansatz_config = AnsatzConfig(\n        depth=2,\n        ansatz_type=AnsatzType.HEA,\n        ansatz_strategy=Strategy.DIGITAL,\n    )\n\n    qnn = QNN.from_configs(\n        register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n    )\n\n    x = torch.rand(2, 2)\n    y = qnn(x)\n    print(str(y)) # markdown-exec: hide\n    ```\n    \"\"\"\n    from .constructors import build_qnn_from_configs\n\n    qnn = build_qnn_from_configs(\n        register=register,\n        observable_config=obs_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        noise=noise,\n        configuration=configuration,\n        input_diff_mode=input_diff_mode,\n    )\n    qnn._model_configs = {\n        \"register\": register,\n        \"observable_config\": obs_config,\n        \"fm_config\": fm_config,\n        \"ansatz_config\": ansatz_config,\n    }\n    return qnn\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.derivative","title":"<code>derivative(ufa, x, derivative_indices)</code>","text":"<p>Compute derivatives w.r.t.</p> <p>inputs of a UFA with a single output. The <code>derivative_indices</code> specify which derivative(s) are computed.  E.g. <code>derivative_indices=(1,2)</code> would compute the a second order derivative w.r.t to the indices <code>1</code> and <code>2</code> of the input tensor.</p> PARAMETER DESCRIPTION <code>ufa</code> <p>The model for which we want to compute the derivative.</p> <p> TYPE: <code>Module</code> </p> <code>x</code> <p>(batch_size, input_size) input tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>derivative_indices</code> <p>Define which derivatives to compute.</p> <p> TYPE: <code>tuple</code> </p> <p>Examples: If we create a UFA with three inputs and denote the first, second, and third input with <code>x</code>, <code>y</code>, and <code>z</code> we can compute the following derivatives w.r.t to those inputs: <pre><code>import torch\nfrom qadence.ml_tools.models import derivative, QNN\nfrom qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\nfrom qadence.constructors.hamiltonians import ObservableConfig\nfrom qadence.operations import Z\n\nfm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\nansatz_config = AnsatzConfig()\nobs_config = ObservableConfig(detuning=Z)\n\nf = QNN.from_configs(\n    register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n)\ninputs = torch.rand(5,3,requires_grad=True)\n\n# df_dx\nderivative(f, inputs, (0,))\n\n# d2f_dydz\nderivative(f, inputs, (1,2))\n\n# d3fdy2dx\nderivative(f, inputs, (1,1,0))\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def derivative(ufa: torch.nn.Module, x: Tensor, derivative_indices: tuple[int, ...]) -&gt; Tensor:\n    \"\"\"Compute derivatives w.r.t.\n\n    inputs of a UFA with a single output. The\n    `derivative_indices` specify which derivative(s) are computed.  E.g.\n    `derivative_indices=(1,2)` would compute the a second order derivative w.r.t\n    to the indices `1` and `2` of the input tensor.\n\n    Arguments:\n        ufa: The model for which we want to compute the derivative.\n        x (Tensor): (batch_size, input_size) input tensor.\n        derivative_indices (tuple): Define which derivatives to compute.\n\n    Examples:\n    If we create a UFA with three inputs and denote the first, second, and third\n    input with `x`, `y`, and `z` we can compute the following derivatives w.r.t\n    to those inputs:\n    ```py exec=\"on\" source=\"material-block\"\n    import torch\n    from qadence.ml_tools.models import derivative, QNN\n    from qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\n    from qadence.constructors.hamiltonians import ObservableConfig\n    from qadence.operations import Z\n\n    fm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\n    ansatz_config = AnsatzConfig()\n    obs_config = ObservableConfig(detuning=Z)\n\n    f = QNN.from_configs(\n        register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n    )\n    inputs = torch.rand(5,3,requires_grad=True)\n\n    # df_dx\n    derivative(f, inputs, (0,))\n\n    # d2f_dydz\n    derivative(f, inputs, (1,2))\n\n    # d3fdy2dx\n    derivative(f, inputs, (1,1,0))\n    ```\n    \"\"\"\n    assert ufa.out_features == 1, \"Can only call `derivative` on models with 1D output.\"\n    return ufa._derivative(x, derivative_indices)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.format_to_dict_fn","title":"<code>format_to_dict_fn(inputs=[])</code>","text":"<p>Format an input tensor into the format required by the forward pass.</p> <p>The tensor is assumed to have dimensions: n_batches x in_features where in_features corresponds to the number of input features of the QNN</p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def format_to_dict_fn(\n    inputs: list[sympy.Symbol | str] = [],\n) -&gt; Callable[[Tensor | ParamDictType], ParamDictType]:\n    \"\"\"Format an input tensor into the format required by the forward pass.\n\n    The tensor is assumed to have dimensions: n_batches x in_features where in_features\n    corresponds to the number of input features of the QNN\n    \"\"\"\n    in_features = len(inputs)\n\n    def tensor_to_dict(values: Tensor | ParamDictType) -&gt; ParamDictType:\n        if isinstance(values, Tensor):\n            values = values.reshape(-1, 1) if len(values.size()) == 1 else values\n            if not values.shape[1] == in_features:\n                raise ValueError(\n                    f\"Model expects in_features={in_features} but got {values.shape[1]}.\"\n                )\n            values = {fparam.name: values[:, inputs.index(fparam)] for fparam in inputs}  # type: ignore[union-attr]\n        return values\n\n    return tensor_to_dict\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback","title":"<code>Callback(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>Base class for defining various training callbacks.</p> ATTRIBUTE DESCRIPTION <code>on</code> <p>The event on which to trigger the callback. Must be a valid on value from: [\"train_start\", \"train_end\",     \"train_epoch_start\", \"train_epoch_end\", \"train_batch_start\",     \"train_batch_end\",\"val_epoch_start\", \"val_epoch_end\",     \"val_batch_start\", \"val_batch_end\", \"test_batch_start\",     \"test_batch_end\"]</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>callback</code> <p>The function to call if the condition is met.</p> <p> TYPE: <code>CallbackFunction | None</code> </p> <code>callback_condition</code> <p>Condition to check before calling.</p> <p> TYPE: <code>CallbackConditionFunction | None</code> </p> <code>modify_optimize_result</code> <p>Function to modify <code>OptimizeResult</code>.</p> <p> TYPE: <code>CallbackFunction | dict[str, Any] | None</code> </p> <p>A callback can be defined in two ways:</p> <ol> <li>By providing a callback function directly in the base class:    This is useful for simple callbacks that don't require subclassing.</li> </ol> <p>Example:    <pre><code>from qadence.ml_tools.callbacks import Callback\n\ndef custom_callback_function(trainer, config, writer):\n    print(\"Custom callback executed.\")\n\ncustom_callback = Callback(\n    on=\"train_end\",\n    called_every=5,\n    callback=custom_callback_function\n)\n</code></pre> <pre><code>\n</code></pre> </p> <ol> <li>By inheriting and implementing the <code>run_callback</code> method:    This is suitable for more complex callbacks that require customization.</li> </ol> <p>Example:    <pre><code>from qadence.ml_tools.callbacks import Callback\nclass CustomCallback(Callback):\n    def run_callback(self, trainer, config, writer):\n        print(\"Custom behavior in the inherited run_callback method.\")\n\ncustom_callback = CustomCallback(on=\"train_end\", called_every=10)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback.on","title":"<code>on</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the TrainingStage.</p> RETURNS DESCRIPTION <code>TrainingStage</code> <p>TrainingStage for the callback</p> <p> TYPE: <code>TrainingStage | str</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback.__call__","title":"<code>__call__(when, trainer, config, writer)</code>","text":"<p>Executes the callback if conditions are met.</p> PARAMETER DESCRIPTION <code>when</code> <p>The event when the callback is triggered.</p> <p> TYPE: <code>str</code> </p> <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Result of the callback function if executed.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __call__(\n    self, when: TrainingStage, trainer: Any, config: TrainConfig, writer: BaseWriter\n) -&gt; Any:\n    \"\"\"Executes the callback if conditions are met.\n\n    Args:\n        when (str): The event when the callback is triggered.\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n\n    Returns:\n        Any: Result of the callback function if executed.\n    \"\"\"\n    opt_result = trainer.opt_result\n    if self.on == when:\n        if opt_result:\n            opt_result = self.modify_optimize_result(opt_result)\n        if self._should_call(when, opt_result):\n            return self.run_callback(trainer, config, writer)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Executes the defined callback.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Result of the callback execution.</p> <p> TYPE: <code>Any</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If not implemented in subclasses.</p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Executes the defined callback.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n\n    Returns:\n        Any: Result of the callback execution.\n\n    Raises:\n        NotImplementedError: If not implemented in subclasses.\n    \"\"\"\n    if self.callback is not None:\n        return self.callback(trainer, config, writer)\n    raise NotImplementedError(\"Subclasses should override the run_callback method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.EarlyStopping","title":"<code>EarlyStopping(on, called_every, monitor, patience=5, mode='min')</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Stops training when a monitored metric has not improved for a specified number of epochs.</p> <p>This callback monitors a specified metric (e.g., validation loss or accuracy). If the metric does not improve for a given patience period, training is stopped.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>EarlyStopping</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import EarlyStopping\n\n# Create an instance of the EarlyStopping callback\nearly_stopping = EarlyStopping(on=\"val_epoch_end\",\n                               called_every=1,\n                               monitor=\"val_loss\",\n                               patience=5,\n                               mode=\"min\")\n\nconfig = TrainConfig(\n    max_iter=10000,\n    print_every=1000,\n    callbacks=[early_stopping]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the EarlyStopping callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback (e.g., \"val_epoch_end\").</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>monitor</code> <p>The metric to monitor (e.g., \"val_loss\" or \"train_loss\"). All metrics returned by optimize step are available to monitor. Please add \"val_\" and \"train_\" strings at the start of the metric name.</p> <p> TYPE: <code>str</code> </p> <code>patience</code> <p>Number of iterations to wait for improvement. Default is 5.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>mode</code> <p>Whether to minimize (\"min\") or maximize (\"max\") the metric. Default is \"min\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'min'</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self, on: str, called_every: int, monitor: str, patience: int = 5, mode: str = \"min\"\n):\n    \"\"\"Initializes the EarlyStopping callback.\n\n    Args:\n        on (str): The event to trigger the callback (e.g., \"val_epoch_end\").\n        called_every (int): Frequency of callback calls in terms of iterations.\n        monitor (str): The metric to monitor (e.g., \"val_loss\" or \"train_loss\").\n            All metrics returned by optimize step are available to monitor.\n            Please add \"val_\" and \"train_\" strings at the start of the metric name.\n        patience (int, optional): Number of iterations to wait for improvement. Default is 5.\n        mode (str, optional): Whether to minimize (\"min\") or maximize (\"max\") the metric.\n            Default is \"min\".\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.monitor = monitor\n    self.patience = patience\n    self.mode = mode\n    self.best_value = float(\"inf\") if mode == \"min\" else -float(\"inf\")\n    self.counter = 0\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.EarlyStopping.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Monitors the metric and stops training if no improvement is observed.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Monitors the metric and stops training if no improvement is observed.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    current_value = trainer.opt_result.metrics.get(self.monitor)\n    if current_value is None:\n        raise ValueError(f\"Metric '{self.monitor}' is not available in the trainer's metrics.\")\n\n    if (self.mode == \"min\" and current_value &lt; self.best_value) or (\n        self.mode == \"max\" and current_value &gt; self.best_value\n    ):\n        self.best_value = current_value\n        self.counter = 0\n    else:\n        self.counter += 1\n\n    if self.counter &gt;= self.patience:\n        logger.info(\n            f\"EarlyStopping: No improvement in '{self.monitor}' for {self.patience} epochs. \"\n            \"Stopping training.\"\n        )\n        trainer._stop_training.fill_(1)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.GradientMonitoring","title":"<code>GradientMonitoring(on, called_every=1)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Logs gradient statistics (e.g., mean, standard deviation, max) during training.</p> <p>This callback monitors and logs statistics about the gradients of the model parameters to help debug or optimize the training process.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>GradientMonitoring</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import GradientMonitoring\n\n# Create an instance of the GradientMonitoring callback\ngradient_monitoring = GradientMonitoring(on=\"train_batch_end\", called_every=10)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    print_every=1000,\n    callbacks=[gradient_monitoring]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the GradientMonitoring callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback (e.g., \"train_batch_end\").</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int = 1):\n    \"\"\"Initializes the GradientMonitoring callback.\n\n    Args:\n        on (str): The event to trigger the callback (e.g., \"train_batch_end\").\n        called_every (int): Frequency of callback calls in terms of iterations.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.GradientMonitoring.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Logs gradient statistics.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Logs gradient statistics.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        gradient_stats = {}\n        for name, param in trainer.model.named_parameters():\n            if param.grad is not None:\n                grad = param.grad\n                gradient_stats.update(\n                    {\n                        name + \"_mean\": grad.mean().item(),\n                        name + \"_std\": grad.std().item(),\n                        name + \"_max\": grad.max().item(),\n                        name + \"_min\": grad.min().item(),\n                    }\n                )\n\n        writer.write(trainer.opt_result.iteration, gradient_stats)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCosineAnnealing","title":"<code>LRSchedulerCosineAnnealing(on, called_every, t_max, min_lr=0.0)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Applies cosine annealing to the learning rate during training.</p> <p>This callback decreases the learning rate following a cosine curve, starting from the initial learning rate and annealing to a minimum (min_lr).</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LRSchedulerCosineAnnealing</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCosineAnnealing\n\n# Create an instance of the LRSchedulerCosineAnnealing callback\nlr_cosine = LRSchedulerCosineAnnealing(on=\"train_batch_end\",\n                                       called_every=1,\n                                       t_max=5000,\n                                       min_lr=1e-6)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback\n    callbacks=[lr_cosine]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the LRSchedulerCosineAnnealing callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>t_max</code> <p>The total number of iterations for one annealing cycle.</p> <p> TYPE: <code>int</code> </p> <code>min_lr</code> <p>The minimum learning rate. Default is 0.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int, t_max: int, min_lr: float = 0.0):\n    \"\"\"Initializes the LRSchedulerCosineAnnealing callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n        t_max (int): The total number of iterations for one annealing cycle.\n        min_lr (float, optional): The minimum learning rate. Default is 0.0.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.t_max = t_max\n    self.min_lr = min_lr\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCosineAnnealing.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Adjusts the learning rate using cosine annealing.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Adjusts the learning rate using cosine annealing.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    for param_group in trainer.optimizer.param_groups:\n        max_lr = param_group[\"lr\"]\n        new_lr = (\n            self.min_lr\n            + (max_lr - self.min_lr)\n            * (1 + math.cos(math.pi * trainer.opt_result.iteration / self.t_max))\n            / 2\n        )\n        param_group[\"lr\"] = new_lr\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCyclic","title":"<code>LRSchedulerCyclic(on, called_every, base_lr, max_lr, step_size)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Applies a cyclic learning rate schedule during training.</p> <p>This callback oscillates the learning rate between a minimum (base_lr) and a maximum (max_lr) over a defined cycle length (step_size). The learning rate follows a triangular wave pattern.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LRSchedulerCyclic</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCyclic\n\n# Create an instance of the LRSchedulerCyclic callback\nlr_cyclic = LRSchedulerCyclic(on=\"train_batch_end\",\n                              called_every=1,\n                              base_lr=0.001,\n                              max_lr=0.01,\n                              step_size=2000)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback\n    callbacks=[lr_cyclic]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the LRSchedulerCyclic callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>base_lr</code> <p>The minimum learning rate.</p> <p> TYPE: <code>float</code> </p> <code>max_lr</code> <p>The maximum learning rate.</p> <p> TYPE: <code>float</code> </p> <code>step_size</code> <p>Number of iterations for half a cycle.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int, base_lr: float, max_lr: float, step_size: int):\n    \"\"\"Initializes the LRSchedulerCyclic callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n        base_lr (float): The minimum learning rate.\n        max_lr (float): The maximum learning rate.\n        step_size (int): Number of iterations for half a cycle.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.base_lr = base_lr\n    self.max_lr = max_lr\n    self.step_size = step_size\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCyclic.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Adjusts the learning rate cyclically.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Adjusts the learning rate cyclically.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    cycle = trainer.opt_result.iteration // (2 * self.step_size)\n    x = abs(trainer.opt_result.iteration / self.step_size - 2 * cycle - 1)\n    scale = max(0, (1 - x))\n    new_lr = self.base_lr + (self.max_lr - self.base_lr) * scale\n    for param_group in trainer.optimizer.param_groups:\n        param_group[\"lr\"] = new_lr\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerStepDecay","title":"<code>LRSchedulerStepDecay(on, called_every, gamma=0.5)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Reduces the learning rate by a factor at regular intervals.</p> <p>This callback adjusts the learning rate by multiplying it with a decay factor after a specified number of iterations. The learning rate is updated as:     lr = lr * gamma</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LRSchedulerStepDecay</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerStepDecay\n\n# Create an instance of the LRSchedulerStepDecay callback\nlr_step_decay = LRSchedulerStepDecay(on=\"train_epoch_end\",\n                                     called_every=100,\n                                     gamma=0.5)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback\n    callbacks=[lr_step_decay]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the LRSchedulerStepDecay callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>gamma</code> <p>The decay factor applied to the learning rate. A value &lt; 1 reduces the learning rate over time. Default is 0.5.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.5</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int, gamma: float = 0.5):\n    \"\"\"Initializes the LRSchedulerStepDecay callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n        gamma (float, optional): The decay factor applied to the learning rate.\n            A value &lt; 1 reduces the learning rate over time. Default is 0.5.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.gamma = gamma\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerStepDecay.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Runs the callback to apply step decay to the learning rate.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Runs the callback to apply step decay to the learning rate.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    for param_group in trainer.optimizer.param_groups:\n        param_group[\"lr\"] *= self.gamma\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LoadCheckpoint","title":"<code>LoadCheckpoint(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to load a model checkpoint.</p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LoadCheckpoint.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Loads a model checkpoint.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result of loading the checkpoint.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Loads a model checkpoint.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n\n    Returns:\n        Any: The result of loading the checkpoint.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        folder = config.log_folder\n        model = trainer.model\n        optimizer = trainer.optimizer\n        device = trainer.accelerator.execution.log_device\n        return load_checkpoint(folder, model, optimizer, device=device)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogHyperparameters","title":"<code>LogHyperparameters(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to log hyperparameters using the writer.</p> <p>The <code>LogHyperparameters</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LogHyperparameters</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LogHyperparameters\n\n# Create an instance of the LogHyperparameters callback\nlog_hyper_callback = LogHyperparameters(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[log_hyper_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogHyperparameters.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Logs hyperparameters using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Logs hyperparameters using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        hyperparams = config.hyperparams\n        writer.log_hyperparams(hyperparams)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogModelTracker","title":"<code>LogModelTracker(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to log the model using the writer.</p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogModelTracker.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Logs the model using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Logs the model using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        model = trainer.model\n        writer.log_model(\n            model, trainer.train_dataloader, trainer.val_dataloader, trainer.test_dataloader\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PlotMetrics","title":"<code>PlotMetrics(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to plot metrics using the writer.</p> <p>The <code>PlotMetrics</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>PlotMetrics</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PlotMetrics\n\n# Create an instance of the PlotMetrics callback\nplot_metrics_callback = PlotMetrics(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[plot_metrics_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PlotMetrics.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Plots metrics using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Plots metrics using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        opt_result = trainer.opt_result\n        plotting_functions = config.plotting_functions\n        writer.plot(trainer.model, opt_result.iteration, plotting_functions)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PrintMetrics","title":"<code>PrintMetrics(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to print metrics using the writer.</p> <p>The <code>PrintMetrics</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>PrintMetrics</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PrintMetrics\n\n# Create an instance of the PrintMetrics callback\nprint_metrics_callback = PrintMetrics(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[print_metrics_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PrintMetrics.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Prints metrics using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Prints metrics using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    opt_result = trainer.opt_result\n    writer.print_metrics(opt_result)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveBestCheckpoint","title":"<code>SaveBestCheckpoint(on, called_every)</code>","text":"<p>               Bases: <code>SaveCheckpoint</code></p> <p>Callback to save the best model checkpoint based on a validation criterion.</p> <p>Initializes the SaveBestCheckpoint callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int):\n    \"\"\"Initializes the SaveBestCheckpoint callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.best_loss = float(\"inf\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveBestCheckpoint.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Saves the checkpoint if the current loss is better than the best loss.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Saves the checkpoint if the current loss is better than the best loss.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        opt_result = trainer.opt_result\n        if config.validation_criterion and config.validation_criterion(\n            opt_result.loss, self.best_loss, config.val_epsilon\n        ):\n            self.best_loss = opt_result.loss\n\n            folder = config.log_folder\n            model = trainer.model\n            optimizer = trainer.optimizer\n            opt_result = trainer.opt_result\n            write_checkpoint(folder, model, optimizer, \"best\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveCheckpoint","title":"<code>SaveCheckpoint(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to save a model checkpoint.</p> <p>The <code>SaveCheckpoint</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>SaveCheckpoint</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveCheckpoint\n\n# Create an instance of the SaveCheckpoint callback\nsave_checkpoint_callback = SaveCheckpoint(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[save_checkpoint_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveCheckpoint.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Saves a model checkpoint.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Saves a model checkpoint.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        folder = config.log_folder\n        model = trainer.model\n        optimizer = trainer.optimizer\n        opt_result = trainer.opt_result\n        write_checkpoint(folder, model, optimizer, opt_result.iteration)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.WriteMetrics","title":"<code>WriteMetrics(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to write metrics using the writer.</p> <p>The <code>WriteMetrics</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>WriteMetrics</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import WriteMetrics\n\n# Create an instance of the WriteMetrics callback\nwrite_metrics_callback = WriteMetrics(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[write_metrics_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.WriteMetrics.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Writes metrics using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Writes metrics using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        opt_result = trainer.opt_result\n        writer.write(opt_result.iteration, opt_result.metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer","title":"<code>BaseTrainer(model, optimizer, config, loss_fn='mse', optimize_step=optimize_step, train_dataloader=None, val_dataloader=None, test_dataloader=None, max_batches=None)</code>","text":"<p>Base class for training machine learning models using a given optimizer.</p> <p>The base class implements contextmanager for gradient based/free optimization, properties, property setters, input validations, callback decorator generator, and empty hooks for different training steps.</p> This class provides <ul> <li>Context managers for enabling/disabling gradient-based optimization</li> <li>Properties for managing models, optimizers, and dataloaders</li> <li>Input validations and a callback decorator generator</li> <li>Config and callback managers using the provided <code>TrainConfig</code></li> </ul> ATTRIBUTE DESCRIPTION <code>use_grad</code> <p>Indicates if gradients are used for optimization. Default is True.</p> <p> TYPE: <code>bool</code> </p> <code>model</code> <p>The neural network model.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The optimizer for training.</p> <p> TYPE: <code>Optimizer | Optimizer | None</code> </p> <code>config</code> <p>The configuration settings for training.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> </p> <code>optimize_step</code> <p>Function for performing an optimization step.</p> <p> TYPE: <code>Callable</code> </p> <code>loss_fn</code> <p>loss function to use. Default loss function used is 'mse'</p> <p> TYPE: <code>Callable | str ]</code> </p> <code>num_training_batches</code> <p>Number of training batches. In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int</code> </p> <code>num_validation_batches</code> <p>Number of validation batches. In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int</code> </p> <code>num_test_batches</code> <p>Number of test batches. In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int</code> </p> <code>state</code> <p>Current state in the training process</p> <p> TYPE: <code>str</code> </p> <p>Initializes the BaseTrainer.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to train.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The optimizer for training.</p> <p> TYPE: <code>Optimizer | Optimizer | None</code> </p> <code>config</code> <p>The TrainConfig settings for training.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>The loss function to use. str input to be specified to use a default loss function. currently supported loss functions: 'mse', 'cross_entropy'. If not specified, default mse loss will be used.</p> <p> TYPE: <code>str | Callable</code> DEFAULT: <code>'mse'</code> </p> <code>train_dataloader</code> <p>DataLoader for training data. If the model does not need data to evaluate loss, no dataset should be provided.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>max_batches</code> <p>Maximum number of batches to process per epoch. This is only valid in case of finite TensorDataset dataloaders. if max_batches is not None, the maximum number of batches used will be min(max_batches, len(dataloader.dataset)) In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def __init__(\n    self,\n    model: nn.Module,\n    optimizer: optim.Optimizer | NGOptimizer | None,\n    config: TrainConfig,\n    loss_fn: str | Callable = \"mse\",\n    optimize_step: Callable = optimize_step,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n    max_batches: int | None = None,\n):\n    \"\"\"\n    Initializes the BaseTrainer.\n\n    Args:\n        model (nn.Module): The model to train.\n        optimizer (optim.Optimizer | NGOptimizer | None): The optimizer\n            for training.\n        config (TrainConfig): The TrainConfig settings for training.\n        loss_fn (str | Callable): The loss function to use.\n            str input to be specified to use a default loss function.\n            currently supported loss functions: 'mse', 'cross_entropy'.\n            If not specified, default mse loss will be used.\n        train_dataloader (Dataloader | DictDataLoader | None): DataLoader for training data.\n            If the model does not need data to evaluate loss, no dataset\n            should be provided.\n        val_dataloader (Dataloader | DictDataLoader | None): DataLoader for validation data.\n        test_dataloader (Dataloader | DictDataLoader | None): DataLoader for testing data.\n        max_batches (int | None): Maximum number of batches to process per epoch.\n            This is only valid in case of finite TensorDataset dataloaders.\n            if max_batches is not None, the maximum number of batches used will\n            be min(max_batches, len(dataloader.dataset))\n            In case of InfiniteTensorDataset only 1 batch per epoch is used.\n    \"\"\"\n    self._model: nn.Module\n    self._optimizer: optim.Optimizer | NGOptimizer | None\n    self._config: TrainConfig\n    self._train_dataloader: DataLoader | DictDataLoader | None = None\n    self._val_dataloader: DataLoader | DictDataLoader | None = None\n    self._test_dataloader: DataLoader | DictDataLoader | None = None\n\n    self.config = config\n    self.model = model\n    self.optimizer = optimizer\n    self.max_batches = max_batches\n\n    self.num_training_batches: int\n    self.num_validation_batches: int\n    self.num_test_batches: int\n\n    self.train_dataloader = train_dataloader\n    self.val_dataloader = val_dataloader\n    self.test_dataloader = test_dataloader\n\n    self.loss_fn: Callable = get_loss_fn(loss_fn)\n    self.optimize_step: Callable = optimize_step\n    self.ng_params: ng.p.Array\n    self.training_stage: TrainingStage = TrainingStage(\"idle\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.config","title":"<code>config</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the training configuration.</p> RETURNS DESCRIPTION <code>TrainConfig</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.model","title":"<code>model</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the model if set, otherwise raises an error.</p> RETURNS DESCRIPTION <code>Module</code> <p>nn.Module: The model.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.optimizer","title":"<code>optimizer</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the optimizer if set, otherwise raises an error.</p> RETURNS DESCRIPTION <code>Optimizer | Optimizer | None</code> <p>optim.Optimizer | NGOptimizer | None: The optimizer.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.test_dataloader","title":"<code>test_dataloader</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the test DataLoader, validating its type.</p> RETURNS DESCRIPTION <code>DataLoader</code> <p>The DataLoader for testing data.</p> <p> TYPE: <code>DataLoader</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.train_dataloader","title":"<code>train_dataloader</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the training DataLoader, validating its type.</p> RETURNS DESCRIPTION <code>DataLoader</code> <p>The DataLoader for training data.</p> <p> TYPE: <code>DataLoader</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.use_grad","title":"<code>use_grad</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the optimization framework for the trainer.</p> <p>use_grad = True : Gradient based optimization use_grad = False : Gradient free optimization</p> RETURNS DESCRIPTION <code>bool</code> <p>Bool value for using gradient.</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.val_dataloader","title":"<code>val_dataloader</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the validation DataLoader, validating its type.</p> RETURNS DESCRIPTION <code>DataLoader</code> <p>The DataLoader for validation data.</p> <p> TYPE: <code>DataLoader</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.callback","title":"<code>callback(phase)</code>  <code>staticmethod</code>","text":"<p>Decorator for executing callbacks before and after a phase.</p> <p>Phase are different hooks during the training. list of valid phases is defined in Callbacks. We also update the current state of the training process in the callback decorator.</p> PARAMETER DESCRIPTION <code>phase</code> <p>The phase for which the callback is executed (e.g., \"train\", \"train_epoch\", \"train_batch\").</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>The decorated function.</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@staticmethod\ndef callback(phase: str) -&gt; Callable:\n    \"\"\"\n    Decorator for executing callbacks before and after a phase.\n\n    Phase are different hooks during the training. list of valid\n    phases is defined in Callbacks.\n    We also update the current state of the training process in\n    the callback decorator.\n\n    Args:\n        phase (str): The phase for which the callback is executed (e.g., \"train\",\n            \"train_epoch\", \"train_batch\").\n\n    Returns:\n        Callable: The decorated function.\n    \"\"\"\n\n    def decorator(method: Callable) -&gt; Callable:\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -&gt; Any:\n            start_event = f\"{phase}_start\"\n            end_event = f\"{phase}_end\"\n\n            self.training_stage = TrainingStage(start_event)\n            self.callback_manager.run_callbacks(trainer=self)\n            result = method(self, *args, **kwargs)\n\n            self.training_stage = TrainingStage(end_event)\n            # build_optimize_result method is defined in the trainer.\n            self.build_optimize_result(result)\n            self.callback_manager.run_callbacks(trainer=self)\n\n            return result\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.disable_grad_opt","title":"<code>disable_grad_opt(optimizer=None)</code>","text":"<p>Context manager to temporarily disable gradient-based optimization.</p> PARAMETER DESCRIPTION <code>optimizer</code> <p>The Nevergrad optimizer to use. If no optimizer is provided, default optimizer for trainer object will be used.</p> <p> TYPE: <code>Optimizer</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@contextmanager\ndef disable_grad_opt(self, optimizer: NGOptimizer | None = None) -&gt; Iterator[None]:\n    \"\"\"\n    Context manager to temporarily disable gradient-based optimization.\n\n    Args:\n        optimizer (NGOptimizer): The Nevergrad optimizer to use.\n            If no optimizer is provided, default optimizer for trainer\n            object will be used.\n    \"\"\"\n    original_mode = self.use_grad\n    original_optimizer = self._optimizer\n    try:\n        self.use_grad = False\n        self.callback_manager.use_grad = False\n        self.optimizer = optimizer if optimizer else self.optimizer\n        yield\n    finally:\n        self.use_grad = original_mode\n        self.callback_manager.use_grad = original_mode\n        self.optimizer = original_optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.enable_grad_opt","title":"<code>enable_grad_opt(optimizer=None)</code>","text":"<p>Context manager to temporarily enable gradient-based optimization.</p> PARAMETER DESCRIPTION <code>optimizer</code> <p>The PyTorch optimizer to use. If no optimizer is provided, default optimizer for trainer object will be used.</p> <p> TYPE: <code>Optimizer</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@contextmanager\ndef enable_grad_opt(self, optimizer: optim.Optimizer | None = None) -&gt; Iterator[None]:\n    \"\"\"\n    Context manager to temporarily enable gradient-based optimization.\n\n    Args:\n        optimizer (optim.Optimizer): The PyTorch optimizer to use.\n            If no optimizer is provided, default optimizer for trainer\n            object will be used.\n    \"\"\"\n    original_mode = self.use_grad\n    original_optimizer = self._optimizer\n    try:\n        self.use_grad = True\n        self.callback_manager.use_grad = True\n        self.optimizer = optimizer if optimizer else self.optimizer\n        yield\n    finally:\n        self.use_grad = original_mode\n        self.callback_manager.use_grad = original_mode\n        self.optimizer = original_optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_test_batch_end","title":"<code>on_test_batch_end(test_batch_loss_metrics)</code>","text":"<p>Called at the end of each testing batch.</p> PARAMETER DESCRIPTION <code>test_batch_loss_metrics</code> <p>Metrics for the testing batch loss. tuple of (loss, metrics)</p> <p> TYPE: <code>tuple[Tensor, Any]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_test_batch_end(self, test_batch_loss_metrics: tuple[torch.Tensor, Any]) -&gt; None:\n    \"\"\"\n    Called at the end of each testing batch.\n\n    Args:\n        test_batch_loss_metrics: Metrics for the testing batch loss.\n            tuple of (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_test_batch_start","title":"<code>on_test_batch_start(batch)</code>","text":"<p>Called at the start of each testing batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>A batch of data from the DataLoader. Typically a tuple containing input tensors and corresponding target tensors.</p> <p> TYPE: <code>tuple[Tensor, ...] | None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_test_batch_start(self, batch: tuple[torch.Tensor, ...] | None) -&gt; None:\n    \"\"\"\n    Called at the start of each testing batch.\n\n    Args:\n        batch: A batch of data from the DataLoader. Typically a tuple containing\n            input tensors and corresponding target tensors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_batch_end","title":"<code>on_train_batch_end(train_batch_loss_metrics)</code>","text":"<p>Called at the end of each training batch.</p> PARAMETER DESCRIPTION <code>train_batch_loss_metrics</code> <p>Metrics for the training batch loss. tuple of (loss, metrics)</p> <p> TYPE: <code>tuple[Tensor, Any]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_batch_end(self, train_batch_loss_metrics: tuple[torch.Tensor, Any]) -&gt; None:\n    \"\"\"\n    Called at the end of each training batch.\n\n    Args:\n        train_batch_loss_metrics: Metrics for the training batch loss.\n            tuple of (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_batch_start","title":"<code>on_train_batch_start(batch)</code>","text":"<p>Called at the start of each training batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>A batch of data from the DataLoader. Typically a tuple containing input tensors and corresponding target tensors.</p> <p> TYPE: <code>tuple[Tensor, ...] | None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_batch_start(self, batch: tuple[torch.Tensor, ...] | None) -&gt; None:\n    \"\"\"\n    Called at the start of each training batch.\n\n    Args:\n        batch: A batch of data from the DataLoader. Typically a tuple containing\n            input tensors and corresponding target tensors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_end","title":"<code>on_train_end(train_losses, val_losses=None)</code>","text":"<p>Called at the end of training.</p> PARAMETER DESCRIPTION <code>train_losses</code> <p>Metrics for the training losses. list    -&gt; list                  -&gt; tuples Epochs  -&gt; Training Batches      -&gt; (loss, metrics)</p> <p> TYPE: <code>list[list[tuple[Tensor, Any]]]</code> </p> <code>val_losses</code> <p>Metrics for the validation losses. list    -&gt; list                  -&gt; tuples Epochs  -&gt; Validation Batches    -&gt; (loss, metrics)</p> <p> TYPE: <code>list[list[tuple[Tensor, Any]]] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_end(\n    self,\n    train_losses: list[list[tuple[torch.Tensor, Any]]],\n    val_losses: list[list[tuple[torch.Tensor, Any]]] | None = None,\n) -&gt; None:\n    \"\"\"\n    Called at the end of training.\n\n    Args:\n        train_losses (list[list[tuple[torch.Tensor, Any]]]):\n            Metrics for the training losses.\n            list    -&gt; list                  -&gt; tuples\n            Epochs  -&gt; Training Batches      -&gt; (loss, metrics)\n        val_losses (list[list[tuple[torch.Tensor, Any]]] | None):\n            Metrics for the validation losses.\n            list    -&gt; list                  -&gt; tuples\n            Epochs  -&gt; Validation Batches    -&gt; (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_epoch_end","title":"<code>on_train_epoch_end(train_epoch_loss_metrics)</code>","text":"<p>Called at the end of each training epoch.</p> PARAMETER DESCRIPTION <code>train_epoch_loss_metrics</code> <p>Metrics for the training epoch losses. list                  -&gt; tuples Training Batches      -&gt; (loss, metrics)</p> <p> TYPE: <code>list[tuple[Tensor, Any]]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_epoch_end(self, train_epoch_loss_metrics: list[tuple[torch.Tensor, Any]]) -&gt; None:\n    \"\"\"\n    Called at the end of each training epoch.\n\n    Args:\n        train_epoch_loss_metrics: Metrics for the training epoch losses.\n            list                  -&gt; tuples\n            Training Batches      -&gt; (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_epoch_start","title":"<code>on_train_epoch_start()</code>","text":"<p>Called at the start of each training epoch.</p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_epoch_start(self) -&gt; None:\n    \"\"\"Called at the start of each training epoch.\"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_start","title":"<code>on_train_start()</code>","text":"<p>Called at the start of training.</p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_start(self) -&gt; None:\n    \"\"\"Called at the start of training.\"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_batch_end","title":"<code>on_val_batch_end(val_batch_loss_metrics)</code>","text":"<p>Called at the end of each validation batch.</p> PARAMETER DESCRIPTION <code>val_batch_loss_metrics</code> <p>Metrics for the validation batch loss. tuple of (loss, metrics)</p> <p> TYPE: <code>tuple[Tensor, Any]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_batch_end(self, val_batch_loss_metrics: tuple[torch.Tensor, Any]) -&gt; None:\n    \"\"\"\n    Called at the end of each validation batch.\n\n    Args:\n        val_batch_loss_metrics: Metrics for the validation batch loss.\n            tuple of (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_batch_start","title":"<code>on_val_batch_start(batch)</code>","text":"<p>Called at the start of each validation batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>A batch of data from the DataLoader. Typically a tuple containing input tensors and corresponding target tensors.</p> <p> TYPE: <code>tuple[Tensor, ...] | None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_batch_start(self, batch: tuple[torch.Tensor, ...] | None) -&gt; None:\n    \"\"\"\n    Called at the start of each validation batch.\n\n    Args:\n        batch: A batch of data from the DataLoader. Typically a tuple containing\n            input tensors and corresponding target tensors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_epoch_end","title":"<code>on_val_epoch_end(val_epoch_loss_metrics)</code>","text":"<p>Called at the end of each validation epoch.</p> PARAMETER DESCRIPTION <code>val_epoch_loss_metrics</code> <p>Metrics for the validation epoch loss. list                    -&gt; tuples Validation Batches      -&gt; (loss, metrics)</p> <p> TYPE: <code>list[tuple[Tensor, Any]]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_epoch_end(self, val_epoch_loss_metrics: list[tuple[torch.Tensor, Any]]) -&gt; None:\n    \"\"\"\n    Called at the end of each validation epoch.\n\n    Args:\n        val_epoch_loss_metrics: Metrics for the validation epoch loss.\n            list                    -&gt; tuples\n            Validation Batches      -&gt; (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_epoch_start","title":"<code>on_val_epoch_start()</code>","text":"<p>Called at the start of each validation epoch.</p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_epoch_start(self) -&gt; None:\n    \"\"\"Called at the start of each validation epoch.\"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.set_use_grad","title":"<code>set_use_grad(value)</code>  <code>classmethod</code>","text":"<p>Sets the global use_grad flag.</p> PARAMETER DESCRIPTION <code>value</code> <p>Whether to use gradient-based optimization.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@classmethod\ndef set_use_grad(cls, value: bool) -&gt; None:\n    \"\"\"\n    Sets the global use_grad flag.\n\n    Args:\n        value (bool): Whether to use gradient-based optimization.\n    \"\"\"\n    if not isinstance(value, bool):\n        raise TypeError(\"use_grad must be a boolean value.\")\n    cls._use_grad = value\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter","title":"<code>BaseWriter</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for experiment tracking writers.</p> METHOD DESCRIPTION <code>open</code> <p>Opens the writer and sets up the logging environment.</p> <code>close</code> <p>Closes the writer and finalizes any ongoing logging processes.</p> <code>print_metrics</code> <p>Prints metrics and loss in a formatted manner.</p> <code>write</code> <p>Writes the optimization results to the tracking tool.</p> <code>log_hyperparams</code> <p>Logs the hyperparameters to the tracking tool.</p> <code>plot</code> <p>Logs model plots using provided plotting functions.</p> <code>log_model</code> <p>Logs the model and any relevant information.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.close","title":"<code>close()</code>  <code>abstractmethod</code>","text":"<p>Closes the writer and finalizes logging.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef close(self) -&gt; None:\n    \"\"\"Closes the writer and finalizes logging.\"\"\"\n    raise NotImplementedError(\"Writers must implement a close method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.log_hyperparams","title":"<code>log_hyperparams(hyperparams)</code>  <code>abstractmethod</code>","text":"<p>Logs hyperparameters.</p> PARAMETER DESCRIPTION <code>hyperparams</code> <p>A dictionary of hyperparameters to log.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef log_hyperparams(self, hyperparams: dict) -&gt; None:\n    \"\"\"\n    Logs hyperparameters.\n\n    Args:\n        hyperparams (dict): A dictionary of hyperparameters to log.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a log_hyperparams method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.log_model","title":"<code>log_model(model, train_dataloader=None, val_dataloader=None, test_dataloader=None)</code>  <code>abstractmethod</code>","text":"<p>Logs the model and associated data.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to log.</p> <p> TYPE: <code>Module</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef log_model(\n    self,\n    model: Module,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; None:\n    \"\"\"\n    Logs the model and associated data.\n\n    Args:\n        model (Module): The model to log.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a log_model method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.open","title":"<code>open(config, iteration=None)</code>  <code>abstractmethod</code>","text":"<p>Opens the writer and prepares it for logging.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object containing settings for logging.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>iteration</code> <p>The iteration step to start logging from. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef open(self, config: TrainConfig, iteration: int | None = None) -&gt; Any:\n    \"\"\"\n    Opens the writer and prepares it for logging.\n\n    Args:\n        config: Configuration object containing settings for logging.\n        iteration (int, optional): The iteration step to start logging from.\n            Defaults to None.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement an open method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.plot","title":"<code>plot(model, iteration, plotting_functions)</code>  <code>abstractmethod</code>","text":"<p>Logs plots of the model using provided plotting functions.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to plot.</p> <p> TYPE: <code>Module</code> </p> <code>iteration</code> <p>The current iteration number.</p> <p> TYPE: <code>int</code> </p> <code>plotting_functions</code> <p>Functions used to generate plots.</p> <p> TYPE: <code>tuple[PlottingFunction, ...]</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef plot(\n    self,\n    model: Module,\n    iteration: int,\n    plotting_functions: tuple[PlottingFunction, ...],\n) -&gt; None:\n    \"\"\"\n    Logs plots of the model using provided plotting functions.\n\n    Args:\n        model (Module): The model to plot.\n        iteration (int): The current iteration number.\n        plotting_functions (tuple[PlottingFunction, ...]): Functions used to\n            generate plots.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a plot method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.print_metrics","title":"<code>print_metrics(result)</code>","text":"<p>Prints the metrics and loss in a readable format.</p> PARAMETER DESCRIPTION <code>result</code> <p>The optimization results to display.</p> <p> TYPE: <code>OptimizeResult</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def print_metrics(self, result: OptimizeResult) -&gt; None:\n    \"\"\"Prints the metrics and loss in a readable format.\n\n    Args:\n        result (OptimizeResult): The optimization results to display.\n    \"\"\"\n\n    # Find the key in result.metrics that contains \"loss\" (case-insensitive)\n    loss_key = next((k for k in result.metrics if \"loss\" in k.lower()), None)\n    initial = f\"P {result.rank: &gt;2}|{result.device: &lt;7}| Iteration {result.iteration: &gt;7}| \"\n    if loss_key:\n        loss_value = result.metrics[loss_key]\n        msg = initial + f\"{loss_key.title()}: {loss_value:.7f} -\"\n    else:\n        msg = initial + f\"Loss: None -\"\n    msg += \" \".join([f\"{k}: {v:.7f}\" for k, v in result.metrics.items() if k != loss_key])\n    print(msg)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.write","title":"<code>write(iteration, metrics)</code>  <code>abstractmethod</code>","text":"<p>Logs the results of the current iteration.</p> PARAMETER DESCRIPTION <code>iteration</code> <p>The current training iteration.</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>A dictionary of metrics to log, where keys are metric names             and values are the corresponding metric values.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef write(self, iteration: int, metrics: dict) -&gt; None:\n    \"\"\"\n    Logs the results of the current iteration.\n\n    Args:\n        iteration (int): The current training iteration.\n        metrics (dict): A dictionary of metrics to log, where keys are metric names\n                        and values are the corresponding metric values.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a write method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter","title":"<code>MLFlowWriter()</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for logging to MLflow.</p> ATTRIBUTE DESCRIPTION <code>run</code> <p>The active MLflow run.</p> <p> TYPE: <code>Run</code> </p> <code>mlflow</code> <p>The MLflow module.</p> <p> TYPE: <code>ModuleType</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def __init__(self) -&gt; None:\n    try:\n        from mlflow.entities import Run\n    except ImportError:\n        raise ImportError(\n            \"mlflow is not installed. Please install qadence with the mlflow feature: \"\n            \"`pip install qadence[mlflow]`.\"\n        )\n\n    self.run: Run\n    self.mlflow: ModuleType\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.close","title":"<code>close()</code>","text":"<p>Closes the MLflow run.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Closes the MLflow run.\"\"\"\n    if self.run:\n        self.mlflow.end_run()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.get_signature_from_dataloader","title":"<code>get_signature_from_dataloader(model, dataloader)</code>","text":"<p>Infers the signature of the model based on the input data from the dataloader.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to use for inference.</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>DataLoader for model inputs.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Optional[Any]: The inferred signature, if available.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def get_signature_from_dataloader(\n    self, model: Module, dataloader: DataLoader | DictDataLoader | None\n) -&gt; Any:\n    \"\"\"\n    Infers the signature of the model based on the input data from the dataloader.\n\n    Args:\n        model (Module): The model to use for inference.\n        dataloader (DataLoader | DictDataLoader |  None): DataLoader for model inputs.\n\n    Returns:\n        Optional[Any]: The inferred signature, if available.\n    \"\"\"\n    from mlflow.models import infer_signature\n\n    if dataloader is None:\n        return None\n\n    xs: InputData\n    xs, *_ = next(iter(dataloader))\n    preds = model(xs)\n\n    if isinstance(xs, Tensor):\n        xs = xs.detach().cpu().numpy()\n        preds = preds.detach().cpu().numpy()\n        return infer_signature(xs, preds)\n\n    return None\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.log_hyperparams","title":"<code>log_hyperparams(hyperparams)</code>","text":"<p>Logs hyperparameters to MLflow.</p> PARAMETER DESCRIPTION <code>hyperparams</code> <p>A dictionary of hyperparameters to log.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_hyperparams(self, hyperparams: dict) -&gt; None:\n    \"\"\"\n    Logs hyperparameters to MLflow.\n\n    Args:\n        hyperparams (dict): A dictionary of hyperparameters to log.\n    \"\"\"\n    if self.mlflow:\n        self.mlflow.log_params(hyperparams)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.log_model","title":"<code>log_model(model, train_dataloader=None, val_dataloader=None, test_dataloader=None)</code>","text":"<p>Logs the model and its signature to MLflow using the provided data loaders.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to log.</p> <p> TYPE: <code>Module</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_model(\n    self,\n    model: Module,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; None:\n    \"\"\"\n    Logs the model and its signature to MLflow using the provided data loaders.\n\n    Args:\n        model (Module): The model to log.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.\n    \"\"\"\n    if not self.mlflow:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n\n    signatures = self.get_signature_from_dataloader(model, train_dataloader)\n    self.mlflow.pytorch.log_model(model, artifact_path=\"model\", signature=signatures)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.open","title":"<code>open(config, iteration=None)</code>","text":"<p>Opens the MLflow writer and initializes an MLflow run.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object containing settings for logging.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>iteration</code> <p>The iteration step to start logging from. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>mlflow</code> <p>The MLflow module instance.</p> <p> TYPE: <code>ModuleType | None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def open(self, config: TrainConfig, iteration: int | None = None) -&gt; ModuleType | None:\n    \"\"\"\n    Opens the MLflow writer and initializes an MLflow run.\n\n    Args:\n        config: Configuration object containing settings for logging.\n        iteration (int, optional): The iteration step to start logging from.\n            Defaults to None.\n\n    Returns:\n        mlflow: The MLflow module instance.\n    \"\"\"\n    import mlflow\n\n    self.mlflow = mlflow\n    tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"\")\n    experiment_name = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", str(uuid4()))\n    run_name = os.getenv(\"MLFLOW_RUN_NAME\", str(uuid4()))\n\n    if self.mlflow:\n        self.mlflow.set_tracking_uri(tracking_uri)\n\n        # Create or get the experiment\n        exp_filter_string = f\"name = '{experiment_name}'\"\n        experiments = self.mlflow.search_experiments(filter_string=exp_filter_string)\n        if not experiments:\n            self.mlflow.create_experiment(name=experiment_name)\n\n        self.mlflow.set_experiment(experiment_name)\n        self.run = self.mlflow.start_run(run_name=run_name, nested=False)\n\n    return self.mlflow\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.plot","title":"<code>plot(model, iteration, plotting_functions)</code>","text":"<p>Logs plots of the model using provided plotting functions.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to plot.</p> <p> TYPE: <code>Module</code> </p> <code>iteration</code> <p>The current iteration number.</p> <p> TYPE: <code>int</code> </p> <code>plotting_functions</code> <p>Functions used to generate plots.</p> <p> TYPE: <code>tuple[PlottingFunction, ...]</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def plot(\n    self,\n    model: Module,\n    iteration: int,\n    plotting_functions: tuple[PlottingFunction, ...],\n) -&gt; None:\n    \"\"\"\n    Logs plots of the model using provided plotting functions.\n\n    Args:\n        model (Module): The model to plot.\n        iteration (int): The current iteration number.\n        plotting_functions (tuple[PlottingFunction, ...]): Functions used\n            to generate plots.\n    \"\"\"\n    if self.mlflow:\n        for pf in plotting_functions:\n            descr, fig = pf(model, iteration)\n            self.mlflow.log_figure(fig, descr)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.write","title":"<code>write(iteration, metrics)</code>","text":"<p>Logs the results of the current iteration to MLflow.</p> PARAMETER DESCRIPTION <code>iteration</code> <p>The current training iteration.</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>A dictionary of metrics to log, where keys are metric names             and values are the corresponding metric values.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def write(self, iteration: int, metrics: dict) -&gt; None:\n    \"\"\"\n    Logs the results of the current iteration to MLflow.\n\n    Args:\n        iteration (int): The current training iteration.\n        metrics (dict): A dictionary of metrics to log, where keys are metric names\n                        and values are the corresponding metric values.\n    \"\"\"\n    if self.mlflow:\n        self.mlflow.log_metrics(metrics, step=iteration)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing.\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter","title":"<code>TensorBoardWriter()</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for logging to TensorBoard.</p> ATTRIBUTE DESCRIPTION <code>writer</code> <p>The TensorBoard SummaryWriter instance.</p> <p> TYPE: <code>SummaryWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.writer = None\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.close","title":"<code>close()</code>","text":"<p>Closes the TensorBoard writer.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Closes the TensorBoard writer.\"\"\"\n    if self.writer:\n        self.writer.close()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.log_hyperparams","title":"<code>log_hyperparams(hyperparams)</code>","text":"<p>Logs hyperparameters to TensorBoard.</p> PARAMETER DESCRIPTION <code>hyperparams</code> <p>A dictionary of hyperparameters to log.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_hyperparams(self, hyperparams: dict) -&gt; None:\n    \"\"\"\n    Logs hyperparameters to TensorBoard.\n\n    Args:\n        hyperparams (dict): A dictionary of hyperparameters to log.\n    \"\"\"\n    if self.writer:\n        self.writer.add_hparams(hyperparams, {})\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.log_model","title":"<code>log_model(model, train_dataloader=None, val_dataloader=None, test_dataloader=None)</code>","text":"<p>Logs the model.</p> <p>Currently not supported by TensorBoard.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to log.</p> <p> TYPE: <code>Module</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_model(\n    self,\n    model: Module,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; None:\n    \"\"\"\n    Logs the model.\n\n    Currently not supported by TensorBoard.\n\n    Args:\n        model (Module): The model to log.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.\n    \"\"\"\n    logger.warning(\"Model logging is not supported by tensorboard. No model will be logged.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.open","title":"<code>open(config, iteration=None)</code>","text":"<p>Opens the TensorBoard writer.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object containing settings for logging.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>iteration</code> <p>The iteration step to start logging from. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SummaryWriter</code> <p>The initialized TensorBoard writer.</p> <p> TYPE: <code>SummaryWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def open(self, config: TrainConfig, iteration: int | None = None) -&gt; SummaryWriter:\n    \"\"\"\n    Opens the TensorBoard writer.\n\n    Args:\n        config: Configuration object containing settings for logging.\n        iteration (int, optional): The iteration step to start logging from.\n            Defaults to None.\n\n    Returns:\n        SummaryWriter: The initialized TensorBoard writer.\n    \"\"\"\n    log_dir = str(config.log_folder)\n    purge_step = iteration if isinstance(iteration, int) else None\n    self.writer = SummaryWriter(log_dir=log_dir, purge_step=purge_step)\n    return self.writer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.plot","title":"<code>plot(model, iteration, plotting_functions)</code>","text":"<p>Logs plots of the model using provided plotting functions.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to plot.</p> <p> TYPE: <code>Module</code> </p> <code>iteration</code> <p>The current iteration number.</p> <p> TYPE: <code>int</code> </p> <code>plotting_functions</code> <p>Functions used to generate plots.</p> <p> TYPE: <code>tuple[PlottingFunction, ...]</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def plot(\n    self,\n    model: Module,\n    iteration: int,\n    plotting_functions: tuple[PlottingFunction, ...],\n) -&gt; None:\n    \"\"\"\n    Logs plots of the model using provided plotting functions.\n\n    Args:\n        model (Module): The model to plot.\n        iteration (int): The current iteration number.\n        plotting_functions (tuple[PlottingFunction, ...]): Functions used\n            to generate plots.\n    \"\"\"\n    if self.writer:\n        for pf in plotting_functions:\n            descr, fig = pf(model, iteration)\n            self.writer.add_figure(descr, fig, global_step=iteration)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.write","title":"<code>write(iteration, metrics)</code>","text":"<p>Logs the results of the current iteration to TensorBoard.</p> PARAMETER DESCRIPTION <code>iteration</code> <p>The current training iteration.</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>A dictionary of metrics to log, where keys are metric names             and values are the corresponding metric values.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def write(self, iteration: int, metrics: dict) -&gt; None:\n    \"\"\"\n    Logs the results of the current iteration to TensorBoard.\n\n    Args:\n        iteration (int): The current training iteration.\n        metrics (dict): A dictionary of metrics to log, where keys are metric names\n                        and values are the corresponding metric values.\n    \"\"\"\n    if self.writer:\n        for key, value in metrics.items():\n            self.writer.add_scalar(key, value, iteration)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing.\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.get_writer","title":"<code>get_writer(tracking_tool)</code>","text":"<p>Factory method to get the appropriate writer based on the tracking tool.</p> PARAMETER DESCRIPTION <code>tracking_tool</code> <p>The experiment tracking tool to use.</p> <p> TYPE: <code>ExperimentTrackingTool</code> </p> RETURNS DESCRIPTION <code>BaseWriter</code> <p>An instance of the appropriate writer.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def get_writer(tracking_tool: ExperimentTrackingTool) -&gt; BaseWriter:\n    \"\"\"Factory method to get the appropriate writer based on the tracking tool.\n\n    Args:\n        tracking_tool (ExperimentTrackingTool): The experiment tracking tool to use.\n\n    Returns:\n        BaseWriter: An instance of the appropriate writer.\n    \"\"\"\n    writer_class = WRITER_REGISTRY.get(tracking_tool)\n    if writer_class:\n        return writer_class()\n    else:\n        raise ValueError(f\"Unsupported tracking tool: {tracking_tool}\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent","title":"<code>InformationContent(model, loss_fn, xs, epsilons, variation_multiple=20)</code>","text":"<p>Information Landscape class.</p> <p>This class handles the study of loss landscape from information theoretic perspective and provides methods to get bounds on the norm of the gradient from the Information Content of the loss landscape.</p> PARAMETER DESCRIPTION <code>model</code> <p>The quantum or classical model to analyze.</p> <p> TYPE: <code>Module</code> </p> <code>loss_fn</code> <p>Loss function that takes model output and calculates loss</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>Input data to evaluate the model on</p> <p> TYPE: <code>Any</code> </p> <code>epsilons</code> <p>The thresholds to use for discretization of the finite derivatives</p> <p> TYPE: <code>Tensor</code> </p> <code>variation_multiple</code> <p>The number of sets of variational parameters to generate per each variational parameter. The number of variational parameters required for the statistical analysis scales linearly with the amount of them present in the model. This is that linear factor.</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> Notes <p>This class provides flexibility in terms of what the model, the loss function, and the xs are. The only requirement is that the loss_fn takes the model and xs as arguments and returns the loss, and another dictionary of other metrics.</p> <p>Thus, assumed structure:     loss_fn(model, xs) -&gt; (loss, metrics, ...)</p> <p>Example: A Classifier     <pre><code>model = nn.Linear(10, 1)\n\ndef loss_fn(\n    model: nn.Module,\n    xs: tuple[torch.Tensor, torch.Tensor]\n) -&gt; tuple[torch.Tensor, dict[str, float]:\n    criterion = nn.MSELoss()\n    inputs, labels = xs\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    metrics = {\"loss\": loss.item()}\n    return loss, metrics\n\nxs = (torch.randn(10, 10), torch.randn(10, 1))\n\ninfo_landscape = InfoLandscape(model, loss_fn, xs)\n</code></pre>     In this example, the model is a linear classifier, and the <code>xs</code> include both the     inputs and the target labels. The logic for calculation of the loss from this lies     entirely within the <code>loss_fn</code> function. This can then further be used to obtain the     bounds on the average norm of the gradient of the loss function.</p> <p>Example: A Physics Informed Neural Network     <pre><code>class PhysicsInformedNN(nn.Module):\n    // &lt;Initialization Logic&gt;\n\n    def forward(self, xs: dict[str, torch.Tensor]):\n        return {\n            \"pde_residual\": pde_residual(xs[\"pde\"]),\n            \"boundary_condition\": bc_term(xs[\"bc\"]),\n        }\n\ndef loss_fn(\n    model: PhysicsInformedNN,\n    xs: dict[str, torch.Tensor]\n) -&gt; tuple[torch.Tensor, dict[str, float]:\n    pde_residual, bc_term = model(xs)\n    loss = torch.mean(torch.sum(pde_residual**2, dim=1), dim=0)\n        + torch.mean(torch.sum(bc_term**2, dim=1), dim=0)\n\n    return loss, {\"pde_residual\": pde_residual, \"bc_term\": bc_term}\n\nxs = {\n    \"pde\": torch.linspace(0, 1, 10),\n    \"bc\": torch.tensor([0.0]),\n}\n\ninfo_landscape = InfoLandscape(model, loss_fn, xs)\n</code></pre></p> <pre><code>In this example, the model is a Physics Informed Neural Network, and the `xs`\nare the inputs to the different residual components of the model. The logic\nfor calculation of the residuals lies within the PhysicsInformedNN class, and\nthe loss function is defined to calculate the loss that is to be optimized\nfrom these residuals. This can then further be used to obtain the\nbounds on the average norm of the gradient of the loss function.\n</code></pre> <p>The first value that the <code>loss_fn</code> returns is the loss value that is being optimized. The function is also expected to return other value(s), often the metrics that are used to calculate the loss. These values are ignored for the purpose of this class.</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def __init__(\n    self,\n    model: nn.Module,\n    loss_fn: Callable,\n    xs: Any,\n    epsilons: torch.Tensor,\n    variation_multiple: int = 20,\n) -&gt; None:\n    \"\"\"Information Landscape class.\n\n    This class handles the study of loss landscape from information theoretic\n    perspective and provides methods to get bounds on the norm of the\n    gradient from the Information Content of the loss landscape.\n\n    Args:\n        model: The quantum or classical model to analyze.\n        loss_fn: Loss function that takes model output and calculates loss\n        xs: Input data to evaluate the model on\n        epsilons: The thresholds to use for discretization of the finite derivatives\n        variation_multiple: The number of sets of variational parameters to generate per each\n            variational parameter. The number of variational parameters required for the\n            statistical analysis scales linearly with the amount of them present in the\n            model. This is that linear factor.\n\n    Notes:\n        This class provides flexibility in terms of what the model, the loss function,\n        and the xs are. The only requirement is that the loss_fn takes the model and xs as\n        arguments and returns the loss, and another dictionary of other metrics.\n\n        Thus, assumed structure:\n            loss_fn(model, xs) -&gt; (loss, metrics, ...)\n\n        Example: A Classifier\n            ```python\n            model = nn.Linear(10, 1)\n\n            def loss_fn(\n                model: nn.Module,\n                xs: tuple[torch.Tensor, torch.Tensor]\n            ) -&gt; tuple[torch.Tensor, dict[str, float]:\n                criterion = nn.MSELoss()\n                inputs, labels = xs\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                metrics = {\"loss\": loss.item()}\n                return loss, metrics\n\n            xs = (torch.randn(10, 10), torch.randn(10, 1))\n\n            info_landscape = InfoLandscape(model, loss_fn, xs)\n            ```\n            In this example, the model is a linear classifier, and the `xs` include both the\n            inputs and the target labels. The logic for calculation of the loss from this lies\n            entirely within the `loss_fn` function. This can then further be used to obtain the\n            bounds on the average norm of the gradient of the loss function.\n\n        Example: A Physics Informed Neural Network\n            ```python\n            class PhysicsInformedNN(nn.Module):\n                // &lt;Initialization Logic&gt;\n\n                def forward(self, xs: dict[str, torch.Tensor]):\n                    return {\n                        \"pde_residual\": pde_residual(xs[\"pde\"]),\n                        \"boundary_condition\": bc_term(xs[\"bc\"]),\n                    }\n\n            def loss_fn(\n                model: PhysicsInformedNN,\n                xs: dict[str, torch.Tensor]\n            ) -&gt; tuple[torch.Tensor, dict[str, float]:\n                pde_residual, bc_term = model(xs)\n                loss = torch.mean(torch.sum(pde_residual**2, dim=1), dim=0)\n                    + torch.mean(torch.sum(bc_term**2, dim=1), dim=0)\n\n                return loss, {\"pde_residual\": pde_residual, \"bc_term\": bc_term}\n\n            xs = {\n                \"pde\": torch.linspace(0, 1, 10),\n                \"bc\": torch.tensor([0.0]),\n            }\n\n            info_landscape = InfoLandscape(model, loss_fn, xs)\n            ```\n\n            In this example, the model is a Physics Informed Neural Network, and the `xs`\n            are the inputs to the different residual components of the model. The logic\n            for calculation of the residuals lies within the PhysicsInformedNN class, and\n            the loss function is defined to calculate the loss that is to be optimized\n            from these residuals. This can then further be used to obtain the\n            bounds on the average norm of the gradient of the loss function.\n\n        The first value that the `loss_fn` returns is the loss value that is being optimized.\n        The function is also expected to return other value(s), often the metrics that are\n        used to calculate the loss. These values are ignored for the purpose of this class.\n    \"\"\"\n    self.model = model\n    self.loss_fn = loss_fn\n    self.xs = xs\n    self.epsilons = epsilons\n    self.device = next(model.parameters()).device\n\n    self.param_shapes = {}\n    self.total_params = 0\n\n    for name, param in model.named_parameters():\n        self.param_shapes[name] = param.shape\n        self.total_params += param.numel()\n    self.n_variations = variation_multiple * self.total_params\n    self.all_variations = torch.empty(\n        (self.n_variations, self.total_params), device=self.device\n    ).uniform_(0, 2 * torch.pi)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.calculate_IC","title":"<code>calculate_IC</code>  <code>cached</code> <code>property</code>","text":"<p>Calculate Information Content for multiple epsilon values.</p> <p>Returns: Tensor of IC values for each epsilon [n_epsilons]</p>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.batched_loss","title":"<code>batched_loss()</code>","text":"<p>Calculate loss for all parameter variations in a batched manner.</p> <p>Returns: Tensor of loss values for each parameter variation</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def batched_loss(self) -&gt; torch.Tensor:\n    \"\"\"Calculate loss for all parameter variations in a batched manner.\n\n    Returns: Tensor of loss values for each parameter variation\n    \"\"\"\n    param_variations = self.reshape_param_variations()\n    losses = torch.zeros(self.n_variations, device=self.device)\n\n    for i in range(self.n_variations):\n        params = {name: param[i] for name, param in param_variations.items()}\n        current_model = lambda x: functional_call(self.model, params, (x,))\n        losses[i] = self.loss_fn(current_model, self.xs)[0]\n\n    return losses\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.calculate_transition_probabilities_batch","title":"<code>calculate_transition_probabilities_batch()</code>","text":"<p>Calculate transition probabilities for multiple epsilon values.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor of shape [n_epsilons, 6] containing probabilities for each transition type</p> <code>Tensor</code> <p>Columns order: [+1to0, +1to-1, 0to+1, 0to-1, -1to0, -1to+1]</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def calculate_transition_probabilities_batch(self) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate transition probabilities for multiple epsilon values.\n\n    Returns:\n        Tensor of shape [n_epsilons, 6] containing probabilities for each transition type\n        Columns order: [+1to0, +1to-1, 0to+1, 0to-1, -1to0, -1to+1]\n    \"\"\"\n    discretized = self.discretize_derivatives()\n\n    current = discretized[:, :-1]\n    next_val = discretized[:, 1:]\n\n    transitions = torch.stack(\n        [\n            ((current == 1) &amp; (next_val == 0)).sum(dim=1),\n            ((current == 1) &amp; (next_val == -1)).sum(dim=1),\n            ((current == 0) &amp; (next_val == 1)).sum(dim=1),\n            ((current == 0) &amp; (next_val == -1)).sum(dim=1),\n            ((current == -1) &amp; (next_val == 0)).sum(dim=1),\n            ((current == -1) &amp; (next_val == 1)).sum(dim=1),\n        ],\n        dim=1,\n    ).float()\n\n    total_transitions = current.size(1)\n    probabilities = transitions / total_transitions\n\n    return probabilities\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.discretize_derivatives","title":"<code>discretize_derivatives()</code>","text":"<p>Convert finite derivatives into discrete values.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor containing discretized derivatives with shape [n_epsilons, n_variations-2]</p> <code>Tensor</code> <p>Each row contains {-1, 0, 1} values for that epsilon</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def discretize_derivatives(self) -&gt; torch.Tensor:\n    \"\"\"\n    Convert finite derivatives into discrete values.\n\n    Returns:\n        Tensor containing discretized derivatives with shape [n_epsilons, n_variations-2]\n        Each row contains {-1, 0, 1} values for that epsilon\n    \"\"\"\n    derivatives = self.randomized_finite_der()\n\n    derivatives = derivatives.unsqueeze(0)\n    epsilons = self.epsilons.unsqueeze(1)\n\n    discretized = torch.zeros((len(epsilons), len(derivatives[0])), device=self.device)\n    discretized[derivatives &gt; epsilons] = 1\n    discretized[derivatives &lt; -epsilons] = -1\n\n    return discretized\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.get_grad_norm_bounds_max_IC","title":"<code>get_grad_norm_bounds_max_IC()</code>","text":"<p>Compute the bounds on the average norm of the gradient.</p> RETURNS DESCRIPTION <code>tuple[float, float]</code> <p>tuple[Tensor, Tensor]: The lower and upper bounds.</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def get_grad_norm_bounds_max_IC(self) -&gt; tuple[float, float]:\n    \"\"\"\n    Compute the bounds on the average norm of the gradient.\n\n    Returns:\n        tuple[Tensor, Tensor]: The lower and upper bounds.\n    \"\"\"\n    max_IC, epsilon_m = self.max_IC()\n    lower_bound = (\n        epsilon_m\n        * sqrt(self.total_params)\n        / (NormalDist().inv_cdf(1 - 2 * self.q_value(max_IC)))\n    )\n    upper_bound = (\n        epsilon_m\n        * sqrt(self.total_params)\n        / (NormalDist().inv_cdf(0.5 * (1 + 2 * self.q_value(max_IC))))\n    )\n\n    if max_IC &lt; log(2, 6):\n        logger.warning(\n            \"Warning: The maximum IC is less than the required value. The bounds may be\"\n            + \" inaccurate.\"\n        )\n\n    return lower_bound, upper_bound\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.get_grad_norm_bounds_sensitivity_IC","title":"<code>get_grad_norm_bounds_sensitivity_IC(eta)</code>","text":"<p>Compute the bounds on the average norm of the gradient.</p> PARAMETER DESCRIPTION <code>eta</code> <p>The sensitivity IC.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The lower bound.</p> <p> TYPE: <code>float</code> </p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def get_grad_norm_bounds_sensitivity_IC(self, eta: float) -&gt; float:\n    \"\"\"\n    Compute the bounds on the average norm of the gradient.\n\n    Args:\n        eta (float): The sensitivity IC.\n\n    Returns:\n        Tensor: The lower bound.\n    \"\"\"\n    epsilon_sensitivity = self.sensitivity_IC(eta)\n    upper_bound = (\n        epsilon_sensitivity * sqrt(self.total_params) / (NormalDist().inv_cdf(1 - 3 * eta / 2))\n    )\n    return upper_bound\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.max_IC","title":"<code>max_IC()</code>","text":"<p>Get the maximum Information Content and its corresponding epsilon.</p> <p>Returns: Tuple of (maximum IC value, optimal epsilon)</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def max_IC(self) -&gt; tuple[float, float]:\n    \"\"\"\n    Get the maximum Information Content and its corresponding epsilon.\n\n    Returns: Tuple of (maximum IC value, optimal epsilon)\n    \"\"\"\n    max_ic, max_idx = torch.max(self.calculate_IC, dim=0)\n    max_epsilon = self.epsilons[max_idx]\n    return max_ic.item(), max_epsilon.item()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.q_value","title":"<code>q_value(H_value)</code>  <code>cached</code> <code>staticmethod</code>","text":"<p>Compute the q value.</p> <p>q is the solution to the equation: H(x) = 4h(x) + 2h(1/2 - 2x)</p> <p>It is the value of the probability of 4 of the 6 transitions such that the IC is the same as the IC of our system.</p> <p>This quantity is useful in calculating the bounds on the norms of the gradients.</p> PARAMETER DESCRIPTION <code>H_value</code> <p>The information content.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>float</code> <p>The q value</p> <p> TYPE: <code>float</code> </p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>@staticmethod\n@functools.lru_cache\ndef q_value(H_value: float) -&gt; float:\n    \"\"\"\n    Compute the q value.\n\n    q is the solution to the equation:\n    H(x) = 4h(x) + 2h(1/2 - 2x)\n\n    It is the value of the probability of 4 of the 6 transitions such that\n    the IC is the same as the IC of our system.\n\n    This quantity is useful in calculating the bounds on the norms of the gradients.\n\n    Args:\n        H_value (float): The information content.\n\n    Returns:\n        float: The q value\n    \"\"\"\n\n    x = torch.linspace(0.001, 0.16667, 10000)\n\n    H = -4 * x * torch.log(x) / torch.log(torch.tensor(6)) - 2 * (0.5 - 2 * x) * torch.log(\n        0.5 - 2 * x\n    ) / torch.log(torch.tensor(6))\n    err = torch.abs(H - H_value)\n    idx = torch.argmin(err)\n    return float(x[idx].item())\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.randomized_finite_der","title":"<code>randomized_finite_der()</code>","text":"<p>Calculate normalized finite difference of loss on doing random walk in the parameter space.</p> <p>This serves as a proxy for the derivative of the loss with respect to parameters.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor containing normalized finite differences (approximate directional derivatives)</p> <code>Tensor</code> <p>between consecutive points in the random walk. Shape: [n_variations - 1]</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def randomized_finite_der(self) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate normalized finite difference of loss on doing random walk in the parameter space.\n\n    This serves as a proxy for the derivative of the loss with respect to parameters.\n\n    Returns:\n        Tensor containing normalized finite differences (approximate directional derivatives)\n        between consecutive points in the random walk. Shape: [n_variations - 1]\n    \"\"\"\n    losses = self.batched_loss()\n\n    return (losses[1:] - losses[:-1]) / (\n        torch.norm(self.all_variations[1:] - self.all_variations[:-1], dim=1) + 1e-8\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.reshape_param_variations","title":"<code>reshape_param_variations()</code>","text":"<p>Reshape variations of the model's variational parameters.</p> RETURNS DESCRIPTION <code>dict[str, Tensor]</code> <p>Dictionary of parameter tensors, each with shape [n_variations, *param_shape]</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def reshape_param_variations(self) -&gt; dict[str, torch.Tensor]:\n    \"\"\"Reshape variations of the model's variational parameters.\n\n    Returns:\n        Dictionary of parameter tensors, each with shape [n_variations, *param_shape]\n    \"\"\"\n    param_variations = {}\n    start_idx = 0\n\n    for name, shape in self.param_shapes.items():\n        param_size = torch.prod(torch.tensor(shape)).item()\n        param_variations[name] = self.all_variations[\n            :, start_idx : start_idx + param_size\n        ].view(self.n_variations, *shape)\n        start_idx += param_size\n\n    return param_variations\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.sensitivity_IC","title":"<code>sensitivity_IC(eta)</code>","text":"<p>Find the minimum value of epsilon such that the information content is less than eta.</p> PARAMETER DESCRIPTION <code>eta</code> <p>Threshold value, the sensitivity IC.</p> <p> TYPE: <code>float</code> </p> <p>Returns: The epsilon value that gives IC that is less than the sensitivity IC.</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def sensitivity_IC(self, eta: float) -&gt; float:\n    \"\"\"\n    Find the minimum value of epsilon such that the information content is less than eta.\n\n    Args:\n        eta: Threshold value, the sensitivity IC.\n\n    Returns: The epsilon value that gives IC that is less than the sensitivity IC.\n    \"\"\"\n    ic_values = self.calculate_IC\n    mask = ic_values &lt; eta\n    epsilons = self.epsilons[mask]\n    return float(epsilons.min().item())\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator","title":"<code>Accelerator(nprocs=1, compute_setup='auto', log_setup='cpu', backend='gloo', dtype=None)</code>","text":"<p>               Bases: <code>Distributor</code></p> <p>A class for handling distributed training.</p> <p>This class extends <code>Distributor</code> to manage distributed training using PyTorch's <code>torch.distributed</code> API. It supports spawning multiple processes and wrapping models with <code>DistributedDataParallel</code> (DDP) when required.</p> <p>This class is provides head level method - distribute() - which wraps a function at a head process level, before launching <code>nprocs</code> processes as required. Furthermore, it provides processes level methods, such as prepare(), and prepare_batch() which can be run inside each process for correct movement and preparation of model, optimizers and datasets.</p> Inherited Attributes <p>nprocs (int): Number of processes to launch for distributed training. execution (BaseExecution): Detected execution instance for process launch (e.g., \"torchrun\",\"default\"). execution_type (ExecutionType): Type of execution used. rank (int): Global rank of the process (to be set during environment setup). world_size (int): Total number of processes (to be set during environment setup). local_rank (int | None): Local rank on the node (to be set during environment setup). master_addr (str): Master node address (to be set during environment setup). master_port (str): Master node port (to be set during environment setup). node_rank (int): Rank of the node on the cluster setup.</p> There are three different indicators for number of processes executed. <ul> <li> <ol> <li>self._config_nprocs: Number of processes specified by the user. Provided in the initilization of the Accelerator. (acc = Accelerator(nprocs = 2))</li> </ol> </li> <li> <ol> <li>self.nprocs: Number of processes defined at the head level.</li> <li>When accelerator is used to spawn processes (e.g., In case default, python execution), nprocs = _config_nprocs.</li> <li>When an external elastic method is used to spawn processes (e.g., In case of torchrun), nprocs = 1. This is because the external launcher already spawns multiple processes, and the accelerator init is called from each process.</li> </ol> </li> <li> <ol> <li>self.world_size: Number of processes actually executed.</li> </ol> </li> </ul> <p>Initializes the Accelerator class.</p> PARAMETER DESCRIPTION <code>nprocs</code> <p>Number of processes to launch. Default is 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>compute_setup</code> <p>Compute device setup; options are \"auto\" (default), \"gpu\", or \"cpu\". - \"auto\": Uses GPU if available, otherwise CPU. - \"gpu\": Forces GPU usage, raising an error if no CUDA device is available. - \"cpu\": Forces CPU usage.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'auto'</code> </p> <code>log_setup</code> <p>Logging device setup; options are \"auto\", \"cpu\" (default). - \"auto\": Uses same device to log as used for computation. - \"cpu\": Forces CPU logging.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <code>backend</code> <p>The backend for distributed communication. Default is \"gloo\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gloo'</code> </p> <code>dtype</code> <p>Data type for controlling numerical precision. Default is None.</p> <p> TYPE: <code>dtype | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def __init__(\n    self,\n    nprocs: int = 1,\n    compute_setup: str = \"auto\",\n    log_setup: str = \"cpu\",\n    backend: str = \"gloo\",\n    dtype: torch_dtype | None = None,\n) -&gt; None:\n    \"\"\"\n    Initializes the Accelerator class.\n\n    Args:\n        nprocs (int): Number of processes to launch. Default is 1.\n        compute_setup (str): Compute device setup; options are \"auto\" (default), \"gpu\", or \"cpu\".\n            - \"auto\": Uses GPU if available, otherwise CPU.\n            - \"gpu\": Forces GPU usage, raising an error if no CUDA device is available.\n            - \"cpu\": Forces CPU usage.\n        log_setup (str): Logging device setup; options are \"auto\", \"cpu\" (default).\n            - \"auto\": Uses same device to log as used for computation.\n            - \"cpu\": Forces CPU logging.\n        backend (str): The backend for distributed communication. Default is \"gloo\".\n        dtype (torch.dtype | None): Data type for controlling numerical precision. Default is None.\n    \"\"\"\n    super().__init__(nprocs, compute_setup, log_setup, backend, dtype)\n\n    # Default values\n    self.rank = 0\n    self.local_rank = 0\n    self.world_size = self.execution.get_world_size(0, self.nprocs)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.all_reduce_dict","title":"<code>all_reduce_dict(d, op='mean')</code>","text":"<p>Performs an all-reduce operation on a dictionary of tensors, averaging values across all processes.</p> PARAMETER DESCRIPTION <code>d</code> <p>A dictionary where values are tensors to be reduced across processes.</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> <code>op</code> <p>Operation method to all_reduce with. Available options include <code>sum</code>, <code>avg</code>, and <code>max</code>.             Defaults to <code>avg</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>dict[str, Tensor]</code> <p>dict[str, torch.Tensor]: A dictionary with the reduced tensors, averaged over the world size.</p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def all_reduce_dict(\n    self, d: dict[str, torch.Tensor], op: str = \"mean\"\n) -&gt; dict[str, torch.Tensor]:\n    \"\"\"\n    Performs an all-reduce operation on a dictionary of tensors, averaging values across all processes.\n\n    Args:\n        d (dict[str, torch.Tensor]): A dictionary where values are tensors to be reduced across processes.\n        op (str): Operation method to all_reduce with. Available options include `sum`, `avg`, and `max`.\n                        Defaults to `avg`\n\n    Returns:\n        dict[str, torch.Tensor]: A dictionary with the reduced tensors, averaged over the world size.\n    \"\"\"\n    if dist.is_initialized():\n        world_size = dist.get_world_size()\n        reduced: dict[str, torch.Tensor] = {}\n        for key, tensor in d.items():\n            if not isinstance(tensor, torch.Tensor):\n                tensor = torch.tensor(\n                    tensor, device=self.execution.device, dtype=self.execution.data_dtype\n                )\n            tensor = tensor.detach().clone()\n            if op == \"max\":\n                dist.all_reduce(tensor, op=dist.ReduceOp.MAX)\n            elif op == \"sum\":\n                dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n            else:\n                dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n                tensor /= world_size\n            reduced[key] = tensor\n        return reduced\n    else:\n        return d\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.broadcast","title":"<code>broadcast(obj, src)</code>","text":"<p>Broadcasts an object from the source process to all processes.</p> <p>On non-source processes, this value is ignored.</p> PARAMETER DESCRIPTION <code>obj</code> <p>The object to broadcast on the source process.</p> <p> TYPE: <code>Any</code> </p> <code>src</code> <p>The source process rank.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The broadcasted object from the source process.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def broadcast(self, obj: Any, src: int) -&gt; Any:\n    \"\"\"\n    Broadcasts an object from the source process to all processes.\n\n    On non-source processes, this value is ignored.\n\n    Args:\n        obj (Any): The object to broadcast on the source process.\n        src (int): The source process rank.\n\n    Returns:\n        Any : The broadcasted object from the source process.\n    \"\"\"\n    if dist.is_initialized():\n        obj_list = [obj] if self.rank == src else [None]\n        dist.broadcast_object_list(obj_list, src=src)\n        return obj_list[0]\n    else:\n        return obj\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.distribute","title":"<code>distribute(fun)</code>","text":"<p>Decorator to distribute the fit function across multiple processes.</p> <p>This function is generic and can work with other methods as well. Weather it is bound or unbound.</p> <p>When applied to a function (typically a fit function), this decorator will execute the function in a distributed fashion using torch.multiprocessing. The number of processes used is determined by <code>self.nprocs</code>, and if multiple nodes are involved (<code>self.num_nodes &gt; 1</code>), the process count is adjusted accordingly. In single process mode (<code>self.nporcs</code> is 1), the function is executed directly in the current process.</p> <p>After execution, the decorator returns the model stored in <code>instance.model</code>.</p> PARAMETER DESCRIPTION <code>fun</code> <p>The function to be decorated. This function usually implements             a model fitting or training routine.</p> <p> TYPE: <code>callable</code> </p> RETURNS DESCRIPTION <code>callable</code> <p>The wrapped function. When called, it will execute in distributed mode       (if configured) and return the value of <code>instance.model</code>.</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def distribute(self, fun: Callable) -&gt; Callable:\n    \"\"\"\n    Decorator to distribute the fit function across multiple processes.\n\n    This function is generic and can work with other methods as well.\n    Weather it is bound or unbound.\n\n    When applied to a function (typically a fit function), this decorator\n    will execute the function in a distributed fashion using torch.multiprocessing.\n    The number of processes used is determined by `self.nprocs`,\n    and if multiple nodes are involved (`self.num_nodes &gt; 1`), the process count is\n    adjusted accordingly. In single process mode (`self.nporcs` is 1), the function\n    is executed directly in the current process.\n\n    After execution, the decorator returns the model stored in `instance.model`.\n\n    Parameters:\n        fun (callable): The function to be decorated. This function usually implements\n                        a model fitting or training routine.\n\n    Returns:\n        callable: The wrapped function. When called, it will execute in distributed mode\n                  (if configured) and return the value of `instance.model`.\n    \"\"\"\n\n    @functools.wraps(fun)\n    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n\n        # Get the original picklable function\n        # for the case of bound class method\n        # as well as a function\n        if self.is_class_method(fun, args):\n            instance = args[0]\n            method_name = fun.__name__\n            method = getattr(instance, method_name)\n            args = args[1:]\n            self._spawn_method(instance, method, args, kwargs)\n        else:\n            instance = None\n            # method_name = fun.__name__\n            # module = inspect.getmodule(fun)\n            # method = getattr(module, method_name) if module else fun\n            self._spawn_method(instance, fun, args, kwargs)\n\n        if instance and hasattr(instance, \"accelerator\"):\n            instance.accelerator.finalize()\n        else:\n            self.finalize()\n\n        # TODO: Return the original returns from fun\n        # Currently it only returns the model and optimizer\n        # similar to the fit method.\n        try:\n            return instance.model, instance.optimizer\n        except Exception:\n            return\n\n    return wrapper\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.is_class_method","title":"<code>is_class_method(fun, args)</code>","text":"<p>Determines if <code>fun</code> is a class method or a standalone function.</p> <p>Frist argument of the args should be: - An object and has dict: making it a class - Has a method named fun: making it a class that has this method.</p> PARAMETER DESCRIPTION <code>fun</code> <p>The function being checked.</p> <p> TYPE: <code>Callable</code> </p> <code>args</code> <p>The arguments passed to the function.</p> <p> TYPE: <code>tuple</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if <code>fun</code> is a class method, False otherwise.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def is_class_method(self, fun: Callable, args: Any) -&gt; bool:\n    \"\"\"\n    Determines if `fun` is a class method or a standalone function.\n\n    Frist argument of the args should be:\n    - An object and has __dict__: making it a class\n    - Has a method named fun: making it a class that has this method.\n\n    Args:\n        fun (Callable): The function being checked.\n        args (tuple): The arguments passed to the function.\n\n    Returns:\n        bool: True if `fun` is a class method, False otherwise.\n    \"\"\"\n    return (\n        bool(args)\n        and isinstance(args[0], object)\n        and hasattr(args[0], \"__dict__\")\n        and hasattr(args[0], fun.__name__)\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.prepare","title":"<code>prepare(*args)</code>","text":"<p>Prepares models, optimizers, and dataloaders for distributed training.</p> <p>This method iterates over the provided objects and: - Moves models to the specified device (e.g., GPU or CPU) and casts them to the     desired precision (specified by <code>self.dtype</code>). It then wraps models in     DistributedDataParallel (DDP) if more than one device is used. - Passes through optimizers unchanged. - For dataloaders, it adjusts them to use a distributed sampler (if applicable)     by calling a helper method. Note that only the sampler is prepared; moving the     actual batch data to the device is handled separately during training.     Please use the <code>prepare_batch</code> method to move the batch to correct device/dtype.</p> PARAMETER DESCRIPTION <code>*args</code> <p>A variable number of objects to be prepared. These can include: - PyTorch models (<code>nn.Module</code>) - Optimizers (<code>optim.Optimizer</code>) - DataLoaders (or a dictionary-like <code>DictDataLoader</code> of dataloaders)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>tuple[Any, ...]</code> <p>tuple[Any, ...]: A tuple containing the prepared objects, where each object has been             modified as needed to support distributed training.</p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def prepare(self, *args: Any) -&gt; tuple[Any, ...]:\n    \"\"\"\n    Prepares models, optimizers, and dataloaders for distributed training.\n\n    This method iterates over the provided objects and:\n    - Moves models to the specified device (e.g., GPU or CPU) and casts them to the\n        desired precision (specified by `self.dtype`). It then wraps models in\n        DistributedDataParallel (DDP) if more than one device is used.\n    - Passes through optimizers unchanged.\n    - For dataloaders, it adjusts them to use a distributed sampler (if applicable)\n        by calling a helper method. Note that only the sampler is prepared; moving the\n        actual batch data to the device is handled separately during training.\n        Please use the `prepare_batch` method to move the batch to correct device/dtype.\n\n    Args:\n        *args (Any): A variable number of objects to be prepared. These can include:\n            - PyTorch models (`nn.Module`)\n            - Optimizers (`optim.Optimizer`)\n            - DataLoaders (or a dictionary-like `DictDataLoader` of dataloaders)\n\n    Returns:\n        tuple[Any, ...]: A tuple containing the prepared objects, where each object has been\n                        modified as needed to support distributed training.\n    \"\"\"\n    prepared: list = []\n    for obj in args:\n        if obj is None:\n            prepared.append(None)\n        elif isinstance(obj, nn.Module):\n            prepared.append(self._prepare_model(obj))\n        elif isinstance(obj, optim.Optimizer):\n            prepared.append(self._prepare_optimizer(obj))\n        elif isinstance(obj, (DataLoader, DictDataLoader)):\n            prepared.append(self._prepare_data(obj))\n        else:\n            prepared.append(obj)\n    return tuple(prepared)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.prepare_batch","title":"<code>prepare_batch(batch)</code>","text":"<p>Moves a batch of data to the target device and casts it to the desired data dtype.</p> <p>This method is typically called within the optimization step of your training loop. It supports various batch formats:     - If the batch is a dictionary, each value is moved individually.     - If the batch is a tuple or list, each element is processed and returned as a tuple.     - Otherwise, the batch is processed directly.</p> PARAMETER DESCRIPTION <code>batch</code> <p>The batch of data to move to the device. This can be a dict, tuple, list,          or any type compatible with <code>data_to_device</code>.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The batch with all elements moved to <code>self.device</code> and cast to <code>self.data_dtype</code>.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def prepare_batch(self, batch: dict | list | tuple | torch.Tensor | None) -&gt; Any:\n    \"\"\"\n    Moves a batch of data to the target device and casts it to the desired data dtype.\n\n    This method is typically called within the optimization step of your training loop.\n    It supports various batch formats:\n        - If the batch is a dictionary, each value is moved individually.\n        - If the batch is a tuple or list, each element is processed and returned as a tuple.\n        - Otherwise, the batch is processed directly.\n\n    Args:\n        batch (Any): The batch of data to move to the device. This can be a dict, tuple, list,\n                     or any type compatible with `data_to_device`.\n\n    Returns:\n        Any: The batch with all elements moved to `self.device` and cast to `self.data_dtype`.\n    \"\"\"\n    if batch is None:\n        return None\n\n    if isinstance(batch, dict):\n        return {\n            key: data_to_device(\n                value, device=self.execution.device, dtype=self.execution.data_dtype\n            )\n            for key, value in batch.items()\n        }\n    elif isinstance(batch, (tuple, list)):\n        return tuple(\n            data_to_device(x, device=self.execution.device, dtype=self.execution.data_dtype)\n            for x in batch\n        )\n    elif isinstance(batch, torch.Tensor):\n        return data_to_device(\n            batch, device=self.execution.device, dtype=self.execution.data_dtype\n        )\n    return\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.worker","title":"<code>worker(rank, instance, fun, args, kwargs)</code>","text":"<p>Worker function to be executed in each spawned process.</p> <p>This function is called in every subprocess created by torch.multiprocessing (via mp.spawn). It performs the following tasks:   1. Sets up the accelerator for the given process rank. This typically involves configuring      the GPU or other hardware resources for distributed training.   2. If the retrieved method has been decorated (i.e. it has a 'wrapped' attribute),      the original, unwrapped function is invoked with the given arguments. Otherwise,      the method is called directly.</p> PARAMETER DESCRIPTION <code>rank</code> <p>The rank (or identifier) of the spawned process.</p> <p> TYPE: <code>int</code> </p> <code>instance</code> <p>The object (Trainer) that contains the method to execute.                This object is expected to have an <code>accelerator</code> attribute with a <code>setup_process(rank)</code> method.                This argument is optional, in case it is None, the fun will be called independently.</p> <p> TYPE: <code>object</code> </p> <code>fun</code> <p>The function of the method on the instance to be executed.</p> <p> TYPE: <code>Callable</code> </p> <code>args</code> <p>Positional arguments to pass to the target method.</p> <p> TYPE: <code>tuple</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the target method.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def worker(self, rank: int, instance: Any, fun: Callable, args: tuple, kwargs: dict) -&gt; None:\n    \"\"\"\n    Worker function to be executed in each spawned process.\n\n    This function is called in every subprocess created by torch.multiprocessing (via mp.spawn).\n    It performs the following tasks:\n      1. Sets up the accelerator for the given process rank. This typically involves configuring\n         the GPU or other hardware resources for distributed training.\n      2. If the retrieved method has been decorated (i.e. it has a '__wrapped__' attribute),\n         the original, unwrapped function is invoked with the given arguments. Otherwise,\n         the method is called directly.\n\n    Args:\n        rank (int): The rank (or identifier) of the spawned process.\n        instance (object): The object (Trainer) that contains the method to execute.\n                           This object is expected to have an `accelerator` attribute with a `setup_process(rank)` method.\n                           This argument is optional, in case it is None, the fun will be called independently.\n        fun (Callable): The function of the method on the instance to be executed.\n        args (tuple): Positional arguments to pass to the target method.\n        kwargs (dict): Keyword arguments to pass to the target method.\n    \"\"\"\n    # Setup the accelerator for the given process rank (e.g., configuring GPU)\n    if instance and instance.accelerator:\n        instance.accelerator.setup_process(rank)\n    else:\n        self.setup_process(rank)\n\n    if hasattr(fun, \"__wrapped__\"):\n        # Explicitly get the original (unbound) method, passing in the instance.\n        # We need to call the original method in case so that MP spawn does not\n        # create multiple processes. (To Avoid infinite loop)\n        fun = fun.__wrapped__  # Unwrap if decorated\n        fun(instance, *args, **kwargs) if instance else fun(*args, **kwargs)\n    else:\n        fun(*args, **kwargs)\n</code></pre>"},{"location":"api/models/","title":"Quantum models","text":""},{"location":"api/models/#qadence.model.QuantumModel","title":"<code>QuantumModel(circuit, observable=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, mitigation=None, configuration=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>The central class of qadence that executes <code>QuantumCircuit</code>s and make them differentiable.</p> <p>This class should be used as base class for any new quantum model supported in the qadence framework for information on the implementation of custom models see here.</p> <p>Example: <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit, RX, RY, Z, PI, chain, kron\nfrom qadence import FeatureParameter, VariationalParameter\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, theta), RY(1, theta)),\n    kron(RX(0, phi), RY(1, phi)),\n)\n\ncircuit = QuantumCircuit(2, block)\n\nobservable = Z(0) + Z(1)\n\nmodel = QuantumModel(circuit, observable)\nvalues = {\"phi\": torch.tensor([PI, PI/2]), \"theta\": torch.tensor([PI, PI/2])}\n\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\nprint(wf)\nprint(xs)\nprint(ex)\n</code></pre> <pre><code>tensor([[ 1.0000e+00+0.0000e+00j, -1.2246e-16+0.0000e+00j,\n          0.0000e+00+1.2246e-16j,  0.0000e+00-1.4998e-32j],\n        [ 4.9304e-32+0.0000e+00j,  2.2204e-16+0.0000e+00j,\n          0.0000e+00-2.2204e-16j,  0.0000e+00-1.0000e+00j]])\n[OrderedCounter({'00': 100}), OrderedCounter({'11': 100})]\ntensor([[ 2.],\n        [-2.]], requires_grad=True)\n</code></pre>  ```</p> <p>Initialize a generic QuantumModel instance.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>Optional observable(s) that are used only in the <code>expectation</code> method. You can also provide observables on the fly to the expectation call directly.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>A backend for circuit execution.</p> <p> TYPE: <code>BackendName | str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>A differentiability mode. Parameter shift based modes work on all backends. AD based modes only on PyTorch based backends.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Configuration for the backend.</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if the <code>diff_mode</code> argument is set to None</p> Source code in <code>qadence/model.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock | None = None,\n    backend: BackendName | str = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n):\n    \"\"\"Initialize a generic QuantumModel instance.\n\n    Arguments:\n        circuit: The circuit that is executed.\n        observable: Optional observable(s) that are used only in the `expectation` method. You\n            can also provide observables on the fly to the expectation call directly.\n        backend: A backend for circuit execution.\n        diff_mode: A differentiability mode. Parameter shift based modes work on all backends.\n            AD based modes only on PyTorch based backends.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        configuration: Configuration for the backend.\n        noise: A noise model to use.\n\n    Raises:\n        ValueError: if the `diff_mode` argument is set to None\n    \"\"\"\n    super().__init__()\n\n    if not isinstance(circuit, QuantumCircuit):\n        TypeError(\n            f\"The circuit should be of type '&lt;class QuantumCircuit&gt;'. Got {type(circuit)}.\"\n        )\n\n    if diff_mode is None:\n        raise ValueError(\"`diff_mode` cannot be `None` in a `QuantumModel`.\")\n\n    self.backend = backend_factory(\n        backend=backend, diff_mode=diff_mode, configuration=configuration\n    )\n\n    if isinstance(observable, list) or observable is None:\n        observable = observable\n    else:\n        observable = [observable]\n\n    def _is_feature_param(p: Parameter) -&gt; bool:\n        return not p.trainable and not p.is_number\n\n    if observable is None:\n        self.inputs = list(filter(_is_feature_param, circuit.unique_parameters))\n    else:\n        uparams = unique_parameters(chain(circuit.block, *observable))\n        self.inputs = list(filter(_is_feature_param, uparams))\n\n    conv = self.backend.convert(circuit, observable)\n    self.embedding_fn = conv.embedding_fn\n    self._circuit = conv.circuit\n    self._observable = conv.observable\n    self._backend_name = backend\n    self._diff_mode = diff_mode\n    self._measurement = measurement\n    self._noise = noise\n    self._mitigation = mitigation\n    self._params = nn.ParameterDict(\n        {\n            str(key): nn.Parameter(val, requires_grad=val.requires_grad)\n            for key, val in conv.params.items()\n        }\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.device","title":"<code>device</code>  <code>property</code>","text":"<p>Get device.</p> RETURNS DESCRIPTION <code>device</code> <p>torch.device</p>"},{"location":"api/models/#qadence.model.QuantumModel.in_features","title":"<code>in_features</code>  <code>property</code>","text":"<p>Number of inputs.</p>"},{"location":"api/models/#qadence.model.QuantumModel.num_vparams","title":"<code>num_vparams</code>  <code>property</code>","text":"<p>The number of variational parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.out_features","title":"<code>out_features</code>  <code>property</code>","text":"<p>Number of outputs.</p>"},{"location":"api/models/#qadence.model.QuantumModel.params","title":"<code>params</code>  <code>property</code>","text":"<p>All parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.show_config","title":"<code>show_config</code>  <code>property</code>","text":"<p>Attain current quantum model configurations.</p>"},{"location":"api/models/#qadence.model.QuantumModel.vals_vparams","title":"<code>vals_vparams</code>  <code>property</code>","text":"<p>Dictionary with parameters which are actually updated during optimization.</p>"},{"location":"api/models/#qadence.model.QuantumModel.vparams","title":"<code>vparams</code>  <code>property</code>","text":"<p>Variational parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.assign_parameters","title":"<code>assign_parameters(values)</code>","text":"<p>Return the final, assigned circuit that is used in e.g. <code>backend.run</code>.</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Final, assigned circuit that is used in e.g. <code>backend.run</code></p> Source code in <code>qadence/model.py</code> <pre><code>def assign_parameters(self, values: dict[str, Tensor]) -&gt; Any:\n    \"\"\"Return the final, assigned circuit that is used in e.g. `backend.run`.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n\n    Returns:\n        Final, assigned circuit that is used in e.g. `backend.run`\n    \"\"\"\n    params = self.embedding_fn(self._params, values)\n    return self.backend.assign_parameters(self._circuit, params)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.change_config","title":"<code>change_config(new_config)</code>","text":"<p>Change configuration with the input.</p> Source code in <code>qadence/model.py</code> <pre><code>def change_config(self, new_config: dict) -&gt; None:\n    \"\"\"Change configuration with the input.\"\"\"\n    if isinstance(self.backend, DifferentiableBackend):\n        current_config = self.backend.backend.config\n    BackendConfiguration.change_config(current_config, new_config)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.circuit","title":"<code>circuit(circuit)</code>","text":"<p>Get backend-converted circuit.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>QuantumCircuit instance.</p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>Backend circuit.</p> Source code in <code>qadence/model.py</code> <pre><code>def circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Get backend-converted circuit.\n\n    Args:\n        circuit: QuantumCircuit instance.\n\n    Returns:\n        Backend circuit.\n    \"\"\"\n    return self.backend.circuit(circuit)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.expectation","title":"<code>expectation(values={}, observable=None, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute expectation using the given backend.</p> <p>Given an input state \\(|\\psi_0 \\rangle\\), a set of variational parameters \\(\\vec{\\theta}\\) and the unitary representation of the model \\(U(\\vec{\\theta})\\) we return \\(\\langle \\psi_0 | U(\\vec{\\theta}) | \\psi_0 \\rangle\\).</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>observable</code> <p>Observable part of the expectation.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable | None</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional input state.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>A mitigation protocol to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>when no observable is set.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor of shape n_batches x n_obs</p> Source code in <code>qadence/model.py</code> <pre><code>def expectation(\n    self,\n    values: dict[str, Tensor] = {},\n    observable: list[ConvertedObservable] | ConvertedObservable | None = None,\n    state: Optional[Tensor] = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    r\"\"\"Compute expectation using the given backend.\n\n\n\n    Given an input state $|\\psi_0 \\rangle$,\n    a set of variational parameters $\\vec{\\theta}$\n    and the unitary representation of the model $U(\\vec{\\theta})$\n    we return $\\langle \\psi_0 | U(\\vec{\\theta}) | \\psi_0 \\rangle$.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        observable: Observable part of the expectation.\n        state: Optional input state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: A mitigation protocol to use.\n        endianness: Storage convention for binary information.\n\n    Raises:\n        ValueError: when no observable is set.\n\n    Returns:\n        A torch.Tensor of shape n_batches x n_obs\n    \"\"\"\n    if observable is None:\n        if self._observable is None:\n            raise ValueError(\n                \"Provide an AbstractBlock as the observable to compute expectation.\"\n                \"Either pass a 'native_observable' directly to 'QuantumModel.expectation'\"\n                \"or pass a (non-native) '&lt;class AbstractBlock&gt;' to the 'QuantumModel.__init__'.\"\n            )\n        observable = self._observable\n\n    params = self.embedding_fn(self._params, values)\n    if measurement is None:\n        measurement = self._measurement\n    if noise is None:\n        noise = self._noise\n    else:\n        self._noise = noise\n    if mitigation is None:\n        mitigation = self._mitigation\n    return self.backend.expectation(\n        circuit=self._circuit,\n        observable=observable,\n        param_values=params,\n        state=state,\n        measurement=measurement,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Calls run method with arguments.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor representing output.</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def forward(self, *args: Any, **kwargs: Any) -&gt; Tensor:\n    \"\"\"Calls run method with arguments.\n\n    Returns:\n        Tensor: A torch.Tensor representing output.\n    \"\"\"\n    return self.run(*args, **kwargs)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.load","title":"<code>load(file_path, as_torch=False, map_location='cpu')</code>  <code>classmethod</code>","text":"<p>Load QuantumModel.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>File path to load model from.</p> <p> TYPE: <code>str | Path</code> </p> <code>as_torch</code> <p>Load parameters as torch tensor. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>map_location</code> <p>Location for loading. Defaults to \"cpu\".</p> <p> TYPE: <code>str | device</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>QuantumModel</code> <p>QuantumModel from file_path.</p> Source code in <code>qadence/model.py</code> <pre><code>@classmethod\ndef load(\n    cls, file_path: str | Path, as_torch: bool = False, map_location: str | torch.device = \"cpu\"\n) -&gt; QuantumModel:\n    \"\"\"Load QuantumModel.\n\n    Arguments:\n        file_path: File path to load model from.\n        as_torch: Load parameters as torch tensor. Defaults to False.\n        map_location (str | torch.device, optional): Location for loading. Defaults to \"cpu\".\n\n    Returns:\n        QuantumModel from file_path.\n    \"\"\"\n    qm_pt = {}\n    if isinstance(file_path, str):\n        file_path = Path(file_path)\n    if os.path.isdir(file_path):\n        from qadence.ml_tools.callbacks.saveload import get_latest_checkpoint_name\n\n        file_path = file_path / get_latest_checkpoint_name(file_path, \"model\")\n\n    try:\n        qm_pt = torch.load(file_path, map_location=map_location, weights_only=False)\n    except Exception as e:\n        logger.error(f\"Unable to load QuantumModel due to {e}\")\n    return cls._from_dict(qm_pt, as_torch)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.load_params_from_dict","title":"<code>load_params_from_dict(d, strict=True)</code>","text":"<p>Copy parameters from dictionary into this QuantumModel.</p> <p>Unlike :meth:<code>~qadence.QuantumModel.from_dict</code>, this method does not create a new QuantumModel instance, but rather loads the parameters into the same QuantumModel. The behaviour of this method is similar to :meth:<code>~torch.nn.Module.load_state_dict</code>.</p> <p>The dictionary is assumed to have the format as saved via :meth:<code>~qadence.QuantumModel.to_dict</code></p> PARAMETER DESCRIPTION <code>d</code> <p>The dictionary</p> <p> TYPE: <code>dict</code> </p> <code>strict</code> <p>Whether to strictly enforce that the parameter keys in the dictionary and in the model match exactly. Default: <code>True</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def load_params_from_dict(self, d: dict, strict: bool = True) -&gt; None:\n    \"\"\"Copy parameters from dictionary into this QuantumModel.\n\n    Unlike :meth:`~qadence.QuantumModel.from_dict`, this method does not create a new\n    QuantumModel instance, but rather loads the parameters into the same QuantumModel.\n    The behaviour of this method is similar to :meth:`~torch.nn.Module.load_state_dict`.\n\n    The dictionary is assumed to have the format as saved via\n    :meth:`~qadence.QuantumModel.to_dict`\n\n    Args:\n        d (dict): The dictionary\n        strict (bool, optional):\n            Whether to strictly enforce that the parameter keys in the dictionary and\n            in the model match exactly. Default: ``True``.\n    \"\"\"\n    param_dict = d[\"param_dict\"]\n    missing_keys = set(self._params.keys()) - set(param_dict.keys())\n    unexpected_keys = set(param_dict.keys()) - set(self._params.keys())\n\n    if strict:\n        error_msgs = []\n        if len(unexpected_keys) &gt; 0:\n            error_msgs.append(f\"Unexpected key(s) in dictionary: {unexpected_keys}\")\n        if len(missing_keys) &gt; 0:\n            error_msgs.append(f\"Missing key(s) in dictionary: {missing_keys}\")\n        if len(error_msgs) &gt; 0:\n            errors_string = \"\\n\\t\".join(error_msgs)\n            raise RuntimeError(\n                f\"Error(s) loading the parameter dictionary due to: \\n\\t{errors_string}\\n\"\n                \"This error was thrown because the `strict` argument is set `True`.\"\n                \"If you don't need the parameter keys of the dictionary to exactly match \"\n                \"the model parameters, set `strict=False`.\"\n            )\n\n    for n, param in param_dict.items():\n        try:\n            with torch.no_grad():\n                self._params[n].copy_(\n                    torch.nn.Parameter(param, requires_grad=param.requires_grad)\n                )\n        except Exception as e:\n            logger.warning(f\"Unable to load parameter {n} from dictionary due to {e}.\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.observable","title":"<code>observable(observable, n_qubits)</code>","text":"<p>Get backend observable.</p> PARAMETER DESCRIPTION <code>observable</code> <p>Observable block.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Backend observable.</p> Source code in <code>qadence/model.py</code> <pre><code>def observable(self, observable: AbstractBlock, n_qubits: int) -&gt; Any:\n    \"\"\"Get backend observable.\n\n    Args:\n        observable: Observable block.\n        n_qubits: Number of qubits\n\n    Returns:\n        Backend observable.\n    \"\"\"\n    return self.backend.observable(observable, n_qubits)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.observables_to_expression","title":"<code>observables_to_expression()</code>","text":"<pre><code>Convert the observable to a dictionary representation of Pauli terms.\n</code></pre> <p>If no observable is set, returns an empty dictionary. Each observable is represented by its tag (if available) as the key and its mathematical expression as the value.</p> RETURNS DESCRIPTION <code>dict[str, str] | str</code> <p>dict[str, str]: A dictionary where the keys are observable tags (or \"Obs.\" if not provided)             and the values are the corresponding mathematical expressions.</p> Source code in <code>qadence/model.py</code> <pre><code>def observables_to_expression(self) -&gt; dict[str, str] | str:\n    \"\"\"\n        Convert the observable to a dictionary representation of Pauli terms.\n\n    If no observable is set, returns an empty dictionary. Each observable is\n    represented by its tag (if available) as the key and its mathematical expression\n    as the value.\n\n    Returns:\n        dict[str, str]: A dictionary where the keys are observable tags (or \"Obs.\" if not provided)\n                        and the values are the corresponding mathematical expressions.\n    \"\"\"\n    if self._observable is None:\n        return \"No observable set.\"\n    else:\n        return {\n            obs.original.tag if obs.original.tag else \"Obs.\": block_to_mathematical_expression(\n                obs.original\n            )\n            for obs in self._observable\n        }\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.overlap","title":"<code>overlap()</code>","text":"<p>Overlap of model.</p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>The overlap method is not implemented for this model.</p> Source code in <code>qadence/model.py</code> <pre><code>def overlap(self) -&gt; Tensor:\n    \"\"\"Overlap of model.\n\n    Raises:\n        NotImplementedError: The overlap method is not implemented for this model.\n    \"\"\"\n    raise NotImplementedError(\"The overlap method is not implemented for this model.\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.reset_vparams","title":"<code>reset_vparams(values)</code>","text":"<p>Reset all the variational parameters with a given list of values.</p> Source code in <code>qadence/model.py</code> <pre><code>def reset_vparams(self, values: Sequence) -&gt; None:\n    \"\"\"Reset all the variational parameters with a given list of values.\"\"\"\n    current_vparams = OrderedDict({k: v for k, v in self._params.items() if v.requires_grad})\n\n    assert (\n        len(values) == self.num_vparams\n    ), \"Pass an iterable with the values of all variational parameters\"\n    for i, k in enumerate(current_vparams.keys()):\n        current_vparams[k].data = torch.tensor([values[i]])\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.run","title":"<code>run(values=None, state=None, endianness=Endianness.BIG)</code>","text":"<p>Run model.</p> <p>Given an input state \\(| \\psi_0 \\rangle\\), a set of variational parameters \\(\\vec{\\theta}\\) and the unitary representation of the model \\(U(\\vec{\\theta})\\) we return \\(U(\\vec{\\theta}) | \\psi_0 \\rangle\\).</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional input state to apply model on.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor representing output.</p> Source code in <code>qadence/model.py</code> <pre><code>def run(\n    self,\n    values: dict[str, Tensor] = None,\n    state: Tensor | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    r\"\"\"Run model.\n\n    Given an input state $| \\psi_0 \\rangle$,\n    a set of variational parameters $\\vec{\\theta}$\n    and the unitary representation of the model $U(\\vec{\\theta})$\n    we return $U(\\vec{\\theta}) | \\psi_0 \\rangle$.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        state: Optional input state to apply model on.\n        endianness: Storage convention for binary information.\n\n    Returns:\n        A torch.Tensor representing output.\n    \"\"\"\n    if values is None:\n        values = {}\n\n    params = self.embedding_fn(self._params, values)\n\n    return self.backend.run(self._circuit, params, state=state, endianness=endianness)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.sample","title":"<code>sample(values={}, n_shots=1000, state=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Obtain samples from model.</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Observable part of the expectation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Optional input state to apply model on.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>A mitigation protocol to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results.</p> Source code in <code>qadence/model.py</code> <pre><code>def sample(\n    self,\n    values: dict[str, torch.Tensor] = {},\n    n_shots: int = 1000,\n    state: torch.Tensor | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n    \"\"\"Obtain samples from model.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        n_shots: Observable part of the expectation.\n        state: Optional input state to apply model on.\n        noise: A noise model to use.\n        mitigation: A mitigation protocol to use.\n        endianness: Storage convention for binary information.\n\n    Returns:\n        A list of Counter instances with the sample results.\n    \"\"\"\n    params = self.embedding_fn(self._params, values)\n    if noise is None:\n        noise = self._noise\n    if mitigation is None:\n        mitigation = self._mitigation\n    return self.backend.sample(\n        self._circuit,\n        params,\n        n_shots=n_shots,\n        state=state,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.save","title":"<code>save(folder, file_name='quantum_model.pt', save_params=True)</code>","text":"<p>Save model.</p> PARAMETER DESCRIPTION <code>folder</code> <p>Folder where model is saved.</p> <p> TYPE: <code>str | Path</code> </p> <code>file_name</code> <p>File name for saving model. Defaults to \"quantum_model.pt\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'quantum_model.pt'</code> </p> <code>save_params</code> <p>Save parameters if True. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If folder is not a directory.</p> Source code in <code>qadence/model.py</code> <pre><code>def save(\n    self, folder: str | Path, file_name: str = \"quantum_model.pt\", save_params: bool = True\n) -&gt; None:\n    \"\"\"Save model.\n\n    Arguments:\n        folder: Folder where model is saved.\n        file_name: File name for saving model. Defaults to \"quantum_model.pt\".\n        save_params: Save parameters if True. Defaults to True.\n\n    Raises:\n        FileNotFoundError: If folder is not a directory.\n    \"\"\"\n    if not os.path.isdir(folder):\n        raise FileNotFoundError\n    try:\n        torch.save(self._to_dict(save_params), folder / Path(file_name))\n    except Exception as e:\n        logger.error(f\"Unable to write QuantumModel to disk due to {e}\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.to","title":"<code>to(*args, **kwargs)</code>","text":"<p>Conversion method for device or types.</p> RETURNS DESCRIPTION <code>QuantumModel</code> <p>QuantumModel with conversions.</p> Source code in <code>qadence/model.py</code> <pre><code>def to(self, *args: Any, **kwargs: Any) -&gt; QuantumModel:\n    \"\"\"Conversion method for device or types.\n\n    Returns:\n        QuantumModel with conversions.\n    \"\"\"\n    from pyqtorch import QuantumCircuit as PyQCircuit\n\n    try:\n        if isinstance(self._circuit.native, PyQCircuit):\n            self._circuit.native = self._circuit.native.to(*args, **kwargs)\n            if self._observable is not None:\n                if isinstance(self._observable, ConvertedObservable):\n                    self._observable.native = self._observable.native.to(*args, **kwargs)\n                elif isinstance(self._observable, list):\n                    for obs in self._observable:\n                        obs.native = obs.native.to(*args, **kwargs)\n            self._params = self._params.to(\n                device=self._circuit.native.device,\n                dtype=(\n                    torch.float64\n                    if self._circuit.native.dtype == torch.cdouble\n                    else torch.float32\n                ),\n            )\n            logger.debug(f\"Moved {self} to {args}, {kwargs}.\")\n        else:\n            logger.debug(\"QuantumModel.to only supports pyqtorch.QuantumCircuits.\")\n    except Exception as e:\n        logger.warning(f\"Unable to move {self} to {args}, {kwargs} due to {e}.\")\n    return self\n</code></pre>"},{"location":"api/noise/","title":"Noise","text":""},{"location":"api/noise/#noise-for-simulations","title":"Noise for simulations","text":""},{"location":"api/noise/#qadence.noise.protocols.NoiseHandler","title":"<code>NoiseHandler(protocol, options=dict())</code>","text":"<p>A container for multiple sources of noise.</p> <p>Note <code>NoiseProtocol.ANALOG</code> and <code>NoiseProtocol.DIGITAL</code> sources cannot be both present. Also <code>NoiseProtocol.READOUT</code> can only be present once as the last noise sources, and only exclusively with <code>NoiseProtocol.DIGITAL</code> sources.</p> PARAMETER DESCRIPTION <code>protocol</code> <p>The protocol(s) applied. To be defined from <code>NoiseProtocol</code>.</p> <p> TYPE: <code>NoiseEnum | list[NoiseEnum]</code> </p> <code>options</code> <p>A list of options defining the protocol. For <code>NoiseProtocol.ANALOG</code>, options should contain a field <code>noise_probs</code>. For <code>NoiseProtocol.DIGITAL</code>, options should contain a field <code>error_probability</code>.</p> <p> TYPE: <code>dict | list[dict]</code> DEFAULT: <code>dict()</code> </p> <p>Examples:</p> <pre><code>    from qadence import NoiseProtocol, NoiseHandler\n\n    analog_options = {\"noise_probs\": 0.1}\n    digital_options = {\"error_probability\": 0.1}\n    readout_options = {\"error_probability\": 0.1, \"seed\": 0}\n\n    # single noise sources\n    analog_noise = NoiseHandler(NoiseProtocol.ANALOG.DEPOLARIZING, analog_options)\n    digital_depo_noise = NoiseHandler(NoiseProtocol.DIGITAL.DEPOLARIZING, digital_options)\n    readout_noise = NoiseHandler(NoiseProtocol.READOUT, readout_options)\n\n    # init from multiple sources\n    protocols: list = [NoiseProtocol.DIGITAL.DEPOLARIZING, NoiseProtocol.READOUT]\n    options: list = [digital_options, readout_noise]\n    noise_combination = NoiseHandler(protocols, options)\n\n    # Appending noise sources\n    noise_combination = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, digital_options)\n    noise_combination.append([digital_depo_noise, readout_noise])\n</code></pre> Source code in <code>qadence/noise/protocols.py</code> <pre><code>def __init__(\n    self,\n    protocol: NoiseEnum | list[NoiseEnum],\n    options: dict | list[dict] = dict(),\n) -&gt; None:\n    self.protocol = protocol if isinstance(protocol, list) else [protocol]\n    self.options = options if isinstance(options, list) else [options] * len(self.protocol)\n    self.verify_all_protocols()\n</code></pre>"},{"location":"api/noise/#qadence.noise.protocols.NoiseHandler.append","title":"<code>append(other)</code>","text":"<p>Append noises.</p> PARAMETER DESCRIPTION <code>other</code> <p>The noises to add.</p> <p> TYPE: <code>NoiseHandler | list[NoiseHandler]</code> </p> Source code in <code>qadence/noise/protocols.py</code> <pre><code>def append(self, other: NoiseHandler | list[NoiseHandler]) -&gt; None:\n    \"\"\"Append noises.\n\n    Args:\n        other (NoiseHandler | list[NoiseHandler]): The noises to add.\n    \"\"\"\n    # To avoid overwriting the noise_sources list if an error is raised, make a copy\n    other_list = other if isinstance(other, list) else [other]\n    protocols = self.protocol[:]\n    options = self.options[:]\n\n    for noise in other_list:\n        protocols += noise.protocol\n        options += noise.options\n\n    # init may raise an error\n    temp_handler = NoiseHandler(protocols, options)\n    # if verify passes, replace protocols and options\n    self.protocol = temp_handler.protocol\n    self.options = temp_handler.options\n</code></pre>"},{"location":"api/noise/#qadence.noise.protocols.NoiseHandler.verify_all_protocols","title":"<code>verify_all_protocols()</code>","text":"<p>Make sure all protocols are correct in terms and their combination too.</p> Source code in <code>qadence/noise/protocols.py</code> <pre><code>def verify_all_protocols(self) -&gt; None:\n    \"\"\"Make sure all protocols are correct in terms and their combination too.\"\"\"\n\n    if len(self.protocol) == 0:\n        raise ValueError(\"NoiseHandler should be specified with one valid configuration.\")\n\n    if len(self.protocol) != len(self.options):\n        raise ValueError(\"Specify lists of same length when defining noises.\")\n\n    for protocol, option in zip(self.protocol, self.options):\n        self._verify_single_protocol(protocol, option)\n\n    types = [type(p) for p in self.protocol]\n    unique_types = set(types)\n    if NoiseProtocol.DIGITAL in unique_types and NoiseProtocol.ANALOG in unique_types:\n        raise ValueError(\"Cannot define a config with both Digital and Analog noises.\")\n\n    if NoiseProtocol.ANALOG in unique_types:\n        if NoiseProtocol.READOUT in unique_types:\n            raise ValueError(\"Cannot define a config with both READOUT and Analog noises.\")\n        if types.count(NoiseProtocol.ANALOG) &gt; 1:\n            raise ValueError(\"Multiple Analog Noises are not supported yet.\")\n\n    if NoiseProtocol.READOUT in unique_types:\n        if (\n            not isinstance(self.protocol[-1], NoiseProtocol.READOUT)\n            or types.count(NoiseProtocol.READOUT) &gt; 1\n        ):\n            raise ValueError(\"Only define a NoiseHandler with one READOUT as the last Noise.\")\n</code></pre>"},{"location":"api/operations/","title":"Operations","text":"<p>Operations are common <code>PrimitiveBlocks</code>, these are often called gates elsewhere.</p>"},{"location":"api/operations/#constant-blocks","title":"Constant blocks","text":"<p>CY gate not implemented</p>"},{"location":"api/operations/#qadence.operations.X","title":"<code>X(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The X gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.Y","title":"<code>Y(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Y gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.Z","title":"<code>Z(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Z gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.I","title":"<code>I(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The identity gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.H","title":"<code>H(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hadamard or H gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = (1 / np.sqrt(2)) * (X(target) + Z(target) - np.sqrt(2) * I(target))\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.S","title":"<code>S(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The S / Phase gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.SDagger","title":"<code>SDagger(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the S / Phase gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.SWAP","title":"<code>SWAP(control, target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The SWAP gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    a11 = 0.5 * (Z(control) - I(control))\n    a22 = -0.5 * (Z(target) + I(target))\n    a12 = 0.5 * (chain(X(control), Z(control)) + X(control))\n    a21 = 0.5 * (chain(Z(target), X(target)) + X(target))\n    self.generator = (\n        kron(-1.0 * a22, a11) + kron(-1.0 * a11, a22) + kron(a12, a21) + kron(a21, a12)\n    )\n    super().__init__((control, target), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.T","title":"<code>T(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The T gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.TDagger","title":"<code>TDagger(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the T gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CNOT","title":"<code>CNOT(control, target, noise=None)</code>","text":"<p>               Bases: <code>ControlBlock</code></p> <p>The CNot, or CX, gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(self, control: int, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    self.generator = kron(N(control), X(target) - I(target))\n    super().__init__((control,), X(target), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CZ","title":"<code>CZ(control, target, noise=None)</code>","text":"<p>               Bases: <code>MCZ</code></p> <p>The CZ gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(self, control: int, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((control,), target, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CPHASE","title":"<code>CPHASE(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCPHASE</code></p> <p>The CPHASE gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#parametrized-blocks","title":"Parametrized blocks","text":""},{"location":"api/operations/#qadence.operations.RX","title":"<code>RX(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Rx gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TParameter | ParamMap,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    # TODO: should we give them more meaningful names? like 'angle'?\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = X(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.RY","title":"<code>RY(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Ry gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TParameter | ParamMap,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = Y(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.RZ","title":"<code>RZ(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Rz gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TParameter | ParamMap,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRX","title":"<code>CRX(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCRX</code></p> <p>The CRX gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRY","title":"<code>CRY(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCRY</code></p> <p>The CRY gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self, control: int, target: int, parameter: TParameter, noise: NoiseHandler | None = None\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRZ","title":"<code>CRZ(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCRZ</code></p> <p>The CRZ gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.PHASE","title":"<code>PHASE(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Parametric Phase / S gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.parameters = ParamMap(parameter=parameter)\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#hamiltonian-evolution","title":"Hamiltonian Evolution","text":"<p>AnalogSWAP should be turned into a proper analog block</p>"},{"location":"api/operations/#qadence.operations.HamEvo","title":"<code>HamEvo(generator, parameter, qubit_support=None, duration=None, noise_operators=list())</code>","text":"<p>               Bases: <code>TimeEvolutionBlock</code></p> <p>The Hamiltonian evolution operator U(t).</p> <p>For time-independent Hamiltonians the solution is exact:</p> <pre><code>U(t) = exp(-iGt)\n</code></pre> <p>where G represents an Hermitian generator, or Hamiltonian and t represents the time parameter. For time-dependent Hamiltonians, the solution is obtained by numerical integration of the Schrodinger equation.</p> PARAMETER DESCRIPTION <code>generator</code> <p>Hamiltonian generator, either symbolic as an AbstractBlock, or as a torch.Tensor or numpy.ndarray.</p> <p> TYPE: <code>Union[TGenerator, AbstractBlock]</code> </p> <code>parameter</code> <p>The time parameter for evolution operator. For the time-independent case, it represents the actual value for which the evolution will be evaluated. For the time-dependent case, it should be an instance of TimeParameter to signal the solver the variable that will be integrated over.</p> <p> TYPE: <code>TParameter</code> </p> <code>qubit_support</code> <p>The qubits on which the evolution will be performed on. Only required for generators that are not a composition of blocks.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>duration</code> <p>(optional) duration of the evolution in case of time-dependent generator. By default, a FeatureParameter with tag \"duration\" will be initialized, and the value will then be required in the values dict.</p> <p> TYPE: <code>TParameter | None</code> DEFAULT: <code>None</code> </p> <code>noise_operators</code> <p>(optional) the list of jump operators to use when using a shrodinger solver, allowing to perform noisy simulations.</p> <p> TYPE: <code>list[AbstractBlock]</code> DEFAULT: <code>list()</code> </p> <p>Examples:</p> <pre><code>from qadence import X, HamEvo, PI, add, run\nfrom qadence import FeatureParameter, TimeParameter\nimport torch\n\nn_qubits = 3\n\n# Hamiltonian as a block composition\nhamiltonian = add(X(i) for i in range(n_qubits))\nhevo = HamEvo(hamiltonian, parameter=torch.rand(2))\nstate = run(hevo)\n\n# Hamiltonian as a random matrix\nhamiltonian = torch.rand(2, 2, dtype=torch.complex128)\nhevo = HamEvo(hamiltonian, parameter=torch.rand(2), qubit_support=(0,))\nstate = run(hevo)\n\n# Time-dependent Hamiltonian\nt = TimeParameter(\"t\")\nhamiltonian = t * add(X(i) for i in range(n_qubits))\nhevo = HamEvo(hamiltonian, parameter=t)\nstate = run(hevo, values = {\"duration\": torch.tensor(1.0)})\n\n# Adding noise operators\nnoise_ops = [X(0)]\nhevo = HamEvo(hamiltonian, parameter=t, noise_operators=noise_ops)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/operations/ham_evo.py</code> <pre><code>def __init__(\n    self,\n    generator: Union[TGenerator, AbstractBlock],\n    parameter: TParameter,\n    qubit_support: tuple[int, ...] = None,\n    duration: TParameter | None = None,\n    noise_operators: list[AbstractBlock] = list(),\n):\n    params = {}\n    if qubit_support is None and not isinstance(generator, AbstractBlock):\n        raise ValueError(\"You have to supply a qubit support for non-block generators.\")\n    super().__init__(qubit_support if qubit_support else generator.qubit_support)\n    if isinstance(generator, AbstractBlock):\n        qubit_support = generator.qubit_support\n        if generator.is_parametric:\n            params = {str(e): e for e in expressions(generator)}\n        if generator.is_time_dependent:\n            if isinstance(duration, str):\n                duration = Parameter(duration, trainable=False)\n            elif duration is None:\n                duration = Parameter(\"duration\", trainable=False)\n        if not generator.is_time_dependent and duration is not None:\n            raise TypeError(\n                \"Duration argument is only supported for time-dependent generators.\"\n            )\n    elif isinstance(generator, torch.Tensor):\n        if duration is not None:\n            raise TypeError(\n                \"Duration argument is only supported for time-dependent generators.\"\n            )\n        msg = \"Please provide a square generator.\"\n        if len(generator.shape) == 2:\n            assert generator.shape[0] == generator.shape[1], msg\n        elif len(generator.shape) == 3:\n            assert generator.shape[1] == generator.shape[2], msg\n            assert generator.shape[0] == 1, \"Qadence doesnt support batched generators.\"\n        else:\n            raise TypeError(\n                \"Only 2D or 3D generators are supported.\\\n                            In case of a 3D generator, the batch dim\\\n                            is expected to be at dim 0.\"\n            )\n        params = {str(generator.__hash__()): generator}\n    elif isinstance(generator, (sympy.Basic, sympy.Array)):\n        if duration is not None:\n            raise TypeError(\n                \"Duration argument is only supported for time-dependent generators.\"\n            )\n        params = {str(generator): generator}\n    else:\n        raise TypeError(\n            f\"Generator of type {type(generator)} not supported.\\\n                        If you're using a numpy.ndarray, please cast it to a torch tensor.\"\n        )\n    if duration is not None:\n        params = {\"duration\": Parameter(duration), **params}\n    params = {\"parameter\": Parameter(parameter), **params}\n    self.parameters = ParamMap(**params)\n    self.time_param = parameter\n    self.generator = generator\n    self.duration = duration\n\n    if len(noise_operators) &gt; 0:\n        if not all(\n            [\n                len(set(op.qubit_support + self.qubit_support) - set(self.qubit_support)) == 0\n                for op in noise_operators\n            ]\n        ):\n            raise ValueError(\n                \"Noise operators should be defined\"\n                \" over the same or a subset of the qubit support\"\n            )\n        if True in [op.is_parametric for op in noise_operators]:\n            raise ValueError(\"Parametric operators are not supported\")\n    self.noise_operators = noise_operators\n</code></pre>"},{"location":"api/operations/#qadence.operations.HamEvo.digital_decomposition","title":"<code>digital_decomposition(approximation=LTSOrder.ST4)</code>","text":"<p>Decompose the Hamiltonian evolution into digital gates.</p> PARAMETER DESCRIPTION <code>approximation</code> <p>Choose the type of decomposition. Defaults to \"st4\". Available types are: * 'basic' = apply first-order Trotter formula and decompose each term of     the exponential into digital gates. It is exact only if applied to an     operator whose terms are mutually commuting. * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting     Hamiltonians. * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting     Hamiltonians.</p> <p> TYPE: <code>str</code> DEFAULT: <code>ST4</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>a block with the digital decomposition</p> <p> TYPE: <code>AbstractBlock</code> </p> Source code in <code>qadence/operations/ham_evo.py</code> <pre><code>def digital_decomposition(self, approximation: LTSOrder = LTSOrder.ST4) -&gt; AbstractBlock:\n    \"\"\"Decompose the Hamiltonian evolution into digital gates.\n\n    Args:\n        approximation (str, optional): Choose the type of decomposition. Defaults to \"st4\".\n            Available types are:\n            * 'basic' = apply first-order Trotter formula and decompose each term of\n                the exponential into digital gates. It is exact only if applied to an\n                operator whose terms are mutually commuting.\n            * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting\n                Hamiltonians.\n            * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting\n                Hamiltonians.\n\n    Returns:\n        AbstractBlock: a block with the digital decomposition\n    \"\"\"\n\n    # psi(t) = exp(-i * H * t * psi0)\n    # psi(t) = exp(-i * lambda * t * psi0)\n    # H = sum(Paulin) + sum(Pauli1*Pauli2)\n    logger.info(\"Quantum simulation of the time-independent Schr\u00f6dinger equation.\")\n\n    blocks = []\n\n    # how to change the type/dict to enum effectively\n\n    # when there is a term including non-commuting matrices use st2 or st4\n\n    # 1) should check that the given generator respects the constraints\n    # single-qubit gates\n\n    assert isinstance(\n        self.generator, AbstractBlock\n    ), \"Only a generator represented as a block can be decomposed\"\n\n    if block_is_qubit_hamiltonian(self.generator):\n        try:\n            block_is_commuting_hamiltonian(self.generator)\n            approximation = LTSOrder.BASIC  # use the simpler approach if the H is commuting\n        except TypeError:\n            logger.warning(\n                \"\"\"Non-commuting terms in the Pauli operator.\n                The Suzuki-Trotter approximation is applied.\"\"\"\n            )\n\n        blocks.extend(\n            lie_trotter_suzuki(\n                block=self.generator,\n                parameter=self.parameters.parameter,\n                order=LTSOrder[approximation],\n            )\n        )\n\n        # 2) return an AbstractBlock instance with the set of gates\n        # resulting from the decomposition\n\n        return chain(*blocks)\n    else:\n        raise NotImplementedError(\n            \"The current digital decomposition can be applied only to Pauli Hamiltonians.\"\n        )\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogSWAP","title":"<code>AnalogSWAP(control, target, parameter=3 * PI / 4)</code>","text":"<p>               Bases: <code>HamEvo</code></p> <p>Single time-independent Hamiltonian evolution over a Rydberg Ising.</p> <p>hamiltonian yielding a SWAP (up to global phase).</p> <p>Derived from Bapat et al. where it is applied to XX-type Hamiltonian</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def __init__(self, control: int, target: int, parameter: TParameter = 3 * PI / 4):\n    rydberg_ising_hamiltonian_generator = (\n        4.0 * kron((I(control) - Z(control)) / 2.0, (I(target) - Z(target)) / 2.0)\n        + (2.0 / 3.0) * np.sqrt(2.0) * X(control)\n        + (2.0 / 3.0) * np.sqrt(2.0) * X(target)\n        + (1.0 + np.sqrt(5.0) / 3) * Z(control)\n        + (1.0 + np.sqrt(5.0) / 3) * Z(target)\n    )\n    super().__init__(rydberg_ising_hamiltonian_generator, parameter, (control, target))\n</code></pre>"},{"location":"api/operations/#analog-blocks","title":"Analog blocks","text":""},{"location":"api/operations/#qadence.operations.AnalogRX","title":"<code>AnalogRX(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog X rotation.</p> <p>Shorthand for <code>AnalogRot</code>:</p> <pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9)\n</code></pre> PARAMETER DESCRIPTION <code>angle</code> <p>Rotation angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRX(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog X rotation.\n\n    Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9)\n    ```\n\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n    return _analog_rot(angle, qubit_support, phase=0, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRY","title":"<code>AnalogRY(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog Y rotation.</p> <p>Shorthand for <code>AnalogRot</code>:</p> <p><pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n</code></pre> Arguments:     angle: Rotation angle [rad]     qubit_support: Defines the (local/global) qubit support</p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRY(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog Y rotation.\n\n    Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n    return _analog_rot(angle, qubit_support, phase=-PI / 2, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRZ","title":"<code>AnalogRZ(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog Z rotation. Shorthand for <code>AnalogRot</code>: <pre><code>\u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\nAnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n</code></pre></p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRZ(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog Z rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```\n    \u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\n    AnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n    ```\n    \"\"\"\n    q = _cast(QubitSupport, qubit_support)\n    alpha = _cast(Parameter, angle)\n    delta = PI\n    omega = 0\n    duration = alpha / delta * 1000\n    h_norm = sympy.sqrt(omega**2 + delta**2)\n    ps = ParamMap(\n        alpha=alpha, duration=duration, omega=omega, delta=delta, phase=0.0, h_norm=h_norm\n    )\n    return ConstantAnalogRotation(qubit_support=q, parameters=ps, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRot","title":"<code>AnalogRot(duration, omega=0, delta=0, phase=0, qubit_support='global', add_pattern=True)</code>","text":"<p>General analog rotation operation.</p> PARAMETER DESCRIPTION <code>duration</code> <p>Duration of the rotation [ns].</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>omega</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>delta</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>phase</code> <p>Phase angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> <code>add_pattern</code> <p>False disables the semi-local addressing pattern for the execution of this specific block.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRot(\n    duration: float | str | Parameter,\n    omega: float | str | Parameter = 0,\n    delta: float | str | Parameter = 0,\n    phase: float | str | Parameter = 0,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"General analog rotation operation.\n\n    Arguments:\n        duration: Duration of the rotation [ns].\n        omega: Rotation frequency [rad/\u03bcs]\n        delta: Rotation frequency [rad/\u03bcs]\n        phase: Phase angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n        add_pattern: False disables the semi-local addressing pattern\n            for the execution of this specific block.\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n\n    if omega == 0 and delta == 0:\n        raise ValueError(\"Parameters omega and delta cannot both be 0.\")\n\n    q = _cast(QubitSupport, qubit_support)\n    duration = Parameter(duration)\n    omega = Parameter(omega)\n    delta = Parameter(delta)\n    phase = Parameter(phase)\n    h_norm = sympy.sqrt(omega**2 + delta**2)\n    alpha = duration * h_norm / 1000\n    ps = ParamMap(\n        alpha=alpha, duration=duration, omega=omega, delta=delta, phase=phase, h_norm=h_norm\n    )\n    return ConstantAnalogRotation(parameters=ps, qubit_support=q, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogInteraction","title":"<code>AnalogInteraction(duration, qubit_support='global', add_pattern=True)</code>","text":"<p>Evolution of the interaction term for a register of qubits.</p> <p>Constructs a <code>InteractionBlock</code>.</p> PARAMETER DESCRIPTION <code>duration</code> <p>Time to evolve the interaction for in nanoseconds.</p> <p> TYPE: <code>TNumber | Basic</code> </p> <code>qubit_support</code> <p>Qubits the <code>InteractionBlock</code> is applied to. Can be either <code>\"global\"</code> to evolve the interaction block to all qubits or a tuple of integers.</p> <p> TYPE: <code>str | QubitSupport | tuple</code> DEFAULT: <code>'global'</code> </p> <code>add_pattern</code> <p>False disables the semi-local addressing pattern for the execution of this specific block.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>InteractionBlock</code> <p>a <code>InteractionBlock</code></p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogInteraction(\n    duration: TNumber | sympy.Basic,\n    qubit_support: str | QubitSupport | tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; InteractionBlock:\n    \"\"\"Evolution of the interaction term for a register of qubits.\n\n    Constructs a [`InteractionBlock`][qadence.blocks.analog.InteractionBlock].\n\n    Arguments:\n        duration: Time to evolve the interaction for in nanoseconds.\n        qubit_support: Qubits the `InteractionBlock` is applied to. Can be either\n            `\"global\"` to evolve the interaction block to all qubits or a tuple of integers.\n        add_pattern: False disables the semi-local addressing pattern\n            for the execution of this specific block.\n\n    Returns:\n        a `InteractionBlock`\n    \"\"\"\n    q = _cast(QubitSupport, qubit_support)\n    ps = ParamMap(duration=duration)\n    return InteractionBlock(parameters=ps, qubit_support=q, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/parameters/","title":"Parameters","text":""},{"location":"api/parameters/#parameters","title":"Parameters","text":""},{"location":"api/parameters/#qadence.parameters.ParamMap","title":"<code>ParamMap(**kwargs)</code>","text":"<p>Connects UUIDs of parameters to their expressions and names.</p> <p>This class is not user-facing and only needed for more complex block definitions. It provides convenient access to expressions/UUIDs/names needed in different backends.</p> PARAMETER DESCRIPTION <code>kwargs</code> <p>Parameters.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>import sympy\nfrom qadence.parameters import ParamMap\n\n(x,y) = sympy.symbols(\"x y\")\nps = ParamMap(omega=2.0, duration=x+y)\n\nprint(f\"{ps.names() = }\")\nprint(f\"{ps.expressions() = }\")\nprint(f\"{ps.uuids() = }\")\n</code></pre> <pre><code>ps.names() = dict_keys(['omega', 'duration'])\nps.expressions() = dict_values([2.00000000000000, x + y])\nps.uuids() = dict_keys(['efb4c324-b9ae-4840-8983-6edb67aad01d', 'b56d3cc7-787d-44d7-a705-d195dd398ed4'])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __init__(self, **kwargs: str | TNumber | Tensor | Basic | Parameter):\n    self._name_dict: dict[str, tuple[str, Basic]] = {}\n    self._uuid_dict: dict[str, str] = {}\n    for name, v in kwargs.items():\n        param = v if isinstance(v, sympy.Basic) else Parameter(v)\n        uuid = str(uuid4())\n        self._name_dict[name] = (uuid, param)\n        self._uuid_dict[uuid] = param\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.Parameter","title":"<code>Parameter</code>","text":"<p>               Bases: <code>Symbol</code></p> <p>A wrapper on top of <code>sympy.Symbol</code>.</p> <p>Includes two additional keywords: <code>trainable</code> and <code>value</code>. This class is to define both feature parameter and variational parameters.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.trainable","title":"<code>trainable</code>  <code>instance-attribute</code>","text":"<p>Trainable parameters are variational parameters.</p> <p>Non-trainable parameters are feature parameters.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.value","title":"<code>value</code>  <code>instance-attribute</code>","text":"<p>(Initial) value of the parameter.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.__new__","title":"<code>__new__(name, **assumptions)</code>","text":"<p>Arguments:</p> <pre><code>name: When given a string only, the class\n    constructs a trainable Parameter with a a randomly initialized value.\n**assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n    kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n</code></pre> <p>Example: <pre><code>from qadence.parameters import Parameter, VariationalParameter\n\ntheta = Parameter(\"theta\")\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\nassert not theta.is_number\n\n# you can specify both trainable/value in the constructor\ntheta = Parameter(\"theta\", trainable=True, value=2.0)\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n\n# VariationalParameter/FeatureParameter are constructing\n# trainable/untrainable Parameters\ntheta = VariationalParameter(\"theta\", value=2.0)\nassert theta == Parameter(\"theta\", trainable=True, value=2.0)\n\n# When provided with a numeric type, Parameter constructs a sympy numeric type\":\nconstant_zero = Parameter(0)\nassert constant_zero.is_number\n\n# When passed a Parameter or a sympy expression, it just returns it.\nexpr = Parameter(\"x\") * Parameter(\"y\")\nprint(f\"{expr=} : {expr.free_symbols}\")\n</code></pre> <pre><code>theta: trainable=True value=0.9558957529779211\ntheta: trainable=True value=2.0\nexpr=x*y : {x, y}\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __new__(\n    cls, name: str | TNumber | Tensor | Basic | Parameter, **assumptions: Any\n) -&gt; Parameter | Basic | Expr | Array:\n    \"\"\"\n    Arguments:\n\n        name: When given a string only, the class\n            constructs a trainable Parameter with a a randomly initialized value.\n        **assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n            kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, VariationalParameter\n\n    theta = Parameter(\"theta\")\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    assert not theta.is_number\n\n    # you can specify both trainable/value in the constructor\n    theta = Parameter(\"theta\", trainable=True, value=2.0)\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n\n    # VariationalParameter/FeatureParameter are constructing\n    # trainable/untrainable Parameters\n    theta = VariationalParameter(\"theta\", value=2.0)\n    assert theta == Parameter(\"theta\", trainable=True, value=2.0)\n\n    # When provided with a numeric type, Parameter constructs a sympy numeric type\":\n    constant_zero = Parameter(0)\n    assert constant_zero.is_number\n\n    # When passed a Parameter or a sympy expression, it just returns it.\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    print(f\"{expr=} : {expr.free_symbols}\")\n    ```\n    \"\"\"\n    p: Parameter\n    if isinstance(name, get_args(TNumber)):\n        return sympify(name)\n    elif isinstance(name, Tensor):\n        if name.numel() == 1:\n            return sympify(name)\n        else:\n            return Array(name.detach().numpy())\n    elif isinstance(name, Parameter):\n        p = super().__new__(cls, name.name, **assumptions)\n        p.name = name.name\n        p.trainable = name.trainable\n        p.value = name.value\n        p.is_time = name.is_time\n        return p\n    elif isinstance(name, (Basic, Expr)):\n        if name.is_number:\n            return sympify(evaluate(name))\n        return name\n    elif isinstance(name, str):\n        p = super().__new__(cls, name, **assumptions)\n        p.trainable = assumptions.get(\"trainable\", True)\n        p.value = assumptions.get(\"value\", None)\n        p.is_time = assumptions.get(\"is_time\", False)\n        if p.value is None:\n            p.value = rand(1).item()\n        return p\n    else:\n        raise TypeError(f\"Parameter does not support type {type(name)}\")\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.FeatureParameter","title":"<code>FeatureParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def FeatureParameter(name: str, **kwargs: Any) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=False)`.\"\"\"\n    return Parameter(name, trainable=False, **kwargs)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.TimeParameter","title":"<code>TimeParameter(name)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False, is_time=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def TimeParameter(name: str) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=False, is_time=True)`.\"\"\"\n    return Parameter(name, trainable=False, is_time=True)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.VariationalParameter","title":"<code>VariationalParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def VariationalParameter(name: str, **kwargs: Any) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=True)`.\"\"\"\n    return Parameter(name, trainable=True, **kwargs)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.evaluate","title":"<code>evaluate(expr, values=None, as_torch=False)</code>","text":"<p>Arguments:</p> <pre><code>expr: An expression consisting of Parameters.\nvalues: values dict which contains values for the Parameters,\n    if empty, Parameter.value will be used.\nas_torch: Whether to retrieve a torch-differentiable expression result.\n</code></pre> <p>Example: <pre><code>from qadence.parameters import Parameter, evaluate\n\nexpr = Parameter(\"x\") * Parameter(\"y\")\n\n# Unless specified, Parameter initialized random values\n# Lets evaluate this expression and see what the result is\nres = evaluate(expr)\nprint(res)\n\n# We can also evaluate the expr using a custom dict\nd = {\"x\": 1, \"y\":2}\nres = evaluate(expr, d)\nprint(res)\n\n# Lastly, if we want a differentiable result, lets put the as_torch flag\nres = evaluate(expr, d, as_torch=True)\nprint(res)\n</code></pre> <pre><code>0.46340063661090397\n2\ntensor([2])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def evaluate(expr: Expr, values: dict | None = None, as_torch: bool = False) -&gt; TNumber | Tensor:\n    \"\"\"\n    Arguments:\n\n        expr: An expression consisting of Parameters.\n        values: values dict which contains values for the Parameters,\n            if empty, Parameter.value will be used.\n        as_torch: Whether to retrieve a torch-differentiable expression result.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, evaluate\n\n    expr = Parameter(\"x\") * Parameter(\"y\")\n\n    # Unless specified, Parameter initialized random values\n    # Lets evaluate this expression and see what the result is\n    res = evaluate(expr)\n    print(res)\n\n    # We can also evaluate the expr using a custom dict\n    d = {\"x\": 1, \"y\":2}\n    res = evaluate(expr, d)\n    print(res)\n\n    # Lastly, if we want a differentiable result, lets put the as_torch flag\n    res = evaluate(expr, d, as_torch=True)\n    print(res)\n    ```\n    \"\"\"\n    res: Basic\n    res_value: TNumber | Tensor\n    query: dict[Parameter, TNumber | Tensor] = dict()\n    values = values or dict()\n    if isinstance(expr, Array):\n        return Tensor(expr.tolist())\n    else:\n        if not expr.is_number:\n            for s in expr.free_symbols:\n                if s.name in values.keys():\n                    query[s] = values[s.name]\n                elif hasattr(s, \"value\"):\n                    query[s] = s.value\n                else:\n                    raise ValueError(f\"No value provided for symbol {s.name}\")\n        if as_torch:\n            res_value = make_differentiable(expr)(**{s.name: tensor(v) for s, v in query.items()})\n        else:\n            res = expr.subs(query)\n            res_value = sympy_to_numeric(res)\n        return res_value\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.extract_original_param_entry","title":"<code>extract_original_param_entry(param)</code>","text":"<p>Given an Expression, what was the original \"param\" given by the user? It is either.</p> <p>going to be a numeric value, or a sympy Expression (in case a string was given, it was converted via Parameter(\"string\").</p> Source code in <code>qadence/parameters.py</code> <pre><code>def extract_original_param_entry(\n    param: Expr,\n) -&gt; TNumber | Tensor | Expr:\n    \"\"\"\n    Given an Expression, what was the original \"param\" given by the user? It is either.\n\n    going to be a numeric value, or a sympy Expression (in case a string was given,\n    it was converted via Parameter(\"string\").\n    \"\"\"\n    return param if not param.is_number else evaluate(param)\n</code></pre>"},{"location":"api/parameters/#parameter-embedding","title":"Parameter embedding","text":""},{"location":"api/parameters/#qadence.blocks.embedding.embedding","title":"<code>embedding(block, to_gate_params=False, engine=Engine.TORCH)</code>","text":"<p>Construct embedding function which maps user-facing parameters to either expression-level.</p> <p>parameters or gate-level parameters. The constructed embedding function has the signature:</p> <pre><code> embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n</code></pre> <p>which means that it maps the variational parameter dict <code>params</code> and the feature parameter dict <code>inputs</code> to one new parameter dict <code>embedded_dict</code> which holds all parameters that are needed to execute a circuit on a given backend. There are two different modes for this mapping:</p> <ul> <li>Expression-level parameters: For AD-based optimization. For every unique expression we end   up with one entry in the embedded dict:   <code>len(embedded_dict) == len(unique_parameter_expressions)</code>.</li> <li>Gate-level parameters: For PSR-based optimization or real devices. One parameter for each   gate parameter, regardless if they are based on the same expression. <code>len(embedded_dict) ==   len(parametric_gates)</code>. This is needed because PSR requires to shift the angles of every   gate where the same parameter appears.</li> </ul> PARAMETER DESCRIPTION <code>block</code> <p>parametrized block into which we want to embed parameters.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>to_gate_params</code> <p>A boolean flag whether to generate gate-level parameters or expression-level parameters.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>tuple[ParamDictType, Callable[[ParamDictType, ParamDictType], ParamDictType]]</code> <p>A tuple with variational parameter dict and the embedding function.</p> Source code in <code>qadence/blocks/embedding.py</code> <pre><code>def embedding(\n    block: AbstractBlock, to_gate_params: bool = False, engine: Engine = Engine.TORCH\n) -&gt; tuple[\n    ParamDictType,\n    Callable[[ParamDictType, ParamDictType], ParamDictType],\n]:\n    \"\"\"Construct embedding function which maps user-facing parameters to either *expression-level*.\n\n    parameters or *gate-level* parameters. The constructed embedding function has the signature:\n\n         embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n\n    which means that it maps the *variational* parameter dict `params` and the *feature* parameter\n    dict `inputs` to one new parameter dict `embedded_dict` which holds all parameters that are\n    needed to execute a circuit on a given backend. There are two different *modes* for this\n    mapping:\n\n    - *Expression-level* parameters: For AD-based optimization. For every unique expression we end\n      up with one entry in the embedded dict:\n      `len(embedded_dict) == len(unique_parameter_expressions)`.\n    - *Gate-level* parameters: For PSR-based optimization or real devices. One parameter for each\n      gate parameter, regardless if they are based on the same expression. `len(embedded_dict) ==\n      len(parametric_gates)`. This is needed because PSR requires to shift the angles of **every**\n      gate where the same parameter appears.\n\n    Arguments:\n        block: parametrized block into which we want to embed parameters.\n        to_gate_params: A boolean flag whether to generate gate-level parameters or\n            expression-level parameters.\n\n    Returns:\n        A tuple with variational parameter dict and the embedding function.\n    \"\"\"\n    concretize_parameter = _concretize_parameter(engine)\n    if engine == Engine.TORCH:\n        cast_dtype = tensor\n    else:\n        from jax.numpy import array\n\n        cast_dtype = array\n\n    unique_expressions = unique(expressions(block))\n    unique_symbols = [p for p in unique(parameters(block)) if not isinstance(p, sympy.Array)]\n    unique_const_matrices = [e for e in unique_expressions if isinstance(e, sympy.Array)]\n    unique_expressions = [e for e in unique_expressions if not isinstance(e, sympy.Array)]\n\n    # NOTE\n    # there are 3 kinds of parameters in qadence\n    # - non-trainable which are considered as inputs for classical data\n    # - trainable which are the variational parameters to be optimized\n    # - fixed: which are non-trainable parameters with fixed value (e.g. pi/2)\n    #\n    # both non-trainable and trainable parameters can have the same element applied\n    # to different operations in the quantum circuit, e.g. assigning the same parameter\n    # to multiple gates.\n    non_numeric_symbols = [p for p in unique_symbols if not p.is_number]\n    trainable_symbols = [p for p in non_numeric_symbols if p.trainable]\n    constant_expressions = [expr for expr in unique_expressions if expr.is_number]\n    # we dont need to care about constant symbols if they are contained in an symbolic expression\n    # we only care about gate params which are ONLY a constant\n\n    embeddings: dict[sympy.Expr, DifferentiableExpression] = {\n        expr: make_differentiable(expr=expr, engine=engine)\n        for expr in unique_expressions\n        if not expr.is_number\n    }\n\n    uuid_to_expr = uuid_to_expression(block)\n\n    def embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n        embedded_params: dict[sympy.Expr, ArrayLike] = {}\n        for expr, fn in embeddings.items():\n            angle: ArrayLike\n            values = {}\n            for symbol in expr.free_symbols:\n                if symbol.name in inputs:\n                    value = inputs[symbol.name]\n                elif symbol.name in params:\n                    value = params[symbol.name]\n                else:\n                    if symbol.is_time:\n                        value = tensor(1.0)\n                    else:\n                        msg_trainable = \"Trainable\" if symbol.trainable else \"Non-trainable\"\n                        raise KeyError(\n                            f\"{msg_trainable} parameter '{symbol.name}' not found in the \"\n                            f\"inputs list: {list(inputs.keys())} nor the \"\n                            f\"params list: {list(params.keys())}.\"\n                        )\n                values[symbol.name] = value\n            angle = fn(**values)\n            # do not reshape parameters which are multi-dimensional\n            # tensors, such as for example generator matrices\n            if not len(angle.squeeze().shape) &gt; 1:\n                angle = angle.reshape(-1)\n            embedded_params[expr] = angle\n\n        for e in constant_expressions + unique_const_matrices:\n            embedded_params[e] = params[stringify(e)]\n\n        if to_gate_params:\n            gate_lvl_params: ParamDictType = {}\n            for uuid, e in uuid_to_expr.items():\n                gate_lvl_params[uuid] = embedded_params[e]\n            return gate_lvl_params\n        else:\n            embedded_params.update(inputs)\n            for k, v in params.items():\n                if k not in embedded_params:\n                    embedded_params[k] = v\n            out = {\n                stringify(k) if not isinstance(k, str) else k: (\n                    as_tensor(v)[None] if as_tensor(v).ndim == 0 else v\n                )\n                for k, v in embedded_params.items()\n            }\n            return out\n\n    params: ParamDictType\n    params = {\n        p.name: concretize_parameter(value=p.value, trainable=True) for p in trainable_symbols\n    }\n    params.update(\n        {\n            stringify(expr): concretize_parameter(value=evaluate(expr), trainable=False)\n            for expr in constant_expressions\n        }\n    )\n    params.update(\n        {\n            stringify(expr): cast_dtype(nparray(expr.tolist(), dtype=npcdouble))\n            for expr in unique_const_matrices\n        }\n    )\n    return params, embedding_fn\n</code></pre>"},{"location":"api/pasqal_cloud_connection/","title":"Pasqal Cloud Connection","text":""},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.WorkloadNotDoneError","title":"<code>WorkloadNotDoneError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Is raised if a workload is not yet finished running on remote.</p>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.WorkloadSpec","title":"<code>WorkloadSpec(circuit, backend, result_types, parameter_values=None, observable=None)</code>  <code>dataclass</code>","text":"<p>Specification of a workload to be executed on Pasqal Cloud.</p> <p>This data class defines a single workload specification that is to be executed on Pasqal's cloud platform.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The quantum circuit to be executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>backend</code> <p>The backend to execute the workload on. Not all backends are available on the cloud platform. Currently the supported backend is <code>BackendName.PYQTORCH</code>.</p> <p> TYPE: <code>BackendName | str</code> </p> <code>result_types</code> <p>The types of result to compute for this workload. The circuit will be run for all result types specified here one by one.</p> <p> TYPE: <code>list[ResultType]</code> </p> <code>parameter_values</code> <p>If the quantum circuit has feature parameters, values for those need to be provided. In the case there are only variational parameters, this field is optional. In the case there are no parameters, this field needs to be <code>None</code>. The parameter values can be either a tensor of dimension 0 or 1, which can differ per parameter. For parameters that are an array, i.e. dimension 1, all array lengths should be equal.</p> <p> TYPE: <code>dict[str, Tensor] | None</code> DEFAULT: <code>None</code> </p> <code>observable</code> <p>Observable that is used when <code>result_types</code> contains <code>ResultType.EXPECTATION</code>. The observable field is mandatory in this case. If not, the value of this field will be ignored. Only a single observable can be passed for cloud submission; providing a list of observables is not supported.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.WorkloadStoppedError","title":"<code>WorkloadStoppedError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Is raised when a workload has stopped running on remote for some reason.</p>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.check_status","title":"<code>check_status(connection, workload_id)</code>","text":"<p>Checks if the workload is successfully finished on remote connection.</p> PARAMETER DESCRIPTION <code>connection</code> <p>A <code>pasqal_cloud.SDK</code> instance which is used to connect to the cloud.</p> <p> TYPE: <code>SDK</code> </p> <code>workload_id</code> <p>the id <code>str</code> that is associated with the workload.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>WorkloadNotDoneError</code> <p>Is raised when the workload status is \"PENDING\", \"RUNNING\" or \"PAUSED\".</p> <code>WorkloadStoppedError</code> <p>Is raise when the workload status is \"CANCELED\", \"TIMED_OUT\" or \"ERROR\".</p> <code>ValueError</code> <p>Is raised when the workload status has an unsupported value.</p> RETURNS DESCRIPTION <code>Workload</code> <p>The workload result if its status is \"DONE\" as a <code>pasqal_cloud.Workload</code> object.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def check_status(connection: SDK, workload_id: str) -&gt; WorkloadResult:\n    \"\"\"Checks if the workload is successfully finished on remote connection.\n\n    Args:\n        connection: A `pasqal_cloud.SDK` instance which is used to connect to the cloud.\n        workload_id: the id `str` that is associated with the workload.\n\n    Raises:\n        WorkloadNotDoneError: Is raised when the workload status is \"PENDING\", \"RUNNING\" or\n            \"PAUSED\".\n        WorkloadStoppedError: Is raise when the workload status is \"CANCELED\", \"TIMED_OUT\" or\n            \"ERROR\".\n        ValueError: Is raised when the workload status has an unsupported value.\n\n    Returns:\n        The workload result if its status is \"DONE\" as a `pasqal_cloud.Workload` object.\n    \"\"\"\n    # TODO Make the function return a \"nice\" result object\n    result = connection.get_workload(workload_id)\n    if result.status == \"DONE\":\n        return result\n    if result.status in (\"PENDING\", \"RUNNING\", \"PAUSED\"):\n        raise WorkloadNotDoneError(\n            f\"Workload with id {workload_id} is not yet finished, the status is {result.status}\"\n        )\n    if result.status in (\"CANCELED\", \"TIMED_OUT\", \"ERROR\"):\n        message = f\"Workload with id {workload_id} couldn't finish, the status is {result.status}.\"\n        if result.status == \"ERROR\":\n            message += f\"The following error(s) occurred {result.errors}\"\n        raise WorkloadStoppedError(message)\n    raise ValueError(\n        f\"Undefined workload status ({result.status}) was returned for workload ({result.id})\"\n    )\n</code></pre>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.get_result","title":"<code>get_result(connection, workload_id, timeout=60.0, refresh_time=1.0)</code>","text":"<p>Repeatedly checks if a workload has finished and returns the result.</p> PARAMETER DESCRIPTION <code>connection</code> <p>A <code>pasqal_cloud.SDK</code> instance which is used to connect to the cloud.</p> <p> TYPE: <code>SDK</code> </p> <code>workload_id</code> <p>the id <code>str</code> that is associated with the workload.</p> <p> TYPE: <code>str</code> </p> <code>timeout</code> <p>Time in seconds after which the function times out. Defaults to 60.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>60.0</code> </p> <code>refresh_time</code> <p>Time in seconds after which the remote is requested to update the status again, when the workload is not finished yet. Defaults to 1.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> RAISES DESCRIPTION <code>TimeoutError</code> <p>description</p> RETURNS DESCRIPTION <code>Workload</code> <p>The workload result if its status is \"DONE\" as a <code>pasqal_cloud.Workload</code> object.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def get_result(\n    connection: SDK, workload_id: str, timeout: float = 60.0, refresh_time: float = 1.0\n) -&gt; WorkloadResult:\n    \"\"\"Repeatedly checks if a workload has finished and returns the result.\n\n    Args:\n        connection: A `pasqal_cloud.SDK` instance which is used to connect to the cloud.\n        workload_id: the id `str` that is associated with the workload.\n        timeout: Time in seconds after which the function times out. Defaults to 60.0.\n        refresh_time: Time in seconds after which the remote is requested to update the status\n            again, when the workload is not finished yet. Defaults to 1.0.\n\n    Raises:\n        TimeoutError: _description_\n\n    Returns:\n        The workload result if its status is \"DONE\" as a `pasqal_cloud.Workload` object.\n    \"\"\"\n    max_refresh_count = int(timeout // refresh_time)\n    for _ in range(max_refresh_count):\n        try:\n            result = check_status(connection, workload_id)\n        except WorkloadNotDoneError:\n            time.sleep(refresh_time)\n            continue\n        return result\n    raise TimeoutError(\"Request timed out because it wasn't finished in the specified time. \")\n</code></pre>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.get_workload_spec","title":"<code>get_workload_spec(model, result_types, parameter_values=None, observable=None)</code>","text":"<p>Creates a <code>WorkloadSpec</code> from a quantum model.</p> <p>This function creates a <code>WorkloadSpec</code> from a <code>QuantumModel</code> and the other arguments provided. The circuit, that is extracted from the model, is the original circuit that was used to initialize the model, not the backend converted circuit in <code>model.circuit</code>. The backend set in the model will be used in the workload specification.</p> <p>It is important to note that in case there is an observable defined in the model, it is ignored in the workload specification. To provide an observable to the workload specification, it is only possible to set it in the observable argument of this function.</p> PARAMETER DESCRIPTION <code>model</code> <p>The quantum model that defines the circuit and backend for the workload spec.</p> <p> TYPE: <code>QuantumModel</code> </p> <code>result_types</code> <p>A list of result types that is requested in this workload.</p> <p> TYPE: <code>list[ResultType]</code> </p> <code>parameter_values</code> <p>The parameter values that should be used during execution of the workload.</p> <p> TYPE: <code>dict[str, Tensor] | None</code> DEFAULT: <code>None</code> </p> <code>observable</code> <p>Observable that is used when <code>result_types</code> contains <code>ResultType.EXPECTATION</code>. The observable field is mandatory in this case. If not, the value of this field will be ignored. Only a single observable can be passed for cloud submission; providing a list of observables is not supported.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>WorkloadSpec</code> <p>A <code>WorkloadSpec</code> instance based on the quantum model passed to this function.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def get_workload_spec(\n    model: QuantumModel,\n    result_types: list[ResultType],\n    parameter_values: dict[str, Tensor] | None = None,\n    observable: AbstractBlock | None = None,\n) -&gt; WorkloadSpec:\n    \"\"\"Creates a `WorkloadSpec` from a quantum model.\n\n    This function creates a `WorkloadSpec` from a `QuantumModel` and the other arguments provided.\n    The circuit, that is extracted from the model, is the original circuit that was used to\n    initialize the model, not the backend converted circuit in `model.circuit`. The backend set in\n    the model will be used in the workload specification.\n\n    It is important to note that in case there is an observable defined in the model, it is ignored\n    in the workload specification. To provide an observable to the workload specification, it is\n    only possible to set it in the observable argument of this function.\n\n    Args:\n        model: The quantum model that defines the circuit and backend for the workload spec.\n        result_types: A list of result types that is requested in this workload.\n        parameter_values: The parameter values that should be used during execution of the\n            workload.\n        observable: Observable that is used when `result_types` contains `ResultType.EXPECTATION`.\n            The observable field is mandatory in this case. If not, the value of this field will\n            be ignored. Only a single observable can be passed for cloud submission; providing a\n            list of observables is not supported.\n\n    Returns:\n        A `WorkloadSpec` instance based on the quantum model passed to this function.\n    \"\"\"\n    circuit = model._circuit.original\n    backend = model._backend_name\n    return WorkloadSpec(circuit, backend, result_types, parameter_values, observable)\n</code></pre>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.submit_workload","title":"<code>submit_workload(connection, workload)</code>","text":"<p>Uploads a workload to Pasqal's Cloud and returns the created workload ID.</p> PARAMETER DESCRIPTION <code>connection</code> <p>A <code>pasqal_cloud.SDK</code> instance which is used to connect to the cloud.</p> <p> TYPE: <code>SDK</code> </p> <code>workload</code> <p>A <code>WorkloadSpec</code> object, defining the specification of the workload that needs to be uploaded.</p> <p> TYPE: <code>WorkloadSpec</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A workload id as a <code>str</code>.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def submit_workload(connection: SDK, workload: WorkloadSpec) -&gt; str:\n    \"\"\"Uploads a workload to Pasqal's Cloud and returns the created workload ID.\n\n    Args:\n        connection: A `pasqal_cloud.SDK` instance which is used to connect to the cloud.\n        workload: A `WorkloadSpec` object, defining the specification of the workload that needs to\n            be uploaded.\n\n    Returns:\n        A workload id as a `str`.\n    \"\"\"\n    workload_json = _workload_spec_to_json(workload)\n    remote_workload = connection.create_workload(\n        workload_json.workload_type, workload_json.backend_type, workload_json.config\n    )\n    workload_id: str = remote_workload.id\n    return workload_id\n</code></pre>"},{"location":"api/quantumcircuit/","title":"QuantumCircuit","text":""},{"location":"api/quantumcircuit/#quantumcircuit","title":"QuantumCircuit","text":"<p>The abstract <code>QuantumCircuit</code> is the key object in Qadence, as it is what can be executed.</p>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit","title":"<code>QuantumCircuit(support, *blocks)</code>  <code>dataclass</code>","text":"<p>Am abstract QuantumCircuit instance.</p> <p>It needs to be passed to a quantum backend for execution.</p> <p>Arguments:</p> <pre><code>support: `Register` or number of qubits. If an integer is provided, a register is\n    constructed with `Register.all_to_all(x)`\n*blocks: (Possibly multiple) blocks to construct the circuit from.\n</code></pre> Source code in <code>qadence/circuit.py</code> <pre><code>def __init__(self, support: int | Register, *blocks: AbstractBlock):\n    \"\"\"\n    Arguments:\n\n        support: `Register` or number of qubits. If an integer is provided, a register is\n            constructed with `Register.all_to_all(x)`\n        *blocks: (Possibly multiple) blocks to construct the circuit from.\n    \"\"\"\n    self.block = chain(*blocks) if len(blocks) != 1 else blocks[0]\n    self.register = Register(support) if isinstance(support, int) else support\n\n    global_block = isinstance(self.block, AnalogBlock) and self.block.qubit_support.is_global\n    if not global_block and len(self.block) and self.block.n_qubits &gt; self.register.n_qubits:\n        raise ValueError(\n            f\"Register with {self.register.n_qubits} qubits is too small for the \"\n            f\"given block with {self.block.n_qubits} qubits\"\n        )\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.unique_parameters","title":"<code>unique_parameters</code>  <code>property</code>","text":"<p>Return the unique parameters in the circuit.</p> <p>These parameters are the actual user-facing parameters which can be assigned by the user. Multiple gates can contain the same unique parameter</p> RETURNS DESCRIPTION <code>list[Parameter]</code> <p>list[Parameter]: List of unique parameters in the circuit</p>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.dagger","title":"<code>dagger()</code>","text":"<p>Reverse the QuantumCircuit by calling dagger on the block.</p> Source code in <code>qadence/circuit.py</code> <pre><code>def dagger(self) -&gt; QuantumCircuit:\n    \"\"\"Reverse the QuantumCircuit by calling dagger on the block.\"\"\"\n    return QuantumCircuit(self.n_qubits, self.block.dagger())\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.get_blocks_by_tag","title":"<code>get_blocks_by_tag(tag)</code>","text":"<p>Extract one or more blocks using the human-readable tag.</p> <p>This function recursively explores all composite blocks to find all the occurrences of a certain tag in the blocks.</p> PARAMETER DESCRIPTION <code>tag</code> <p>the tag to look for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>list[AbstractBlock]: The block(s) corresponding to the given tag</p> Source code in <code>qadence/circuit.py</code> <pre><code>def get_blocks_by_tag(self, tag: str) -&gt; list[AbstractBlock]:\n    \"\"\"Extract one or more blocks using the human-readable tag.\n\n    This function recursively explores all composite blocks to find\n    all the occurrences of a certain tag in the blocks.\n\n    Args:\n        tag (str): the tag to look for\n\n    Returns:\n        list[AbstractBlock]: The block(s) corresponding to the given tag\n    \"\"\"\n\n    def _get_block(block: AbstractBlock) -&gt; list[AbstractBlock]:\n        blocks = []\n        if block.tag == tag:\n            blocks += [block]\n        if isinstance(block, CompositeBlock):\n            blocks += flatten(*[_get_block(b) for b in block.blocks])\n        return blocks\n\n    return _get_block(self.block)\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.parameters","title":"<code>parameters()</code>","text":"<p>Extract all parameters for primitive blocks in the circuit.</p> <p>Notice that this function returns all the unique Parameters used in the quantum circuit. These can correspond to constants too.</p> RETURNS DESCRIPTION <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>List[tuple[Parameter]]: A list of tuples containing the Parameter</p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>instance of each of the primitive blocks in the circuit or, if the <code>flatten</code></p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>flag is set to True, a flattened list of all circuit parameters</p> Source code in <code>qadence/circuit.py</code> <pre><code>def parameters(self) -&gt; list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]:\n    \"\"\"Extract all parameters for primitive blocks in the circuit.\n\n    Notice that this function returns all the unique Parameters used\n    in the quantum circuit. These can correspond to constants too.\n\n    Returns:\n        List[tuple[Parameter]]: A list of tuples containing the Parameter\n        instance of each of the primitive blocks in the circuit or, if the `flatten`\n        flag is set to True, a flattened list of all circuit parameters\n    \"\"\"\n    return parameters(self.block)\n</code></pre>"},{"location":"api/register/","title":"Register","text":""},{"location":"api/register/#quantum-registers","title":"Quantum Registers","text":""},{"location":"api/register/#qadence.register.Register","title":"<code>Register(support, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>","text":"<p>A register of qubits including 2D coordinates.</p> <p>Instantiating the Register class directly is only recommended for building custom registers. For most uses where a predefined lattice is desired it is recommended to use the various class methods available, e.g. <code>Register.triangular_lattice</code>.</p> PARAMETER DESCRIPTION <code>support</code> <p>A NetworkX graph or number of qubits. Nodes can include a <code>\"pos\"</code> attribute such that e.g.: <code>graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}</code> which will be used in backends that need qubit coordinates. Passing a number of qubits calls <code>Register.all_to_all(n_qubits)</code>.</p> <p> TYPE: <code>Graph | int</code> </p> <code>spacing</code> <p>Value set as the distance between the two closest qubits. The spacing argument is also available for all the class method constructors.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>1.0</code> </p> <p>Examples: <pre><code>from qadence import Register\n\nreg_all = Register.all_to_all(n_qubits = 4)\nreg_line = Register.line(n_qubits = 4)\nreg_circle = Register.circle(n_qubits = 4)\nreg_squre = Register.square(qubits_side = 2)\nreg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\nreg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\nreg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n</code></pre> </p> Source code in <code>qadence/register.py</code> <pre><code>def __init__(\n    self,\n    support: nx.Graph | int,\n    spacing: float | None = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n):\n    \"\"\"\n    A register of qubits including 2D coordinates.\n\n    Instantiating the Register class directly is only recommended for building custom registers.\n    For most uses where a predefined lattice is desired it is recommended to use the various\n    class methods available, e.g. `Register.triangular_lattice`.\n\n    Arguments:\n        support: A NetworkX graph or number of qubits. Nodes can include a `\"pos\"` attribute\n            such that e.g.: `graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}` which\n            will be used in backends that need qubit coordinates. Passing a number of qubits\n            calls `Register.all_to_all(n_qubits)`.\n        spacing: Value set as the distance between the two closest qubits. The spacing\n            argument is also available for all the class method constructors.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import Register\n\n    reg_all = Register.all_to_all(n_qubits = 4)\n    reg_line = Register.line(n_qubits = 4)\n    reg_circle = Register.circle(n_qubits = 4)\n    reg_squre = Register.square(qubits_side = 2)\n    reg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\n    reg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\n    reg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n    ```\n    \"\"\"\n    if device_specs is not None and not isinstance(device_specs, RydbergDevice):\n        raise ValueError(\"Device specs are not valid. Please pass a `RydbergDevice` instance.\")\n\n    self.device_specs = device_specs\n\n    self.graph = support if isinstance(support, nx.Graph) else alltoall_graph(support)\n\n    if spacing is not None and self.min_distance != 0.0:\n        _scale_node_positions(self.graph, self.min_distance, spacing)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.all_node_pairs","title":"<code>all_node_pairs</code>  <code>property</code>","text":"<p>Return a list of all possible qubit pairs in the register.</p>"},{"location":"api/register/#qadence.register.Register.coords","title":"<code>coords</code>  <code>property</code>","text":"<p>Return the dictionary of qubit coordinates.</p>"},{"location":"api/register/#qadence.register.Register.distances","title":"<code>distances</code>  <code>property</code>","text":"<p>Return a dictionary of distances for all qubit pairs in the register.</p>"},{"location":"api/register/#qadence.register.Register.edge_distances","title":"<code>edge_distances</code>  <code>property</code>","text":"<p>Return a dictionary of distances for the qubit pairs that are.</p> <p>connected by an edge in the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return the EdgeView of the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.min_distance","title":"<code>min_distance</code>  <code>property</code>","text":"<p>Return the minimum distance between two qubts in the register.</p>"},{"location":"api/register/#qadence.register.Register.n_qubits","title":"<code>n_qubits</code>  <code>property</code>","text":"<p>Total number of qubits in the register.</p>"},{"location":"api/register/#qadence.register.Register.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return the NodeView of the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.support","title":"<code>support</code>  <code>property</code>","text":"<p>Return the set of qubits in the register.</p>"},{"location":"api/register/#qadence.register.Register.all_to_all","title":"<code>all_to_all(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a register with an all-to-all connectivity graph.</p> <p>The graph is projected onto a 2D space and the qubit coordinates are set using a spring layout algorithm.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef all_to_all(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a register with an all-to-all connectivity graph.\n\n    The graph is projected\n    onto a 2D space and the qubit coordinates are set using a spring layout algorithm.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    return cls(alltoall_graph(n_qubits), spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.circle","title":"<code>circle(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a circle register.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef circle(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a circle register.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    graph = nx.grid_2d_graph(n_qubits, 1, periodic=True)\n    graph = nx.relabel_nodes(graph, {(i, 0): i for i in range(n_qubits)})\n    coords = nx.circular_layout(graph)\n    values = {i: {\"pos\": pos} for i, pos in coords.items()}\n    nx.set_node_attributes(graph, values)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.draw","title":"<code>draw(show=True)</code>","text":"<p>Draw the underlying NetworkX graph representing the register.</p> Source code in <code>qadence/register.py</code> <pre><code>def draw(self, show: bool = True) -&gt; None:\n    \"\"\"Draw the underlying NetworkX graph representing the register.\"\"\"\n    coords = {i: n[\"pos\"] for i, n in self.graph.nodes.items()}\n    nx.draw(self.graph, with_labels=True, pos=coords)\n    if show:\n        plt.gcf().show()\n</code></pre>"},{"location":"api/register/#qadence.register.Register.from_coordinates","title":"<code>from_coordinates(coords, lattice=LatticeTopology.ARBITRARY, spacing=None, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a register from a list of qubit coordinates.</p> <p>Each node is added to the underlying graph with the respective coordinates, but the edges are left empty.</p> PARAMETER DESCRIPTION <code>coords</code> <p>List of qubit coordinate tuples.</p> <p> TYPE: <code>list[tuple]</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef from_coordinates(\n    cls,\n    coords: list[tuple],\n    lattice: LatticeTopology | str = LatticeTopology.ARBITRARY,\n    spacing: float | None = None,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a register from a list of qubit coordinates.\n\n    Each node is added to the underlying\n    graph with the respective coordinates, but the edges are left empty.\n\n    Arguments:\n        coords: List of qubit coordinate tuples.\n    \"\"\"\n    graph = nx.Graph()\n    for i, pos in enumerate(coords):\n        graph.add_node(i, pos=pos)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.honeycomb_lattice","title":"<code>honeycomb_lattice(n_cells_row, n_cells_col, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a honeycomb lattice register.</p> <p>Each cell is an hexagon made up of six qubits.</p> PARAMETER DESCRIPTION <code>n_cells_row</code> <p>Number of cells in each row.</p> <p> TYPE: <code>int</code> </p> <code>n_cells_col</code> <p>Number of cells in each column.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef honeycomb_lattice(\n    cls,\n    n_cells_row: int,\n    n_cells_col: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a honeycomb lattice register.\n\n    Each cell is an hexagon made up of six qubits.\n\n    Arguments:\n        n_cells_row: Number of cells in each row.\n        n_cells_col: Number of cells in each column.\n    \"\"\"\n    graph = nx.hexagonal_lattice_graph(n_cells_row, n_cells_col)\n    graph = nx.relabel_nodes(graph, {(i, j): k for k, (i, j) in enumerate(graph.nodes)})\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.line","title":"<code>line(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a line register.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef line(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a line register.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    return cls(line_graph(n_qubits), spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.rescale_coords","title":"<code>rescale_coords(scaling)</code>","text":"<p>Rescale the coordinates of all qubits in the register.</p> PARAMETER DESCRIPTION <code>scaling</code> <p>Scaling value.</p> <p> TYPE: <code>float</code> </p> Source code in <code>qadence/register.py</code> <pre><code>def rescale_coords(self, scaling: float) -&gt; Register:\n    \"\"\"\n    Rescale the coordinates of all qubits in the register.\n\n    Arguments:\n        scaling: Scaling value.\n    \"\"\"\n    g = deepcopy(self.graph)\n    _scale_node_positions(g, min_distance=1.0, spacing=scaling)\n    return Register(g, spacing=None, device_specs=self.device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.square","title":"<code>square(qubits_side, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a square register.</p> PARAMETER DESCRIPTION <code>qubits_side</code> <p>Number of qubits on one side of the square.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef square(\n    cls,\n    qubits_side: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a square register.\n\n    Arguments:\n        qubits_side: Number of qubits on one side of the square.\n    \"\"\"\n    n_points = 4 * (qubits_side - 1)\n\n    def gen_points() -&gt; np.ndarray:\n        rotate_left = np.array([[0.0, -1.0], [1.0, 0.0]])\n        increment = np.array([0.0, 1.0])\n\n        points = [np.array([0.0, 0.0])]\n        counter = 1\n        while len(points) &lt; n_points:\n            points.append(points[-1] + increment)\n\n            counter = (counter + 1) % qubits_side\n            if counter == 0:\n                increment = rotate_left.dot(increment)\n                counter = 1\n        points = np.array(points)  # type: ignore[assignment]\n        points -= np.mean(points, axis=0)\n\n        return points  # type: ignore[return-value]\n\n    graph = nx.grid_2d_graph(n_points, 1, periodic=True)\n    graph = nx.relabel_nodes(graph, {(i, 0): i for i in range(n_points)})\n    values = {i: {\"pos\": point} for i, point in zip(graph.nodes, gen_points())}\n    nx.set_node_attributes(graph, values)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.triangular_lattice","title":"<code>triangular_lattice(n_cells_row, n_cells_col, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a triangular lattice register.</p> <p>Each cell is a triangle made up of three qubits.</p> PARAMETER DESCRIPTION <code>n_cells_row</code> <p>Number of cells in each row.</p> <p> TYPE: <code>int</code> </p> <code>n_cells_col</code> <p>Number of cells in each column.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef triangular_lattice(\n    cls,\n    n_cells_row: int,\n    n_cells_col: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a triangular lattice register.\n\n    Each cell is a triangle made up of three qubits.\n\n    Arguments:\n        n_cells_row: Number of cells in each row.\n        n_cells_col: Number of cells in each column.\n    \"\"\"\n    return cls(triangular_lattice_graph(n_cells_row, n_cells_col), spacing, device_specs)\n</code></pre>"},{"location":"api/serialization/","title":"Serialization","text":""},{"location":"api/serialization/#serialization","title":"Serialization","text":""},{"location":"api/serialization/#qadence.serialization.SerializationModel","title":"<code>SerializationModel(d=dict())</code>  <code>dataclass</code>","text":"<p>A serialization model class to serialize data from <code>QuantumModel</code>s,.</p> <p><code>torch.nn.Module</code> and similar structures. The data included in the serialization logic includes: the <code>AbstractBlock</code> and its children classes, <code>QuantumCircuit</code>, <code>Register</code>, and <code>sympy</code> expressions (including <code>Parameter</code> class from <code>qadence.parameters</code>).</p> <p>A children class must define the <code>value</code> attribute type and how to handle it, since it is the main property for the class to be used by the serialization process. For instance:</p> <pre><code>@dataclass\nclass QuantumCircuitSerialization(SerializationModel):\n    value: QuantumCircuit = dataclass_field(init=False)\n\n    def __post_init__(self) -&gt; None:\n        self.value = (\n            QuantumCircuit._from_dict(self.d)\n            if isinstance(self.d, dict)\n            else self.d\n        )\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.deserialize","title":"<code>deserialize(d, as_torch=False)</code>","text":"<p>Supported Types:</p> <p>AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module Deserializes a dict to one of the supported types.</p> PARAMETER DESCRIPTION <code>d</code> <p>A dict containing a serialized object.</p> <p> TYPE: <code>dict</code> </p> <code>as_torch</code> <p>Whether to transform to torch for the deserialized object.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Returns:     AbstractBlock, QuantumCircuit, QuantumModel, Register, torch.nn.Module.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n\n## Lets use myblock in a QuantumCircuit and serialize it.\n\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('2d678c5f-e4c8-4b30-8041-95c7b8f1ebd0', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.8645975839861424'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('f4285831-0313-4cd2-bad0-f124d21de721', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.0972339211342822'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('2d829a9c-60cd-4f1e-bd09-4d8197154697', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.40851880829799214'}}})}}, 'noise': None}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('53d5b702-3300-47c4-8e08-a73ef960dc49', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.08809158150488472'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('73deb98e-1071-4b2f-a82d-74007b1254f6', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.08767700023603009'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('e5594264-7c7c-4092-a3d1-00a96749dc1f', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.5225891150772385'}}})}}, 'noise': None}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None, 'noise': None}], 'noise': None}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def deserialize(d: dict, as_torch: bool = False) -&gt; SUPPORTED_TYPES:\n    \"\"\"\n    Supported Types:\n\n    AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module\n    Deserializes a dict to one of the supported types.\n\n    Arguments:\n        d (dict): A dict containing a serialized object.\n        as_torch (bool): Whether to transform to torch for the deserialized object.\n    Returns:\n        AbstractBlock, QuantumCircuit, QuantumModel, Register, torch.nn.Module.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\n    obj: SerializationModel\n    if d.get(\"expression\"):\n        obj = ExpressionSerialization(d)\n    elif d.get(\"block\") and d.get(\"register\"):\n        obj = QuantumCircuitSerialization(d)\n    elif d.get(\"graph\"):\n        obj = RegisterSerialization(d)\n    elif d.get(\"type\"):\n        obj = BlockTypeSerialization(d)\n    else:\n        obj = ModelSerialization(d, as_torch=as_torch)\n    return obj.value\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.load","title":"<code>load(file_path, map_location='cpu')</code>","text":"<p>Same as serialize/deserialize but for storing/loading files.</p> <p>Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register Loads a .json or .pt file to one of the supported types.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> </p> <code>map_location</code> <p>In case of a .pt file, on which device to load the object (cpu,cuda).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <p>Returns:     A object of type AbstractBlock, QuantumCircuit, QuantumModel, Register.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\n\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def load(file_path: str | Path, map_location: str = \"cpu\") -&gt; SUPPORTED_TYPES:\n    \"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n\n    Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register\n    Loads a .json or .pt file to one of the supported types.\n\n    Arguments:\n        file_path (str): The name of the file.\n        map_location (str): In case of a .pt file, on which device to load the object (cpu,cuda).\n    Returns:\n        A object of type AbstractBlock, QuantumCircuit, QuantumModel, Register.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\n    d = {}\n    if isinstance(file_path, str):\n        file_path = Path(file_path)\n    if not os.path.exists(file_path):\n        logger.error(f\"File {file_path} not found.\")\n        raise FileNotFoundError\n    FORMAT = file_extension(file_path)\n    _, _, load_fn, _ = FORMAT_DICT[FORMAT]  # type: ignore[index]\n    try:\n        d = load_fn(file_path, map_location)\n        logger.debug(f\"Successfully loaded {d} from {file_path}.\")\n    except Exception as e:\n        logger.error(f\"Unable to load Object from {file_path} due to {e}\")\n    return deserialize(d)\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.parse_expr_fn","title":"<code>parse_expr_fn(code)</code>","text":"<p>A parsing expressions function that checks whether a given code is valid on.</p> <p>the parsing grammar. The grammar is defined to be compatible with <code>sympy</code> expressions, such as <code>Float('-0.33261030434342942', precision=53)</code>, while avoiding code injection such as <code>2*3</code> or <code>__import__('os').system('ls -la')</code>.</p> PARAMETER DESCRIPTION <code>code</code> <p>code to be parsed and checked.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Boolean indicating whether the code matches the defined grammar or not.</p> Source code in <code>qadence/serialization.py</code> <pre><code>def parse_expr_fn(code: str) -&gt; bool:\n    \"\"\"\n    A parsing expressions function that checks whether a given code is valid on.\n\n    the parsing grammar. The grammar is defined to be compatible with `sympy`\n    expressions, such as `Float('-0.33261030434342942', precision=53)`, while\n    avoiding code injection such as `2*3` or `__import__('os').system('ls -la')`.\n\n    Args:\n        code (str): code to be parsed and checked.\n\n    Returns:\n        Boolean indicating whether the code matches the defined grammar or not.\n    \"\"\"\n\n    parser = _parsing_serialize_expr\n    try:\n        parser.parse(code)\n    except NoMatch:\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.save","title":"<code>save(obj, folder, file_name='', format=SerializationFormat.JSON)</code>","text":"<p>Same as serialize/deserialize but for storing/loading files.</p> <p>Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module Saves a qadence object to a json/.pt.</p> PARAMETER DESCRIPTION <code>obj</code> <pre><code>Either AbstractBlock, QuantumCircuit, QuantumModel, Register.\n</code></pre> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register</code> </p> <code>file_name</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>format</code> <p>The type of file to save.</p> <p> TYPE: <code>str</code> DEFAULT: <code>JSON</code> </p> <p>Returns:     None.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\n\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def save(\n    obj: SUPPORTED_TYPES,\n    folder: str | Path,\n    file_name: str = \"\",\n    format: SerializationFormat = SerializationFormat.JSON,\n) -&gt; None:\n    \"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n\n    Supported types:\n    AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module\n    Saves a qadence object to a json/.pt.\n\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register):\n                Either AbstractBlock, QuantumCircuit, QuantumModel, Register.\n        file_name (str): The name of the file.\n        format (str): The type of file to save.\n    Returns:\n        None.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\n    if not isinstance(obj, get_args(SUPPORTED_TYPES)):\n        logger.error(f\"Serialization of object type {type(obj)} not supported.\")\n    folder = Path(folder)\n    if not folder.is_dir():\n        logger.error(NotADirectoryError)\n    if file_name == \"\":\n        file_name = type(obj).__name__\n    try:\n        suffix, save_fn, _, save_params = FORMAT_DICT[format]\n        d = serialize(obj, save_params)\n        file_path = folder / Path(file_name + suffix)\n        save_fn(d, file_path)\n        logger.debug(f\"Successfully saved {obj} from to {folder}.\")\n    except Exception as e:\n        logger.error(f\"Unable to write {type(obj)} to disk due to {e}\")\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.serialize","title":"<code>serialize(obj, save_params=False)</code>","text":"<p>Supported Types:</p> <p>AbstractBlock | QuantumCircuit | QuantumModel | torch.nn.Module | Register | Module Serializes a qadence object to a dictionary.</p> PARAMETER DESCRIPTION <code>obj</code> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register | Module</code> </p> <p>Returns:     A dict.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n\n## Lets use myblock in a QuantumCircuit and serialize it.\n\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('f96c2bf7-13ac-450a-865f-5ea87ef5eeb7', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.9980992926108123'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('14fe36b6-cef5-4de3-b1c0-8067d9e73d33', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.4557869111468842'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('cc362b6c-18c7-4d3f-a4ad-378925249a5d', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.17464944147924844'}}})}}, 'noise': None}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('5898f96f-cb6f-4c71-aefa-408eceb08721', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.4503067501905429'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('ee98202e-fc9f-478c-9141-cd47b0d593f5', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.9057210203112367'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('36148edd-c286-4344-9a3e-535afc39d1c9', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.8223678766577187'}}})}}, 'noise': None}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None, 'noise': None}], 'noise': None}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def serialize(obj: SUPPORTED_TYPES, save_params: bool = False) -&gt; dict:\n    \"\"\"\n    Supported Types:\n\n    AbstractBlock | QuantumCircuit | QuantumModel | torch.nn.Module | Register | Module\n    Serializes a qadence object to a dictionary.\n\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module):\n    Returns:\n        A dict.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\n    if not isinstance(obj, get_args(SUPPORTED_TYPES)):\n        logger.error(TypeError(f\"Serialization of object type {type(obj)} not supported.\"))\n\n    d: dict = dict()\n    try:\n        if isinstance(obj, core.Expr):\n            symb_dict = dict()\n            expr_dict = {\"name\": str(obj), \"expression\": srepr(obj)}\n            symbs: set[Parameter | core.Basic] = obj.free_symbols\n            if symbs:\n                symb_dict = {\"symbols\": {str(s): s._to_dict() for s in symbs}}\n            d = {**expr_dict, **symb_dict}\n        else:\n            if hasattr(obj, \"_to_dict\"):\n                model_to_dict: Callable = obj._to_dict\n                d = (\n                    model_to_dict(save_params)\n                    if isinstance(obj, torch.nn.Module)\n                    else model_to_dict()\n                )\n            elif hasattr(obj, \"state_dict\"):\n                d = {type(obj).__name__: obj.state_dict()}\n            else:\n                raise ValueError(f\"Cannot serialize object {obj}.\")\n    except Exception as e:\n        logger.error(f\"Serialization of object {obj} failed due to {e}\")\n    return d\n</code></pre>"},{"location":"api/states/","title":"State preparation","text":""},{"location":"api/states/#state-preparation-routines","title":"State Preparation Routines","text":""},{"location":"api/states/#qadence.states.density_mat","title":"<code>density_mat(state)</code>","text":"<p>Computes the density matrix from a pure state vector.</p> PARAMETER DESCRIPTION <code>state</code> <p>The pure state vector :math:<code>|\\psi\\rangle</code>.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The density matrix :math:<code>\\rho = |\\psi \\rangle \\langle\\psi|</code>.</p> <p> TYPE: <code>DensityMatrix</code> </p> Source code in <code>qadence/states.py</code> <pre><code>def density_mat(state: Tensor) -&gt; DensityMatrix:\n    \"\"\"\n    Computes the density matrix from a pure state vector.\n\n    Arguments:\n        state: The pure state vector :math:`|\\\\psi\\\\rangle`.\n\n    Returns:\n        Tensor: The density matrix :math:`\\\\rho = |\\psi \\\\rangle \\\\langle\\\\psi|`.\n    \"\"\"\n    if isinstance(state, DensityMatrix):\n        return state\n    return DensityMatrix(torch.einsum(\"bi,bj-&gt;bij\", (state, state.conj())))\n</code></pre>"},{"location":"api/states/#qadence.states.ghz_block","title":"<code>ghz_block(n_qubits)</code>","text":"<p>Generates the abstract ghz state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A ChainBlock representing the GHZ state.</p> <p>Examples: <pre><code>from qadence.states import ghz_block\n\nblock = ghz_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 CNOT(0, 1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_block(n_qubits: int) -&gt; ChainBlock:\n    \"\"\"\n    Generates the abstract ghz state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A ChainBlock representing the GHZ state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_block\n\n    block = ghz_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    cnots = chain(CNOT(i - 1, i) for i in range(1, n_qubits))\n    return chain(H(0), cnots)\n</code></pre>"},{"location":"api/states/#qadence.states.ghz_state","title":"<code>ghz_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a GHZ state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import ghz_state\n\nprint(ghz_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j],\n        [0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Creates a GHZ state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_state\n\n    print(ghz_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\n    norm = 1 / torch.sqrt(torch.tensor(2))\n    return norm * (zero_state(n_qubits, batch_size) + one_state(n_qubits, batch_size))\n</code></pre>"},{"location":"api/states/#qadence.states.is_normalized","title":"<code>is_normalized(wf, atol=NORMALIZATION_ATOL)</code>","text":"<p>Checks if a wave function is normalized.</p> PARAMETER DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>atol</code> <p>The tolerance.</p> <p> TYPE: <code>float) </code> DEFAULT: <code>NORMALIZATION_ATOL</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A bool.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, is_normalized\n\nprint(is_normalized(uniform_state(2)))\n</code></pre> <pre><code>True\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def is_normalized(wf: Tensor, atol: float = NORMALIZATION_ATOL) -&gt; bool:\n    \"\"\"\n    Checks if a wave function is normalized.\n\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n        atol (float) : The tolerance.\n\n    Returns:\n        A bool.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, is_normalized\n\n    print(is_normalized(uniform_state(2)))\n    ```\n    \"\"\"\n    if wf.dim() == 1:\n        wf = wf.unsqueeze(0)\n    sum_probs: Tensor = (wf.abs() ** 2).sum(dim=1)\n    ones = torch.ones_like(sum_probs)\n    return torch.allclose(sum_probs, ones, rtol=0.0, atol=atol)  # type: ignore[no-any-return]\n</code></pre>"},{"location":"api/states/#qadence.states.normalize","title":"<code>normalize(wf)</code>","text":"<p>Normalizes a wavefunction or batch of wave functions.</p> PARAMETER DESCRIPTION <code>wf</code> <p>Normalized wavefunctions.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, normalize\n\nprint(normalize(uniform_state(2, 2)))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j],\n        [0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def normalize(wf: Tensor) -&gt; Tensor:\n    \"\"\"\n    Normalizes a wavefunction or batch of wave functions.\n\n    Arguments:\n        wf (torch.Tensor): Normalized wavefunctions.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, normalize\n\n    print(normalize(uniform_state(2, 2)))\n    ```\n    \"\"\"\n    if wf.dim() == 1:\n        return wf / torch.sqrt((wf.abs() ** 2).sum())\n    else:\n        return wf / torch.sqrt((wf.abs() ** 2).sum(1)).unsqueeze(1)\n</code></pre>"},{"location":"api/states/#qadence.states.one_block","title":"<code>one_block(n_qubits)</code>","text":"<p>Generates the abstract one state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the one state.</p> <p>Examples: <pre><code>from qadence.states import one_block\n\nblock = one_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract one state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the one state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_block\n\n    block = one_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(X, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.one_state","title":"<code>one_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the one state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import one_state\n\nstate = one_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the one state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_state\n\n    state = one_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    bitstring = \"1\" * n_qubits\n    return _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"api/states/#qadence.states.overlap","title":"<code>overlap(s0, s1)</code>","text":"<p>Computes the exact overlap between two statevectors.</p> PARAMETER DESCRIPTION <code>s0</code> <p>A statevector or batch of statevectors.</p> <p> TYPE: <code>Tensor</code> </p> <code>s1</code> <p>A statevector or batch of statevectors.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor with the result.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\n\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>10101011\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def overlap(s0: torch.Tensor, s1: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the exact overlap between two statevectors.\n\n    Arguments:\n        s0 (torch.Tensor): A statevector or batch of statevectors.\n        s1 (torch.Tensor): A statevector or batch of statevectors.\n\n    Returns:\n        A torch.Tensor with the result.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\n    from qadence.overlap import overlap_exact\n\n    return overlap_exact(s0, s1)\n</code></pre>"},{"location":"api/states/#qadence.states.pmf","title":"<code>pmf(wf)</code>","text":"<p>Converts a wave function into a torch Distribution.</p> PARAMETER DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Distribution</code> <p>A torch.distributions.Distribution.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, pmf\n\nprint(pmf(uniform_state(2)).probs)\n</code></pre> <pre><code>tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def pmf(wf: Tensor) -&gt; Distribution:\n    \"\"\"\n    Converts a wave function into a torch Distribution.\n\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n\n    Returns:\n        A torch.distributions.Distribution.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, pmf\n\n    print(pmf(uniform_state(2)).probs)\n    ```\n    \"\"\"\n    return Categorical(torch.abs(torch.pow(wf, 2)))\n</code></pre>"},{"location":"api/states/#qadence.states.product_block","title":"<code>product_block(bitstring)</code>","text":"<p>Creates an abstract product state from a bitstring.</p> PARAMETER DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import product_block\n\nprint(product_block(\"1100\"))\n</code></pre> <pre><code>KronBlock(0,1,2,3)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u251c\u2500\u2500 I(2)\n\u2514\u2500\u2500 I(3)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def product_block(bitstring: str) -&gt; KronBlock:\n    \"\"\"\n    Creates an abstract product state from a bitstring.\n\n    Arguments:\n        bitstring (str): A bitstring.\n\n    Returns:\n        A KronBlock representing the product state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_block\n\n    print(product_block(\"1100\"))\n    ```\n    \"\"\"\n    return _block_from_bitstring(bitstring)\n</code></pre>"},{"location":"api/states/#qadence.states.product_state","title":"<code>product_state(bitstring, batch_size=1, endianness=Endianness.BIG, backend=BackendName.PYQTORCH)</code>","text":"<p>Creates a product state from a bitstring.</p> PARAMETER DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size.</p> <p> TYPE: <code>int) </code> DEFAULT: <code>1</code> </p> <code>backend</code> <p>The backend to use. Default is \"pyqtorch\".</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> RETURNS DESCRIPTION <code>ArrayLike</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import product_state\n\nprint(product_state(\"1100\", backend=\"pyqtorch\"))\nprint(product_state(\"1100\", backend=\"horqrux\"))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n         1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n 0.+0.j 0.+0.j 1.+0.j 0.+0.j 0.+0.j 0.+0.j]\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>@singledispatch\ndef product_state(\n    bitstring: str,\n    batch_size: int = 1,\n    endianness: Endianness = Endianness.BIG,\n    backend: BackendName = BackendName.PYQTORCH,\n) -&gt; ArrayLike:\n    \"\"\"\n    Creates a product state from a bitstring.\n\n    Arguments:\n        bitstring (str): A bitstring.\n        batch_size (int) : Batch size.\n        backend (BackendName): The backend to use. Default is \"pyqtorch\".\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_state\n\n    print(product_state(\"1100\", backend=\"pyqtorch\"))\n    print(product_state(\"1100\", backend=\"horqrux\"))\n    ```\n    \"\"\"\n    if batch_size:\n        logger.debug(\n            \"The input `batch_size` is going to be deprecated. \"\n            \"For now, default batch_size is set to 1.\"\n        )\n    return run(product_block(bitstring), backend=backend, endianness=endianness)\n</code></pre>"},{"location":"api/states/#qadence.states.rand_bitstring","title":"<code>rand_bitstring(N)</code>","text":"<p>Creates a random bistring.</p> PARAMETER DESCRIPTION <code>N</code> <p>The length of the bitstring.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\n\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>11100010\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_bitstring(N: int) -&gt; str:\n    \"\"\"\n    Creates a random bistring.\n\n    Arguments:\n        N (int): The length of the bitstring.\n\n    Returns:\n        A string.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\n    return \"\".join(str(random.randint(0, 1)) for _ in range(N))\n</code></pre>"},{"location":"api/states/#qadence.states.rand_product_block","title":"<code>rand_product_block(n_qubits)</code>","text":"<p>Creates a block representing a random abstract product state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import rand_product_block\n\nprint(rand_product_block(n_qubits=2))\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Creates a block representing a random abstract product state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the product state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_block\n\n    print(rand_product_block(n_qubits=2))\n    ```\n    \"\"\"\n    return product_block(rand_bitstring(n_qubits))\n</code></pre>"},{"location":"api/states/#qadence.states.rand_product_state","title":"<code>rand_product_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a random product state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import rand_product_state\n\nprint(rand_product_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Creates a random product state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_state\n\n    print(rand_product_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\n    wf_batch = torch.zeros(batch_size, 2**n_qubits, dtype=DTYPE)\n    rand_pos = torch.randint(0, 2**n_qubits, (batch_size,))\n    wf_batch[torch.arange(batch_size), rand_pos] = torch.tensor(1.0 + 0j, dtype=DTYPE)\n    return wf_batch\n</code></pre>"},{"location":"api/states/#qadence.states.random_state","title":"<code>random_state(n_qubits, batch_size=1, backend=BackendName.PYQTORCH, type=StateGeneratorType.HAAR_MEASURE_FAST)</code>","text":"<p>Generates a random state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>backend</code> <p>The backend to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>type</code> <p>StateGeneratorType.</p> <p> DEFAULT: <code>HAAR_MEASURE_FAST</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import random_state, StateGeneratorType\nfrom qadence.states import random_state, is_normalized, pmf\nfrom qadence.types import BackendName\nfrom torch.distributions import Distribution\n\n### We have the following options:\nprint([g.value for g in StateGeneratorType])\n\nn_qubits = 2\n# The default is StateGeneratorType.HAAR_MEASURE_FAST\nstate = random_state(n_qubits=n_qubits)\nprint(state)\n\n### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\nrandom = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\nprint(random)\n</code></pre> <pre><code>['RandomRotations', 'HaarMeasureFast', 'HaarMeasureSlow']\ntensor([[-0.1714-0.3939j,  0.2067-0.6433j,  0.2543+0.0872j,  0.2212-0.4875j]])\ntensor([[ 0.6860+0.3639j, -0.5566-0.2952j,  0.0000+0.0000j,  0.0000+0.0000j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def random_state(\n    n_qubits: int,\n    batch_size: int = 1,\n    backend: str = BackendName.PYQTORCH,\n    type: StateGeneratorType = StateGeneratorType.HAAR_MEASURE_FAST,\n) -&gt; Tensor:\n    \"\"\"\n    Generates a random state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        backend (str): The backend to use.\n        batch_size (int): The batch size.\n        type : StateGeneratorType.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import random_state, StateGeneratorType\n    from qadence.states import random_state, is_normalized, pmf\n    from qadence.types import BackendName\n    from torch.distributions import Distribution\n\n    ### We have the following options:\n    print([g.value for g in StateGeneratorType])\n\n    n_qubits = 2\n    # The default is StateGeneratorType.HAAR_MEASURE_FAST\n    state = random_state(n_qubits=n_qubits)\n    print(state)\n\n    ### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\n    random = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\n    print(random)\n    ```\n    \"\"\"\n\n    if type == StateGeneratorType.HAAR_MEASURE_FAST:\n        state = concat(tuple(_rand_haar_fast(n_qubits) for _ in range(batch_size)), dim=0)\n    elif type == StateGeneratorType.HAAR_MEASURE_SLOW:\n        state = concat(tuple(_rand_haar_slow(n_qubits) for _ in range(batch_size)), dim=0)\n    elif type == StateGeneratorType.RANDOM_ROTATIONS:\n        state = run(_abstract_random_state(n_qubits, batch_size))  # type: ignore\n    assert all(list(map(is_normalized, state)))\n    return state\n</code></pre>"},{"location":"api/states/#qadence.states.uniform_block","title":"<code>uniform_block(n_qubits)</code>","text":"<p>Generates the abstract uniform state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the uniform state.</p> <p>Examples: <pre><code>from qadence.states import uniform_block\n\nblock = uniform_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract uniform state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the uniform state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_block\n\n    block = uniform_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(H, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.uniform_state","title":"<code>uniform_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the uniform state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state\n\nstate = uniform_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the uniform state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state\n\n    state = uniform_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    norm = 1 / torch.sqrt(torch.tensor(2**n_qubits))\n    return norm * torch.ones(batch_size, 2**n_qubits, dtype=DTYPE)\n</code></pre>"},{"location":"api/states/#qadence.states.zero_block","title":"<code>zero_block(n_qubits)</code>","text":"<p>Generates the abstract zero state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the zero state.</p> <p>Examples: <pre><code>from qadence.states import zero_block\n\nblock = zero_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract zero state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the zero state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_block\n\n    block = zero_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(I, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.zero_state","title":"<code>zero_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the zero state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits for which the zero state is to be generated.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size for the zero state.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import zero_state\n\nstate = zero_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the zero state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits for which the zero state is to be generated.\n        batch_size (int): The batch size for the zero state.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_state\n\n    state = zero_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    bitstring = \"0\" * n_qubits\n    return _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"api/transpile/","title":"Transpilation","text":"<p>Contains functions that operate on blocks and circuits to <code>transpile</code> them to new blocks/circuits.</p>"},{"location":"api/transpile/#qadence.transpile.transpile.transpile","title":"<code>transpile(*fs)</code>","text":"<pre><code>transpile(*fs: Callable[[AbstractBlock], AbstractBlock]) -&gt; Callable[[AbstractBlock], AbstractBlock]\n</code></pre><pre><code>transpile(*fs: Callable[[QuantumCircuit], QuantumCircuit]) -&gt; Callable[[QuantumCircuit], QuantumCircuit]\n</code></pre> <p><code>AbstractBlock</code> or <code>QuantumCircuit</code> transpilation.</p> <p>Compose functions that accept a circuit/block and returns a circuit/block.</p> PARAMETER DESCRIPTION <code>*fs</code> <p>composable functions that either map blocks to blocks (<code>Callable[[AbstractBlock], AbstractBlock]</code>) or circuits to circuits (<code>Callable[[QuantumCircuit], QuantumCircuit]</code>).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Composed function.</p> <p>Examples:</p> <p>Flatten a block of nested chains and krons: <pre><code>from qadence import *\nfrom qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n\nb = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\nprint(b)\n\n# both flatten and scale_primitive_blocks_only are functions that accept and\n# return a block\nt = transpile(flatten, scale_primitive_blocks_only)(b)\nprint(t)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 ChainBlock(0)\n\u2502           \u251c\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u251c\u2500\u2500 X(0)\n        \u2514\u2500\u2500 X(1)\n\nChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 X(1)\n</code></pre> </p> <p>We also proved a decorator to easily turn a function <code>Callable[[AbstractBlock], AbstractBlock]</code> into a <code>Callable[[QuantumCircuit], QuantumCircuit]</code> to be used in circuit transpilation. <pre><code>from qadence import *\nfrom qadence.transpile import transpile, blockfn_to_circfn, flatten\n\n# We want to pass this circuit to `transpile` instead of a block,\n# so we need functions that map from a circuit to a circuit.\ncirc = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n\n@blockfn_to_circfn\ndef fn(block):\n    # un-decorated function accepts a block and returns a block\n    return block * block\n\ntransp = transpile(\n    # the decorated function accepts a circuit and returns a circuit\n    fn,\n    # already existing functions can also be decorated\n    blockfn_to_circfn(flatten)\n)\nprint(transp(circ))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/transpile/transpile.py</code> <pre><code>def transpile(*fs: Callable) -&gt; Callable:\n    \"\"\"`AbstractBlock` or `QuantumCircuit` transpilation.\n\n    Compose functions that\n    accept a circuit/block and returns a circuit/block.\n\n    Arguments:\n        *fs: composable functions that either map blocks to blocks\n            (`Callable[[AbstractBlock], AbstractBlock]`)\n            or circuits to circuits (`Callable[[QuantumCircuit], QuantumCircuit]`).\n\n    Returns:\n        Composed function.\n\n    Examples:\n\n    Flatten a block of nested chains and krons:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n\n    b = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\n    print(b)\n    print() # markdown-exec: hide\n\n    # both flatten and scale_primitive_blocks_only are functions that accept and\n    # return a block\n    t = transpile(flatten, scale_primitive_blocks_only)(b)\n    print(t)\n    ```\n\n    We also proved a decorator to easily turn a function `Callable[[AbstractBlock], AbstractBlock]`\n    into a `Callable[[QuantumCircuit], QuantumCircuit]` to be used in circuit transpilation.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, blockfn_to_circfn, flatten\n\n    # We want to pass this circuit to `transpile` instead of a block,\n    # so we need functions that map from a circuit to a circuit.\n    circ = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n\n    @blockfn_to_circfn\n    def fn(block):\n        # un-decorated function accepts a block and returns a block\n        return block * block\n\n    transp = transpile(\n        # the decorated function accepts a circuit and returns a circuit\n        fn,\n        # already existing functions can also be decorated\n        blockfn_to_circfn(flatten)\n    )\n    print(transp(circ))\n    ```\n    \"\"\"\n    return lambda x: reduce(lambda acc, f: f(acc), reversed(fs), x)\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.chain_single_qubit_ops","title":"<code>chain_single_qubit_ops(block)</code>","text":"<p>Transpile a chain of krons into a kron of chains of single qubit operations.</p> <p>Examples: <pre><code>from qadence import hea\nfrom qadence.transpile.block import chain_single_qubit_ops\n\n# Consider a single HEA layer\nblock = hea(2,1)\nprint(block)\n\n# After applying chain_single_qubit_ops, we get:\nprint(chain_single_qubit_ops(block))\n</code></pre> <pre><code>ChainBlock(0,1) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u2514\u2500\u2500 CNOT(0, 1)\nChainBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502   \u2514\u2500\u2500 ChainBlock(1)\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502       \u251c\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u2514\u2500\u2500 CNOT(0, 1)\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def chain_single_qubit_ops(block: AbstractBlock) -&gt; AbstractBlock:\n    \"\"\"Transpile a chain of krons into a kron of chains of single qubit operations.\n\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import hea\n    from qadence.transpile.block import chain_single_qubit_ops\n\n    # Consider a single HEA layer\n    block = hea(2,1)\n    print(block)\n\n    # After applying chain_single_qubit_ops, we get:\n    print(chain_single_qubit_ops(block))\n    ```\n    \"\"\"\n    if is_chain_of_primitivekrons(block):\n        try:\n            return kron(*map(lambda bs: chain(*bs), zip(*block)))  # type: ignore[misc]\n        except Exception as e:\n            logger.debug(\n                f\"Unable to transpile {block} using chain_single_qubit_ops\\\n                         due to {e}. Returning original circuit.\"\n            )\n            return block\n\n    elif isinstance(block, CompositeBlock):\n        return _construct(type(block), tuple(chain_single_qubit_ops(b) for b in block.blocks))\n    else:\n        return block\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.scale_primitive_blocks_only","title":"<code>scale_primitive_blocks_only(block, scale=None)</code>","text":"<p>Push the scale all the way down into the leaves of the block tree.</p> <p>When given a scaled CompositeBlock consisting of several PrimitiveBlocks.</p> PARAMETER DESCRIPTION <code>block</code> <p>The block to be transpiled.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>scale</code> <p>An optional scale parameter. Only to be used for recursive calls internally.</p> <p> TYPE: <code>Basic</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>A block of the same type where the scales have been moved into the subblocks.</p> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples:</p> <p>There are two different cases: <code>ChainBlock</code>s/<code>KronBlock</code>s: Only the first subblock needs to be scaled because chains/krons represent multiplications. <pre><code>from qadence import chain, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * chain(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 ChainBlock(0)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\nChainBlock(0)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> <p><code>AddBlock</code>s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")). <pre><code>from qadence import add, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * add(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 AddBlock(0)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\nAddBlock(0)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 [mul: 2] \n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>@singledispatch\ndef scale_primitive_blocks_only(block: AbstractBlock, scale: sympy.Basic = None) -&gt; AbstractBlock:\n    \"\"\"Push the scale all the way down into the leaves of the block tree.\n\n    When given a scaled CompositeBlock consisting of several PrimitiveBlocks.\n\n    Arguments:\n        block: The block to be transpiled.\n        scale: An optional scale parameter. Only to be used for recursive calls internally.\n\n    Returns:\n        AbstractBlock: A block of the same type where the scales have been moved into the subblocks.\n\n    Examples:\n\n    There are two different cases:\n    `ChainBlock`s/`KronBlock`s: Only the first subblock needs to be scaled because chains/krons\n    represent multiplications.\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import chain, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * chain(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n\n    `AddBlock`s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all\n    subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")).\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import add, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * add(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    \"\"\"\n    raise NotImplementedError(f\"scale_primitive_blocks_only is not implemented for {type(block)}\")\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.set_trainable","title":"<code>set_trainable(blocks, value=True, inplace=True)</code>","text":"<p>Set the trainability of all parameters in a block to a given value.</p> PARAMETER DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>value</code> <p>The value of the trainable attribute to assign to the input blocks</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to the given value</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_trainable(\n    blocks: AbstractBlock | list[AbstractBlock], value: bool = True, inplace: bool = True\n) -&gt; AbstractBlock | list[AbstractBlock]:\n    \"\"\"Set the trainability of all parameters in a block to a given value.\n\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        value (bool, optional): The value of the trainable attribute to assign to the input blocks\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to the given value\n    \"\"\"\n\n    if isinstance(blocks, AbstractBlock):\n        blocks = [blocks]\n\n    if inplace:\n        for block in blocks:\n            params: list[sympy.Basic] = parameters(block)\n            for p in params:\n                if not p.is_number:\n                    p.trainable = value\n    else:\n        raise NotImplementedError(\"Not inplace set_trainable is not yet available\")\n\n    return blocks if len(blocks) &gt; 1 else blocks[0]\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.validate","title":"<code>validate(block)</code>","text":"<p>Moves a block from global to local qubit numbers by adding PutBlocks.</p> <p>Reassigns qubit locations appropriately.</p>"},{"location":"api/transpile/#qadence.transpile.block.validate--example","title":"Example","text":"<pre><code>from qadence.blocks import chain\nfrom qadence.operations import X\nfrom qadence.transpile import validate\n\nx = chain(chain(X(0)), chain(X(1)))\nprint(x)\nprint(validate(x))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 ChainBlock(1)\n    \u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 put on (0)\n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 put on (0)\n\u2502           \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 put on (1)\n    \u2514\u2500\u2500 ChainBlock(0)\n        \u2514\u2500\u2500 put on (0)\n            \u2514\u2500\u2500 X(0)\n</code></pre> Source code in <code>qadence/transpile/block.py</code> <pre><code>def validate(block: AbstractBlock) -&gt; AbstractBlock:\n    \"\"\"Moves a block from global to local qubit numbers by adding PutBlocks.\n\n    Reassigns qubit locations appropriately.\n\n    # Example\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence.blocks import chain\n    from qadence.operations import X\n    from qadence.transpile import validate\n\n    x = chain(chain(X(0)), chain(X(1)))\n    print(x)\n    print(validate(x))\n    ```\n    \"\"\"\n    vblock: AbstractBlock\n    from qadence.transpile import reassign\n\n    if isinstance(block, ControlBlock):\n        vblock = deepcopy(block)\n        b: AbstractBlock\n        (b,) = block.blocks\n        b = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\n        b = validate(b)\n        vblock.blocks = (b,)  # type: ignore[assignment]\n\n    elif isinstance(block, CompositeBlock):\n        blocks = []\n        for b in block.blocks:\n            mi, ma = min(b.qubit_support), max(b.qubit_support)\n            nb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\n            nb = validate(nb)\n            nb = PutBlock(nb, tuple(range(mi, ma + 1)))\n            blocks.append(nb)\n        try:\n            vblock = _construct(type(block), tuple(blocks))\n        except AssertionError as e:\n            if str(e) == \"Make sure blocks act on distinct qubits!\":\n                vblock = chain(*blocks)\n            else:\n                raise e\n\n    elif isinstance(block, PrimitiveBlock):\n        vblock = deepcopy(block)\n\n    else:\n        raise NotImplementedError\n\n    vblock.tag = block.tag\n    return vblock\n</code></pre>"},{"location":"api/types/","title":"Types","text":""},{"location":"api/types/#qadence-types","title":"Qadence Types","text":""},{"location":"api/types/#qadence.types.TArray","title":"<code>TArray = Union[Iterable, Tensor, np.ndarray]</code>  <code>module-attribute</code>","text":"<p>Union of common array types.</p>"},{"location":"api/types/#qadence.types.TGenerator","title":"<code>TGenerator = Union[Tensor, sympy.Array, sympy.Basic]</code>  <code>module-attribute</code>","text":"<p>Union of torch tensors and numpy arrays.</p>"},{"location":"api/types/#qadence.types.TNumber","title":"<code>TNumber = Union[int, float, complex, np.int64, np.float64]</code>  <code>module-attribute</code>","text":"<p>Union of python and numpy numeric types.</p>"},{"location":"api/types/#qadence.types.TParameter","title":"<code>TParameter = Union[TNumber, Tensor, sympy.Basic, str]</code>  <code>module-attribute</code>","text":"<p>Union of numbers, tensors, and parameter types.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo","title":"<code>AlgoHEvo</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Hamiltonian Evolution algorithms that can be used by the backend.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.EIG","title":"<code>EIG = 'EIG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using Hamiltonian diagonalization.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.EXP","title":"<code>EXP = 'EXP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using torch.matrix_exp on the generator matrix.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.RK4","title":"<code>RK4 = 'RK4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>4th order Runge-Kutta approximation.</p>"},{"location":"api/types/#qadence.types.AnalogNoise","title":"<code>AnalogNoise</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Type of noise protocol.</p>"},{"location":"api/types/#qadence.types.AnsatzType","title":"<code>AnsatzType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Ansatz types for variational circuits.</p>"},{"location":"api/types/#qadence.types.AnsatzType.ALA","title":"<code>ALA = 'ala'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Alternating Layer Ansatz.</p>"},{"location":"api/types/#qadence.types.AnsatzType.HEA","title":"<code>HEA = 'hea'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hardware-efficient ansatz.</p>"},{"location":"api/types/#qadence.types.AnsatzType.IIA","title":"<code>IIA = 'iia'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Identity-Initialised Ansatz.</p>"},{"location":"api/types/#qadence.types.BasisSet","title":"<code>BasisSet</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Basis set for feature maps.</p>"},{"location":"api/types/#qadence.types.BasisSet.CHEBYSHEV","title":"<code>CHEBYSHEV = 'Chebyshev'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Chebyshev polynomials of the first kind.</p>"},{"location":"api/types/#qadence.types.BasisSet.FOURIER","title":"<code>FOURIER = 'Fourier'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fourier basis set.</p>"},{"location":"api/types/#qadence.types.DeviceType","title":"<code>DeviceType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Supported types of devices for Pulser backend.</p>"},{"location":"api/types/#qadence.types.DeviceType.IDEALIZED","title":"<code>IDEALIZED = 'IdealDevice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Idealized device, least realistic.</p>"},{"location":"api/types/#qadence.types.DeviceType.REALISTIC","title":"<code>REALISTIC = 'RealisticDevice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Device with realistic specs.</p>"},{"location":"api/types/#qadence.types.DiffMode","title":"<code>DiffMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Differentiation modes to choose from.</p>"},{"location":"api/types/#qadence.types.DiffMode.AD","title":"<code>AD = 'ad'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Automatic Differentiation.</p>"},{"location":"api/types/#qadence.types.DiffMode.ADJOINT","title":"<code>ADJOINT = 'adjoint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Adjoint Differentiation.</p>"},{"location":"api/types/#qadence.types.DiffMode.GPSR","title":"<code>GPSR = 'gpsr'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic generalized parameter shift rule.</p>"},{"location":"api/types/#qadence.types.Endianness","title":"<code>Endianness</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The endianness convention to use.</p>"},{"location":"api/types/#qadence.types.Endianness.BIG","title":"<code>BIG = 'Big'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use Big endianness.</p>"},{"location":"api/types/#qadence.types.Endianness.LITTLE","title":"<code>LITTLE = 'Little'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use little endianness.</p>"},{"location":"api/types/#qadence.types.ExecutionType","title":"<code>ExecutionType</code>","text":"<p>               Bases: <code>StrEnum</code></p>"},{"location":"api/types/#qadence.types.ExecutionType.DEFAULT","title":"<code>DEFAULT = 'default'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default distribution execution.</p>"},{"location":"api/types/#qadence.types.ExecutionType.TORCHRUN","title":"<code>TORCHRUN = 'torchrun'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torchrun based distribution execution.</p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool","title":"<code>ExperimentTrackingTool</code>","text":"<p>               Bases: <code>StrEnum</code></p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool.MLFLOW","title":"<code>MLFLOW = 'mlflow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the ml-flow experiment tracker.</p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool.TENSORBOARD","title":"<code>TENSORBOARD = 'tensorboard'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the tensorboard experiment tracker.</p>"},{"location":"api/types/#qadence.types.FigFormat","title":"<code>FigFormat</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available output formats for exporting visualized circuits to a file.</p>"},{"location":"api/types/#qadence.types.FigFormat.PDF","title":"<code>PDF = 'PDF'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PDF format.</p>"},{"location":"api/types/#qadence.types.FigFormat.PNG","title":"<code>PNG = 'PNG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PNG format.</p>"},{"location":"api/types/#qadence.types.FigFormat.SVG","title":"<code>SVG = 'SVG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>SVG format.</p>"},{"location":"api/types/#qadence.types.GenDAQC","title":"<code>GenDAQC</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The type of interaction for the DAQC transform.</p>"},{"location":"api/types/#qadence.types.GenDAQC.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN</p>"},{"location":"api/types/#qadence.types.GenDAQC.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ</p>"},{"location":"api/types/#qadence.types.InputDiffMode","title":"<code>InputDiffMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Derivative modes w.r.t inputs of UFAs.</p>"},{"location":"api/types/#qadence.types.InputDiffMode.AD","title":"<code>AD = 'ad'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Reverse automatic differentiation.</p>"},{"location":"api/types/#qadence.types.InputDiffMode.FD","title":"<code>FD = 'fd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Central finite differencing.</p>"},{"location":"api/types/#qadence.types.Interaction","title":"<code>Interaction</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Interaction types used in.</p> <ul> <li><code>RydbergDevice</code>.</li> <li><code>hamiltonian_factory</code>.</li> </ul>"},{"location":"api/types/#qadence.types.Interaction.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN-Ising Interaction, N=(I-Z)/2.</p>"},{"location":"api/types/#qadence.types.Interaction.XY","title":"<code>XY = 'XY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XY Interaction.</p>"},{"location":"api/types/#qadence.types.Interaction.XYZ","title":"<code>XYZ = 'XYZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XYZ Interaction.</p>"},{"location":"api/types/#qadence.types.Interaction.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ-Ising Interaction.</p>"},{"location":"api/types/#qadence.types.LTSOrder","title":"<code>LTSOrder</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Lie-Trotter-Suzuki approximation order.</p>"},{"location":"api/types/#qadence.types.LTSOrder.BASIC","title":"<code>BASIC = 'BASIC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic.</p>"},{"location":"api/types/#qadence.types.LTSOrder.ST2","title":"<code>ST2 = 'ST2'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST2.</p>"},{"location":"api/types/#qadence.types.LTSOrder.ST4","title":"<code>ST4 = 'ST4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST4.</p>"},{"location":"api/types/#qadence.types.LatticeTopology","title":"<code>LatticeTopology</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Lattice topologies to choose from for the register.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.ALL_TO_ALL","title":"<code>ALL_TO_ALL = 'all_to_all'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>All to all- connected lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.ARBITRARY","title":"<code>ARBITRARY = 'arbitrary'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Arbitrarily-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.CIRCLE","title":"<code>CIRCLE = 'circle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Circular lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.HONEYCOMB_LATTICE","title":"<code>HONEYCOMB_LATTICE = 'honeycomb_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Honeycomb-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.LINE","title":"<code>LINE = 'line'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Line-format lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.RECTANGULAR_LATTICE","title":"<code>RECTANGULAR_LATTICE = 'rectangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rectangular-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.SQUARE","title":"<code>SQUARE = 'square'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Square lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.TRIANGULAR_LATTICE","title":"<code>TRIANGULAR_LATTICE = 'triangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Triangular-shaped shape.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy","title":"<code>MultivariateStrategy</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Multivariate strategy for feature maps.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy.PARALLEL","title":"<code>PARALLEL = 'Parallel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Parallel strategy.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy.SERIES","title":"<code>SERIES = 'Series'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Serial strategy.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol","title":"<code>NoiseProtocol()</code>  <code>dataclass</code>","text":"<p>Type of noise protocol.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol.ANALOG","title":"<code>ANALOG = AnalogNoise</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Noise applied in analog blocks.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol.DIGITAL","title":"<code>DIGITAL = DigitalNoise</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Noise applied to digital blocks.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol.READOUT","title":"<code>READOUT = ReadoutNoise</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Noise applied on outputs of quantum programs.</p>"},{"location":"api/types/#qadence.types.OpName","title":"<code>OpName</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>A list of all available of digital-analog operations.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGENTANG","title":"<code>ANALOGENTANG = 'AnalogEntanglement'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog entanglement operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGINTERACTION","title":"<code>ANALOGINTERACTION = 'AnalogInteraction'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog interaction operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRX","title":"<code>ANALOGRX = 'AnalogRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RX operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRY","title":"<code>ANALOGRY = 'AnalogRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RY operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRZ","title":"<code>ANALOGRZ = 'AnalogRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RZ operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGSWAP","title":"<code>ANALOGSWAP = 'AnalogSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog SWAP operation.</p>"},{"location":"api/types/#qadence.types.OpName.CNOT","title":"<code>CNOT = 'CNOT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CNOT gate.</p>"},{"location":"api/types/#qadence.types.OpName.CPHASE","title":"<code>CPHASE = 'CPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The controlled PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRX","title":"<code>CRX = 'CRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRY","title":"<code>CRY = 'CRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Controlled RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRZ","title":"<code>CRZ = 'CRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.CSWAP","title":"<code>CSWAP = 'CSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control SWAP gate.</p>"},{"location":"api/types/#qadence.types.OpName.CZ","title":"<code>CZ = 'CZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.ENTANGLE","title":"<code>ENTANGLE = 'entangle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The entanglement operation.</p>"},{"location":"api/types/#qadence.types.OpName.H","title":"<code>H = 'H'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hadamard gate.</p>"},{"location":"api/types/#qadence.types.OpName.HAMEVO","title":"<code>HAMEVO = 'HamEvo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hamiltonian Evolution operation.</p>"},{"location":"api/types/#qadence.types.OpName.I","title":"<code>I = 'I'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Identity gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCPHASE","title":"<code>MCPHASE = 'MCPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRX","title":"<code>MCRX = 'MCRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRY","title":"<code>MCRY = 'MCRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRZ","title":"<code>MCRZ = 'MCRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCZ","title":"<code>MCZ = 'MCZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol CZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.N","title":"<code>N = 'N'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The N = (1/2)(I-Z) operator.</p>"},{"location":"api/types/#qadence.types.OpName.PHASE","title":"<code>PHASE = 'PHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.PROJ","title":"<code>PROJ = 'Projector'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The projector operation.</p>"},{"location":"api/types/#qadence.types.OpName.RX","title":"<code>RX = 'RX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.RY","title":"<code>RY = 'RY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.RZ","title":"<code>RZ = 'RZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.S","title":"<code>S = 'S'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S gate.</p>"},{"location":"api/types/#qadence.types.OpName.SDAGGER","title":"<code>SDAGGER = 'SDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S dagger gate.</p>"},{"location":"api/types/#qadence.types.OpName.SWAP","title":"<code>SWAP = 'SWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The SWAP gate.</p>"},{"location":"api/types/#qadence.types.OpName.T","title":"<code>T = 'T'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T gate.</p>"},{"location":"api/types/#qadence.types.OpName.TDAGGER","title":"<code>TDAGGER = 'TDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T dagger gate.</p>"},{"location":"api/types/#qadence.types.OpName.TOFFOLI","title":"<code>TOFFOLI = 'Toffoli'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Toffoli gate.</p>"},{"location":"api/types/#qadence.types.OpName.U","title":"<code>U = 'U'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The U gate.</p>"},{"location":"api/types/#qadence.types.OpName.X","title":"<code>X = 'X'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The X gate.</p>"},{"location":"api/types/#qadence.types.OpName.Y","title":"<code>Y = 'Y'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Y gate.</p>"},{"location":"api/types/#qadence.types.OpName.Z","title":"<code>Z = 'Z'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Z gate.</p>"},{"location":"api/types/#qadence.types.OpName.ZERO","title":"<code>ZERO = 'Zero'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The zero gate.</p>"},{"location":"api/types/#qadence.types.OverlapMethod","title":"<code>OverlapMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Overlap Methods to choose from.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.COMPUTE_UNCOMPUTE","title":"<code>COMPUTE_UNCOMPUTE = 'compute_uncompute'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute-uncompute.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.EXACT","title":"<code>EXACT = 'exact'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exact.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.HADAMARD_TEST","title":"<code>HADAMARD_TEST = 'hadamard_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hadamard-test.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.JENSEN_SHANNON","title":"<code>JENSEN_SHANNON = 'jensen_shannon'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Jensen-shannon.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.SWAP_TEST","title":"<code>SWAP_TEST = 'swap_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Swap-test.</p>"},{"location":"api/types/#qadence.types.ParameterType","title":"<code>ParameterType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Parameter types available in qadence.</p>"},{"location":"api/types/#qadence.types.ParameterType.FEATURE","title":"<code>FEATURE = 'Feature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>FeatureParameters act as input and are not trainable.</p>"},{"location":"api/types/#qadence.types.ParameterType.FIXED","title":"<code>FIXED = 'Fixed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fixed/ constant parameters are neither trainable nor act as input.</p>"},{"location":"api/types/#qadence.types.ParameterType.VARIATIONAL","title":"<code>VARIATIONAL = 'Variational'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>VariationalParameters are trainable.</p>"},{"location":"api/types/#qadence.types.QubitSupportType","title":"<code>QubitSupportType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Qubit support types.</p>"},{"location":"api/types/#qadence.types.QubitSupportType.GLOBAL","title":"<code>GLOBAL = 'global'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use global qubit support.</p>"},{"location":"api/types/#qadence.types.ReadoutNoise","title":"<code>ReadoutNoise</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Type of readout protocol.</p>"},{"location":"api/types/#qadence.types.ReadoutNoise.CORRELATED","title":"<code>CORRELATED = 'Correlated Readout'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using a confusion matrix (2n, 2n) for corrupting bitstrings values.</p>"},{"location":"api/types/#qadence.types.ReadoutNoise.INDEPENDENT","title":"<code>INDEPENDENT = 'Independent Readout'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Simple readout protocols where each qubit is corrupted independently.</p>"},{"location":"api/types/#qadence.types.ResultType","title":"<code>ResultType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available data types for generating certain results.</p>"},{"location":"api/types/#qadence.types.ResultType.NUMPY","title":"<code>NUMPY = 'Numpy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Numpy Array Type.</p>"},{"location":"api/types/#qadence.types.ResultType.STRING","title":"<code>STRING = 'String'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String Type.</p>"},{"location":"api/types/#qadence.types.ResultType.TORCH","title":"<code>TORCH = 'Torch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torch Tensor Type.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling","title":"<code>ReuploadScaling</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Scaling for data reuploads in feature maps.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.CONSTANT","title":"<code>CONSTANT = 'Constant'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Constant scaling.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.EXP","title":"<code>EXP = 'Exponential'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exponentially increasing scaling.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.TOWER","title":"<code>TOWER = 'Tower'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Linearly increasing scaling.</p>"},{"location":"api/types/#qadence.types.SerializationFormat","title":"<code>SerializationFormat</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available serialization formats for circuits.</p>"},{"location":"api/types/#qadence.types.SerializationFormat.JSON","title":"<code>JSON = 'JSON'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Json format.</p>"},{"location":"api/types/#qadence.types.SerializationFormat.PT","title":"<code>PT = 'PT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PT format used by Torch.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType","title":"<code>StateGeneratorType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Methods to generate random states.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_FAST","title":"<code>HAAR_MEASURE_FAST = 'HaarMeasureFast'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_SLOW","title":"<code>HAAR_MEASURE_SLOW = 'HaarMeasureSlow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure non-optimized version.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.RANDOM_ROTATIONS","title":"<code>RANDOM_ROTATIONS = 'RandomRotations'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Random Rotations.</p>"},{"location":"api/types/#qadence.types.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"api/types/#qadence.types.StrEnum.__str__","title":"<code>__str__()</code>","text":"<p>Used when dumping enum fields in a schema.</p> Source code in <code>qadence/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Used when dumping enum fields in a schema.\"\"\"\n    ret: str = self.value\n    return ret\n</code></pre>"},{"location":"api/types/#qadence.types.Strategy","title":"<code>Strategy</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Computing paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.ANALOG","title":"<code>ANALOG = 'Analog'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the analog paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.BDAQC","title":"<code>BDAQC = 'bDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the banged digital-analog QC paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.DIGITAL","title":"<code>DIGITAL = 'Digital'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the digital paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.RYDBERG","title":"<code>RYDBERG = 'Rydberg'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the Rydberg QC paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.SDAQC","title":"<code>SDAQC = 'sDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the step-wise digital-analog QC paradigm.</p>"},{"location":"api/types/#qadence.types.TensorType","title":"<code>TensorType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Tensor Types for converting blocks to tensors.</p>"},{"location":"api/types/#qadence.types.TensorType.DENSE","title":"<code>DENSE = 'Dense'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a block to a dense tensor.</p>"},{"location":"api/types/#qadence.types.TensorType.SPARSE","title":"<code>SPARSE = 'Sparse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a observable block to a sparse tensor.</p>"},{"location":"api/types/#qadence.types.TensorType.SPARSEDIAGONAL","title":"<code>SPARSEDIAGONAL = 'SparseDiagonal'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a diagonal observable block to a sparse diagonal if possible.</p>"},{"location":"api/backends/backend/","title":"Abstract backend","text":""},{"location":"api/backends/backend/#qadence.backend.Backend","title":"<code>Backend(name, supports_ad, support_bp, supports_adjoint, is_remote, with_measurements, native_endianness, engine, with_noise, config)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The abstract class that defines the interface for the backends.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>backend unique string identifier</p> <p> TYPE: <code>BackendName</code> </p> <code>supports_ad</code> <p>whether or not the backend has a native autograd</p> <p> TYPE: <code>bool</code> </p> <code>supports_bp</code> <p>whether or not the backend has a native backprop</p> <p> TYPE: <code>bool</code> </p> <code>supports_adjoint</code> <p>Does the backend support native adjoint differentation.</p> <p> TYPE: <code>bool</code> </p> <code>is_remote</code> <p>whether computations are executed locally or remotely on this backend, useful when using cloud platforms where credentials are needed for example.</p> <p> TYPE: <code>bool</code> </p> <code>with_measurements</code> <p>whether it supports counts or not</p> <p> TYPE: <code>bool</code> </p> <code>with_noise</code> <p>whether to add realistic noise or not</p> <p> TYPE: <code>bool</code> </p> <code>native_endianness</code> <p>The native endianness of the backend</p> <p> TYPE: <code>Endianness</code> </p> <code>engine</code> <p>The underlying (native) automatic differentiation engine of the backend.</p> <p> TYPE: <code>Engine</code> </p>"},{"location":"api/backends/backend/#qadence.backend.Backend.circuit","title":"<code>circuit(circuit)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract <code>QuantumCircuit</code> to the native backend representation.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A circuit, for example: <code>QuantumCircuit(2, X(0))</code></p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>A converted circuit <code>c</code>. You can access the original, arbstract circuit via <code>c.abstract</code></p> <code>ConvertedCircuit</code> <p>and the converted (or backend native) circuit via <code>c.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Converts an abstract `QuantumCircuit` to the native backend representation.\n\n    Arguments:\n        circuit: A circuit, for example: `QuantumCircuit(2, X(0))`\n\n    Returns:\n        A converted circuit `c`. You can access the original, arbstract circuit via `c.abstract`\n        and the converted (or backend *native*) circuit via `c.native`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit and an optional observable to their native representation.</p> <p>Additionally, this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\n    self, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n    \"\"\"Convert an abstract circuit and an optional observable to their native representation.\n\n    Additionally, this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\n\n    def check_observable(obs_obj: Any) -&gt; AbstractBlock:\n        if isinstance(obs_obj, QubitOperator):\n            from qadence.blocks.manipulate import from_openfermion\n\n            assert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\n\n            return from_openfermion(obs_obj)\n\n        elif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\n            from qadence.blocks.utils import block_is_qubit_hamiltonian\n\n            assert block_is_qubit_hamiltonian(\n                obs_obj\n            ), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\n            return obs_obj\n        raise TypeError(\n            \"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n        )\n\n    conv_circ = self.circuit(circuit)\n    circ_params, circ_embedding_fn = embedding(\n        conv_circ.abstract.block, self.config._use_gate_params, self.engine\n    )\n    params = circ_params\n    if observable is not None:\n        observable = observable if isinstance(observable, list) else [observable]\n        conv_obs = []\n        obs_embedding_fn_list = []\n\n        for obs in observable:\n            obs = check_observable(obs)\n            c_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\n            obs_params, obs_embedding_fn = embedding(\n                c_obs.abstract, self.config._use_gate_params, self.engine\n            )\n            params.update(obs_params)\n            obs_embedding_fn_list.append(obs_embedding_fn)\n            conv_obs.append(c_obs)\n\n        def embedding_fn_dict(a: dict, b: dict) -&gt; dict:\n            embedding_dict = circ_embedding_fn(a, b)\n            for o in obs_embedding_fn_list:\n                embedding_dict.update(o(a, b))\n            return embedding_dict\n\n        return Converted(conv_circ, conv_obs, embedding_fn_dict, params)\n\n    def embedding_fn(a: dict, b: dict) -&gt; dict:\n        return circ_embedding_fn(a, b)\n\n    return Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.observable","title":"<code>observable(observable, n_qubits)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract observable (which is just an <code>AbstractBlock</code>) to the native backend.</p> <p>representation.</p> PARAMETER DESCRIPTION <code>observable</code> <p>An observable.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits the observable covers. This is typically <code>circuit.n_qubits</code>.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ConvertedObservable</code> <p>A converted observable <code>o</code>. You can access the original, arbstract observable via</p> <code>ConvertedObservable</code> <p><code>o.abstract</code> and the converted (or backend native) observable via <code>o.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef observable(self, observable: AbstractBlock, n_qubits: int) -&gt; ConvertedObservable:\n    \"\"\"Converts an abstract observable (which is just an `AbstractBlock`) to the native backend.\n\n    representation.\n\n    Arguments:\n        observable: An observable.\n        n_qubits: Number of qubits the observable covers. This is typically `circuit.n_qubits`.\n\n    Returns:\n        A converted observable `o`. You can access the original, arbstract observable via\n        `o.abstract` and the converted (or backend *native*) observable via `o.native`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG, *args, **kwargs)</code>","text":"<p>Run a circuit and return the resulting wave function.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, ArrayLike]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting wavefunction.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>ArrayLike</code> <p>A list of Counter objects where each key represents a bitstring</p> <code>ArrayLike</code> <p>and its value the number of times it has been sampled from the given wave function.</p> Source code in <code>qadence/backend.py</code> <pre><code>def run(\n    self,\n    circuit: ConvertedCircuit,\n    param_values: dict[str, ArrayLike] = {},\n    state: Tensor | None = None,\n    endianness: Endianness = Endianness.BIG,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Run a circuit and return the resulting wave function.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting wavefunction.\n\n    Returns:\n        A list of Counter objects where each key represents a bitstring\n        and its value the number of times it has been sampled from the given wave function.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1000, state=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Sample bit strings.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Number of shots to sample.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>An error mitigation protocol to apply.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef sample(\n    self,\n    circuit: ConvertedCircuit,\n    param_values: dict[str, Tensor] = {},\n    n_shots: int = 1000,\n    state: ArrayLike | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n    \"\"\"Sample bit strings.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        n_shots: Number of shots to sample.\n        state: Initial state.\n        noise: A noise model to use.\n        mitigation: An error mitigation protocol to apply.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration","title":"<code>BackendConfiguration(_use_gate_params=True, use_sparse_observable=False, use_gradient_checkpointing=False, use_single_qubit_composition=False, transpilation_passes=None)</code>  <code>dataclass</code>","text":""},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.available_options","title":"<code>available_options()</code>","text":"<p>Return as a string the available fields with types of the configuration.</p> RETURNS DESCRIPTION <code>str</code> <p>a string with all the available fields, one per line</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>def available_options(self) -&gt; str:\n    \"\"\"Return as a string the available fields with types of the configuration.\n\n    Returns:\n        str: a string with all the available fields, one per line\n    \"\"\"\n    conf_msg = \"\"\n    for _field in fields(self):\n        if not _field.name.startswith(\"_\"):\n            conf_msg += f\"Name: {_field.name} - Type: {_field.type} - Current value: {getattr(self, _field.name)} - Default value: {_field.default}\\n\"\n    return conf_msg\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.change_config","title":"<code>change_config(new_config)</code>","text":"<p>Change configuration with the input.</p> Source code in <code>qadence/backend.py</code> <pre><code>def change_config(self, new_config: dict) -&gt; None:\n    \"\"\"Change configuration with the input.\"\"\"\n\n    for key, value in new_config.items():\n        if hasattr(self, key):\n            setattr(self, key, value)\n        else:\n            raise ValueError(f\"Warning: '{key}' is not a valid configuration attribute.\")\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.get_param_name","title":"<code>get_param_name(blk)</code>","text":"<p>Return parameter names for the current backend.</p> <p>Depending on which backend is in use this function returns either UUIDs or expressions of parameters.</p> Source code in <code>qadence/backend.py</code> <pre><code>def get_param_name(self, blk: AbstractBlock) -&gt; Tuple[str, ...]:\n    \"\"\"Return parameter names for the current backend.\n\n    Depending on which backend is in use this\n    function returns either UUIDs or expressions of parameters.\n    \"\"\"\n    param_ids: Tuple\n    # FIXME: better type hiearchy?\n    types = (TimeEvolutionBlock, ParametricBlock, ConstantAnalogRotation, InteractionBlock)\n    if not isinstance(blk, types):\n        raise TypeError(f\"Can not infer param name from {type(blk)}\")\n    else:\n        if self._use_gate_params:\n            param_ids = tuple(blk.parameters.uuids())\n        else:\n            param_ids = tuple(map(stringify, blk.parameters.expressions()))\n    return param_ids\n</code></pre>"},{"location":"api/backends/differentiable/","title":"DifferentiableBackend","text":""},{"location":"api/backends/differentiable/#qadence.engines.torch.differentiable_backend.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>               Bases: <code>DifferentiableBackend</code></p> <p>A class which wraps a QuantumBackend with the automatic differentation engine TORCH.</p> PARAMETER DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/engines/torch/differentiable_backend.py</code> <pre><code>def __init__(\n    self,\n    backend: QuantumBackend,\n    diff_mode: DiffMode = DiffMode.AD,\n    **psr_args: int | float | None,\n) -&gt; None:\n    super().__init__(backend=backend, engine=Engine.TORCH, diff_mode=diff_mode)\n    self.psr_args = psr_args\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.torch.differentiable_backend.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A converted observable as returned by <code>backend.observable</code>.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>The error mitigation to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/engines/torch/differentiable_backend.py</code> <pre><code>def expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        observable: A converted observable as returned by `backend.observable`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: The error mitigation to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    observable = observable if isinstance(observable, list) else [observable]\n    differentiable_expectation = DifferentiableExpectation(\n        backend=self.backend,\n        circuit=circuit,\n        observable=observable,\n        param_values=param_values,\n        state=state,\n        measurement=measurement,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n\n    if self.diff_mode == DiffMode.AD:\n        expectation = differentiable_expectation.ad\n    elif self.diff_mode == DiffMode.ADJOINT:\n        expectation = differentiable_expectation.adjoint\n    elif self.diff_mode == DiffMode.GPSR:\n        expectation = partial(\n            differentiable_expectation.psr, psr_fn=general_psr, **self.psr_args\n        )\n    return expectation()\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.jax.differentiable_backend.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>               Bases: <code>DifferentiableBackend</code></p> <p>A class which wraps a QuantumBackend with the automatic differentation engine JAX.</p> PARAMETER DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/engines/jax/differentiable_backend.py</code> <pre><code>def __init__(\n    self,\n    backend: Backend,\n    diff_mode: DiffMode = DiffMode.AD,\n    **psr_args: int | float | None,\n) -&gt; None:\n    super().__init__(backend=backend, engine=Engine.JAX, diff_mode=diff_mode)\n    self.psr_args = psr_args\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.jax.differentiable_backend.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A converted observable as returned by <code>backend.observable</code>.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>The error mitigation to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/engines/jax/differentiable_backend.py</code> <pre><code>def expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        observable: A converted observable as returned by `backend.observable`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: The error mitigation to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    observable = observable if isinstance(observable, list) else [observable]\n\n    if self.diff_mode == DiffMode.AD:\n        expectation = self.backend.expectation(circuit, observable, param_values, state)\n    else:\n        expectation = DifferentiableExpectation(\n            backend=self.backend,\n            circuit=circuit,\n            observable=observable,\n            param_values=param_values,\n            state=state,\n            measurement=measurement,\n            noise=noise,\n            mitigation=mitigation,\n            endianness=endianness,\n        ).psr()\n    return expectation\n</code></pre>"},{"location":"api/backends/pulser/","title":"Pulser","text":"<p>The Pulser backend features a basic integration with the pulse-level programming interface Pulser. This backend offers for now few simple operations which are translated into a valid, non time-dependent pulse sequence. In particular, one has access to:</p> <ul> <li>analog rotations: <code>AnalogRx</code> and <code>AnalogRy</code> blocks</li> <li>free evolution blocks (basically no pulse, just interaction): <code>AnalogWait</code> block</li> <li>a block for creating entangled states: <code>AnalogEntanglement</code></li> <li>digital rotation <code>Rx</code> and <code>Ry</code></li> </ul>"},{"location":"api/backends/pulser/#qadence.backends.pulser.backend.Backend","title":"<code>Backend(name=BackendName.PULSER, supports_ad=False, support_bp=False, supports_adjoint=False, is_remote=False, with_measurements=True, native_endianness=Endianness.BIG, engine=Engine.TORCH, with_noise=False, config=Configuration())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Backend</code></p> <p>The Pulser backend.</p>"},{"location":"api/backends/pulser/#qadence.backends.pulser.backend.create_register","title":"<code>create_register(register)</code>","text":"<p>Convert Qadence Register to Pulser Register.</p> Source code in <code>qadence/backends/pulser/backend.py</code> <pre><code>def create_register(register: Register) -&gt; PulserRegister:\n    \"\"\"Convert Qadence Register to Pulser Register.\"\"\"\n    coords = np.array(list(register.coords.values()))\n    return PulserRegister.from_coordinates(coords)\n</code></pre>"},{"location":"api/backends/pyqtorch/","title":"PyQTorch","text":"<p>Fast differentiable statevector emulator based on PyTorch. The code is open source, hosted on Github and maintained by Pasqal.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend","title":"<code>Backend(name=BackendName.PYQTORCH, supports_ad=True, support_bp=True, supports_adjoint=True, is_remote=False, with_measurements=True, native_endianness=Endianness.BIG, engine=Engine.TORCH, with_noise=False, config=Configuration())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Backend</code></p> <p>PyQTorch backend.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.circuit","title":"<code>circuit(circuit)</code>","text":"<p>Return the converted circuit.</p> <p>Note that to get a representation with noise, noise should be passed within the config.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Original circuit</p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>ConvertedCircuit instance for backend.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Return the converted circuit.\n\n    Note that to get a representation with noise, noise\n    should be passed within the config.\n\n    Args:\n        circuit (QuantumCircuit): Original circuit\n\n    Returns:\n        ConvertedCircuit: ConvertedCircuit instance for backend.\n    \"\"\"\n    passes = self.config.transpilation_passes\n    if passes is None:\n        passes = default_passes(self.config)\n\n    original_circ = circuit\n    if len(passes) &gt; 0:\n        circuit = transpile(*passes)(circuit)\n    # Setting noise in the circuit.\n    if self.config.noise:\n        set_noise(circuit, self.config.noise)\n\n    ops = convert_block(circuit.block, n_qubits=circuit.n_qubits, config=self.config)\n    readout_noise = (\n        convert_readout_noise(circuit.n_qubits, self.config.noise)\n        if self.config.noise\n        else None\n    )\n    if self.config.dropout_probability == 0:\n        native = pyq.QuantumCircuit(\n            circuit.n_qubits,\n            ops,\n            readout_noise,\n        )\n    else:\n        native = pyq.DropoutQuantumCircuit(\n            circuit.n_qubits,\n            ops,\n            readout_noise,\n            dropout_prob=self.config.dropout_probability,\n            dropout_mode=self.config.dropout_mode,\n        )\n    return ConvertedCircuit(native=native, abstract=circuit, original=original_circ)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit and an optional observable to their native representation.</p> <p>Additionally, this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\n    self, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n    \"\"\"Convert an abstract circuit and an optional observable to their native representation.\n\n    Additionally, this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\n\n    def check_observable(obs_obj: Any) -&gt; AbstractBlock:\n        if isinstance(obs_obj, QubitOperator):\n            from qadence.blocks.manipulate import from_openfermion\n\n            assert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\n\n            return from_openfermion(obs_obj)\n\n        elif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\n            from qadence.blocks.utils import block_is_qubit_hamiltonian\n\n            assert block_is_qubit_hamiltonian(\n                obs_obj\n            ), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\n            return obs_obj\n        raise TypeError(\n            \"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n        )\n\n    conv_circ = self.circuit(circuit)\n    circ_params, circ_embedding_fn = embedding(\n        conv_circ.abstract.block, self.config._use_gate_params, self.engine\n    )\n    params = circ_params\n    if observable is not None:\n        observable = observable if isinstance(observable, list) else [observable]\n        conv_obs = []\n        obs_embedding_fn_list = []\n\n        for obs in observable:\n            obs = check_observable(obs)\n            c_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\n            obs_params, obs_embedding_fn = embedding(\n                c_obs.abstract, self.config._use_gate_params, self.engine\n            )\n            params.update(obs_params)\n            obs_embedding_fn_list.append(obs_embedding_fn)\n            conv_obs.append(c_obs)\n\n        def embedding_fn_dict(a: dict, b: dict) -&gt; dict:\n            embedding_dict = circ_embedding_fn(a, b)\n            for o in obs_embedding_fn_list:\n                embedding_dict.update(o(a, b))\n            return embedding_dict\n\n        return Converted(conv_circ, conv_obs, embedding_fn_dict, params)\n\n    def embedding_fn(a: dict, b: dict) -&gt; dict:\n        return circ_embedding_fn(a, b)\n\n    return Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.set_block_and_readout_noises","title":"<code>set_block_and_readout_noises(circuit, noise, config)</code>","text":"<p>Add noise on blocks and readout on circuit.</p> <p>We first start by adding noise to the abstract blocks. Then we do a conversion to their native representation. Finally, we add readout.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Input circuit.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>noise</code> <p>Noise to add.</p> <p> TYPE: <code>NoiseHandler | None</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def set_block_and_readout_noises(\n    circuit: ConvertedCircuit, noise: NoiseHandler | None, config: Configuration\n) -&gt; None:\n    \"\"\"Add noise on blocks and readout on circuit.\n\n    We first start by adding noise to the abstract blocks. Then we do a conversion to their\n    native representation. Finally, we add readout.\n\n    Args:\n        circuit (ConvertedCircuit): Input circuit.\n        noise (NoiseHandler | None): Noise to add.\n    \"\"\"\n    if noise:\n        set_noise(circuit, noise)\n        set_noise_abstract_to_native(circuit, config)\n        set_readout_noise(circuit, noise)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.set_noise_abstract_to_native","title":"<code>set_noise_abstract_to_native(circuit, config)</code>","text":"<p>Set noise in native blocks from the abstract ones with noise.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Input converted circuit.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def set_noise_abstract_to_native(circuit: ConvertedCircuit, config: Configuration) -&gt; None:\n    \"\"\"Set noise in native blocks from the abstract ones with noise.\n\n    Args:\n        circuit (ConvertedCircuit): Input converted circuit.\n    \"\"\"\n    ops = convert_block(circuit.abstract.block, n_qubits=circuit.native.n_qubits, config=config)\n    circuit.native = pyq.QuantumCircuit(circuit.native.n_qubits, ops, circuit.native.readout_noise)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.set_readout_noise","title":"<code>set_readout_noise(circuit, noise)</code>","text":"<p>Set readout noise in place in native.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Input converted circuit.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>noise</code> <p>Noise.</p> <p> TYPE: <code>NoiseHandler | None</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def set_readout_noise(circuit: ConvertedCircuit, noise: NoiseHandler) -&gt; None:\n    \"\"\"Set readout noise in place in native.\n\n    Args:\n        circuit (ConvertedCircuit):  Input converted circuit.\n        noise (NoiseHandler | None): Noise.\n    \"\"\"\n    readout = convert_readout_noise(circuit.abstract.n_qubits, noise)\n    if readout:\n        circuit.native.readout_noise = readout\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration","title":"<code>Configuration(_use_gate_params=True, use_sparse_observable=False, use_gradient_checkpointing=False, use_single_qubit_composition=False, transpilation_passes=None, algo_hevo=AlgoHEvo.EXP, ode_solver=SolverType.DP5_SE, n_steps_hevo=100, loop_expectation=False, noise=None, dropout_probability=0.0, dropout_mode=DropoutMode.ROTATIONAL, n_eqs=None, shift_prefac=0.5, gap_step=1.0, lb=None, ub=None)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BackendConfiguration</code></p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.algo_hevo","title":"<code>algo_hevo = AlgoHEvo.EXP</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Determine which kind of Hamiltonian evolution algorithm to use.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.dropout_mode","title":"<code>dropout_mode = DropoutMode.ROTATIONAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of quantum dropout to perform.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.dropout_probability","title":"<code>dropout_probability = 0.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Quantum dropout probability (0 means no dropout).</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.gap_step","title":"<code>gap_step = 1.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Step between generated pseudo-gaps when using aGPSR algorithm.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.lb","title":"<code>lb = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Lower bound of optimal shift value search interval.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.loop_expectation","title":"<code>loop_expectation = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>When computing batches of expectation values, only allocate one wavefunction.</p> <p>Loop over the batch of parameters to only allocate a single wavefunction at any given time.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.n_eqs","title":"<code>n_eqs = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of equations to use in aGPSR calculations.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.n_steps_hevo","title":"<code>n_steps_hevo = 100</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default number of steps for the Hamiltonian evolution.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.noise","title":"<code>noise = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NoiseHandler containing readout noise applied in backend.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.ode_solver","title":"<code>ode_solver = SolverType.DP5_SE</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Determine which ODE solver to use for time-dependent blocks.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.shift_prefac","title":"<code>shift_prefac = 0.5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Prefactor governing the magnitude of parameter shift values.</p> <p>Select smaller value if spectral gaps are large.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.ub","title":"<code>ub = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Upper bound of optimal shift value search interval.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_gradient_checkpointing","title":"<code>use_gradient_checkpointing = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use gradient checkpointing.</p> <p>Recommended for higher-order optimization tasks.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_single_qubit_composition","title":"<code>use_single_qubit_composition = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Composes chains of single qubit gates into a single matmul if possible.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.supported_gates","title":"<code>supported_gates = list(set(OpName.list()) - set([OpName.TDAGGER]))</code>  <code>module-attribute</code>","text":"<p>The set of supported gates.</p> <p>Tdagger is currently not supported.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.convert_block","title":"<code>convert_block(block, n_qubits=None, config=None)</code>","text":"<p>Convert block to native Pyqtorch representation.</p> PARAMETER DESCRIPTION <code>block</code> <p>Block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Backend configuration instance. Defaults to None.</p> <p> TYPE: <code>Configuration</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>For non supported blocks.</p> RETURNS DESCRIPTION <code>Sequence[Module | Tensor | str | Expr]</code> <p>Sequence[Module | Tensor | str | sympy.Expr]: List of native operations.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def convert_block(\n    block: AbstractBlock,\n    n_qubits: int = None,\n    config: Configuration = None,\n) -&gt; Sequence[Module | Tensor | str | sympy.Expr]:\n    \"\"\"Convert block to native Pyqtorch representation.\n\n    Args:\n        block (AbstractBlock): Block to convert.\n        n_qubits (int, optional): Number of qubits. Defaults to None.\n        config (Configuration, optional): Backend configuration instance. Defaults to None.\n\n    Raises:\n        NotImplementedError: For non supported blocks.\n\n    Returns:\n        Sequence[Module | Tensor | str | sympy.Expr]: List of native operations.\n    \"\"\"\n    if isinstance(block, (Tensor, str, sympy.Expr)):  # case for hamevo generators\n        if isinstance(block, Tensor):\n            block = block.permute(1, 2, 0)  # put batch size in the back\n        return [block]\n    qubit_support = block.qubit_support\n    if n_qubits is None:\n        n_qubits = max(qubit_support) + 1\n\n    if config is None:\n        config = Configuration()\n\n    noise: NoiseHandler | None = None\n    if hasattr(block, \"noise\") and block.noise:\n        noise = convert_digital_noise(block.noise)\n\n    if isinstance(block, ScaleBlock):\n        scaled_ops = convert_block(block.block, n_qubits, config)\n        scale = extract_parameter(block, config=config)\n\n        # replace underscore by dot when underscore is between two numbers in string\n        if isinstance(scale, str):\n            scale = replace_underscore_floats(scale)\n\n        if isinstance(scale, str) and not config._use_gate_params:\n            param = sympy_to_pyq(sympy.parse_expr(scale))\n        else:\n            param = scale\n\n        return [pyq.Scale(pyq.Sequence(scaled_ops), param)]\n\n    elif isinstance(block, TimeEvolutionBlock):\n        duration = block.duration  # type: ignore [attr-defined]\n        if getattr(block.generator, \"is_time_dependent\", False):\n            config._use_gate_params = False\n            duration = config.get_param_name(block)[1]\n            generator = convert_block(block.generator, config=config)[0]  # type: ignore [arg-type]\n        elif isinstance(block.generator, sympy.Basic):\n            generator = config.get_param_name(block)[1]\n\n        elif isinstance(block.generator, Tensor):\n            m = block.generator.to(dtype=cdouble)\n            generator = convert_block(\n                MatrixBlock(\n                    m,\n                    qubit_support=qubit_support,\n                    check_unitary=False,\n                    check_hermitian=True,\n                )\n            )[0]\n        else:\n            generator = convert_block(block.generator, n_qubits, config)[0]  # type: ignore[arg-type]\n        time_param = config.get_param_name(block)[0]\n\n        # convert noise operators here\n        noise_operators: list = [\n            convert_block(noise_block, config=config)[0] for noise_block in block.noise_operators\n        ]\n        if len(noise_operators) &gt; 0:\n            # squeeze batch size for noise operators\n            noise_operators = [\n                pyq_op.tensor(full_support=qubit_support).squeeze(-1) for pyq_op in noise_operators\n            ]\n\n        return [\n            pyq.HamiltonianEvolution(\n                qubit_support=qubit_support,\n                generator=generator,\n                time=time_param,\n                cache_length=0,\n                duration=duration,\n                solver=config.ode_solver,\n                steps=config.n_steps_hevo,\n                noise=noise_operators if len(noise_operators) &gt; 0 else None,\n            )\n        ]\n\n    elif isinstance(block, MatrixBlock):\n        return [pyq.primitives.Primitive(block.matrix, block.qubit_support, noise=noise)]\n    elif isinstance(block, CompositeBlock):\n        ops = list(flatten(*(convert_block(b, n_qubits, config) for b in block.blocks)))\n        if isinstance(block, AddBlock):\n            return [pyq.Add(ops)]  # add\n        elif is_single_qubit_chain(block) and config.use_single_qubit_composition:\n            return [pyq.Merge(ops)]  # for chains of single qubit ops on the same qubit\n        else:\n            return [pyq.Sequence(ops)]  # for kron and chain\n    elif isinstance(block, tuple(non_unitary_gateset)):\n        if isinstance(block, ProjectorBlock):\n            projector = getattr(pyq, block.name)\n            if block.name == OpName.N:\n                return [projector(target=qubit_support, noise=noise)]\n            else:\n                return [\n                    projector(\n                        qubit_support=qubit_support,\n                        ket=block.ket,\n                        bra=block.bra,\n                        noise=noise,\n                    )\n                ]\n        else:\n            return [getattr(pyq, block.name)(qubit_support[0])]\n    elif isinstance(block, tuple(single_qubit_gateset)):\n        pyq_cls = getattr(pyq, block.name)\n        if isinstance(block, ParametricBlock):\n            if isinstance(block, U):\n                op = pyq_cls(\n                    qubit_support[0],\n                    *config.get_param_name(block),\n                    noise=noise,\n                )\n            else:\n                param = extract_parameter(block, config)\n                op = pyq_cls(qubit_support[0], param, noise=noise)\n        else:\n            op = pyq_cls(qubit_support[0], noise=noise)  # type: ignore [attr-defined]\n        return [op]\n    elif isinstance(block, tuple(two_qubit_gateset)):\n        pyq_cls = getattr(pyq, block.name)\n        if isinstance(block, ParametricBlock):\n            op = pyq_cls(\n                qubit_support[0],\n                qubit_support[1],\n                extract_parameter(block, config),\n                noise=noise,\n            )\n        else:\n            op = pyq_cls(\n                qubit_support[0], qubit_support[1], noise=noise  # type: ignore [attr-defined]\n            )\n        return [op]\n    elif isinstance(block, tuple(three_qubit_gateset) + tuple(multi_qubit_gateset)):\n        block_name = block.name[1:] if block.name.startswith(\"M\") else block.name\n        pyq_cls = getattr(pyq, block_name)\n        if isinstance(block, ParametricBlock):\n            op = pyq_cls(\n                qubit_support[:-1],\n                qubit_support[-1],\n                extract_parameter(block, config),\n                noise=noise,\n            )\n        else:\n            if \"CSWAP\" in block_name:\n                op = pyq_cls(\n                    qubit_support[:-2], qubit_support[-2:], noise=noise  # type: ignore [attr-defined]\n                )\n            else:\n                op = pyq_cls(\n                    qubit_support[:-1], qubit_support[-1], noise=noise  # type: ignore [attr-defined]\n                )\n        return [op]\n    else:\n        raise NotImplementedError(\n            f\"Non supported operation of type {type(block)}. \"\n            \"In case you are trying to run an `AnalogBlock`, make sure you \"\n            \"specify the `device_specs` in your `Register` first.\"\n        )\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.convert_digital_noise","title":"<code>convert_digital_noise(noise)</code>","text":"<p>Convert the digital noise into pyqtorch NoiseProtocol.</p> PARAMETER DESCRIPTION <code>noise</code> <p>Noise to convert.</p> <p> TYPE: <code>NoiseHandler</code> </p> RETURNS DESCRIPTION <code>DigitalNoiseProtocol | None</code> <p>pyq.noise.DigitalNoiseProtocol | None: Pyqtorch native noise protocol if there are any digital noise protocols.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def convert_digital_noise(noise: NoiseHandler) -&gt; pyq.noise.DigitalNoiseProtocol | None:\n    \"\"\"Convert the digital noise into pyqtorch NoiseProtocol.\n\n    Args:\n        noise (NoiseHandler): Noise to convert.\n\n    Returns:\n        pyq.noise.DigitalNoiseProtocol | None: Pyqtorch native noise protocol\n            if there are any digital noise protocols.\n    \"\"\"\n    digital_part = noise.filter(NoiseProtocol.DIGITAL)\n    if digital_part is None:\n        return None\n    return pyq.noise.DigitalNoiseProtocol(\n        [\n            pyq.noise.DigitalNoiseProtocol(proto, option.get(\"error_probability\"))\n            for proto, option in zip(digital_part.protocol, digital_part.options)\n        ]\n    )\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.convert_readout_noise","title":"<code>convert_readout_noise(n_qubits, noise)</code>","text":"<p>Convert the readout noise into pyqtorch ReadoutNoise.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Number of qubits</p> <p> TYPE: <code>int</code> </p> <code>noise</code> <p>Noise to convert.</p> <p> TYPE: <code>NoiseHandler</code> </p> RETURNS DESCRIPTION <code>ReadoutNoise | None</code> <p>pyq.noise.ReadoutNoise | None: Pyqtorch native ReadoutNoise instance if readout is is noise.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def convert_readout_noise(n_qubits: int, noise: NoiseHandler) -&gt; pyq.noise.ReadoutNoise | None:\n    \"\"\"Convert the readout noise into pyqtorch ReadoutNoise.\n\n    Args:\n        n_qubits (int): Number of qubits\n        noise (NoiseHandler):  Noise to convert.\n\n    Returns:\n        pyq.noise.ReadoutNoise | None: Pyqtorch native ReadoutNoise instance\n            if readout is is noise.\n    \"\"\"\n    readout_part = noise.filter(NoiseProtocol.READOUT)\n    if readout_part is None:\n        return None\n\n    if readout_part.protocol[0] == NoiseProtocol.READOUT.INDEPENDENT:\n        return pyq.noise.ReadoutNoise(n_qubits, **readout_part.options[0])\n    else:\n        return pyq.noise.CorrelatedReadoutNoise(**readout_part.options[0])\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.extract_parameter","title":"<code>extract_parameter(block, config)</code>","text":"<p>Extract the parameter as string or its tensor value.</p> PARAMETER DESCRIPTION <code>block</code> <p>Block to extract parameter from.</p> <p> TYPE: <code>ScaleBlock | ParametricBlock</code> </p> <code>config</code> <p>Configuration instance.</p> <p> TYPE: <code>Configuration</code> </p> RETURNS DESCRIPTION <code>str | Tensor</code> <p>str | Tensor: Parameter value or symbol.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def extract_parameter(block: ScaleBlock | ParametricBlock, config: Configuration) -&gt; str | Tensor:\n    \"\"\"Extract the parameter as string or its tensor value.\n\n    Args:\n        block (ScaleBlock | ParametricBlock): Block to extract parameter from.\n        config (Configuration): Configuration instance.\n\n    Returns:\n        str | Tensor: Parameter value or symbol.\n    \"\"\"\n    if not block.is_parametric:\n        tensor_val = tensor([block.parameters.parameter], dtype=complex64)\n        return (\n            tensor([block.parameters.parameter], dtype=float64)\n            if torch.all(tensor_val.imag == 0)\n            else tensor_val\n        )\n\n    return config.get_param_name(block)[0]\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.replace_underscore_floats","title":"<code>replace_underscore_floats(s)</code>","text":"<p>Replace underscores with periods for all floats in given string.</p> <p>Needed for correct parsing of string by sympy parser.</p> PARAMETER DESCRIPTION <code>s</code> <p>string expression</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>transformed string expression</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def replace_underscore_floats(s: str) -&gt; str:\n    \"\"\"Replace underscores with periods for all floats in given string.\n\n    Needed for correct parsing of string by sympy parser.\n\n    Args:\n        s (str): string expression\n\n    Returns:\n        str: transformed string expression\n    \"\"\"\n\n    # Regular expression to match floats written with underscores instead of dots\n    float_with_underscore_pattern = r\"\"\"\n        (?&lt;!\\w)            # Negative lookbehind to ensure not part of a word\n        -?                 # Optional negative sign\n        \\d+                # One or more digits (before underscore)\n        _                  # The underscore acting as decimal separator\n        \\d+                # One or more digits (after underscore)\n        ([eE][-+]?\\d+)?    # Optional exponent part for scientific notation\n        (?!\\w)             # Negative lookahead to ensure not part of a word\n    \"\"\"\n\n    # Function to replace the underscore with a dot\n    def underscore_to_dot(match: re.Match) -&gt; Any:\n        return match.group(0).replace(\"_\", \".\")\n\n    # Compile the regular expression\n    pattern = re.compile(float_with_underscore_pattern, re.VERBOSE)\n\n    return pattern.sub(underscore_to_dot, s)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.sympy_to_pyq","title":"<code>sympy_to_pyq(expr)</code>","text":"<p>Convert sympy expression to pyqtorch ConcretizedCallable object.</p> PARAMETER DESCRIPTION <code>expr</code> <p>sympy expression</p> <p> TYPE: <code>Expr</code> </p> RETURNS DESCRIPTION <code>ConcretizedCallable</code> <p>expression encoded as ConcretizedCallable</p> <p> TYPE: <code>ConcretizedCallable | Tensor</code> </p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def sympy_to_pyq(expr: sympy.Expr) -&gt; ConcretizedCallable | Tensor:\n    \"\"\"Convert sympy expression to pyqtorch ConcretizedCallable object.\n\n    Args:\n        expr (sympy.Expr): sympy expression\n\n    Returns:\n        ConcretizedCallable: expression encoded as ConcretizedCallable\n    \"\"\"\n\n    # base case - independent argument\n    if len(expr.args) == 0:\n        try:\n            res = torch.as_tensor(float(expr))\n        except Exception as e:\n            res = str(expr)\n\n            if \"/\" in res:  # Found a rational\n                res = torch.as_tensor(float(sympy.Rational(res).evalf()))\n        return res\n\n    # Recursively iterate through current function arguments\n    all_results = []\n    for arg in expr.args:\n        res = sympy_to_pyq(arg)\n        all_results.append(res)\n\n    # deal with multi-argument (&gt;2) sympy functions: converting to nested\n    # ConcretizedCallable objects\n    if len(all_results) &gt; 2:\n\n        def fn(x: str | ConcretizedCallable, y: str | ConcretizedCallable) -&gt; Callable:\n            return partial(ConcretizedCallable, call_name=SYMPY_TO_PYQ_MAPPING[expr.func])(  # type: ignore [no-any-return]\n                abstract_args=[x, y]\n            )\n\n        concretized_callable = reduce(fn, all_results)\n    else:\n        concretized_callable = ConcretizedCallable(SYMPY_TO_PYQ_MAPPING[expr.func], all_results)\n    return concretized_callable\n</code></pre>"},{"location":"content/backends/","title":"Backends","text":"<p>Backends allow execution of Qadence abstract quantum circuits. They could be chosen from a variety of simulators, emulators and hardware and can enable circuit differentiability. The primary way to interact and configure a backend is via the high-level API <code>QuantumModel</code>.</p> <p>Not all backends are equivalent</p> <p>Not all backends support the same set of operations, especially while executing analog blocks. Qadence will throw descriptive errors in such cases.</p>"},{"location":"content/backends/#execution-backends","title":"Execution backends","text":"<p>PyQTorch: An efficient, large-scale simulator designed for quantum machine learning, seamlessly integrated with the popular PyTorch deep learning framework for automatic differentiability. It also offers analog computing for time-(in)dependent pulses. See <code>PyQTorchBackend</code>.</p> <p>Pulser: A Python library for pulse-level/analog control of neutral atom devices. Execution via QuTiP. See <code>PulserBackend</code>.</p> <p>More: Proprietary Qadence extensions provide more high-performance backends based on tensor networks or differentiation engines. For more enquiries, please contact: <code>info@pasqal.com</code>.</p>"},{"location":"content/backends/#differentiation-backend","title":"Differentiation backend","text":"<p>The <code>DifferentiableBackend</code> class enables different differentiation modes for the given backend. This can be chosen from two types:</p> <ul> <li>Automatic differentiation (AD): available for PyTorch based backends (PyQTorch).</li> <li>Parameter Shift Rules (PSR): available for all backends. See this section for more information on differentiability and PSR.</li> </ul> <p>In practice, only a <code>diff_mode</code> should be provided in the <code>QuantumModel</code>. Please note that <code>diff_mode</code> defaults to <code>None</code>:</p> <pre><code>import sympy\nimport torch\nfrom qadence import Parameter, RX, RZ, Z, CNOT, QuantumCircuit, QuantumModel, chain, BackendName, DiffMode\n\nx = Parameter(\"x\", trainable=False)\ny = Parameter(\"y\", trainable=False)\nfm = chain(\n    RX(0, 3 * x),\n    RX(0, x),\n    RZ(1, sympy.exp(y)),\n    RX(0, 3.14),\n    RZ(1, \"theta\")\n)\n\nansatz = CNOT(0, 1)\nblock = chain(fm, ansatz)\n\ncircuit = QuantumCircuit(2, block)\n\nobservable = Z(0)\n\n# DiffMode.GPSR is available for any backend.\n# DiffMode.AD is only available for natively differentiable backends.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.GPSR)\n\n# Get some values for the feature parameters.\nvalues = {\"x\": (x := torch.tensor([0.5], requires_grad=True)), \"y\": torch.tensor([0.1])}\n\n# Compute expectation.\nexp = model.expectation(values)\n\n# Differentiate the expectation wrt x.\ndexp_dx = torch.autograd.grad(exp, x, torch.ones_like(exp))\n</code></pre> <pre><code>dexp_dx = (tensor([3.6398]),)\n</code></pre>"},{"location":"content/backends/#low-level-backend_factory-interface","title":"Low-level <code>backend_factory</code> interface","text":"<p>Every backend in Qadence inherits from the abstract <code>Backend</code> class: <code>Backend</code> and implement the following methods:</p> <ul> <li><code>run</code>: propagate the initial state according to the quantum circuit and return the final wavefunction object.</li> <li><code>sample</code>: sample from a circuit.</li> <li><code>expectation</code>: computes the expectation of a circuit given an observable.</li> <li><code>convert</code>: convert the abstract <code>QuantumCircuit</code> object to its backend-native representation including a backend specific parameter embedding function.</li> </ul> <p>Backends are purely functional objects which take as input the values for the circuit parameters and return the desired output from a call to a method. In order to use a backend directly, embedded parameters must be supplied as they are returned by the backend specific embedding function.</p> <p>Here is a simple demonstration of the use of the PyQTorch backend to execute a circuit in non-differentiable mode:</p> <pre><code>from qadence import QuantumCircuit, FeatureParameter, RX, RZ, CNOT, hea, chain\n\n# Construct a feature map.\nx = FeatureParameter(\"x\")\nz = FeatureParameter(\"y\")\nfm = chain(RX(0, 3 * x), RZ(1, z), CNOT(0, 1))\n\n# Construct a circuit with an hardware-efficient ansatz.\ncircuit = QuantumCircuit(3, fm, hea(3,1))\n</code></pre> <p>The abstract <code>QuantumCircuit</code> can now be converted to its native representation via the PyQTorch backend.</p> <pre><code>from qadence import backend_factory\n\n# Use only PyQtorch in non-differentiable mode:\nbackend = backend_factory(\"pyqtorch\")\n\n# The `Converted` object\n# (contains a `ConvertedCircuit` with the original and native representation)\nconv = backend.convert(circuit)\n</code></pre> <pre><code>conv.circuit.original = ChainBlock(0,1,2)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 RX(0) [params: ['3*x']]\n\u2502   \u251c\u2500\u2500 RZ(1) [params: ['y']]\n\u2502   \u2514\u2500\u2500 CNOT(0, 1)\n\u2514\u2500\u2500 ChainBlock(0,1,2) [tag: HEA]\n    \u251c\u2500\u2500 ChainBlock(0,1,2)\n    \u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n    \u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n    \u2502   \u2502   \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n    \u2502   \u2502   \u2514\u2500\u2500 RX(2) [params: ['theta_2']]\n    \u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n    \u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_3']]\n    \u2502   \u2502   \u251c\u2500\u2500 RY(1) [params: ['theta_4']]\n    \u2502   \u2502   \u2514\u2500\u2500 RY(2) [params: ['theta_5']]\n    \u2502   \u2514\u2500\u2500 KronBlock(0,1,2)\n    \u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_6']]\n    \u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_7']]\n    \u2502       \u2514\u2500\u2500 RX(2) [params: ['theta_8']]\n    \u2514\u2500\u2500 ChainBlock(0,1,2)\n        \u251c\u2500\u2500 KronBlock(0,1)\n        \u2502   \u2514\u2500\u2500 CNOT(0, 1)\n        \u2514\u2500\u2500 KronBlock(1,2)\n            \u2514\u2500\u2500 CNOT(1, 2)\nconv.circuit.native = QuantumCircuit(\n  (operations): ModuleList(\n    (0): Sequence(\n      (operations): ModuleList(\n        (0): Sequence(\n          (operations): ModuleList(\n            (0): RX(target: (0,), param: 9af42b89-bde3-4667-95b8-d48aa811d0f9)\n            (1): RZ(target: (1,), param: b999f44c-e0ba-4efb-88f9-9cfcddf7547d)\n            (2): CNOT(control: (0,), target: (1,))\n          )\n        )\n        (1): Sequence(\n          (operations): ModuleList(\n            (0): Sequence(\n              (operations): ModuleList(\n                (0): Merge(\n                  (operations): ModuleList(\n                    (0): RX(target: (0,), param: 07ac2c73-83c6-488a-9582-c1e0f8f320c9)\n                    (1): RY(target: (0,), param: e961cd3d-dd6a-4bee-a4d5-73b3e5986406)\n                    (2): RX(target: (0,), param: 3f65ed7f-f54c-4207-a53c-2445f588c5b5)\n                  )\n                )\n                (1): Merge(\n                  (operations): ModuleList(\n                    (0): RX(target: (1,), param: 36bc4c57-1d35-421c-8b71-39319ad0c374)\n                    (1): RY(target: (1,), param: a56f2451-a0c2-4008-8d10-ace90618fab2)\n                    (2): RX(target: (1,), param: f38f0959-2cd6-4b30-91d7-13992356a759)\n                  )\n                )\n                (2): Merge(\n                  (operations): ModuleList(\n                    (0): RX(target: (2,), param: 8de573e3-d7f1-479d-a59f-4eb347b1d26a)\n                    (1): RY(target: (2,), param: 9c9b858a-f01c-4a4c-9e57-393591e8b258)\n                    (2): RX(target: (2,), param: f3327c9d-ae05-4d4e-8b2d-6b9631523b3d)\n                  )\n                )\n              )\n            )\n            (1): Sequence(\n              (operations): ModuleList(\n                (0): Sequence(\n                  (operations): ModuleList(\n                    (0): CNOT(control: (0,), target: (1,))\n                  )\n                )\n                (1): Sequence(\n                  (operations): ModuleList(\n                    (0): CNOT(control: (1,), target: (2,))\n                  )\n                )\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n)\n</code></pre> <p>Additionally, <code>Converted</code> contains all fixed and variational parameters, as well as an embedding function which accepts feature parameters to construct a dictionary of circuit native parameters. These are needed as each backend uses a different representation of the circuit parameters:</p> <pre><code>import torch\n\n# Contains fixed parameters and variational (from the HEA)\nconv.params\n\ninputs = {\"x\": torch.tensor([1., 1.]), \"y\":torch.tensor([2., 2.])}\n\n# get all circuit parameters (including feature params)\nembedded = conv.embedding_fn(conv.params, inputs)\n</code></pre> <pre><code>conv.params = {\n  theta_1: tensor([0.7195], requires_grad=True)\n  theta_6: tensor([0.2487], requires_grad=True)\n  theta_0: tensor([0.5327], requires_grad=True)\n  theta_5: tensor([0.8272], requires_grad=True)\n  theta_2: tensor([0.2177], requires_grad=True)\n  theta_7: tensor([0.3097], requires_grad=True)\n  theta_4: tensor([0.1798], requires_grad=True)\n  theta_3: tensor([0.4164], requires_grad=True)\n  theta_8: tensor([0.1463], requires_grad=True)\n}\nembedded = {\n  9af42b89-bde3-4667-95b8-d48aa811d0f9: tensor([3., 3.], grad_fn=&lt;ViewBackward0&gt;)\n  b999f44c-e0ba-4efb-88f9-9cfcddf7547d: tensor([2., 2.])\n  07ac2c73-83c6-488a-9582-c1e0f8f320c9: tensor([0.5327], grad_fn=&lt;ViewBackward0&gt;)\n  e961cd3d-dd6a-4bee-a4d5-73b3e5986406: tensor([0.4164], grad_fn=&lt;ViewBackward0&gt;)\n  3f65ed7f-f54c-4207-a53c-2445f588c5b5: tensor([0.2487], grad_fn=&lt;ViewBackward0&gt;)\n  36bc4c57-1d35-421c-8b71-39319ad0c374: tensor([0.7195], grad_fn=&lt;ViewBackward0&gt;)\n  a56f2451-a0c2-4008-8d10-ace90618fab2: tensor([0.1798], grad_fn=&lt;ViewBackward0&gt;)\n  f38f0959-2cd6-4b30-91d7-13992356a759: tensor([0.3097], grad_fn=&lt;ViewBackward0&gt;)\n  8de573e3-d7f1-479d-a59f-4eb347b1d26a: tensor([0.2177], grad_fn=&lt;ViewBackward0&gt;)\n  9c9b858a-f01c-4a4c-9e57-393591e8b258: tensor([0.8272], grad_fn=&lt;ViewBackward0&gt;)\n  f3327c9d-ae05-4d4e-8b2d-6b9631523b3d: tensor([0.1463], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>With the embedded parameters, <code>QuantumModel</code> methods are accessible:</p> <pre><code>output = backend.run(conv.circuit, embedded)\nprint(f\"{output = }\")\n</code></pre> <pre><code>output = tensor([[ 0.2192-0.0577j,  0.0861-0.0675j,  0.0410+0.1452j, -0.0411+0.3100j,\n         -0.6201-0.3545j, -0.3424-0.0385j, -0.0027+0.1880j, -0.1595+0.3555j],\n        [ 0.2192-0.0577j,  0.0861-0.0675j,  0.0410+0.1452j, -0.0411+0.3100j,\n         -0.6201-0.3545j, -0.3424-0.0385j, -0.0027+0.1880j, -0.1595+0.3555j]],\n       grad_fn=&lt;TBackward0&gt;)\n</code></pre>"},{"location":"content/backends/#lower-level-the-backend-representation","title":"Lower-level: the <code>Backend</code> representation","text":"<p>If there is a requirement to work with a specific backend, it is possible to access directly the native circuit. For example, should one wish to use PyQtorch noise features directly instead of using the <code>NoiseHandler</code> interface from Qadence:</p> <pre><code>from pyqtorch.noise import Depolarizing\n\ninputs = {\"x\": torch.rand(1), \"y\":torch.rand(1)}\nembedded = conv.embedding_fn(conv.params, inputs)\n\n# Define a noise channel on qubit 0\nnoise = Depolarizing(0, error_probability=0.1)\n\n# Add noise to circuit\nconv.circuit.native.operations.append(noise)\n</code></pre> <p>When running With noise, one can see that the output is a density matrix:</p> <pre><code>density_result = backend.run(conv.circuit, embedded)\nprint(density_result.shape)\n</code></pre> <pre><code>torch.Size([1, 8, 8])\n</code></pre>"},{"location":"content/block_system/","title":"Block system","text":"<p>Quantum programs in Qadence are constructed using a block-system, with an emphasis on composability of primitive blocks to obtain larger, composite blocks. This functional approach is different from other frameworks which follow a more object-oriented way to construct circuits and express programs.</p>"},{"location":"content/block_system/#primitive-blocks","title":"Primitive blocks","text":"<p>A <code>PrimitiveBlock</code> represents a digital or an analog time-evolution quantum operation applied to a qubit support. Programs can always be decomposed down into a sequence of <code>PrimitiveBlock</code> elements.</p> <p>Two canonical examples of digital primitive blocks are the parametrized <code>RX</code> and the <code>CNOT</code> gates:</p> <pre><code>from qadence import chain, RX, CNOT\n\nrx = RX(0, 0.5)\ncnot = CNOT(0, 1)\n\nblock = chain(rx, cnot)\n</code></pre> %3 01790e7a9fa7414abdd117a862b6eee6 0 61f86cbe07b64ca8ab5c948373e3c363 RX(0.5) 01790e7a9fa7414abdd117a862b6eee6--61f86cbe07b64ca8ab5c948373e3c363 dbe41066c07447dba3ba2118e8e2cb94 1 cb0a427cbb204b59bf64fb73ad58dd12 61f86cbe07b64ca8ab5c948373e3c363--cb0a427cbb204b59bf64fb73ad58dd12 cbf3fa2868984cecb4fee36aff9c355b cb0a427cbb204b59bf64fb73ad58dd12--cbf3fa2868984cecb4fee36aff9c355b 9413e7927fa44a70838ce6a8ccc54206 f127552bf4144b96b4e728d2d9a9f346 dbe41066c07447dba3ba2118e8e2cb94--f127552bf4144b96b4e728d2d9a9f346 859fa33d47914de5934bba2d28dd9dfe X f127552bf4144b96b4e728d2d9a9f346--859fa33d47914de5934bba2d28dd9dfe 859fa33d47914de5934bba2d28dd9dfe--cb0a427cbb204b59bf64fb73ad58dd12 859fa33d47914de5934bba2d28dd9dfe--9413e7927fa44a70838ce6a8ccc54206 <p>A list of all available primitive operations can be found here.</p> How to visualize blocks <p>There are two ways to display blocks in a Python interpreter: either as a tree in ASCII format using <code>print</code>:</p> <pre><code>from qadence import X, Y, kron\n\nkron_block = kron(X(0), Y(1))\nprint(kron_block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> <p>Or using the visualization package:</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nkron_block = kron(X(0), Y(1))\n# display(kron_block)\n</code></pre> %3 87473df5cc06495490969be3d756aea5 0 e263c142b0114f6dbc1321e1153a5561 X 87473df5cc06495490969be3d756aea5--e263c142b0114f6dbc1321e1153a5561 f88dcf20995a4465a4d4961b8c27dacc 1 827bd7596adf47958d9b8f4a189dafc8 e263c142b0114f6dbc1321e1153a5561--827bd7596adf47958d9b8f4a189dafc8 76b63d4f3a2c4b38ace6d3f49b73a3f5 c0b7c25c28e14a03b23151f952c429dc Y f88dcf20995a4465a4d4961b8c27dacc--c0b7c25c28e14a03b23151f952c429dc c0b7c25c28e14a03b23151f952c429dc--76b63d4f3a2c4b38ace6d3f49b73a3f5"},{"location":"content/block_system/#composite-blocks","title":"Composite Blocks","text":"<p>Programs can be expressed by composing blocks to result in a larger <code>CompositeBlock</code> using three fundamental operations: chain, kron, and add.</p> <ul> <li>chain applies a set of blocks in sequence, which can have overlapping qubit supports, and results in a <code>ChainBlock</code> type. It is akin to applying a matrix product of the sub-blocks, and can also be used with the <code>*</code> operator.</li> <li>kron applies a set of blocks in parallel, requiring disjoint qubit support, and results in a <code>KronBlock</code> type. This is akin to applying a tensor product of the sub-blocks, and can also be used with the <code>@</code> operator.</li> <li>add performs a direct sum of the operators, and results in an <code>AddBlock</code> type. Blocks constructed this way are typically non-unitary, as is the case for Hamiltonians which can be constructed through sums of Pauli strings. Addition can also be performed directly with the <code>+</code> operator.</li> </ul> <pre><code>from qadence import X, Y, chain, kron\n\nchain_0 = chain(X(0), Y(0))\nchain_1 = chain(X(1), Y(1))\n\nkron_block = kron(chain_0, chain_1)\n</code></pre> %3 35c7915fc33945aca91182f4053a62ee 0 95d7b161568c430ba94acc7d8bb68913 X 35c7915fc33945aca91182f4053a62ee--95d7b161568c430ba94acc7d8bb68913 d3da5838df2240e59e458e300d7b5889 1 5d02af7b2df044b192807bafd30e01f5 Y 95d7b161568c430ba94acc7d8bb68913--5d02af7b2df044b192807bafd30e01f5 037eada242a144b994fc19ad07d977f6 5d02af7b2df044b192807bafd30e01f5--037eada242a144b994fc19ad07d977f6 391fc32ea1c142b9ac851c7d1648f581 cfbee1fe43e34cc88f7bbd2229ed2bd9 X d3da5838df2240e59e458e300d7b5889--cfbee1fe43e34cc88f7bbd2229ed2bd9 3b358174e7a148dd912a3586dd9ced74 Y cfbee1fe43e34cc88f7bbd2229ed2bd9--3b358174e7a148dd912a3586dd9ced74 3b358174e7a148dd912a3586dd9ced74--391fc32ea1c142b9ac851c7d1648f581 <p>All composition functions support list comprehension syntax. Below we exemplify the creation of an XY Hamiltonian for qubits laid out on a line.</p> <pre><code>from qadence import X, Y, add\n\ndef xy_int(i: int, j: int):\n    return (1/2) * (X(i)@X(j) + Y(i)@Y(j))\n\nn_qubits = 3\n\nxy_ham = add(xy_int(i, i+1) for i in range(n_qubits-1))\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u251c\u2500\u2500 KronBlock(0,1)\n\u2502       \u2502   \u251c\u2500\u2500 X(0)\n\u2502       \u2502   \u2514\u2500\u2500 X(1)\n\u2502       \u2514\u2500\u2500 KronBlock(0,1)\n\u2502           \u251c\u2500\u2500 Y(0)\n\u2502           \u2514\u2500\u2500 Y(1)\n\u2514\u2500\u2500 [mul: 0.500] \n    \u2514\u2500\u2500 AddBlock(1,2)\n        \u251c\u2500\u2500 KronBlock(1,2)\n        \u2502   \u251c\u2500\u2500 X(1)\n        \u2502   \u2514\u2500\u2500 X(2)\n        \u2514\u2500\u2500 KronBlock(1,2)\n            \u251c\u2500\u2500 Y(1)\n            \u2514\u2500\u2500 Y(2)\n</code></pre> <p>Qadence blocks can be directly translated to matrix form by calling <code>block.tensor()</code>. Note that first dimension is the batch dimension, following PyTorch conventions. This becomes relevant if the block are parameterized and batched input values are passed, as we will see later.</p> <pre><code>from qadence import X, Y\n\nxy = (1/2) * (X(0)@X(1) + Y(0)@Y(1))\n\nprint(xy.tensor().real)\n</code></pre> <pre><code>tensor([[[0., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [0., 1., 0., 0.],\n         [0., 0., 0., 0.]]])\n</code></pre> <p>For a final example of the flexibility of functional block composition, below is an implementation of the Quantum Fourier Transform on an arbitrary qubit support.</p> <pre><code>from qadence import H, CPHASE, PI, chain, kron\n\ndef qft_layer(qs: tuple, l: int):\n    cphases = chain(CPHASE(qs[j], qs[l], PI/2**(j-l)) for j in range(l+1, len(qs)))\n    return H(qs[l]) * cphases\n\ndef qft(qs: tuple):\n    return chain(qft_layer(qs, l) for l in range(len(qs)))\n</code></pre> %3 8b0f546ed9a54cf1a1aea3883381f7e6 0 b8223641b3054a74aa0a58dd2176f037 H 8b0f546ed9a54cf1a1aea3883381f7e6--b8223641b3054a74aa0a58dd2176f037 ae1f1d5e45714fbd9239432971f76089 1 da0ccd7ddc524cb1b92a912a05cad9e6 PHASE(1.571) b8223641b3054a74aa0a58dd2176f037--da0ccd7ddc524cb1b92a912a05cad9e6 2e53d9d984384a3ab687e5fe84efdae6 PHASE(0.785) da0ccd7ddc524cb1b92a912a05cad9e6--2e53d9d984384a3ab687e5fe84efdae6 8add5cbf38e1417db079ce8e07657198 da0ccd7ddc524cb1b92a912a05cad9e6--8add5cbf38e1417db079ce8e07657198 58b43875c59b4faeb5c136fddc5e3193 2e53d9d984384a3ab687e5fe84efdae6--58b43875c59b4faeb5c136fddc5e3193 194265611a85422eb654386883dff287 2e53d9d984384a3ab687e5fe84efdae6--194265611a85422eb654386883dff287 869863ad0b2d492bbfb27afcfbf2cdf1 58b43875c59b4faeb5c136fddc5e3193--869863ad0b2d492bbfb27afcfbf2cdf1 4876b9b69dca4fbc98ae28a3d80f2203 869863ad0b2d492bbfb27afcfbf2cdf1--4876b9b69dca4fbc98ae28a3d80f2203 d477a4d4b70545c48c243335618c2b46 4876b9b69dca4fbc98ae28a3d80f2203--d477a4d4b70545c48c243335618c2b46 11888727c86f43cca3652b0d8e1045bd d68c03d6300d41719f6d136de0ee1fce ae1f1d5e45714fbd9239432971f76089--d68c03d6300d41719f6d136de0ee1fce 5344e5f4841b40ac94a3295685e84014 2 d68c03d6300d41719f6d136de0ee1fce--8add5cbf38e1417db079ce8e07657198 c6e94e1a1e3d4c7b8d4d8908f9f914fc 8add5cbf38e1417db079ce8e07657198--c6e94e1a1e3d4c7b8d4d8908f9f914fc 4e0e6ab94a214cb7ac35235f5aae8f95 H c6e94e1a1e3d4c7b8d4d8908f9f914fc--4e0e6ab94a214cb7ac35235f5aae8f95 d7b97a0b686442dfa4d0b15517cde50b PHASE(1.571) 4e0e6ab94a214cb7ac35235f5aae8f95--d7b97a0b686442dfa4d0b15517cde50b c253a8bbb552463ca879733530735339 d7b97a0b686442dfa4d0b15517cde50b--c253a8bbb552463ca879733530735339 6cf3f751b3c84dc8844be9f1c948f6e6 d7b97a0b686442dfa4d0b15517cde50b--6cf3f751b3c84dc8844be9f1c948f6e6 c253a8bbb552463ca879733530735339--11888727c86f43cca3652b0d8e1045bd b93b2cf90d564841a5517982ce02c189 d9ea9dceec84439f91f1f5abca8d07ed 5344e5f4841b40ac94a3295685e84014--d9ea9dceec84439f91f1f5abca8d07ed 06d531c1353a4ed1b6a93cd897d46c18 d9ea9dceec84439f91f1f5abca8d07ed--06d531c1353a4ed1b6a93cd897d46c18 06d531c1353a4ed1b6a93cd897d46c18--194265611a85422eb654386883dff287 7def2c5c9f1c4a18ae71c47ebae0cb61 194265611a85422eb654386883dff287--7def2c5c9f1c4a18ae71c47ebae0cb61 7def2c5c9f1c4a18ae71c47ebae0cb61--6cf3f751b3c84dc8844be9f1c948f6e6 032ce48cc40542b0a334825c56116536 H 6cf3f751b3c84dc8844be9f1c948f6e6--032ce48cc40542b0a334825c56116536 032ce48cc40542b0a334825c56116536--b93b2cf90d564841a5517982ce02c189 <p>Other functionalities are directly built in the block system. For example, the inverse operation can be created with the <code>dagger()</code> method.</p> <pre><code>qft_inv = qft((0, 1, 2)).dagger()\n</code></pre> %3 fec61ffd242f4558acfdcbe27550ec14 0 6afba69f7f204bccaad0cf883edcdacc fec61ffd242f4558acfdcbe27550ec14--6afba69f7f204bccaad0cf883edcdacc 733faad6b31440b6b94e247111de1a6e 1 14311d1b3d5045298857b866c9a0cecd 6afba69f7f204bccaad0cf883edcdacc--14311d1b3d5045298857b866c9a0cecd 34bddec210f54062bcbca3bf1c76a4bf 14311d1b3d5045298857b866c9a0cecd--34bddec210f54062bcbca3bf1c76a4bf d513606f401d46d3a5c274db235f82cf PHASE(-0.785) 34bddec210f54062bcbca3bf1c76a4bf--d513606f401d46d3a5c274db235f82cf 03571fd6e740400a9b3786e9ac62f20f PHASE(-1.571) d513606f401d46d3a5c274db235f82cf--03571fd6e740400a9b3786e9ac62f20f 307dd72e06904efbbdcdddba130cdb7b d513606f401d46d3a5c274db235f82cf--307dd72e06904efbbdcdddba130cdb7b 276c6edeaa8942499f9030a15e518480 H 03571fd6e740400a9b3786e9ac62f20f--276c6edeaa8942499f9030a15e518480 eb213cfc6d8640b09d5ac2bf308fe282 03571fd6e740400a9b3786e9ac62f20f--eb213cfc6d8640b09d5ac2bf308fe282 6c1c4523677c47828713cb3530ef2eef 276c6edeaa8942499f9030a15e518480--6c1c4523677c47828713cb3530ef2eef 00dca956476045ebad925cb4c038491d ea36e589a6e946b488d6f58b035d49f0 733faad6b31440b6b94e247111de1a6e--ea36e589a6e946b488d6f58b035d49f0 96c6309d7ba445d79ac5c7a50fa2a429 2 1e41e41d246640f68830d92373f48298 PHASE(-1.571) ea36e589a6e946b488d6f58b035d49f0--1e41e41d246640f68830d92373f48298 8b439c8b2a0849c89ddd0bfb53d663fc H 1e41e41d246640f68830d92373f48298--8b439c8b2a0849c89ddd0bfb53d663fc 937a714a8ee84ad2aaa3cb7bd41af371 1e41e41d246640f68830d92373f48298--937a714a8ee84ad2aaa3cb7bd41af371 99761a81e468484b84e9d8296c19a675 8b439c8b2a0849c89ddd0bfb53d663fc--99761a81e468484b84e9d8296c19a675 99761a81e468484b84e9d8296c19a675--eb213cfc6d8640b09d5ac2bf308fe282 70cfdf69cd0840829086af136f87818f eb213cfc6d8640b09d5ac2bf308fe282--70cfdf69cd0840829086af136f87818f 70cfdf69cd0840829086af136f87818f--00dca956476045ebad925cb4c038491d 9ce00a27a458402bb46e7919bfbd99a1 43f813553b1d46e6bfe96aa646e31219 H 96c6309d7ba445d79ac5c7a50fa2a429--43f813553b1d46e6bfe96aa646e31219 43f813553b1d46e6bfe96aa646e31219--937a714a8ee84ad2aaa3cb7bd41af371 c680561b80664e9580ef47fed50a1484 937a714a8ee84ad2aaa3cb7bd41af371--c680561b80664e9580ef47fed50a1484 c680561b80664e9580ef47fed50a1484--307dd72e06904efbbdcdddba130cdb7b a44d75616002448b987e3aada1c238a8 307dd72e06904efbbdcdddba130cdb7b--a44d75616002448b987e3aada1c238a8 96f6bc1c2a374ff1bee53bf4f879be8b a44d75616002448b987e3aada1c238a8--96f6bc1c2a374ff1bee53bf4f879be8b 96f6bc1c2a374ff1bee53bf4f879be8b--9ce00a27a458402bb46e7919bfbd99a1"},{"location":"content/block_system/#digital-analog-composition","title":"Digital-analog composition","text":"<p>In Qadence, analog operations are first-class citizens. An analog operation is one whose unitary is best described by the evolution of some hermitian generator, or Hamiltonian, acting on an arbitrary number of qubits. Qadence provides the <code>HamEvo</code> class to initialize analog operations. For a time-independent generator \\(\\mathcal{H}\\) and some time variable \\(t\\), <code>HamEvo(H, t)</code> represents the evolution operator \\(\\exp(-i\\mathcal{H}t)\\).</p> <p>Analog operations constitute a generalization of digital operations, and all digital operations can also be represented as the evolution of some hermitian generator. For example, the <code>RX</code> gate is the evolution of <code>X</code>.</p> <pre><code>from qadence import X, RX, HamEvo, PI\nfrom torch import allclose\n\nangle = PI/2\n\nblock_digital = RX(0, angle)\n\nblock_analog = HamEvo(0.5*X(0), angle)\n\nprint(allclose(block_digital.tensor(), block_analog.tensor()))\n</code></pre> <pre><code>True\n</code></pre> <p>As seen in the previous section, arbitrary Hamiltonians can be constructed using Pauli operators. Their evolution can be combined with other arbitrary digital operations and incorporated into any quantum program.</p> <pre><code>from qadence import X, Y, RX, HamEvo\nfrom qadence import add, kron, PI\n\ndef xy_int(i: int, j: int):\n    return (1/2) * (X(i)@X(j) + Y(i)@Y(j))\n\nn_qubits = 3\n\nxy_ham = add(xy_int(i, i+1) for i in range(n_qubits-1))\n\nanalog_evo = HamEvo(xy_ham, 1.0)\n\ndigital_block = kron(RX(i, i*PI/2) for i in range(n_qubits))\n\nprogram = digital_block * analog_evo * digital_block\n</code></pre> %3 cluster_c9128d941708434d82425c2bd662baa4 ba1243c7a5134258a70b9091a1947e35 0 1c8283fd59d64501b4b2f5d2ea2d0b14 RX(0.0) ba1243c7a5134258a70b9091a1947e35--1c8283fd59d64501b4b2f5d2ea2d0b14 91db0225c71b415483d8096865a9d8a5 1 57f944ef46914ee0ab4fcfa1bd7d5fa1 HamEvo 1c8283fd59d64501b4b2f5d2ea2d0b14--57f944ef46914ee0ab4fcfa1bd7d5fa1 e4b2097bdfda4cacad92c3f7b8f3bbc3 RX(0.0) 57f944ef46914ee0ab4fcfa1bd7d5fa1--e4b2097bdfda4cacad92c3f7b8f3bbc3 51f9bdcc1e3a472ab473795db4fc4446 e4b2097bdfda4cacad92c3f7b8f3bbc3--51f9bdcc1e3a472ab473795db4fc4446 57a7dc73b666436a93a9f8094184f009 385fa77eeab24facab5899f2695946fd RX(1.571) 91db0225c71b415483d8096865a9d8a5--385fa77eeab24facab5899f2695946fd 6ab3a046a14b461cb6d900904a448c78 2 58a01ccff58f422782941467e12afe7b t = 1.000 385fa77eeab24facab5899f2695946fd--58a01ccff58f422782941467e12afe7b 85174aca142446e9aeab2c9a4d6b86af RX(1.571) 58a01ccff58f422782941467e12afe7b--85174aca142446e9aeab2c9a4d6b86af 85174aca142446e9aeab2c9a4d6b86af--57a7dc73b666436a93a9f8094184f009 c74f415e653e4e81b6db4e2ab5da085d c0290b6cf7644709a35deaf9d13953a8 RX(3.142) 6ab3a046a14b461cb6d900904a448c78--c0290b6cf7644709a35deaf9d13953a8 8a66a53d33814550b1d322da9ab9026d c0290b6cf7644709a35deaf9d13953a8--8a66a53d33814550b1d322da9ab9026d 364806dfd2604b2582db9a1ae33fb8fe RX(3.142) 8a66a53d33814550b1d322da9ab9026d--364806dfd2604b2582db9a1ae33fb8fe 364806dfd2604b2582db9a1ae33fb8fe--c74f415e653e4e81b6db4e2ab5da085d"},{"location":"content/block_system/#block-execution","title":"Block execution","text":"<p>To quickly run block operations and access wavefunctions, samples or expectation values of observables, one can use the convenience functions <code>run</code>, <code>sample</code> and <code>expectation</code>.</p> <pre><code>from qadence import kron, add, H, Z, run, sample, expectation\n\nn_qubits = 2\n\n# Prepares a uniform state\nh_block = kron(H(i) for i in range(n_qubits))\n\nwf = run(h_block)\n\nxs = sample(h_block, n_shots=1000)\n\nobs = add(Z(i) for i in range(n_qubits))\nex = expectation(h_block, obs)\n</code></pre> <pre><code>wf = tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\nxs = [OrderedCounter({'01': 265, '00': 254, '10': 251, '11': 230})]\nex = tensor([[0.]])\n</code></pre>"},{"location":"content/block_system/#execution-via-quantumcircuit-and-quantummodel","title":"Execution via <code>QuantumCircuit</code> and <code>QuantumModel</code>","text":"<p>More fine-grained control and better performance is provided via the high-level <code>QuantumModel</code> abstraction. Quantum programs in Qadence are constructed in two steps:</p> <ol> <li>Build a <code>QuantumCircuit</code> which ties together a composite block and a register.</li> <li>Define a <code>QuantumModel</code> which differentiates, compiles and executes the circuit.</li> </ol> <p>Execution of more complex Qadence programs will be explored in the next tutorials.</p>"},{"location":"content/block_system/#adding-noise-to-gates","title":"Adding noise to gates","text":"<p>It is possible to add noise to gates. Please refer to the noise tutorial here.</p>"},{"location":"content/hamiltonians/","title":"Constructing arbitrary Hamiltonians","text":"<p>At the heart of digital-analog quantum computing is the description and execution of analog blocks, which represent a set of interacting qubits under some interaction Hamiltonian. For this purpose, Qadence relies on the <code>hamiltonian_factory</code> function to create arbitrary Hamiltonian blocks to be used as generators of <code>HamEvo</code> or as observables to be measured.</p>"},{"location":"content/hamiltonians/#arbitrary-all-to-all-hamiltonians","title":"Arbitrary all-to-all Hamiltonians","text":"<p>Arbitrary all-to-all interaction Hamiltonians can be easily created by passing the number of qubits in the first argument. The type of <code>interaction</code> can be chosen from the available ones in the <code>Interaction</code> enum type.</p> <pre><code>from qadence import hamiltonian_factory\nfrom qadence import N, X, Y, Z\nfrom qadence import Interaction\n\nn_qubits = 3\n\nhamilt = hamiltonian_factory(n_qubits, interaction=Interaction.ZZ)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 Z(1)\n        \u2514\u2500\u2500 Z(2)\n</code></pre> <p>Alternatively, a custom interaction function can also be defined. The input should be two integer indices \\(i\\) and \\(j\\) and it should return a composition of pauli terms representing the interaction between qubits \\(i\\) and \\(j\\):</p> <pre><code>def custom_int(i: int, j: int):\n    return X(i) @ X(j) + Y(i) @ Y(j)\n\nn_qubits = 2\n\nhamilt = hamiltonian_factory(n_qubits, interaction=custom_int)\n</code></pre> <pre><code>AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 AddBlock(0,1)\n        \u251c\u2500\u2500 KronBlock(0,1)\n        \u2502   \u251c\u2500\u2500 X(0)\n        \u2502   \u2514\u2500\u2500 X(1)\n        \u2514\u2500\u2500 KronBlock(0,1)\n            \u251c\u2500\u2500 Y(0)\n            \u2514\u2500\u2500 Y(1)\n</code></pre> <p>Single-qubit terms can also be added by passing the respective operator directly to the <code>detuning</code> argument. For example, the total magnetization is commonly used as an observable to be measured:</p> <pre><code>total_mag = hamiltonian_factory(n_qubits, detuning = Z)\n</code></pre> <pre><code>AddBlock(0,1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 Z(0)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 Z(1)\n</code></pre> <p>For further customization, arbitrary coefficients can be passed as arrays to the <code>interaction_strength</code> and <code>detuning_strength</code> arguments for the two-qubits and single-qubit terms respectively.</p> <pre><code>n_qubits = 3\n\nhamilt = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.ZZ,\n    detuning=Z,\n    interaction_strength=[0.5, 0.2, 0.1],\n    detuning_strength=[0.1, 0.5, -0.3]\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.100] \n\u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: -0.30] \n\u2502   \u2514\u2500\u2500 Z(2)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 0.200] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 0.100] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 Z(1)\n        \u2514\u2500\u2500 Z(2)\n</code></pre> <p>Ordering interaction strengths matters</p> <p>When passing interaction strengths as an array, the ordering must be identical to the one obtained from the <code>edges</code> property of a Qadence <code>Register</code>:</p> <pre><code>from qadence import Register\n\nprint(Register(n_qubits).edges)\n</code></pre> <pre><code>[(0, 1), (0, 2), (1, 2)]\n</code></pre> <p>For one more example, let's create a transverse-field Ising model,</p> <pre><code>n_qubits = 4\nn_edges = int(0.5 * n_qubits * (n_qubits - 1))\n\nz_terms = [1.0] * n_qubits\nzz_terms = [2.0] * n_edges\n\nzz_ham = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.ZZ,\n    detuning=Z,\n    interaction_strength=zz_terms,\n    detuning_strength=z_terms\n)\n\nx_terms = [-1.0] * n_qubits\nx_ham = hamiltonian_factory(n_qubits, detuning = X, detuning_strength = x_terms)\n\ntransverse_ising = zz_ham + x_ham\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 AddBlock(0,1,2,3)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(0)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u2514\u2500\u2500 [mul: 2.000] \n\u2502       \u2514\u2500\u2500 KronBlock(2,3)\n\u2502           \u251c\u2500\u2500 Z(2)\n\u2502           \u2514\u2500\u2500 Z(3)\n\u2514\u2500\u2500 AddBlock(0,1,2,3)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(0)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(1)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(2)\n    \u2514\u2500\u2500 [mul: -1.00] \n        \u2514\u2500\u2500 X(3)\n</code></pre> <p>Random interaction coefficients</p> <p>Random interaction coefficients can be chosen between -1 and 1 by simply passing <code>random_strength = True</code> instead of <code>detuning_strength</code> and <code>interaction_strength</code>.</p>"},{"location":"content/hamiltonians/#arbitrary-hamiltonian-topologies","title":"Arbitrary Hamiltonian topologies","text":"<p>Arbitrary interaction topologies can be created using the Qadence <code>Register</code>. Simply pass the register with the desired topology as the first argument to the <code>hamiltonian_factory</code>:</p> <pre><code>from qadence import Register\n\nreg = Register.square(qubits_side=2)\n\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(2,3)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(3)\n</code></pre>"},{"location":"content/hamiltonians/#adding-variational-parameters","title":"Adding variational parameters","text":"<p>Finally, fully parameterized Hamiltonians can be created by passing a string to the strength arguments, and used to prefix the name of the variational parameters.</p> <pre><code>n_qubits = 3\n\nnn_ham = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.NN,\n    detuning=N,\n    interaction_strength=\"c\",\n    detuning_strength=\"d\"\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: d_0] \n\u2502   \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: d_1] \n\u2502   \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: d_2] \n\u2502   \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: c_01] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: c_02] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: c_12] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 N(1)\n        \u2514\u2500\u2500 N(2)\n</code></pre> <p>Alternatively, fully customizable sympy functions can be passed in an array using the Qadence parameters. Furthermore, the <code>use_all_node_pairs = True</code> option can be passed so that interactions are created for every single node pair in the register, irrespectively of the topology of the edges. This is useful for creating Hamiltonians that depend on qubit distance.</p> <pre><code>from qadence import VariationalParameter, Register\n\n# Square register of 4 qubits with a dimensionless distance of 8.0\nreg = Register.square(2, spacing = 8.0)\n\n# Get the distances between all pairs of qubits\ndistance_dict = reg.distances\n\n# Create interaction strength with variational parameter and 1/r term\nstrength_list = []\nfor node_pair in reg.all_node_pairs:\n    param = VariationalParameter(\"x\" + f\"_{node_pair[0]}{node_pair[1]}\")\n    dist_factor = reg.distances[node_pair]\n    strength_list.append(param / dist_factor)\n\nnn_ham = hamiltonian_factory(\n    reg,\n    interaction=Interaction.NN,\n    interaction_strength=strength_list,\n    use_all_node_pairs=True,\n)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 0.125*x_01] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 0.088*x_02] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: 0.125*x_03] \n\u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 0.125*x_12] \n\u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: 0.088*x_13] \n\u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(3)\n\u2514\u2500\u2500 [mul: 0.125*x_23] \n    \u2514\u2500\u2500 KronBlock(2,3)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(3)\n</code></pre>"},{"location":"content/noisy_simulation/","title":"Noisy Simulation","text":"<p>Running programs on NISQ devices often leads to imperfect results due to the presence of noise. In order to perform realistic simulations, a number of noise models (for digital operations, analog operations and simulated readout errors) are supported in <code>Qadence</code>.</p> <p>Noisy simulations shift the quantum paradigm from a close-system (noiseless case) to an open-system (noisy case) where a quantum system is represented by a probabilistic combination \\(p_i\\) of possible pure states \\(|\\psi_i \\rangle\\). Thus, the system is described by a density matrix \\(\\rho\\) (and computation modify the density matrix) defined as follows:</p> \\[ \\rho = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i| \\] <p>The noise protocols applicable in <code>Qadence</code> are classified into three types: digital (for digital operations), analog (for analog operations), and readout error (for measurements).</p>"},{"location":"content/noisy_simulation/#specifying-a-noise-protocol","title":"Specifying a noise protocol","text":"<p>Each noise protocol can be specified using <code>NoiseProtocol</code> and requires specific <code>options</code> parameter passed as a dictionary. We show below for each type of noise how this can be done.</p>"},{"location":"content/noisy_simulation/#digital-noise-protocol","title":"Digital noise protocol","text":"<p>Digital noise refer to unintended changes occurring with reference to the application of a noiseless digital gate operation. The following are the protocols of supported digital noise, along with brief descriptions. For digital noise, the <code>error_probability</code> is necessary for the noise initialization at the <code>options</code> parameter.</p> <p>When dealing with programs involving digital operations, <code>Qadence</code> has interface to noise models implemented in <code>PyQTorch</code>. Detailed equations for these protocols are available from PyQTorch.</p> <ul> <li>BITFLIP: flips between |0\u27e9 and |1\u27e9 with <code>error_probability</code></li> <li>PHASEFLIP: flips the phase of a qubit by applying a Z gate with <code>error_probability</code></li> <li>DEPOLARIZING: randomizes the state of a qubit by applying I, X, Y, or Z gates with equal <code>error_probability</code></li> <li>PAULI_CHANNEL: applies the Pauli operators (X, Y, Z) to a qubit with specified <code>error_probabilities</code></li> <li>AMPLITUDE_DAMPING: models the asymmetric process through which the qubit state |1\u27e9 irreversibly decays into the state |0\u27e9 with <code>error_probability</code></li> <li>PHASE_DAMPING: similar to AMPLITUDE_DAMPING but concerning the phase</li> <li>GENERALIZED_AMPLITUDE_DAMPING: extends amplitude damping; the first float is <code>error_probability</code> of amplitude damping, and second float is the <code>damping_rate</code></li> </ul> <p>For digital noise simulation, you need to state <code>NoiseProtocol</code> with <code>DIGITAL</code> and then specify the noise protocol. Also, you put the value of <code>error_probability</code> as in next example.</p> <pre><code>from qadence import NoiseProtocol\n\nprotocol = NoiseProtocol.DIGITAL.DEPOLARIZING\noptions = {\"error_probability\": 0.1}\n</code></pre>"},{"location":"content/noisy_simulation/#analog-noise-protocol","title":"Analog noise protocol","text":"<p>Analog noise can be set for analog operations. At the moment, we only enabled simulations via the <code>Pulser</code> backend. For <code>Pulser</code> noise implementation, you can refer to Pulser. <code>Qadence</code> is in the process of fully supporting all the noise protocols in the backends (especially <code>Pulser</code>). However, we are in transition, and currently, only DEPOLARIZING and DEPHAZING are available as protocols. The <code>options</code> dictionary requires to specify the field <code>noise_probs</code>.</p> <ul> <li>Depolarizing: evolves to the maximally mixed state with <code>noise_probs</code></li> <li>Dephasing: induces the loss of phase coherence without affecting the population of computational basis states</li> </ul> <pre><code>from qadence import NoiseProtocol\n\nprotocol = NoiseProtocol.ANALOG.DEPOLARIZING\noptions = {\"noise_probs\": 0.1}\n</code></pre>"},{"location":"content/noisy_simulation/#readout-error-protocol","title":"Readout error protocol","text":"<p>Readout errors are linked to the incorrect measurement outcomes from the system. In this protocol, we have <code>error_probability</code>, <code>confusion_matrix</code>, and <code>seed</code> option parameters. For the <code>error_probability</code> parameter, if float, the same probability error is applied to every bit. A different probability can be set for each qubit if a 1D tensor has an element number equal to the number of qubits. For <code>confusion_matrix</code> parameter, the square matrix for each possible bitstring of length <code>n</code> qubits. We have a <code>seed</code> parameter for reproducible purposes.</p> <p>Currently, two readout protocols are available via PyQTorch.</p> <ul> <li>Independent: all bits are corrupted independently with each other.</li> <li>Correlated: apply a <code>confusion_matrix</code> of corruption between each possible bitstrings</li> </ul> <pre><code>from qadence import NoiseProtocol\n\nprotocol=NoiseProtocol.READOUT.INDEPENDENT\noptions = {\"error_probability\": 0.01, \"seed\": 0}\n</code></pre>"},{"location":"content/noisy_simulation/#preparing-noise-protocols-for-usage","title":"Preparing noise protocols for usage","text":"<p>In order to apply the noise to <code>Qadence</code> objects, we need a wrapper called the <code>NoiseHandler</code> type. It is a container of several noise instances that require a specific <code>protocol</code> and a dictionary of <code>options</code> (or lists). The <code>protocol</code> field is to be instantiated from <code>NoiseProtocol</code> and <code>options</code> includes error-related information such as <code>error_probability</code>, <code>noise_probs</code>, and <code>seed</code>.</p> <pre><code>from qadence import NoiseHandler, NoiseProtocol\n\ndigital_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.AMPLITUDE_DAMPING, options={\"error_probability\": 0.1})\nanalog_noise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options={\"noise_probs\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\n</code></pre> <p><code>NoiseHandler</code> can be used in a more compact way to represent noise in batches.</p> <ul> <li>A <code>NoiseHandler</code> can be initiated with a list of protocols and a list of options (careful with the order)</li> <li>A <code>NoiseHandler</code> can be appended to other <code>NoiseHandler</code> instances</li> </ul> <pre><code>from qadence import NoiseHandler, NoiseProtocol\n\n# initiating with list of protocols and options\nprotocols = [NoiseProtocol.DIGITAL.DEPOLARIZING, NoiseProtocol.READOUT]\noptions = [{\"error_probability\": 0.1}, {\"error_probability\": 0.1, \"seed\": 0}]\n\nnoise_handler_list = NoiseHandler(protocols, options)\n\n# NoiseHandler appending\ndepo_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.DEPOLARIZING, options={\"error_probability\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\nnoise_combination = NoiseHandler(protocol=NoiseProtocol.DIGITAL.BITFLIP, options={\"error_probability\": 0.1})\n\n# prints noise_combination\nnoise_combination.append([depo_noise, readout_noise])\n</code></pre> <pre><code>Noise(BitFlip, {'error_probability': 0.1})\nNoise(Depolarizing, {'error_probability': 0.1})\nNoise(Independent Readout, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>NoiseHandler scope</p> <p>Note it is not possible to define <code>NoiseHandler</code> instances with both digital and analog noises, both readout and analog noises, several analog noises, several readout noises, or a readout noise that is not the last defined protocol within <code>NoiseHandler</code>.</p>"},{"location":"content/noisy_simulation/#executing-noisy-simulation","title":"Executing Noisy Simulation","text":"<p>Noisy simulation can be set by applying a <code>NoiseHandler</code> to the desired <code>gate</code>, <code>block</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <pre><code>from qadence import NoiseProtocol, RX, run, NoiseHandler\nimport torch\n\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.2})\ncircuit = RX(0, torch.pi, noise = noise)\n\n# prints density matrix\nrun(circuit)\n</code></pre> <pre><code>Noisy density matrix = DensityMatrix([[[0.2000+0.0000e+00j, 0.0000+3.6739e-17j],\n                [0.0000-3.6739e-17j, 0.8000+0.0000e+00j]]])\n</code></pre> <p>We can also apply noise with the <code>set_noise</code> function that apply a given noise configuration to the whole object.</p> <pre><code>from qadence import DiffMode, NoiseHandler, QuantumModel\nfrom qadence.blocks import chain, kron\nfrom qadence.circuit import QuantumCircuit\nfrom qadence.operations import AnalogRX, AnalogRZ, Z\nfrom qadence.types import PI, BackendName, NoiseProtocol\nfrom qadence import set_noise\n\nanalog_block = chain(AnalogRX(PI / 2.0), AnalogRZ(PI))\nobservable = Z(0) + Z(1)\ncircuit = QuantumCircuit(2, analog_block)\n\nnoise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options={\"noise_probs\": 0.2})\nmodel = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR,\n)\n\nnoiseless_expectation = model.expectation()\n\nnoisy_model = set_noise(model, noise)\nnoisy_expectation = noisy_model.expectation()\n</code></pre> <pre><code>Noiseless expectation = tensor([[0.3961]])\nNoisy expectation = tensor([[0.3254]])\n</code></pre> <p>Let's say we want to apply noise only to specific type of gates, a <code>target_class</code> argument can be passed with the corresponding block in <code>set_noise</code>.</p> <pre><code>from qadence import X, chain, set_noise, NoiseHandler, NoiseProtocol\n\nblock = chain(RX(0, \"theta\"), X(0))\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.AMPLITUDE_DAMPING, {\"error_probability\": 0.1})\n\n# prints noise configuration for each gate\nset_noise(block, noise, target_class=X)\n</code></pre> <pre><code>Noise type for gate RX(0) [params: ['theta']] is None.\nNoise type for gate X(0) is Noise(AmplitudeDamping, {'error_probability': 0.1}).\n</code></pre> <p>One can set different noise models for each individual gates within the same circuit as follows:</p> <pre><code>from qadence import QuantumCircuit, X, sample, kron, NoiseHandler, NoiseProtocol\nimport matplotlib.pyplot as plt\n\nn_qubits = 2\nnoise_bitflip = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.1})\nnoise_amplitude_damping = NoiseHandler(NoiseProtocol.DIGITAL.AMPLITUDE_DAMPING, {\"error_probability\": 0.3})\nblock = kron(X(0, noise=noise_bitflip), X(1, noise=noise_amplitude_damping))\ncircuit = QuantumCircuit(n_qubits, block)\n\nn_shots=1000\nxs = sample(circuit, n_shots=n_shots)\n\nitems = list(xs[0].keys())\nvalues = [v/n_shots for v in xs[0].values()]\n\nplt.figure()\nplt.bar(range(len(values)), values, color='blue', alpha=0.7)\nplt.xticks(range(len(items)), items)\nplt.title(\"Probability of state occurrence\")\nplt.xlabel('Possible States')\nplt.ylabel('Probability')\n</code></pre> 2025-04-04T13:33:20.840139 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/ <p>The result of this figure would be a 100% <code>11</code> state without noise. However, with <code>X(0)</code> bitflip noise, the state <code>01</code> has some possibility, and with <code>X(1)</code> amplitude damping noise, more gap appears between state pairs of (<code>00</code>, <code>01</code>) and (<code>10</code>, <code>11</code>), as shown in the figure.</p> <p>The readout error is computed with the density matrix of the state through <code>sample</code> execution.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use.\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1})\n\n# Run noiseless and noisy simulations.\nnoiseless_samples = model.sample(n_shots=100)\nnoisy_samples = model.sample(noise=noise, n_shots=100)\n</code></pre> <pre><code>noiseless = [OrderedCounter({'00': 56, '10': 44})]\nnoisy = [OrderedCounter({'00': 49, '10': 49, '01': 1, '11': 1})]\n</code></pre>"},{"location":"content/overlap/","title":"Wavefunction overlaps","text":"<p>Qadence offers convenience functions for computing the overlap between the wavefunctions generated by two quantum circuits \\(U\\) and \\(W\\) as:</p> \\[ S = |\\langle \\psi_U | \\psi_W \\rangle|^2 \\quad \\textrm{where} \\quad \\psi_U = U|\\psi_0\\rangle \\] <p>Here is an example on how to compute the overlap between two very simple parametric circuits consisting of a single <code>RX</code> rotation on different qubits. The overlap is expected to be non-zero only when the rotation angle is different from \\(\\pi \\; \\textrm{mod}\\; 2\\pi\\) for both rotations:</p> <pre><code>import numpy as np\nfrom torch import tensor\nfrom qadence import Overlap, OverlapMethod, QuantumCircuit, H, RX, X, FeatureParameter, hea, PI\n\n\n# Create two quantum circuits\n# with a single qubit rotation on two random qubits\nn_qubits = 4\nqubits = np.random.choice(n_qubits, n_qubits, replace=False)\n\nphi = FeatureParameter(\"phi\")\ncircuit_bra = QuantumCircuit(n_qubits, RX(qubits[0], phi))\n\npsi = FeatureParameter(\"psi\")\ncircuit_ket = QuantumCircuit(n_qubits, RX(qubits[1], psi))\n\n# Values for the feature parameters\nvalues_bra = {\"phi\": tensor([PI / 2, PI])}\nvalues_ket = {\"psi\": tensor([PI / 2, PI])}\n\n# Calculate overlap by assigning values to the given bra and ket circuits\novrlp = Overlap(circuit_bra, circuit_ket)\novrlp = ovrlp(bra_param_values=values_bra, ket_param_values=values_ket)\n</code></pre> <pre><code>Overlap with exact method:\n tensor([[2.5000e-01, 1.8747e-33],\n        [1.8747e-33, 1.4058e-65]])\n</code></pre> <p>The <code>Overlap</code> class above inherits from <code>QuantumModel</code> and is executed through its inherited forward method for the given input parameter values. By default, the overlap is computed exactly by performing the dot product of the wavefunction propagated from bra and ket circuits.</p> <p>However, it is possible to choose a different method from the <code>OverlapMethod</code> enumeration to be passed via the <code>overlap_method</code> argument in the <code>Overlap</code> initializer. Currently, one can choose from:</p> <ul> <li><code>EXACT</code>: exact computation using the wavefunction matrix representation. Does not work with real devices since it assumes access to the complete qubit system wavefunction.</li> <li><code>COMPUTE_UNCOMPUTE</code>: exact or sampling-based computation using bra \\(U\\) and ket \\(W^{\\dagger}\\) unitaries.</li> <li><code>SWAP_TEST</code>: exact or sampling-based computation using the SWAP test method.</li> <li><code>HADAMARD_TEST</code>: exact or sampling-based computation using the Hadamard test method.</li> <li><code>JENSEN_SHANNON</code>: compute the overlap using the Jensen-Shannon divergence of the two probability distributions obtained by sampling the propagated circuits. This will yield a different result than the other methods.</li> </ul> <p>All methods (except for the <code>EXACT</code> method) take an optional <code>n_shots</code> argument which can be used to perform shot-based calculations.</p> <p>Warning</p> <p>If you select a finite number of shots, the overlap is not differentiable. Therefore, it cannot be used as output of a quantum model if gradients are required.</p> <pre><code># Calculate overlap with SWAP test\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket)\n\n# Calculate overlap with SWAP test\n# using a finite number of shots\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket, n_shots=10_000)\n</code></pre> <pre><code>Overlap with SWAP test:\n tensor([[ 2.5000e-01, -3.3307e-16],\n        [-3.3307e-16, -4.4409e-16]])\nOverlap with SWAP test with finite number of shots:\n tensor([[ 0.2358, -0.0102],\n        [ 0.0018, -0.0062]])\n</code></pre>"},{"location":"content/parameters/","title":"Parametric programs","text":"<p>Qadence provides a flexible parameter system built on top of Sympy. Parameters can be of different types:</p> <ul> <li>Fixed parameter: a constant with a fixed, non-trainable value (e.g. \\(\\dfrac{\\pi}{2}\\)).</li> <li>Variational parameter: a trainable parameter which will be automatically picked up by the optimizer.</li> <li>Feature parameter: a non-trainable parameter which can be used to pass input values.</li> </ul>"},{"location":"content/parameters/#fixed-parameters","title":"Fixed parameters","text":"<p>Passing fixed parameters to blocks can be done by simply passing a Python numeric type or a <code>torch.Tensor</code>.</p> <pre><code>import torch\nfrom qadence import RX, run, PI\n\nwf = run(RX(0, torch.tensor(PI)))\n\nwf = run(RX(0, PI))\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\nwf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\n</code></pre>"},{"location":"content/parameters/#variational-parameters","title":"Variational parameters","text":"<p>To parametrize a block a <code>VariationalParameter</code> instance is required. In most cases Qadence also accepts a Python string, which will be used to automatically initialize a <code>VariationalParameter</code>:</p> <pre><code>from qadence import RX, run, VariationalParameter\n\nblock = RX(0, VariationalParameter(\"theta\"))\nblock = RX(0, \"theta\")  # Equivalent\n\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[0.9967+0.0000j, 0.0000-0.0807j]])\n</code></pre> <p>By calling <code>run</code>, a random value for <code>\"theta\"</code> is initialized at execution. In a <code>QuantumModel</code>, variational parameters are stored in the underlying model parameter dictionary.</p>"},{"location":"content/parameters/#feature-parameters","title":"Feature parameters","text":"<p>A <code>FeatureParameter</code> type can also be used. It requires an input value or a batch of values. In most cases, Qadence accepts a <code>values</code> dictionary to set the input of feature parameters.</p> <pre><code>from torch import tensor\nfrom qadence import RX, PI, run, FeatureParameter\n\nblock = RX(0, FeatureParameter(\"phi\"))\n\nwf = run(block, values = {\"phi\": tensor([PI, PI/2])})\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.0000j, 0.0000e+00-1.0000j],\n        [7.0711e-01+0.0000j, 0.0000e+00-0.7071j]])\n</code></pre> <p>Since a batch of input values was passed, the <code>run</code> function returns a batch of output states. Note that <code>FeatureParameter(\"x\")</code> and <code>VariationalParameter(\"x\")</code> are simply aliases for <code>Parameter(\"x\", trainable = False)</code> and <code>Parameter(\"x\", trainable = True)</code>.</p>"},{"location":"content/parameters/#multiparameter-expressions-and-analog-integration","title":"Multiparameter expressions and analog integration","text":"<p>The integration with Sympy becomes useful when one wishes to write arbitrary parameter compositions. Parameters can also be used as scaling coefficients in the block system, which is essential when defining arbitrary analog operations.</p> <pre><code>from torch import tensor\nfrom qadence import RX, Z, HamEvo, PI\nfrom qadence import VariationalParameter, FeatureParameter, run\nfrom sympy import sin\n\ntheta, phi = VariationalParameter(\"theta\"), FeatureParameter(\"phi\")\n\n# Arbitrary parameter composition\nexpr = PI * sin(theta + phi)\n\n# Use as unitary gate arguments\ngate = RX(0, expr)\n\n# Or as scaling coefficients for Hermitian operators\nh_op = expr * (Z(0) @ Z(1))\n\nwf = run(gate * HamEvo(h_op, 1.0), values = {\"phi\": tensor(PI)})\n</code></pre> <pre><code>wf = tensor([[0.9669+0.2277j, 0.0000+0.0000j, 0.0264+0.1123j, 0.0000+0.0000j]])\n</code></pre>"},{"location":"content/parameters/#parameter-redundancy","title":"Parameter redundancy","text":"<p>Parameters are uniquely defined by their name and redundancy is allowed in composite blocks to assign the same value to different blocks. This is useful, for example, when defining layers of rotation gates typically used as feature maps.</p> <pre><code>from torch import tensor\nfrom qadence import RY, PI, run, kron, FeatureParameter\n\nn_qubits = 3\n\nparam = FeatureParameter(\"phi\")\n\nblock = kron(RY(i, (i+1) * param) for i in range(n_qubits))\n\nwf = run(block, values = {\"phi\": tensor(PI)})\n</code></pre> <pre><code>wf = tensor([[ 1.1248e-32+0.j,  6.1232e-17+0.j, -1.3775e-48+0.j, -7.4988e-33+0.j,\n          1.8370e-16+0.j,  1.0000e+00+0.j, -2.2496e-32+0.j, -1.2246e-16+0.j]])\n</code></pre>"},{"location":"content/parameters/#parametrized-circuits","title":"Parametrized circuits","text":"<p>Let's look at a final example of an arbitrary composition of digital and analog parameterized blocks:</p> <pre><code>import sympy\nfrom qadence import RX, RY, RZ, CNOT, CPHASE, Z, HamEvo\nfrom qadence import run, chain, add, kron, FeatureParameter, VariationalParameter, PI\n\nn_qubits = 3\n\nphi = FeatureParameter(\"\u03a6\")\ntheta = VariationalParameter(\"\u03b8\")\n\nrotation_block = kron(\n    RX(0, phi/theta),\n    RY(1, theta*2),\n    RZ(2, sympy.cos(phi))\n)\ndigital_entangler = CNOT(0, 1) * CPHASE(1, 2, PI)\n\nhamiltonian = add(theta * (Z(i) @ Z(i+1)) for i in range(n_qubits-1))\n\nanalog_evo = HamEvo(hamiltonian, phi)\n\nprogram = chain(rotation_block, digital_entangler, analog_evo)\n</code></pre> %3 cluster_edda39057e6149f29a43dd635ae2509d a7e934c97c654382b09682070bca859b 0 22a111ee56554be5b2538bfe47e1c159 RX(\u03a6/\u03b8) a7e934c97c654382b09682070bca859b--22a111ee56554be5b2538bfe47e1c159 6a1d2d551fe54b928f2af6b41f16a097 1 f21ccf169052489eaadadd8a22564f6f 22a111ee56554be5b2538bfe47e1c159--f21ccf169052489eaadadd8a22564f6f 203425bb1f024f608b7301a597eddb5a f21ccf169052489eaadadd8a22564f6f--203425bb1f024f608b7301a597eddb5a fe682e74b2e244b2a7bcea82a51af935 HamEvo 203425bb1f024f608b7301a597eddb5a--fe682e74b2e244b2a7bcea82a51af935 4261f1592d8a4e7c9dec64e4a251cff7 fe682e74b2e244b2a7bcea82a51af935--4261f1592d8a4e7c9dec64e4a251cff7 df75aba0125648da9a282a7469bfd2da cff8963b78b84c149ca54116c075ad8c RY(2*\u03b8) 6a1d2d551fe54b928f2af6b41f16a097--cff8963b78b84c149ca54116c075ad8c f590dbf1c1964cee87262346d1f51a08 2 d1b9f9c5d4574fe8987a6438e9cb84c3 X cff8963b78b84c149ca54116c075ad8c--d1b9f9c5d4574fe8987a6438e9cb84c3 d1b9f9c5d4574fe8987a6438e9cb84c3--f21ccf169052489eaadadd8a22564f6f 6171544dadb04a3388e7eea48a504ab5 d1b9f9c5d4574fe8987a6438e9cb84c3--6171544dadb04a3388e7eea48a504ab5 455c270394eb42708192a088bcf2104a t = \u03a6 6171544dadb04a3388e7eea48a504ab5--455c270394eb42708192a088bcf2104a 455c270394eb42708192a088bcf2104a--df75aba0125648da9a282a7469bfd2da cc2b962cffc1476993f397dab8a4f362 a05c31ff1c534729b8c9a0c63f974bb0 RZ(cos(\u03a6)) f590dbf1c1964cee87262346d1f51a08--a05c31ff1c534729b8c9a0c63f974bb0 010d077ffae74813b4cf72b49fac9db3 a05c31ff1c534729b8c9a0c63f974bb0--010d077ffae74813b4cf72b49fac9db3 f4f5369c5cd94ac6bf18c3d26272613d PHASE(3.142) 010d077ffae74813b4cf72b49fac9db3--f4f5369c5cd94ac6bf18c3d26272613d f4f5369c5cd94ac6bf18c3d26272613d--6171544dadb04a3388e7eea48a504ab5 8474f0a8e96a422d9df7b1cd8d8752af f4f5369c5cd94ac6bf18c3d26272613d--8474f0a8e96a422d9df7b1cd8d8752af 8474f0a8e96a422d9df7b1cd8d8752af--cc2b962cffc1476993f397dab8a4f362 <p>Please note the different colors for the parametrization with different types. The default palette assigns blue for <code>VariationalParameter</code>, green for <code>FeatureParameter</code>, orange for numeric values, and shaded red for non-parametric gates.</p>"},{"location":"content/qml_constructors/","title":"Quantum machine learning constructors","text":"<p>Besides the arbitrary Hamiltonian constructors, Qadence also provides a complete set of program constructors useful for digital-analog quantum machine learning programs.</p>"},{"location":"content/qml_constructors/#feature-maps","title":"Feature maps","text":"<p>The <code>feature_map</code> function can easily create several types of data-encoding blocks. The two main types of feature maps use a Fourier basis or a Chebyshev basis.</p> <pre><code>from qadence import feature_map, BasisSet, chain\nfrom qadence.draw import display\n\nn_qubits = 3\n\nfourier_fm = feature_map(n_qubits, fm_type=BasisSet.FOURIER)\n\nchebyshev_fm = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV)\n\nblock = chain(fourier_fm, chebyshev_fm)\n</code></pre> %3 cluster_7e69318d9f404449b39393b9ee2d3d83 Constant Chebyshev FM cluster_efbd2e579c0e40c989aac8a2ded2ca7d Constant Fourier FM 6d3897c495384fc09c49fa8438a3baf8 0 c3e615a3bda144618a5f7c4275c2d989 RX(phi) 6d3897c495384fc09c49fa8438a3baf8--c3e615a3bda144618a5f7c4275c2d989 b896f704a2fc445182a1604c07c42cb8 1 e43e380e4557499b9155ff03bd2118de RX(acos(phi)) c3e615a3bda144618a5f7c4275c2d989--e43e380e4557499b9155ff03bd2118de f02befbf4dc14ea9aded9fbd94b34229 e43e380e4557499b9155ff03bd2118de--f02befbf4dc14ea9aded9fbd94b34229 eadacf7807584b38b47117f50bdccabf a16c716dcfda4d1f8954674129561230 RX(phi) b896f704a2fc445182a1604c07c42cb8--a16c716dcfda4d1f8954674129561230 a7264b23eac04951a82f8fb473bfc6fb 2 f23936cbd5b94be8956dcc3b23719ec0 RX(acos(phi)) a16c716dcfda4d1f8954674129561230--f23936cbd5b94be8956dcc3b23719ec0 f23936cbd5b94be8956dcc3b23719ec0--eadacf7807584b38b47117f50bdccabf 66b334b2dd594151af5669e6e49a4e3f 4f847e501f1647ae84e835d29574b299 RX(phi) a7264b23eac04951a82f8fb473bfc6fb--4f847e501f1647ae84e835d29574b299 b9dbb918759545a085d31f1d8d7ee0e3 RX(acos(phi)) 4f847e501f1647ae84e835d29574b299--b9dbb918759545a085d31f1d8d7ee0e3 b9dbb918759545a085d31f1d8d7ee0e3--66b334b2dd594151af5669e6e49a4e3f <p>A custom encoding function can also be passed with <code>sympy</code></p> <pre><code>from sympy import asin, Function\n\nn_qubits = 3\n\n# Using a pre-defined sympy Function\ncustom_fm_0 = feature_map(n_qubits, fm_type=asin)\n\n# Creating a custom function\ndef custom_fn(x):\n    return asin(x) + x**2\n\ncustom_fm_1 = feature_map(n_qubits, fm_type=custom_fn)\n\nblock = chain(custom_fm_0, custom_fm_1)\n</code></pre> %3 cluster_6feb4508b4da459bbdbcebfbb77de30f Constant &lt;function custom_fn at 0x7f51cd3f5630&gt; FM cluster_6ff131aed2154295a6d1bbe2ca6cdfb7 Constant asin FM add8bbe6714241aa9adfb5e40bf18075 0 b93d08e4e12b41979faa1c2d33a10a9b RX(asin(phi)) add8bbe6714241aa9adfb5e40bf18075--b93d08e4e12b41979faa1c2d33a10a9b b6846ca2e63d44648ce049ef70cf9ace 1 1238fadafaf14a90ba96700f04c9501c RX(phi**2 + asin(phi)) b93d08e4e12b41979faa1c2d33a10a9b--1238fadafaf14a90ba96700f04c9501c bffc12fddde249ed9fccd0cde96fb89a 1238fadafaf14a90ba96700f04c9501c--bffc12fddde249ed9fccd0cde96fb89a e2a37f06d22e490e86a266e92f47442d d90c396fcbcd4bdf94c24c7a7c0b9474 RX(asin(phi)) b6846ca2e63d44648ce049ef70cf9ace--d90c396fcbcd4bdf94c24c7a7c0b9474 931cc77548ff48408cabc74dac160174 2 7347dc9fc6e445d69545b14e0aea78cc RX(phi**2 + asin(phi)) d90c396fcbcd4bdf94c24c7a7c0b9474--7347dc9fc6e445d69545b14e0aea78cc 7347dc9fc6e445d69545b14e0aea78cc--e2a37f06d22e490e86a266e92f47442d 40bd7c92ff5c44caa347ef815d5744fc 20112c817ebe43ce8cbd8e8727306829 RX(asin(phi)) 931cc77548ff48408cabc74dac160174--20112c817ebe43ce8cbd8e8727306829 98faff6f7d1a46ff87568cec3483a320 RX(phi**2 + asin(phi)) 20112c817ebe43ce8cbd8e8727306829--98faff6f7d1a46ff87568cec3483a320 98faff6f7d1a46ff87568cec3483a320--40bd7c92ff5c44caa347ef815d5744fc <p>Furthermore, the <code>reupload_scaling</code> argument can be used to change the scaling applied to each qubit in the support of the feature map. The default scalings can be chosen from the <code>ReuploadScaling</code> enumeration.</p> <pre><code>from qadence import ReuploadScaling\nfrom qadence.draw import display\n\nn_qubits = 5\n\n# Default constant value\nfm_constant = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT)\n\n# Linearly increasing scaling\nfm_tower = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.TOWER)\n\n# Exponentially increasing scaling\nfm_exp = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.EXP)\n\nblock = chain(fm_constant, fm_tower, fm_exp)\n</code></pre> %3 cluster_19f80d0e0f134a3685845bf99cab2de5 Exponential Fourier FM cluster_82ae22449d38402eb69dc039fee6afd1 Constant Fourier FM cluster_8130d27aaaac4184b30474ff3ec02bf1 Tower Fourier FM 33c708ca444e4447aa7ddf04795d66a4 0 7ee4521ba93c4d6794bdde06eede3377 RX(phi) 33c708ca444e4447aa7ddf04795d66a4--7ee4521ba93c4d6794bdde06eede3377 ac811fa9aedb4a9e824525b1a23ada6b 1 3277d609052648b3a944f50694dcb8d3 RX(1.0*phi) 7ee4521ba93c4d6794bdde06eede3377--3277d609052648b3a944f50694dcb8d3 519ea05b9dbc45bfbbbc14187f38925d RX(1.0*phi) 3277d609052648b3a944f50694dcb8d3--519ea05b9dbc45bfbbbc14187f38925d 687f697001c54281a0eacb12d6c6c143 519ea05b9dbc45bfbbbc14187f38925d--687f697001c54281a0eacb12d6c6c143 28cc01edf12d4225afc7ac30112500b5 9f826c886d25435aa55ad82e926bbbad RX(phi) ac811fa9aedb4a9e824525b1a23ada6b--9f826c886d25435aa55ad82e926bbbad 80dd478a288449418d5f1bedbe0773fd 2 a44729661ea94d75b9f79efb097192e3 RX(2.0*phi) 9f826c886d25435aa55ad82e926bbbad--a44729661ea94d75b9f79efb097192e3 d176cd36010a486f9ecc1c72967455bf RX(2.0*phi) a44729661ea94d75b9f79efb097192e3--d176cd36010a486f9ecc1c72967455bf d176cd36010a486f9ecc1c72967455bf--28cc01edf12d4225afc7ac30112500b5 919700b7e00b4eb28fff5c31935a0f6e 47e1069f867e43f1a927bad624e029df RX(phi) 80dd478a288449418d5f1bedbe0773fd--47e1069f867e43f1a927bad624e029df 4aa42f0f796c458498b68684810b96cc 3 34537170140240fab8174ceb0b1c8bda RX(3.0*phi) 47e1069f867e43f1a927bad624e029df--34537170140240fab8174ceb0b1c8bda 1265d3f6609a4a8e904f4923db3af87c RX(4.0*phi) 34537170140240fab8174ceb0b1c8bda--1265d3f6609a4a8e904f4923db3af87c 1265d3f6609a4a8e904f4923db3af87c--919700b7e00b4eb28fff5c31935a0f6e 72bdfaca72534dfaa429c02b83e34f4e ad9902f8a5764c4981bb19491bf29958 RX(phi) 4aa42f0f796c458498b68684810b96cc--ad9902f8a5764c4981bb19491bf29958 dda5ac7839464342b9e19a3c48c30e07 4 bfe187e64468460a9ce644003669366b RX(4.0*phi) ad9902f8a5764c4981bb19491bf29958--bfe187e64468460a9ce644003669366b e19baef7d9a04324ba4728699119b9b7 RX(8.0*phi) bfe187e64468460a9ce644003669366b--e19baef7d9a04324ba4728699119b9b7 e19baef7d9a04324ba4728699119b9b7--72bdfaca72534dfaa429c02b83e34f4e b27bde737c6244b2a3ffa7c4101f78cd ad7fdd51d22949fdbad26bc9b22ad93c RX(phi) dda5ac7839464342b9e19a3c48c30e07--ad7fdd51d22949fdbad26bc9b22ad93c 2c07ad2c236640da845b024e020e1054 RX(5.0*phi) ad7fdd51d22949fdbad26bc9b22ad93c--2c07ad2c236640da845b024e020e1054 847ee99f145b49adbe6678df0cbcf59a RX(16.0*phi) 2c07ad2c236640da845b024e020e1054--847ee99f145b49adbe6678df0cbcf59a 847ee99f145b49adbe6678df0cbcf59a--b27bde737c6244b2a3ffa7c4101f78cd <p>A custom scaling can also be defined with a function with an <code>int</code> input and <code>int</code> or <code>float</code> output.</p> <pre><code>n_qubits = 5\n\ndef custom_scaling(i: int) -&gt; int | float:\n    \"\"\"Sqrt(i+1)\"\"\"\n    return (i+1) ** (0.5)\n\n# Custom scaling function\nfm_custom = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV, reupload_scaling=custom_scaling)\n</code></pre> %3 7dac997f97564940bee215acc319cd92 0 c0c80b0637284ea49e51a624f387c4ad RX(1.0*acos(phi)) 7dac997f97564940bee215acc319cd92--c0c80b0637284ea49e51a624f387c4ad 3580549526234e26aad6c85ffcc90e27 1 cbd96976456f430bad745c2835a704f1 c0c80b0637284ea49e51a624f387c4ad--cbd96976456f430bad745c2835a704f1 78d6081ac6044e498a6717bb3dfe2ad9 ddbfed2cde8047e6a8bba6073a3e7d3d RX(1.414*acos(phi)) 3580549526234e26aad6c85ffcc90e27--ddbfed2cde8047e6a8bba6073a3e7d3d 353984f5590b4fa8acfef45df1501f6e 2 ddbfed2cde8047e6a8bba6073a3e7d3d--78d6081ac6044e498a6717bb3dfe2ad9 501fb44959074b8ab8d0df189bf8d7f8 5e4a4a7597ad43c58dbf52663727531f RX(1.732*acos(phi)) 353984f5590b4fa8acfef45df1501f6e--5e4a4a7597ad43c58dbf52663727531f 3e96f8c260d04b5dafe4646bc9b1ddd5 3 5e4a4a7597ad43c58dbf52663727531f--501fb44959074b8ab8d0df189bf8d7f8 1cdea95f39b14094b61f697d6570f8f2 e2f461c0351e443ead3052bb74c82734 RX(2.0*acos(phi)) 3e96f8c260d04b5dafe4646bc9b1ddd5--e2f461c0351e443ead3052bb74c82734 657a2502567f422fbe6a5d2614a2f499 4 e2f461c0351e443ead3052bb74c82734--1cdea95f39b14094b61f697d6570f8f2 ee96196fee6348f592bb9287a7e8c99e 0cf7012e17b14479a90634dad510cb1a RX(2.236*acos(phi)) 657a2502567f422fbe6a5d2614a2f499--0cf7012e17b14479a90634dad510cb1a 0cf7012e17b14479a90634dad510cb1a--ee96196fee6348f592bb9287a7e8c99e <p>To add a trainable parameter that multiplies the feature parameter inside the encoding function, simply pass a <code>param_prefix</code> string:</p> <pre><code>n_qubits = 5\n\nfm_trainable = feature_map(\n    n_qubits,\n    fm_type=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.EXP,\n    param_prefix = \"w\",\n)\n</code></pre> %3 3c30414bd69d424da44acfe5aaba82cf 0 4d4db7133917403e9cafe53b2e14156f RX(1.0*phi*w\u2080) 3c30414bd69d424da44acfe5aaba82cf--4d4db7133917403e9cafe53b2e14156f 3513d927e0e24d96a9b8c536dc6ef847 1 5020dbd032284725a4594ac464428d39 4d4db7133917403e9cafe53b2e14156f--5020dbd032284725a4594ac464428d39 057e5a982e714c5eb69e622ae3a21bd0 24257d34083440328676fadc1532ea3f RX(2.0*phi*w\u2081) 3513d927e0e24d96a9b8c536dc6ef847--24257d34083440328676fadc1532ea3f 9fb0e5fe44b248828397efa0efbc4172 2 24257d34083440328676fadc1532ea3f--057e5a982e714c5eb69e622ae3a21bd0 69b3507e2ea14eb59159b4fb2c989cb0 4e303d7fc5dd460b997bc426cc910015 RX(4.0*phi*w\u2082) 9fb0e5fe44b248828397efa0efbc4172--4e303d7fc5dd460b997bc426cc910015 e16824f1a50f4ae28f3ce2803bc6995b 3 4e303d7fc5dd460b997bc426cc910015--69b3507e2ea14eb59159b4fb2c989cb0 3b54544a9418408599845e2c12230597 5eeb0b0faa1b4c44bea3ae1309b1a2ad RX(8.0*phi*w\u2083) e16824f1a50f4ae28f3ce2803bc6995b--5eeb0b0faa1b4c44bea3ae1309b1a2ad f4e20c4eaf5f458a96ab7c3ac8aa748d 4 5eeb0b0faa1b4c44bea3ae1309b1a2ad--3b54544a9418408599845e2c12230597 c2c39551ece84826aa805d908c95defd 39d0e4ce47a8426fab32b14986741a46 RX(16.0*phi*w\u2084) f4e20c4eaf5f458a96ab7c3ac8aa748d--39d0e4ce47a8426fab32b14986741a46 39d0e4ce47a8426fab32b14986741a46--c2c39551ece84826aa805d908c95defd <p>Note that for the Fourier feature map, the encoding function is simply \\(f(x)=x\\). For other cases, like the Chebyshev <code>acos()</code> encoding, the trainable parameter may cause the feature value to be outside the domain of the encoding function. This will eventually be fixed by adding range constraints to trainable parameters in Qadence.</p> <p>A full description of the remaining arguments can be found in the <code>feature_map</code> API reference. We provide an example below.</p> <pre><code>from qadence import RY\n\nn_qubits = 5\n\n# Custom scaling function\nfm_full = feature_map(\n    n_qubits = n_qubits,\n    support = tuple(reversed(range(n_qubits))), # Reverse the qubit support to run the scaling from bottom to top\n    param = \"x\", # Change the name of the parameter\n    op = RY, # Change the rotation gate between RX, RY, RZ or PHASE\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.EXP,\n    feature_range = (-1.0, 2.0), # Range from which the input data comes from\n    target_range = (1.0, 3.0), # Range the encoder assumes as the natural range\n    multiplier = 5.0, # Extra multiplier, which can also be a Parameter\n    param_prefix = \"w\", # Add trainable parameters\n)\n</code></pre> %3 e389874fc7a3476bbc134725fec29cb9 0 2eddc536f3ee4662ab61d0f664f851a8 RY(80.0*acos(w\u2084*(0.667*x + 1.667))) e389874fc7a3476bbc134725fec29cb9--2eddc536f3ee4662ab61d0f664f851a8 80ab1bbed7254e5e8ec037683bf5976c 1 80c17e73081343f39940273a0463b156 2eddc536f3ee4662ab61d0f664f851a8--80c17e73081343f39940273a0463b156 aa1ec590dc9a40708f1a3509f8d32dcb 60ca7fe4039c4eadb4800ffdd280ecc1 RY(40.0*acos(w\u2083*(0.667*x + 1.667))) 80ab1bbed7254e5e8ec037683bf5976c--60ca7fe4039c4eadb4800ffdd280ecc1 711ba80c09cd49049fa26581e7e9892a 2 60ca7fe4039c4eadb4800ffdd280ecc1--aa1ec590dc9a40708f1a3509f8d32dcb 48ae67e83bb2432c9ebd91d136515187 667530a0cef345e4ae327286c74149fb RY(20.0*acos(w\u2082*(0.667*x + 1.667))) 711ba80c09cd49049fa26581e7e9892a--667530a0cef345e4ae327286c74149fb e24a316f889c4ba4863c6ff78508c91b 3 667530a0cef345e4ae327286c74149fb--48ae67e83bb2432c9ebd91d136515187 656e029a679d43479c90498f28eaa173 5ef79edbc9204f19848575fb5ab70d38 RY(10.0*acos(w\u2081*(0.667*x + 1.667))) e24a316f889c4ba4863c6ff78508c91b--5ef79edbc9204f19848575fb5ab70d38 8466fd969de0440fa0effc2f887ce0a1 4 5ef79edbc9204f19848575fb5ab70d38--656e029a679d43479c90498f28eaa173 e79fe7189ee34d7d8d0bb7520f05c06e 52d27eac3f9b41608cd2ca911338cb72 RY(5.0*acos(w\u2080*(0.667*x + 1.667))) 8466fd969de0440fa0effc2f887ce0a1--52d27eac3f9b41608cd2ca911338cb72 52d27eac3f9b41608cd2ca911338cb72--e79fe7189ee34d7d8d0bb7520f05c06e"},{"location":"content/qml_constructors/#hardware-efficient-ansatz","title":"Hardware-efficient ansatz","text":"<p>Ansatze blocks for quantum machine-learning are typically built following the Hardware-Efficient Ansatz formalism (HEA). Both fully digital and digital-analog HEAs can easily be built with the <code>hea</code> function. By default, the digital version is returned:</p> <pre><code>from qadence import hea\nfrom qadence.draw import display\n\nn_qubits = 3\ndepth = 2\n\nansatz = hea(n_qubits, depth)\n</code></pre> %3 83e3da2e56364f78bcb803e6ebd90b75 0 cc5bf4403eac434ab7eeec440317281e RX(theta\u2080) 83e3da2e56364f78bcb803e6ebd90b75--cc5bf4403eac434ab7eeec440317281e 93cd37186468498ba221efc00a0d1daa 1 7679f2404b504ccba5d85107003ed888 RY(theta\u2083) cc5bf4403eac434ab7eeec440317281e--7679f2404b504ccba5d85107003ed888 926bdbd3c50d4775918ccef4463dfe95 RX(theta\u2086) 7679f2404b504ccba5d85107003ed888--926bdbd3c50d4775918ccef4463dfe95 eb3fe8d884414ae3a247965757854f34 926bdbd3c50d4775918ccef4463dfe95--eb3fe8d884414ae3a247965757854f34 287480fc1ff2484a8c1b58a9509d2564 eb3fe8d884414ae3a247965757854f34--287480fc1ff2484a8c1b58a9509d2564 f2b1a87444084fa0bcf9572f0499b333 RX(theta\u2089) 287480fc1ff2484a8c1b58a9509d2564--f2b1a87444084fa0bcf9572f0499b333 ffb4c3c0919f427fa6f7682397da0f2d RY(theta\u2081\u2082) f2b1a87444084fa0bcf9572f0499b333--ffb4c3c0919f427fa6f7682397da0f2d 0e058077ec62410b8551ff2caf479420 RX(theta\u2081\u2085) ffb4c3c0919f427fa6f7682397da0f2d--0e058077ec62410b8551ff2caf479420 94d9884eb7fa4a63b001174c96238bbf 0e058077ec62410b8551ff2caf479420--94d9884eb7fa4a63b001174c96238bbf adb62669b8cd492b83fa4100986de306 94d9884eb7fa4a63b001174c96238bbf--adb62669b8cd492b83fa4100986de306 fc3ee3c4e6274001ac44e49013fc7fb7 adb62669b8cd492b83fa4100986de306--fc3ee3c4e6274001ac44e49013fc7fb7 d763346e5c764f4cb3cd2ada3fb6e469 da803a0bc6174334a527e6e7aa684765 RX(theta\u2081) 93cd37186468498ba221efc00a0d1daa--da803a0bc6174334a527e6e7aa684765 6184fb09cb564f179c143eb1cb15dbfd 2 27f5a8e2ca57415cba1224e83bce8815 RY(theta\u2084) da803a0bc6174334a527e6e7aa684765--27f5a8e2ca57415cba1224e83bce8815 0552518fc9624058a0fc041882d3cb79 RX(theta\u2087) 27f5a8e2ca57415cba1224e83bce8815--0552518fc9624058a0fc041882d3cb79 96053e3f143b4f87920264b2fb99eb28 X 0552518fc9624058a0fc041882d3cb79--96053e3f143b4f87920264b2fb99eb28 96053e3f143b4f87920264b2fb99eb28--eb3fe8d884414ae3a247965757854f34 c77e717d656c4dfeb7b4ec1858de6821 96053e3f143b4f87920264b2fb99eb28--c77e717d656c4dfeb7b4ec1858de6821 4b69373c34f8466daae1c68222890b41 RX(theta\u2081\u2080) c77e717d656c4dfeb7b4ec1858de6821--4b69373c34f8466daae1c68222890b41 c92a2927957f45ea81d5ae58f85f98d3 RY(theta\u2081\u2083) 4b69373c34f8466daae1c68222890b41--c92a2927957f45ea81d5ae58f85f98d3 4b3975c4d09d4e0ab8d3f58ac385fc1b RX(theta\u2081\u2086) c92a2927957f45ea81d5ae58f85f98d3--4b3975c4d09d4e0ab8d3f58ac385fc1b 776b4f5078c14be6a6a4dd1cd1f1a31b X 4b3975c4d09d4e0ab8d3f58ac385fc1b--776b4f5078c14be6a6a4dd1cd1f1a31b 776b4f5078c14be6a6a4dd1cd1f1a31b--94d9884eb7fa4a63b001174c96238bbf 4cbe629fa09949008fbf0fc9a0d4b967 776b4f5078c14be6a6a4dd1cd1f1a31b--4cbe629fa09949008fbf0fc9a0d4b967 4cbe629fa09949008fbf0fc9a0d4b967--d763346e5c764f4cb3cd2ada3fb6e469 ed9980093c724c7d9f97685cb03568ea b73451ee62d243f4913280a68dd98772 RX(theta\u2082) 6184fb09cb564f179c143eb1cb15dbfd--b73451ee62d243f4913280a68dd98772 b10878bf5cd64babbd3bd8ed29b7aa75 RY(theta\u2085) b73451ee62d243f4913280a68dd98772--b10878bf5cd64babbd3bd8ed29b7aa75 27991fa11cd144fba4be23535e82cf3f RX(theta\u2088) b10878bf5cd64babbd3bd8ed29b7aa75--27991fa11cd144fba4be23535e82cf3f d918923a27f04bd2a5236d76842cbfdc 27991fa11cd144fba4be23535e82cf3f--d918923a27f04bd2a5236d76842cbfdc 771e415ec43c4260b38d8fd7cc82611b X d918923a27f04bd2a5236d76842cbfdc--771e415ec43c4260b38d8fd7cc82611b 771e415ec43c4260b38d8fd7cc82611b--c77e717d656c4dfeb7b4ec1858de6821 ef9a2fdbf77d4a57b63abbb10d36984f RX(theta\u2081\u2081) 771e415ec43c4260b38d8fd7cc82611b--ef9a2fdbf77d4a57b63abbb10d36984f 4d546bf91a544212895b437db7704ce2 RY(theta\u2081\u2084) ef9a2fdbf77d4a57b63abbb10d36984f--4d546bf91a544212895b437db7704ce2 75954f019e804a72a8d5d3f322567177 RX(theta\u2081\u2087) 4d546bf91a544212895b437db7704ce2--75954f019e804a72a8d5d3f322567177 4d8c3806ae4242069ede64f522112ee7 75954f019e804a72a8d5d3f322567177--4d8c3806ae4242069ede64f522112ee7 ba25f32370c54ba3ae84136cc90ec9bc X 4d8c3806ae4242069ede64f522112ee7--ba25f32370c54ba3ae84136cc90ec9bc ba25f32370c54ba3ae84136cc90ec9bc--4cbe629fa09949008fbf0fc9a0d4b967 ba25f32370c54ba3ae84136cc90ec9bc--ed9980093c724c7d9f97685cb03568ea <p>As seen above, the rotation layers are automatically parameterized, and the prefix <code>\"theta\"</code> can be changed with the <code>param_prefix</code> argument.</p> <p>Furthermore, both the single-qubit rotations and the two-qubit entangler can be customized with the <code>operations</code> and <code>entangler</code> argument. The operations can be passed as a list of single-qubit rotations, while the entangler should be either <code>CNOT</code>, <code>CZ</code>, <code>CRX</code>, <code>CRY</code>, <code>CRZ</code> or <code>CPHASE</code>.</p> <pre><code>from qadence import RX, RY, CPHASE\n\nansatz = hea(\n    n_qubits=n_qubits,\n    depth=depth,\n    param_prefix=\"phi\",\n    operations=[RX, RY, RX],\n    entangler=CPHASE\n)\n</code></pre> %3 f75adafda2414938ac4cf2b725aa95b7 0 8c12c255255144458ef8fa078f005232 RX(phi\u2080) f75adafda2414938ac4cf2b725aa95b7--8c12c255255144458ef8fa078f005232 9bbd9f429e5c48e0889cf05cbe80f656 1 13376e281a3642c0962a188d0d5a86a7 RY(phi\u2083) 8c12c255255144458ef8fa078f005232--13376e281a3642c0962a188d0d5a86a7 7b64439bd3a146c4b3c78af2944545f9 RX(phi\u2086) 13376e281a3642c0962a188d0d5a86a7--7b64439bd3a146c4b3c78af2944545f9 3bd02a85d01e4c3f88d1fd5a9f368b27 7b64439bd3a146c4b3c78af2944545f9--3bd02a85d01e4c3f88d1fd5a9f368b27 d072ac49b89944f99d9842d2c1176fca 3bd02a85d01e4c3f88d1fd5a9f368b27--d072ac49b89944f99d9842d2c1176fca e2e44c10c8da4b569f107fb9f0d8106d RX(phi\u2089) d072ac49b89944f99d9842d2c1176fca--e2e44c10c8da4b569f107fb9f0d8106d 2da1654b7fbe4ff1a21ade32869174e4 RY(phi\u2081\u2082) e2e44c10c8da4b569f107fb9f0d8106d--2da1654b7fbe4ff1a21ade32869174e4 2941861bab4b4688b3399666d6e9e36b RX(phi\u2081\u2085) 2da1654b7fbe4ff1a21ade32869174e4--2941861bab4b4688b3399666d6e9e36b 5bfae0f0bac04747bb9a57928c7b4c57 2941861bab4b4688b3399666d6e9e36b--5bfae0f0bac04747bb9a57928c7b4c57 e18867cf541d4326be03b6d694ab90d0 5bfae0f0bac04747bb9a57928c7b4c57--e18867cf541d4326be03b6d694ab90d0 161f0361a5124114b483395ca1328c10 e18867cf541d4326be03b6d694ab90d0--161f0361a5124114b483395ca1328c10 e6659dc85cfc4692983acbe3e5366357 c0975bcb9b1f483ab97fbe4cdd7f1683 RX(phi\u2081) 9bbd9f429e5c48e0889cf05cbe80f656--c0975bcb9b1f483ab97fbe4cdd7f1683 633e1f87ae82449d97df50128a929904 2 1fad4c0cb35245ebbf6e93407e51441d RY(phi\u2084) c0975bcb9b1f483ab97fbe4cdd7f1683--1fad4c0cb35245ebbf6e93407e51441d 5882c568cabf423093a9300e28a8eb45 RX(phi\u2087) 1fad4c0cb35245ebbf6e93407e51441d--5882c568cabf423093a9300e28a8eb45 f6325f30afd54b0a932979fd99c33e94 PHASE(phi_ent\u2080) 5882c568cabf423093a9300e28a8eb45--f6325f30afd54b0a932979fd99c33e94 f6325f30afd54b0a932979fd99c33e94--3bd02a85d01e4c3f88d1fd5a9f368b27 ce93db20c0c349b8b45364302af1aeda f6325f30afd54b0a932979fd99c33e94--ce93db20c0c349b8b45364302af1aeda 943175380daa42e8a0cf324910b7725e RX(phi\u2081\u2080) ce93db20c0c349b8b45364302af1aeda--943175380daa42e8a0cf324910b7725e 284f340dbcb94fc789d3891aed0806b8 RY(phi\u2081\u2083) 943175380daa42e8a0cf324910b7725e--284f340dbcb94fc789d3891aed0806b8 cf6eeb630a434d63a505ce68ca3eb67f RX(phi\u2081\u2086) 284f340dbcb94fc789d3891aed0806b8--cf6eeb630a434d63a505ce68ca3eb67f b3dbcf6208364449a84cf9412e0c33dd PHASE(phi_ent\u2082) cf6eeb630a434d63a505ce68ca3eb67f--b3dbcf6208364449a84cf9412e0c33dd b3dbcf6208364449a84cf9412e0c33dd--5bfae0f0bac04747bb9a57928c7b4c57 f56d9f32e3344da384164ac307cabfa2 b3dbcf6208364449a84cf9412e0c33dd--f56d9f32e3344da384164ac307cabfa2 f56d9f32e3344da384164ac307cabfa2--e6659dc85cfc4692983acbe3e5366357 12bcf8f663654783a0c91fe95dce0b8f b9710e6b891649e88fa5d28ccb042fc9 RX(phi\u2082) 633e1f87ae82449d97df50128a929904--b9710e6b891649e88fa5d28ccb042fc9 e272c00583244a1482841f335f518bc6 RY(phi\u2085) b9710e6b891649e88fa5d28ccb042fc9--e272c00583244a1482841f335f518bc6 964e6ddab37048cfa34a3dcfcfde79be RX(phi\u2088) e272c00583244a1482841f335f518bc6--964e6ddab37048cfa34a3dcfcfde79be c8fa386c969e46cdaf02b155dfab8843 964e6ddab37048cfa34a3dcfcfde79be--c8fa386c969e46cdaf02b155dfab8843 a6adf168a9ed4b4fa2db00b1623616b9 PHASE(phi_ent\u2081) c8fa386c969e46cdaf02b155dfab8843--a6adf168a9ed4b4fa2db00b1623616b9 a6adf168a9ed4b4fa2db00b1623616b9--ce93db20c0c349b8b45364302af1aeda 5827250b819d4b2a811bc5fbb55426d5 RX(phi\u2081\u2081) a6adf168a9ed4b4fa2db00b1623616b9--5827250b819d4b2a811bc5fbb55426d5 929eaf534e9c4f0bbdbd5fc5f2c7c5b5 RY(phi\u2081\u2084) 5827250b819d4b2a811bc5fbb55426d5--929eaf534e9c4f0bbdbd5fc5f2c7c5b5 5462efef0310484fad9f640bed72f141 RX(phi\u2081\u2087) 929eaf534e9c4f0bbdbd5fc5f2c7c5b5--5462efef0310484fad9f640bed72f141 61154d7a495544baa3c06c2340f7e434 5462efef0310484fad9f640bed72f141--61154d7a495544baa3c06c2340f7e434 599cf09a837945718200dee0e3f7824c PHASE(phi_ent\u2083) 61154d7a495544baa3c06c2340f7e434--599cf09a837945718200dee0e3f7824c 599cf09a837945718200dee0e3f7824c--f56d9f32e3344da384164ac307cabfa2 599cf09a837945718200dee0e3f7824c--12bcf8f663654783a0c91fe95dce0b8f <p>Having a truly hardware-efficient ansatz means that the entangling operation can be chosen according to each device's native interactions. Besides digital operations, in Qadence it is also possible to build digital-analog HEAs with the entanglement produced by the natural evolution of a set of interacting qubits, as natively implemented in neutral atom devices. As with other digital-analog functions, this can be controlled with the <code>strategy</code> argument which can be chosen from the <code>Strategy</code> enum type. Currently, only <code>Strategy.DIGITAL</code> and <code>Strategy.SDAQC</code> are available. By default, calling <code>strategy = Strategy.SDAQC</code> will use a global entangling Hamiltonian with Ising-like \\(NN\\) interactions and constant interaction strength,</p> <pre><code>from qadence import Strategy\n\nansatz = hea(\n    n_qubits,\n    depth=depth,\n    strategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_1a8ddda9c30c4e1ab64e47dcf69d4248 cluster_7d73768003464eb69687d68784d35672 500d1c6a664b4c408648fcb93bfaeee5 0 dbb45b57ee5e4201a6704a92a75706fc RX(theta\u2080) 500d1c6a664b4c408648fcb93bfaeee5--dbb45b57ee5e4201a6704a92a75706fc 5ae33bc0757d4fd19a9364a95ffc38ce 1 08f966c4993647699ce8be0d1cd432ff RY(theta\u2083) dbb45b57ee5e4201a6704a92a75706fc--08f966c4993647699ce8be0d1cd432ff 79b624c50eaf4553a2784acf1d82a248 RX(theta\u2086) 08f966c4993647699ce8be0d1cd432ff--79b624c50eaf4553a2784acf1d82a248 303845176795494eab0206c3b62cd4d2 HamEvo 79b624c50eaf4553a2784acf1d82a248--303845176795494eab0206c3b62cd4d2 b5970ed12f724caea70fd105eb94d4c2 RX(theta\u2089) 303845176795494eab0206c3b62cd4d2--b5970ed12f724caea70fd105eb94d4c2 59f7bbf359dc47b4ac3578c8fc2a126d RY(theta\u2081\u2082) b5970ed12f724caea70fd105eb94d4c2--59f7bbf359dc47b4ac3578c8fc2a126d 1585e6e1b38c4731ac90879eaef918ca RX(theta\u2081\u2085) 59f7bbf359dc47b4ac3578c8fc2a126d--1585e6e1b38c4731ac90879eaef918ca dc6b4df5b33a4857bc960c98e2cce8a6 HamEvo 1585e6e1b38c4731ac90879eaef918ca--dc6b4df5b33a4857bc960c98e2cce8a6 ac4f704042464522ba5fc5f2df7cbdf1 dc6b4df5b33a4857bc960c98e2cce8a6--ac4f704042464522ba5fc5f2df7cbdf1 276cc15041f14d2787dcf8a01655a818 c1f8da75599f4e85bf0da1ca6155bc5b RX(theta\u2081) 5ae33bc0757d4fd19a9364a95ffc38ce--c1f8da75599f4e85bf0da1ca6155bc5b 5b10db867e274384a6b70bfba291e239 2 aeb6f447761248439597120c453c67a3 RY(theta\u2084) c1f8da75599f4e85bf0da1ca6155bc5b--aeb6f447761248439597120c453c67a3 26eb13867318493ca4a2c963279252c7 RX(theta\u2087) aeb6f447761248439597120c453c67a3--26eb13867318493ca4a2c963279252c7 d971ff1026764b84bf7d7f4efe623a90 t = theta_t\u2080 26eb13867318493ca4a2c963279252c7--d971ff1026764b84bf7d7f4efe623a90 e76d9f6e010446698d2955873cc5e597 RX(theta\u2081\u2080) d971ff1026764b84bf7d7f4efe623a90--e76d9f6e010446698d2955873cc5e597 7c1e3243da5c4976ba863e645ac109d5 RY(theta\u2081\u2083) e76d9f6e010446698d2955873cc5e597--7c1e3243da5c4976ba863e645ac109d5 43d8bd5812dc4de99382bd99bf2ab3ed RX(theta\u2081\u2086) 7c1e3243da5c4976ba863e645ac109d5--43d8bd5812dc4de99382bd99bf2ab3ed da8796dc5c6d4a9cba5ad377fe72cdea t = theta_t\u2081 43d8bd5812dc4de99382bd99bf2ab3ed--da8796dc5c6d4a9cba5ad377fe72cdea da8796dc5c6d4a9cba5ad377fe72cdea--276cc15041f14d2787dcf8a01655a818 01c8c3cff4384958a2923d0c072ec618 f8779bdf66cf4cd3a1dcd11e5a0c955a RX(theta\u2082) 5b10db867e274384a6b70bfba291e239--f8779bdf66cf4cd3a1dcd11e5a0c955a f60298cd1a2e4739a87c5979657265d5 RY(theta\u2085) f8779bdf66cf4cd3a1dcd11e5a0c955a--f60298cd1a2e4739a87c5979657265d5 11eefb195039405e9f8174e0d49bb053 RX(theta\u2088) f60298cd1a2e4739a87c5979657265d5--11eefb195039405e9f8174e0d49bb053 1f29f8949471463eacd2f22b7d5c4b27 11eefb195039405e9f8174e0d49bb053--1f29f8949471463eacd2f22b7d5c4b27 f28fa0638661472eb1d03e69f21ea63c RX(theta\u2081\u2081) 1f29f8949471463eacd2f22b7d5c4b27--f28fa0638661472eb1d03e69f21ea63c 30e45ab994254fa89e9e669144b18321 RY(theta\u2081\u2084) f28fa0638661472eb1d03e69f21ea63c--30e45ab994254fa89e9e669144b18321 b6928cfb503849acbd9f36130ca4342f RX(theta\u2081\u2087) 30e45ab994254fa89e9e669144b18321--b6928cfb503849acbd9f36130ca4342f a1f9d3d7e89b42fd96c0fc0b13eaccc3 b6928cfb503849acbd9f36130ca4342f--a1f9d3d7e89b42fd96c0fc0b13eaccc3 a1f9d3d7e89b42fd96c0fc0b13eaccc3--01c8c3cff4384958a2923d0c072ec618 <p>Note that, by default, only the time-parameter is automatically parameterized when building a digital-analog HEA. However, as described in the Hamiltonians tutorial, arbitrary interaction Hamiltonians can be easily built with the <code>hamiltonian_factory</code> function, with both customized or fully parameterized interactions, and these can be directly passed as the <code>entangler</code> for a customizable digital-analog HEA.</p> <pre><code>from qadence import hamiltonian_factory, Interaction, N, Register, hea\n\n# Build a parameterized neutral-atom Hamiltonian following a honeycomb_lattice:\nregister = Register.honeycomb_lattice(1, 1)\n\nentangler = hamiltonian_factory(\n    register,\n    interaction=Interaction.NN,\n    detuning=N,\n    interaction_strength=\"e\",\n    detuning_strength=\"n\"\n)\n\n# Build a fully parameterized Digital-Analog HEA:\nn_qubits = register.n_qubits\ndepth = 2\n\nansatz = hea(\n    n_qubits=register.n_qubits,\n    depth=depth,\n    operations=[RX, RY, RX],\n    entangler=entangler,\n    strategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_d83dfddc94f5441c8cb63b764755e2b3 cluster_0f4b31708883481ca01183e770f96fb4 86cbc0e0aa5545009ce3b06de2064230 0 909718207fe5470c9501f2b57145f91b RX(theta\u2080) 86cbc0e0aa5545009ce3b06de2064230--909718207fe5470c9501f2b57145f91b ea3bc56dea054765be7c704d7a9232d3 1 62c38f797da64e418c0535dc9e143484 RY(theta\u2086) 909718207fe5470c9501f2b57145f91b--62c38f797da64e418c0535dc9e143484 184eedb8e89a4d21aa441c36dd5a8cb0 RX(theta\u2081\u2082) 62c38f797da64e418c0535dc9e143484--184eedb8e89a4d21aa441c36dd5a8cb0 2e482002a3f241dfab11f46b1d71ae92 184eedb8e89a4d21aa441c36dd5a8cb0--2e482002a3f241dfab11f46b1d71ae92 2be510e202ed4b1a9407a7ebc6b34568 RX(theta\u2081\u2088) 2e482002a3f241dfab11f46b1d71ae92--2be510e202ed4b1a9407a7ebc6b34568 c0a48baba2904760aa9247467b228715 RY(theta\u2082\u2084) 2be510e202ed4b1a9407a7ebc6b34568--c0a48baba2904760aa9247467b228715 49da8523f6e442efba3d6a560d5b719c RX(theta\u2083\u2080) c0a48baba2904760aa9247467b228715--49da8523f6e442efba3d6a560d5b719c 4c92507c938347b2befe82f1a884a727 49da8523f6e442efba3d6a560d5b719c--4c92507c938347b2befe82f1a884a727 409b9f68ace24e419b3a1b70c8addb2b 4c92507c938347b2befe82f1a884a727--409b9f68ace24e419b3a1b70c8addb2b 9f2e7c687227429c9c08e0b36573abed 978c1d6ce93643b7875950c202a36b2b RX(theta\u2081) ea3bc56dea054765be7c704d7a9232d3--978c1d6ce93643b7875950c202a36b2b 42d60194f6f046d891cc48198c74eb7c 2 6bdfd4f094924296a3f0c1399270ab7d RY(theta\u2087) 978c1d6ce93643b7875950c202a36b2b--6bdfd4f094924296a3f0c1399270ab7d 7afb0a6c0c344cb28d4396327804d60f RX(theta\u2081\u2083) 6bdfd4f094924296a3f0c1399270ab7d--7afb0a6c0c344cb28d4396327804d60f 47e1de3bdf3246bdba39891e717b3357 7afb0a6c0c344cb28d4396327804d60f--47e1de3bdf3246bdba39891e717b3357 3296c2b3f9dc4fe092c7a7af134dc7a9 RX(theta\u2081\u2089) 47e1de3bdf3246bdba39891e717b3357--3296c2b3f9dc4fe092c7a7af134dc7a9 ff6d82ab90484a4db237ae644c7870f1 RY(theta\u2082\u2085) 3296c2b3f9dc4fe092c7a7af134dc7a9--ff6d82ab90484a4db237ae644c7870f1 0e35c9d85eb0445bae4ff417f884b4c3 RX(theta\u2083\u2081) ff6d82ab90484a4db237ae644c7870f1--0e35c9d85eb0445bae4ff417f884b4c3 8fa0139d08684eed9e8fb879002aa2aa 0e35c9d85eb0445bae4ff417f884b4c3--8fa0139d08684eed9e8fb879002aa2aa 8fa0139d08684eed9e8fb879002aa2aa--9f2e7c687227429c9c08e0b36573abed 82b7566ec9e44a35b213b098a6e05bc4 7518ff60c39543bfbbaff01bcb8fc2f3 RX(theta\u2082) 42d60194f6f046d891cc48198c74eb7c--7518ff60c39543bfbbaff01bcb8fc2f3 a655d44f56ce415f8f2288e5fb284229 3 29d7420019094c41ac9bdcf0c9d9f320 RY(theta\u2088) 7518ff60c39543bfbbaff01bcb8fc2f3--29d7420019094c41ac9bdcf0c9d9f320 d5341346744847bea8e1ca883626d50f RX(theta\u2081\u2084) 29d7420019094c41ac9bdcf0c9d9f320--d5341346744847bea8e1ca883626d50f 27ee644d904646ea852aee54b54150a4 HamEvo d5341346744847bea8e1ca883626d50f--27ee644d904646ea852aee54b54150a4 46afb918b96145bdb4e068dff1e5ef04 RX(theta\u2082\u2080) 27ee644d904646ea852aee54b54150a4--46afb918b96145bdb4e068dff1e5ef04 df36ed45182247f5ba8a72bebee0b7b4 RY(theta\u2082\u2086) 46afb918b96145bdb4e068dff1e5ef04--df36ed45182247f5ba8a72bebee0b7b4 716e483dd4b84046b39c1a7729e507ed RX(theta\u2083\u2082) df36ed45182247f5ba8a72bebee0b7b4--716e483dd4b84046b39c1a7729e507ed 97fe04ea29224605adcbb38874fceb94 HamEvo 716e483dd4b84046b39c1a7729e507ed--97fe04ea29224605adcbb38874fceb94 97fe04ea29224605adcbb38874fceb94--82b7566ec9e44a35b213b098a6e05bc4 709dad9884f44b86a3d20d93af4e8eda ad5b1959e44e4ef09accd21aff081b55 RX(theta\u2083) a655d44f56ce415f8f2288e5fb284229--ad5b1959e44e4ef09accd21aff081b55 07c348cd2c8f436d810d1d6489a573c8 4 e331af5f18a94cbaabfd7ff0a499922b RY(theta\u2089) ad5b1959e44e4ef09accd21aff081b55--e331af5f18a94cbaabfd7ff0a499922b 36e898e6bd754fe18aaee5cd132f36b1 RX(theta\u2081\u2085) e331af5f18a94cbaabfd7ff0a499922b--36e898e6bd754fe18aaee5cd132f36b1 eda3af3b5cd44592bf7d5fcfe91d27a5 t = theta_t\u2080 36e898e6bd754fe18aaee5cd132f36b1--eda3af3b5cd44592bf7d5fcfe91d27a5 2e1d909a654746c49ca105e2abadded3 RX(theta\u2082\u2081) eda3af3b5cd44592bf7d5fcfe91d27a5--2e1d909a654746c49ca105e2abadded3 e6281a162afd4a4e80c9ce59a7cec781 RY(theta\u2082\u2087) 2e1d909a654746c49ca105e2abadded3--e6281a162afd4a4e80c9ce59a7cec781 cd4d6410ed174ce59fb28b2061d7f831 RX(theta\u2083\u2083) e6281a162afd4a4e80c9ce59a7cec781--cd4d6410ed174ce59fb28b2061d7f831 d8da232d70804e258b48449c4df9699c t = theta_t\u2081 cd4d6410ed174ce59fb28b2061d7f831--d8da232d70804e258b48449c4df9699c d8da232d70804e258b48449c4df9699c--709dad9884f44b86a3d20d93af4e8eda dba6e09db96346cf9f2d03fc8c5a7e9a 70fc8815fc6e42e0927e5b6e7eb61bd8 RX(theta\u2084) 07c348cd2c8f436d810d1d6489a573c8--70fc8815fc6e42e0927e5b6e7eb61bd8 39f56a47e832406b8609740fc6b98c0e 5 78280e4655ea4ecb96a132917514fb53 RY(theta\u2081\u2080) 70fc8815fc6e42e0927e5b6e7eb61bd8--78280e4655ea4ecb96a132917514fb53 2535c067420345749c54eb38c081ccc2 RX(theta\u2081\u2086) 78280e4655ea4ecb96a132917514fb53--2535c067420345749c54eb38c081ccc2 67254f9c98174450b3c3de8d11de8c94 2535c067420345749c54eb38c081ccc2--67254f9c98174450b3c3de8d11de8c94 b87826343068416d830ca32a0fbb9d3b RX(theta\u2082\u2082) 67254f9c98174450b3c3de8d11de8c94--b87826343068416d830ca32a0fbb9d3b 373d1d89c9d543ac9a3e5d573e0359ac RY(theta\u2082\u2088) b87826343068416d830ca32a0fbb9d3b--373d1d89c9d543ac9a3e5d573e0359ac 1e7abfa873504599968c35c77b3d7a49 RX(theta\u2083\u2084) 373d1d89c9d543ac9a3e5d573e0359ac--1e7abfa873504599968c35c77b3d7a49 86433c33a3254587a7ce461d02226ec8 1e7abfa873504599968c35c77b3d7a49--86433c33a3254587a7ce461d02226ec8 86433c33a3254587a7ce461d02226ec8--dba6e09db96346cf9f2d03fc8c5a7e9a 1577b311e4e44ff59aaf9ee089d00e92 572eeb4cd52241a4ad3a3ebf1de893a9 RX(theta\u2085) 39f56a47e832406b8609740fc6b98c0e--572eeb4cd52241a4ad3a3ebf1de893a9 fcf5a9bc372a4a3a8ea1eb2292162855 RY(theta\u2081\u2081) 572eeb4cd52241a4ad3a3ebf1de893a9--fcf5a9bc372a4a3a8ea1eb2292162855 4923878b71444a55acf9f8903528b8bb RX(theta\u2081\u2087) fcf5a9bc372a4a3a8ea1eb2292162855--4923878b71444a55acf9f8903528b8bb 8a6de21a80c44dcb9fff50ad4469f420 4923878b71444a55acf9f8903528b8bb--8a6de21a80c44dcb9fff50ad4469f420 b56822aa40a644cd91f8e91fdd733509 RX(theta\u2082\u2083) 8a6de21a80c44dcb9fff50ad4469f420--b56822aa40a644cd91f8e91fdd733509 8ba8d94a8de6410cbd4821f9be11220d RY(theta\u2082\u2089) b56822aa40a644cd91f8e91fdd733509--8ba8d94a8de6410cbd4821f9be11220d 8e90f3e3adeb43c29d9548def8c9c37b RX(theta\u2083\u2085) 8ba8d94a8de6410cbd4821f9be11220d--8e90f3e3adeb43c29d9548def8c9c37b 7d89b1700c2a48baba70ab801c7d9243 8e90f3e3adeb43c29d9548def8c9c37b--7d89b1700c2a48baba70ab801c7d9243 7d89b1700c2a48baba70ab801c7d9243--1577b311e4e44ff59aaf9ee089d00e92"},{"location":"content/qml_constructors/#identity-initialized-ansatz","title":"Identity-initialized ansatz","text":"<p>It is widely known that parametrized quantum circuits are characterized by barren plateaus, where the gradient becomes exponentially small in the number of qubits. Here we include one of many techniques that have been proposed in recent years to mitigate this effect and facilitate <code>QNN</code>s training: Grant et al. showed that initializing the weights of a <code>QNN</code> so that each block of the circuit evaluates to identity reduces the effect of barren plateaus in the initial stage of training. In a similar fashion to <code>hea</code>, such circuit can be created via calling the associated function, <code>identity_initialized_ansatz</code>:</p> <pre><code>from qadence.constructors import identity_initialized_ansatz\nfrom qadence.draw import display\n\nn_qubits = 3\ndepth = 2\n\nansatz = identity_initialized_ansatz(n_qubits, depth)\n</code></pre> %3 cluster_f86427560e7a485c92ae71a2f3608451 BPMA-1 cluster_bbace832c7114d5ea13b7450f67cc4b3 BPMA-0 3f1b9b9b025e4069bbe55771379d8704 0 c153ffa6b032462eb1f9e7994f3b0b8f RX(iia_\u03b1\u2080\u2080) 3f1b9b9b025e4069bbe55771379d8704--c153ffa6b032462eb1f9e7994f3b0b8f a0d7218cbc6447bb9ab70c2c0987f948 1 12e0bc152498479783b1a47a75626199 RY(iia_\u03b1\u2080\u2083) c153ffa6b032462eb1f9e7994f3b0b8f--12e0bc152498479783b1a47a75626199 7ee0bc41b0e74665a9e7ec8adb14214c 12e0bc152498479783b1a47a75626199--7ee0bc41b0e74665a9e7ec8adb14214c 0133e751213849adb969226dab5efe2e 7ee0bc41b0e74665a9e7ec8adb14214c--0133e751213849adb969226dab5efe2e 3d1e09dbbbad42f699a89abd28a62d0c RX(iia_\u03b3\u2080\u2080) 0133e751213849adb969226dab5efe2e--3d1e09dbbbad42f699a89abd28a62d0c ddd92beaf5f44be19d4a685712c17e6b 3d1e09dbbbad42f699a89abd28a62d0c--ddd92beaf5f44be19d4a685712c17e6b ed0d8cc1426e469ebb4b830e28bbd96b ddd92beaf5f44be19d4a685712c17e6b--ed0d8cc1426e469ebb4b830e28bbd96b cb76390de85142b085a98dd2bedde431 RY(iia_\u03b2\u2080\u2083) ed0d8cc1426e469ebb4b830e28bbd96b--cb76390de85142b085a98dd2bedde431 854115da95424bf6a9315598eb0f863b RX(iia_\u03b2\u2080\u2080) cb76390de85142b085a98dd2bedde431--854115da95424bf6a9315598eb0f863b 79a6ae4c058b48fcb501cfa8e1c6ed72 RX(iia_\u03b1\u2081\u2080) 854115da95424bf6a9315598eb0f863b--79a6ae4c058b48fcb501cfa8e1c6ed72 20bbbe84d8b8444db7e843e411cd7b53 RY(iia_\u03b1\u2081\u2083) 79a6ae4c058b48fcb501cfa8e1c6ed72--20bbbe84d8b8444db7e843e411cd7b53 d8ec5de036eb48949259da7242f814ea 20bbbe84d8b8444db7e843e411cd7b53--d8ec5de036eb48949259da7242f814ea 04f463a66d9f4fc1906b77a992c2aeb0 d8ec5de036eb48949259da7242f814ea--04f463a66d9f4fc1906b77a992c2aeb0 941a759e1c3d4b38974082c12960ba0f RX(iia_\u03b3\u2081\u2080) 04f463a66d9f4fc1906b77a992c2aeb0--941a759e1c3d4b38974082c12960ba0f 9f2d57e49f11461e88bab9f9d7fe166f 941a759e1c3d4b38974082c12960ba0f--9f2d57e49f11461e88bab9f9d7fe166f 4c6decc5aef442daa5f6fcff58d3c0cd 9f2d57e49f11461e88bab9f9d7fe166f--4c6decc5aef442daa5f6fcff58d3c0cd e7c4bd26af5948e68ebf859007ad3ff9 RY(iia_\u03b2\u2081\u2083) 4c6decc5aef442daa5f6fcff58d3c0cd--e7c4bd26af5948e68ebf859007ad3ff9 d9e00de9e8684ee4acc5d3f6fef29a15 RX(iia_\u03b2\u2081\u2080) e7c4bd26af5948e68ebf859007ad3ff9--d9e00de9e8684ee4acc5d3f6fef29a15 12769e0df085465bab361c2f92b3543a d9e00de9e8684ee4acc5d3f6fef29a15--12769e0df085465bab361c2f92b3543a f12abf4c7ac34d158dd92dc77d2e7319 77acf8ce0ee54766b23e34391784d2ce RX(iia_\u03b1\u2080\u2081) a0d7218cbc6447bb9ab70c2c0987f948--77acf8ce0ee54766b23e34391784d2ce 80d3a4168d1a4db58b26146097f43c0f 2 1d44d54388814841ac14b73f0313e5a5 RY(iia_\u03b1\u2080\u2084) 77acf8ce0ee54766b23e34391784d2ce--1d44d54388814841ac14b73f0313e5a5 b44a9c17858b4313bd6d6d9003bb93ab X 1d44d54388814841ac14b73f0313e5a5--b44a9c17858b4313bd6d6d9003bb93ab b44a9c17858b4313bd6d6d9003bb93ab--7ee0bc41b0e74665a9e7ec8adb14214c efa81104025c470daa4805ae6b31db9d b44a9c17858b4313bd6d6d9003bb93ab--efa81104025c470daa4805ae6b31db9d e247b7b92f5446468963fdf9fb88ba59 RX(iia_\u03b3\u2080\u2081) efa81104025c470daa4805ae6b31db9d--e247b7b92f5446468963fdf9fb88ba59 0ce55d2d9b9947ceb2bc3480fd01f7c8 e247b7b92f5446468963fdf9fb88ba59--0ce55d2d9b9947ceb2bc3480fd01f7c8 27bf3cf6671a4eb0aae737af9ac8a604 X 0ce55d2d9b9947ceb2bc3480fd01f7c8--27bf3cf6671a4eb0aae737af9ac8a604 27bf3cf6671a4eb0aae737af9ac8a604--ed0d8cc1426e469ebb4b830e28bbd96b 6d8b94b9a57b4707b2954932de8024f0 RY(iia_\u03b2\u2080\u2084) 27bf3cf6671a4eb0aae737af9ac8a604--6d8b94b9a57b4707b2954932de8024f0 fbd373dab863408ab38d168aaaa5b476 RX(iia_\u03b2\u2080\u2081) 6d8b94b9a57b4707b2954932de8024f0--fbd373dab863408ab38d168aaaa5b476 b9b914fefe714b459999860769ec1aba RX(iia_\u03b1\u2081\u2081) fbd373dab863408ab38d168aaaa5b476--b9b914fefe714b459999860769ec1aba 3927a10a32404fe2b8fe8a0a4acc45e0 RY(iia_\u03b1\u2081\u2084) b9b914fefe714b459999860769ec1aba--3927a10a32404fe2b8fe8a0a4acc45e0 18bb4cf90a234fb482cef67752cb72c2 X 3927a10a32404fe2b8fe8a0a4acc45e0--18bb4cf90a234fb482cef67752cb72c2 18bb4cf90a234fb482cef67752cb72c2--d8ec5de036eb48949259da7242f814ea 25f1a6f1e5cc43ea99bb563396d6e501 18bb4cf90a234fb482cef67752cb72c2--25f1a6f1e5cc43ea99bb563396d6e501 253ccb9d09d94052b9cc09b7c98094f9 RX(iia_\u03b3\u2081\u2081) 25f1a6f1e5cc43ea99bb563396d6e501--253ccb9d09d94052b9cc09b7c98094f9 6c7e596cf40742aeb9af7d861da2a3b2 253ccb9d09d94052b9cc09b7c98094f9--6c7e596cf40742aeb9af7d861da2a3b2 9269d738b7844d53b6e67abd9ac54e02 X 6c7e596cf40742aeb9af7d861da2a3b2--9269d738b7844d53b6e67abd9ac54e02 9269d738b7844d53b6e67abd9ac54e02--4c6decc5aef442daa5f6fcff58d3c0cd b7dde63744244899b90b8f75b714d6ec RY(iia_\u03b2\u2081\u2084) 9269d738b7844d53b6e67abd9ac54e02--b7dde63744244899b90b8f75b714d6ec c0891f5f071b4620a50e0c1a84d1b551 RX(iia_\u03b2\u2081\u2081) b7dde63744244899b90b8f75b714d6ec--c0891f5f071b4620a50e0c1a84d1b551 c0891f5f071b4620a50e0c1a84d1b551--f12abf4c7ac34d158dd92dc77d2e7319 842cbe589c234464a129d1559c7b4dd4 0eba66ef9ece475fa3b3c05e67adff33 RX(iia_\u03b1\u2080\u2082) 80d3a4168d1a4db58b26146097f43c0f--0eba66ef9ece475fa3b3c05e67adff33 6bb123f22051480da957e78246b7d1a1 RY(iia_\u03b1\u2080\u2085) 0eba66ef9ece475fa3b3c05e67adff33--6bb123f22051480da957e78246b7d1a1 3348aa001c5d4841b1d141b7a22bb311 6bb123f22051480da957e78246b7d1a1--3348aa001c5d4841b1d141b7a22bb311 b50240e5d5dd4330a5d6c83247a3cb12 X 3348aa001c5d4841b1d141b7a22bb311--b50240e5d5dd4330a5d6c83247a3cb12 b50240e5d5dd4330a5d6c83247a3cb12--efa81104025c470daa4805ae6b31db9d 9bcb353a065d4afe802966d81f08a869 RX(iia_\u03b3\u2080\u2082) b50240e5d5dd4330a5d6c83247a3cb12--9bcb353a065d4afe802966d81f08a869 46308f56d82540f69af38372d2f84ebd X 9bcb353a065d4afe802966d81f08a869--46308f56d82540f69af38372d2f84ebd 46308f56d82540f69af38372d2f84ebd--0ce55d2d9b9947ceb2bc3480fd01f7c8 952fffc2e2a14a47b451ffe01e2ba6dc 46308f56d82540f69af38372d2f84ebd--952fffc2e2a14a47b451ffe01e2ba6dc 72d4599c908144679c4c6b332d4cbefc RY(iia_\u03b2\u2080\u2085) 952fffc2e2a14a47b451ffe01e2ba6dc--72d4599c908144679c4c6b332d4cbefc a43fb92f33ea42d1a8573b347726a2a4 RX(iia_\u03b2\u2080\u2082) 72d4599c908144679c4c6b332d4cbefc--a43fb92f33ea42d1a8573b347726a2a4 300fc16b69614427bcb9d3e545021abe RX(iia_\u03b1\u2081\u2082) a43fb92f33ea42d1a8573b347726a2a4--300fc16b69614427bcb9d3e545021abe 9438dfac0b4d484699032c83b0356280 RY(iia_\u03b1\u2081\u2085) 300fc16b69614427bcb9d3e545021abe--9438dfac0b4d484699032c83b0356280 d79b57ef2df043fba21e47cae78d2627 9438dfac0b4d484699032c83b0356280--d79b57ef2df043fba21e47cae78d2627 25d6a170eaee4bffbe880ea984583685 X d79b57ef2df043fba21e47cae78d2627--25d6a170eaee4bffbe880ea984583685 25d6a170eaee4bffbe880ea984583685--25f1a6f1e5cc43ea99bb563396d6e501 8917af56434749d6adfa925a9ebfb418 RX(iia_\u03b3\u2081\u2082) 25d6a170eaee4bffbe880ea984583685--8917af56434749d6adfa925a9ebfb418 a161b667f686414fb002e25b707ad63b X 8917af56434749d6adfa925a9ebfb418--a161b667f686414fb002e25b707ad63b a161b667f686414fb002e25b707ad63b--6c7e596cf40742aeb9af7d861da2a3b2 b264bf05cc1c424f9ec5483fbfe2ef67 a161b667f686414fb002e25b707ad63b--b264bf05cc1c424f9ec5483fbfe2ef67 1b5a55816f4942779de406f9d7a52805 RY(iia_\u03b2\u2081\u2085) b264bf05cc1c424f9ec5483fbfe2ef67--1b5a55816f4942779de406f9d7a52805 71eadf55fd834911afa80ade2b0b5f84 RX(iia_\u03b2\u2081\u2082) 1b5a55816f4942779de406f9d7a52805--71eadf55fd834911afa80ade2b0b5f84 71eadf55fd834911afa80ade2b0b5f84--842cbe589c234464a129d1559c7b4dd4"},{"location":"content/quantummodels/","title":"Quantum models","text":"<p>A quantum program can be expressed and executed using the <code>QuantumModel</code> type. It serves three primary purposes:</p> <p>Parameter handling: by conveniently handling and embedding the two parameter types that Qadence supports: feature and variational (see more details in the previous section).</p> <p>Differentiability: by enabling a differentiable backend that supports two differentiable modes: automatic differentiation (AD) and parameter shift rules (PSR). The former is used general differentiation in statevector simulators based on PyTorch and JAX. The latter is a quantum specific method used to differentiate gate parameters, and is enabled for all backends.</p> <p>Execution: by defining which backend the program is expected to be executed on. Qadence supports circuit compilation to the native backend representation.</p> <p>Backends</p> <p>The goal is for quantum models to be executed seemlessly on a number of different purpose backends: simulators, emulators or real hardware. By default, Qadence executes on the PyQTorch backend which implements a state vector simulator. Currently, this is the most feature rich backend. The Pulser backend is being developed, and currently supports a more limited set of functionalities (pulse sequences on programmable neutral atom arrays). The Horqrux backend, built on JAX, is also available, but currently not supported with the <code>QuantumModel</code> interface. For more information see the backend section.</p> <p>The base <code>QuantumModel</code> exposes the following methods:</p> <ul> <li><code>QuantumModel.run()</code>: To extract the wavefunction after circuit execution. Not supported by all backends.</li> <li><code>QuantumModel.sample()</code>: Sample a bitstring from the resulting quantum state after circuit execution. Supported by all backends.</li> <li><code>QuantumModel.expectation()</code>: Compute the expectation value of an observable.</li> </ul> <p>Every <code>QuantumModel</code> is an instance of a <code>torch.nn.Module</code> that enables differentiability for its <code>expectation</code> method. For statevector simulators, AD also works for the statevector itself.</p> <p>To construct a <code>QuantumModel</code>, the program block must first be initialized into a <code>QuantumCircuit</code> instance by combining it with a <code>Register</code>. An integer number can also be passed for the total number of qubits, which instantiates a <code>Register</code> automatically. The qubit register also includes topological information on the qubit layout, essential for digital-analog computations. However, we will explore that in a later tutorial. For now, let's construct a simple parametrized quantum circuit.</p> <pre><code>from qadence import QuantumCircuit, RX, RY, chain, kron\nfrom qadence import FeatureParameter, VariationalParameter\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, theta), RY(1, theta)),\n    kron(RX(0, phi), RY(1, phi)),\n)\n\ncircuit = QuantumCircuit(2, block)\nunique_params = circuit.unique_parameters\n</code></pre> <pre><code>unique_params = [theta, phi]\n</code></pre> <p>The model can then be instantiated. Similarly to the direct execution functions shown in the previous tutorial, the <code>run</code>, <code>sample</code> and <code>expectation</code> methods are available directly from the model.</p> <pre><code>import torch\nfrom qadence import QuantumModel, PI, Z\n\nobservable = Z(0) + Z(1)\n\nmodel = QuantumModel(circuit, observable)\n\nvalues = {\"phi\": torch.tensor([PI, PI/2])}\n\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\n</code></pre> <pre><code>wf = tensor([[ 0.0446+0.0000j, -0.2065+0.0000j,  0.0000+0.2065j,  0.0000-0.9554j],\n        [ 0.2935+0.0000j,  0.4554+0.0000j,  0.0000-0.4554j,  0.0000-0.7065j]])\nxs = [OrderedCounter({'11': 96, '10': 3, '01': 1}), OrderedCounter({'11': 50, '10': 25, '01': 18, '00': 7})]\nex = tensor([[-1.8215],\n        [-0.8258]])\n</code></pre> <p>By default, the <code>forward</code> method of <code>QuantumModel</code> calls <code>model.run()</code>. To define custom quantum models, the best way is to inherit from <code>QuantumModel</code> and override the <code>forward</code> method, as typically done with custom PyTorch Modules.</p> <p>The <code>QuantumModel</code> class provides convenience methods to manipulate parameters. Being a <code>torch.nn.Module</code>, all torch methods are also available. As shown in the example below, you can pass, check and reset the model parameters. When entering new values for the <code>VariationalParameter</code>, they must match the number of existing variables.</p> <pre><code># To pass onto a torch optimizer\nparameter_generator = model.parameters()\n\n# Number of variational parameters\nnum_vparams = model.num_vparams\n\n# Dictionary to see all the parameter values\nparams_values = model.params\n\n# Dictionary to easily inspect variational parameters (parameters with gradient)\nvparams_values = model.vparams\n\n\n# To reset current variational parameter to other values\nmodel.reset_vparams([torch.rand(1).item()])\n\nvparams_values = model.vparams\n</code></pre> <pre><code>old vparams_values = OrderedDict([('theta', tensor([0.4257]))])\nnew vparams_values = OrderedDict([('theta', tensor([0.7188]))])\n</code></pre>"},{"location":"content/quantummodels/#backend-configuration-in-quantum-models","title":"Backend configuration in quantum models","text":"<p>When initializing a quantum model, available configuration options are determined by the backend, with current support for <code>PyQTorch</code> and <code>Pulser</code>. Information on each configuration option can be found with <code>model.show_config</code> as in below example:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, RX, RY, kron\nfrom qadence import FeatureParameter, VariationalParameter\nfrom qadence import BackendConfiguration\nfrom qadence import BackendName, DiffMode\n\n# Create a quantum circuit\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\nblock = kron(RX(0, theta), RY(1, phi))\ncircuit = QuantumCircuit(2, block)\n\n# Choose your backend (PYQTORCH or PULSER)\nbackend=BackendName.PYQTORCH\n# backend=BackendName.PULSER\n\nmodel = QuantumModel(circuit, backend=backend, diff_mode=DiffMode.GPSR)\n# Check your available configuration options and current values\n</code></pre> <pre><code>Name: use_sparse_observable - Type: bool - Current value: False - Default value: False\nName: use_gradient_checkpointing - Type: bool - Current value: False - Default value: False\nName: use_single_qubit_composition - Type: bool - Current value: True - Default value: False\nName: transpilation_passes - Type: list[Callable] | None - Current value: None - Default value: None\nName: algo_hevo - Type: AlgoHEvo - Current value: EXP - Default value: EXP\nName: ode_solver - Type: SolverType - Current value: dp5_se - Default value: dp5_se\nName: n_steps_hevo - Type: int - Current value: 100 - Default value: 100\nName: loop_expectation - Type: bool - Current value: False - Default value: False\nName: noise - Type: NoiseHandler | None - Current value: None - Default value: None\nName: dropout_probability - Type: float - Current value: 0.0 - Default value: 0.0\nName: dropout_mode - Type: DropoutMode - Current value: rotational_dropout - Default value: rotational_dropout\nName: n_eqs - Type: int | None - Current value: None - Default value: None\nName: shift_prefac - Type: float - Current value: 0.5 - Default value: 0.5\nName: gap_step - Type: float - Current value: 1.0 - Default value: 1.0\nName: lb - Type: float | None - Current value: None - Default value: None\nName: ub - Type: float | None - Current value: None - Default value: None\n</code></pre> <p>The configuration of the quantum model can be changed by passing <code>options_names</code> and <code>value</code> in dictionary format. You can update the existing configuration values using <code>model.change_config()</code>.</p> <pre><code># change dropout_probability from 0 to 0.3\nmodel.change_config({\"dropout_probability\": 0.3})\n# shows modified configuration\n</code></pre> <pre><code>Name: use_sparse_observable - Type: bool - Current value: False - Default value: False\nName: use_gradient_checkpointing - Type: bool - Current value: False - Default value: False\nName: use_single_qubit_composition - Type: bool - Current value: True - Default value: False\nName: transpilation_passes - Type: list[Callable] | None - Current value: None - Default value: None\nName: algo_hevo - Type: AlgoHEvo - Current value: EXP - Default value: EXP\nName: ode_solver - Type: SolverType - Current value: dp5_se - Default value: dp5_se\nName: n_steps_hevo - Type: int - Current value: 100 - Default value: 100\nName: loop_expectation - Type: bool - Current value: False - Default value: False\nName: noise - Type: NoiseHandler | None - Current value: None - Default value: None\nName: dropout_probability - Type: float - Current value: 0.3 - Default value: 0.0\nName: dropout_mode - Type: DropoutMode - Current value: rotational_dropout - Default value: rotational_dropout\nName: n_eqs - Type: int | None - Current value: None - Default value: None\nName: shift_prefac - Type: float - Current value: 0.5 - Default value: 0.5\nName: gap_step - Type: float - Current value: 1.0 - Default value: 1.0\nName: lb - Type: float | None - Current value: None - Default value: None\nName: ub - Type: float | None - Current value: None - Default value: None\n</code></pre>"},{"location":"content/quantummodels/#model-output","title":"Model output","text":"<p>The output of a quantum model is typically encoded in the measurement of an expectation value. In Qadence, one way to customize the number of outputs is by batching the number of observables at model creation by passing a list of blocks.</p> <pre><code>from torch import tensor\nfrom qadence import chain, kron, VariationalParameter, FeatureParameter\nfrom qadence import QuantumModel, QuantumCircuit, PI, Z, RX, CNOT\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, phi), RX(1, phi)),\n    CNOT(0, 1)\n)\n\ncircuit = QuantumCircuit(2, block)\n\nmodel = QuantumModel(circuit, [Z(0), Z(0) + Z(1)])\n\nvalues = {\"phi\": tensor(PI)}\n\nex = model.expectation(values)\n</code></pre> <pre><code>ex = tensor([[-1.0000e+00, -7.4988e-33]])\n</code></pre> <p>As mentioned in the previous tutorial, blocks can also be arbitrarily parameterized through multiplication, which allows the inclusion of trainable parameters in the definition of the observable.</p> <pre><code>from qadence import I, Z\n\na = VariationalParameter(\"a\")\nb = VariationalParameter(\"b\")\n\n# Magnetization with a trainable shift and scale\nobservable = a * I(0) + b * Z(0)\n\nmodel = QuantumModel(circuit, observable)\n</code></pre>"},{"location":"content/quantummodels/#quantum-neural-network-qnn","title":"Quantum Neural Network (QNN)","text":"<p>The <code>QNN</code> is a subclass of the <code>QuantumModel</code> geared towards quantum machine learning and parameter optimisation. See the quantum machine learning section section or the <code>QNN</code> API reference for more detailed information. There are three main differences in interface when compared with the <code>QuantumModel</code>:</p> <ul> <li>It is initialized with a list of the input parameter names, and then supports direct <code>torch.Tensor</code> inputs instead of the values dictionary shown above. The ordering of the input values should respect the order given in the input names.</li> <li>Passing an observable is mandatory.</li> <li>The <code>forward</code> method calls <code>model.expectation()</code>.</li> </ul> <pre><code>from torch import tensor\nfrom qadence import chain, kron, VariationalParameter, FeatureParameter\nfrom qadence import QNN, QuantumCircuit, PI, Z, RX, RY, CNOT\n\ntheta = FeatureParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, phi), RX(1, phi)),\n    kron(RY(0, theta), RY(1, theta)),\n    CNOT(0, 1)\n)\n\ncircuit = QuantumCircuit(2, block)\nobservable = Z(0) + Z(1)\n\nmodel = QNN(circuit, observable, inputs = [\"phi\", \"theta\"])\n\n# \"phi\" = PI, PI/2, \"theta\" = 0.0, 1.0\nvalues = tensor([[PI, 0.0], [PI/2, 1.0]])\n\nex = model(values)\n</code></pre> <pre><code>ex = tensor([[-7.4988e-33],\n        [ 1.1102e-16]])\n</code></pre>"},{"location":"content/register/","title":"Quantum registers","text":"<p>In Qadence, quantum programs can be executed by specifying the layout of a register of resources as a lattice. Built-in <code>Register</code> types can be used or constructed for arbitrary topologies. Common register topologies are available and illustrated in the plot below.</p> 2025-04-04T13:33:21.805838 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"content/register/#building-and-drawing-registers","title":"Building and drawing registers","text":"<p>Built-in topologies are directly accessible in the <code>Register</code> methods:</p> <pre><code>from qadence import Register\n\nreg = Register.all_to_all(n_qubits = 4)\nreg_line = Register.line(n_qubits = 4)\nreg_circle = Register.circle(n_qubits = 4)\nreg_squre = Register.square(qubits_side = 2)\nreg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\nreg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\nreg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n</code></pre> <p>The <code>Register</code> class builds on top of the NetworkX <code>Graph</code>, and the graphs can be visualized with the <code>reg.draw()</code> method</p> <p>Qubit coordinates are saved as node properties in the underlying NetworkX graph, but can be accessed directly with the <code>coords</code> property.</p> <p><pre><code>reg = Register.square(2)\nprint(reg.coords)\n</code></pre> <pre><code>{0: (0.5, -0.5), 1: (0.5, 0.5), 2: (-0.5, 0.5), 3: (-0.5, -0.5)}\n</code></pre>  By default, the coords are scaled such that the minimum distance between any two qubits is 1, unless the register is created directly from specific coordinates as shown below. The <code>spacing</code> argument can be used to set the minimum spacing. The <code>rescale_coords</code> method can be used to create a new register by rescaling the coordinates of an already created register.</p> <pre><code>scaled_reg_1 = Register.square(2, spacing = 4.0)\nscaled_reg_2 = reg.rescale_coords(scaling = 4.0)\nprint(scaled_reg_1.coords)\nprint(scaled_reg_2.coords)\n</code></pre> <pre><code>{0: (2.0, -2.0), 1: (2.0, 2.0), 2: (-2.0, 2.0), 3: (-2.0, -2.0)}\n{0: (2.0, -2.0), 1: (2.0, 2.0), 2: (-2.0, 2.0), 3: (-2.0, -2.0)}\n</code></pre> <p>The distance between qubits can also be directly accessed with the <code>distances</code> and <code>edge_distances</code> properties.</p> <pre><code>print(reg.distances)\nprint(reg.edge_distances)\n</code></pre> <pre><code>Distance between all qubit pairs:\n{(0, 1): 1.0, (0, 2): 1.4142135623730951, (0, 3): 1.0, (1, 2): 1.0, (1, 3): 1.4142135623730951, (2, 3): 1.0}\nDistance between qubits connect by an edge in the graph\n{(0, 1): 1.0, (0, 3): 1.0, (1, 2): 1.0, (2, 3): 1.0}\n</code></pre> <p>By calling the <code>Register</code> directly, either the number of nodes or a specific graph can be given as input. If passing a custom graph directly, the node positions will not be defined automatically, and should be previously saved in the <code>\"pos\"</code> node property. If not, <code>reg.coords</code> will return empty tuples and all distances will be 0.</p> <pre><code>import networkx as nx\n\n# Same as Register.all_to_all(n_qubits = 2):\nreg = Register(2)\n\n# Register from a custom graph:\ngraph = nx.complete_graph(3)\n\n# Set node positions, in this case a simple line:\nfor i, node in enumerate(graph.nodes):\n    graph.nodes[node][\"pos\"] = (1.0 * i, 0.0)\n\nreg = Register(graph)\n\nprint(reg.distances)\n</code></pre> <pre><code>{(0, 1): 1.0, (0, 2): 2.0, (1, 2): 1.0}\n</code></pre> <p>Alternatively, arbitrarily shaped registers can also be constructed by providing the node coordinates. In this case, there will be no edges automatically created in the connectivity graph.</p> <pre><code>import numpy as np\nfrom qadence import Register, PI\n\nreg = Register.from_coordinates(\n    [(x, np.sin(x)) for x in np.linspace(0, 2*PI, 10)]\n)\n\nreg.draw(show=False)\n</code></pre> 2025-04-04T13:33:22.002218 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/ <p>Units for qubit coordinates</p> <p>In general, Qadence makes no assumption about the units for qubit coordinates and distances. However, if used in the context of a Hamiltonian coefficient, care should be taken by the user to guarantee the quantity \\(H.t\\) is dimensionless for exponentiation in the PyQTorch backend, where it is assumed that \\(\\hbar = 1\\). For registers passed to the Pulser backend, coordinates are in \\(\\mu \\textrm{m}\\).</p>"},{"location":"content/register/#connectivity-graphs","title":"Connectivity graphs","text":"<p>Register topology is often assumed in digital simulations to be an all-to-all qubit connectivity. When running on real devices that enable the digital-analog computing paradigm, qubit interactions must be specified either by specifying distances between qubits, or by defining edges in the register connectivity graph.</p> <p>The abstract graph nodes and edges are accessible for direct usage.</p> <pre><code>from qadence import Register\n\nreg = Register.rectangular_lattice(2,3)\n</code></pre> <pre><code>reg.nodes = NodeView((0, 1, 2, 3, 4, 5))\nreg.edges = EdgeView([(0, 2), (0, 1), (1, 3), (2, 4), (2, 3), (3, 5), (4, 5)])\n</code></pre> <p>There is also an <code>all_node_pairs</code> property for convenience:</p> <pre><code>print(reg.all_node_pairs)\n</code></pre> <pre><code>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)]\n</code></pre> <p>More details about the usage of <code>Register</code> types in the digital-analog paradigm can be found in the digital-analog basics section.</p>"},{"location":"content/serializ_and_prep/","title":"Serialization","text":"<p>Qadence offers convenience functions for serializing and deserializing any quantum program. This is useful for storing quantum programs and sending them for execution over the network via an API.</p> <p>Note</p> <p>Qadence currently uses a custom JSON serialization as interchange format. Support for QASM format for digital quantum programs is currently under consideration.</p> <ul> <li><code>serialize/deserialize</code>: serialize and deserialize a Qadence object into a dictionary</li> <li><code>save/load</code>: save and load a Qadence object to a file with one of the supported   formats. Currently, these are <code>.json</code> and the PyTorch-compatible <code>.pt</code> format.</li> </ul> <p>Let's start with serialization into a dictionary.</p> <pre><code>import torch\nfrom qadence import QuantumCircuit, QuantumModel, DiffMode\nfrom qadence import chain, hamiltonian_factory, feature_map, hea, Z\nfrom qadence.serialization import serialize, deserialize\n\nn_qubits = 4\n\nmy_block = chain(feature_map(n_qubits, param=\"x\"), hea(n_qubits, depth=2))\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n\n# Use the block defined above to create a quantum circuit\n# serialize/deserialize it\nqc = QuantumCircuit(n_qubits, my_block)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n# Let's wrap it in a QuantumModel\n# and serialize it\nqm = QuantumModel(qc, obs, diff_mode=DiffMode.AD)\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n\n# Check if the loaded QuantumModel returns the same expectation\nvalues = {\"x\": torch.rand(10)}\nassert torch.allclose(qm.expectation(values=values), qm_deserialized.expectation(values=values))\n</code></pre> <p>Finally, we can save the quantum circuit and the model with the two supported formats.</p> <pre><code>from qadence.serialization import serialize, deserialize, save, load, SerializationFormat\n\nqc_fname = \"circuit\"\nsave(qc, folder=\".\", file_name=qc_fname, format=SerializationFormat.PT)\nloaded_qc = load(f\"{qc_fname}.pt\")\nassert qc == loaded_qc\n\nqm_fname = \"model\"\nsave(qm, folder=\".\", file_name=qm_fname, format=SerializationFormat.JSON)\nmodel = load(f\"{qm_fname}.json\")\nassert isinstance(model, QuantumModel)\n</code></pre>"},{"location":"content/state_conventions/","title":"State Conventions","text":"<p>Here is an overview of the state conventions used in Qadence together with practical examples.</p>"},{"location":"content/state_conventions/#qubit-register-order","title":"Qubit register order","text":"<p>Qubit registers in quantum computing are often indexed in increasing or decreasing order from left to right. In Qadence, the convention is qubit indexation in increasing order. For example, a register of four qubits in bra-ket notation reads:</p> \\[|q_0, q_1, q_2, q_3\\rangle\\] <p>Furthermore, when displaying a quantum circuit, qubits are ordered from top to bottom.</p>"},{"location":"content/state_conventions/#basis-state-order","title":"Basis state order","text":"<p>Basis state ordering refers to how basis states are ordered when considering the conversion from bra-ket notation to the standard linear algebra basis. In Qadence, basis states are ordered in the following manner:</p> \\[ \\begin{align} |00\\rangle = [1, 0, 0, 0]^T\\\\ |01\\rangle = [0, 1, 0, 0]^T\\\\ |10\\rangle = [0, 0, 1, 0]^T\\\\ |11\\rangle = [0, 0, 0, 1]^T \\end{align} \\]"},{"location":"content/state_conventions/#endianness","title":"Endianness","text":"<p>Endianness refers to the storage convention for binary information (in bytes) in a classical memory register. In quantum computing, information is either stored in bits or in qubits. The most commonly used conventions are:</p> <ul> <li>A big-endian system stores the most significant bit of a binary word at the smallest memory address.</li> <li>A little-endian system stores the least significant bit of a binary word at the smallest memory address.</li> </ul> <p>Given the register convention in Qadence, the integer \\(2\\) written in binary big-endian as \\(10\\) can be encoded in a qubit register in both big-endian as \\(|10\\rangle\\) or little-endian as \\(|01\\rangle\\).</p> <p>The convention for Qadence is big-endian.</p>"},{"location":"content/state_conventions/#quantum-states","title":"Quantum states","text":"<p>In practical scenarios, conventions regarding register order, basis state order and endianness are very much intertwined, and identical results can be obtained by fixing or varying any of them. In Qadence, we assume that qubit ordering and basis state ordering is fixed, and allow an <code>endianness</code> argument that can be passed to control the expected result. Here are a few examples:</p> <p>A simple and direct way to exemplify the endianness convention is using convenience functions for state preparation.</p> <p>Bitstring convention as inputs</p> <p>When a bitstring is passed as input to a function for state preparation, it has to be understood in big-endian convention.</p> <pre><code>from qadence import Endianness, product_state\n\n# The state |10&gt;, the 3rd basis state.\nstate_big = product_state(\"10\", endianness=Endianness.BIG) # or just \"Big\"\n\n# The state |01&gt;, the 2nd basis state.\nstate_little = product_state(\"10\", endianness=Endianness.LITTLE) # or just \"Little\"\n</code></pre> <pre><code>State in big endian = tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\nState in little endian = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Here, a bitword expressed as a Python string to encode the integer 2 in big-endian is used to create the respective basis state in both conventions. However, note that the same results can be obtained by fixing the endianness convention as big-endian (thus creating the state \\(|10\\rangle\\) in both cases), and changing the basis state ordering. A similar argument holds for fixing both endianness and basis state ordering and simply changing the qubit index order.</p> <p>Another example where endianness directly comes into play is when measuring a register. A big- or little-endian measurement will choose the first or the last qubit, respectively, as the most significant bit. Let's see this in an example:</p> <pre><code>from qadence import I, H, sample\n\n# Create superposition state: |00&gt; + |01&gt; (normalized)\nblock = I(0) @ H(1)  # Identity on qubit 0, Hadamard on qubit 1\n\n# Generate bitword samples following both conventions\n# Samples \"00\" and \"01\"\nresult_big = sample(block, endianness=Endianness.BIG)\n# Samples \"00\" and \"10\"\nresult_little = sample(block, endianness=Endianness.LITTLE)\n</code></pre> <pre><code>Sample in big endian = [OrderedCounter({'00': 58, '01': 42})]\nSample in little endian = [Counter({'10': 53, '00': 47})]\n</code></pre> <p>In Qadence, endianness can be flipped for many relevant objects:</p> <pre><code>from qadence import invert_endianness\n\n# Equivalent to sampling in little-endian.\nflip_big_sample = invert_endianness(result_big)\n\n# Equivalent to a state created in little-endian.\nflip_big_state = invert_endianness(state_big)\n</code></pre> <pre><code>Flipped sample = [Counter({'00': 58, '10': 42})]\nFlipped state = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"content/state_conventions/#quantum-operations","title":"Quantum operations","text":"<p>When looking at the matricial form of quantum operations, the usage of the term endianness becomes slightly abusive. To exemplify, we may consider the <code>CNOT</code> operation with <code>control = 0</code> and <code>target = 1</code>. This operation is often described with two different matrices:</p> \\[ \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} \\qquad \\text{or} \\qquad \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] <p>The difference can be easily explained either by considering a different ordering of the qubit indices, or a different ordering of the basis states. In Qadence, both can be retrieved through the <code>endianness</code> argument:</p> <pre><code>from qadence import block_to_tensor, CNOT\n\nmatrix_big = block_to_tensor(CNOT(0, 1), endianness=Endianness.BIG)\nmatrix_little = block_to_tensor(CNOT(0, 1), endianness=Endianness.LITTLE)\n</code></pre> <pre><code>CNOT matrix in big endian =\n\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\n\nCNOT matrix in little endian =\n\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre>"},{"location":"content/state_conventions/#backends","title":"Backends","text":"<p>An important part of having clear state conventions is that we need to make sure our results are consistent accross different computational backends, which may have their own conventions. In Qadence, this is taken care of automatically: by calling operations for different backends, the result is expected to be equivalent up to qubit ordering.</p> <pre><code>from qadence import BackendName, RX, run, sample, PI\n\n# RX(PI/4) on qubit 1\nn_qubits = 2\nop = RX(1, PI/4)\n</code></pre> <pre><code>Same sampling order in big endian:\n\nOn PyQTorch = [OrderedCounter({'00': 84, '01': 16})]\nOn Pulser = [Counter({'00': 87, '01': 13})]\n\nSame wavefunction order:\n\nOn PyQTorch = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Pulser = tensor([[0.9239+0.0000j, 0.0000-0.3826j, 0.0000+0.0000j, 0.0000+0.0000j]])\n</code></pre>"},{"location":"content/state_init/","title":"State initialization","text":"<p>Qadence offers convenience routines for preparing initial quantum states. These routines are divided into two approaches:</p> <ul> <li>As a dense matrix.</li> <li>From a suitable quantum circuit. This is available for every backend and it should be added in front of the desired quantum circuit to simulate.</li> </ul> <p>Let's illustrate the usage of the state preparation routine.</p> <pre><code>from qadence import random_state, product_state, is_normalized, StateGeneratorType\n\n# Random initial state.\n# the default `type` is StateGeneratorType.HaarMeasureFast\nstate = random_state(n_qubits=2, type=StateGeneratorType.RANDOM_ROTATIONS)\n\n# Check the normalization.\nassert is_normalized(state)\n\n# Product state from a given bitstring.\n# NB: Qadence follows the big endian convention.\nstate = product_state(\"01\")\n</code></pre> <pre><code>Random initial state generated with rotations:\n\nstate = [0.58439368+0.j         0.7511167 +0.j         0.        -0.18857704j\n 0.        -0.24237662j]\n\nProduct state corresponding to bitstring '01':\n\nstate = [0.+0.j 1.+0.j 0.+0.j 0.+0.j]\n</code></pre> <p>Now we see how to generate the product state corresponding to the one above with a suitable quantum circuit.</p> <p><pre><code>from qadence import product_block, tag, hea, QuantumCircuit\nfrom qadence.draw import display\n\nstate_prep_block = product_block(\"01\")\n# display(state_prep_block)\n\n# Let's now prepare a circuit.\nn_qubits = 4\n\nstate_prep_block = product_block(\"0001\")\ntag(state_prep_block, \"Prep block\")\n\ncircuit_block = tag(hea(n_qubits, depth = 2), \"Circuit block\")\n\nqc_with_state_prep = QuantumCircuit(n_qubits, state_prep_block, circuit_block)\n</code></pre> %3 cluster_42b987aee0e145599f0505e67416d347 Circuit block cluster_12246ae069bd43fbae47157c07d5c92f Prep block 6e8dd027077d4ec0b48b5111e624cb02 0 69f9a648d295487fb92b8b2fe19eea3f 6e8dd027077d4ec0b48b5111e624cb02--69f9a648d295487fb92b8b2fe19eea3f dda3a8843d644cb8945d8e9b91760247 1 7b6f4cd13b54477b911ea6b76d1b6157 RX(theta\u2080) 69f9a648d295487fb92b8b2fe19eea3f--7b6f4cd13b54477b911ea6b76d1b6157 ed4bf0305ee6497181b6b61288d74391 RY(theta\u2084) 7b6f4cd13b54477b911ea6b76d1b6157--ed4bf0305ee6497181b6b61288d74391 44438ce787ef4f9d8e9ef6968f50c13a RX(theta\u2088) ed4bf0305ee6497181b6b61288d74391--44438ce787ef4f9d8e9ef6968f50c13a 81f6dc1b719e460f9c4ddb6c95dd086b 44438ce787ef4f9d8e9ef6968f50c13a--81f6dc1b719e460f9c4ddb6c95dd086b 417e3d6d26884466bf34068c644e0c48 81f6dc1b719e460f9c4ddb6c95dd086b--417e3d6d26884466bf34068c644e0c48 2348f7d5ac204ed8a422d3283f3a6312 RX(theta\u2081\u2082) 417e3d6d26884466bf34068c644e0c48--2348f7d5ac204ed8a422d3283f3a6312 f44b537d748b4294b4337e03f5cc0bb0 RY(theta\u2081\u2086) 2348f7d5ac204ed8a422d3283f3a6312--f44b537d748b4294b4337e03f5cc0bb0 2f8162d263d14222b8f355bc6e2c5831 RX(theta\u2082\u2080) f44b537d748b4294b4337e03f5cc0bb0--2f8162d263d14222b8f355bc6e2c5831 75aaa75fd28a470c94c087a06c0ee32e 2f8162d263d14222b8f355bc6e2c5831--75aaa75fd28a470c94c087a06c0ee32e 8cb25009e487402ba10b924f1de7ca85 75aaa75fd28a470c94c087a06c0ee32e--8cb25009e487402ba10b924f1de7ca85 1c557cba5a17424ca4d21b2e308b139e 8cb25009e487402ba10b924f1de7ca85--1c557cba5a17424ca4d21b2e308b139e a34f9b9730694ebf87d3725220a407ed 552554a8353b4234b09e11ee2cc7e46b dda3a8843d644cb8945d8e9b91760247--552554a8353b4234b09e11ee2cc7e46b ed2b40f4f87f4dfe9a7b1c2aa4b0cedb 2 1054d4ed07d94c9ba80e206272877043 RX(theta\u2081) 552554a8353b4234b09e11ee2cc7e46b--1054d4ed07d94c9ba80e206272877043 72b46bb0e7834a3a949df860ce7246c0 RY(theta\u2085) 1054d4ed07d94c9ba80e206272877043--72b46bb0e7834a3a949df860ce7246c0 06db1a35d7774d8b9f07bfc1abb970b4 RX(theta\u2089) 72b46bb0e7834a3a949df860ce7246c0--06db1a35d7774d8b9f07bfc1abb970b4 65bbe9a5b3074f0ea1e5fbd2b4b12598 X 06db1a35d7774d8b9f07bfc1abb970b4--65bbe9a5b3074f0ea1e5fbd2b4b12598 65bbe9a5b3074f0ea1e5fbd2b4b12598--81f6dc1b719e460f9c4ddb6c95dd086b 2de8db6ffdc74e078a60c4a7274644c6 65bbe9a5b3074f0ea1e5fbd2b4b12598--2de8db6ffdc74e078a60c4a7274644c6 fae4e93803ab47efb9a77a532d047bc0 RX(theta\u2081\u2083) 2de8db6ffdc74e078a60c4a7274644c6--fae4e93803ab47efb9a77a532d047bc0 df6fd412f1b7476994da5599e67d8106 RY(theta\u2081\u2087) fae4e93803ab47efb9a77a532d047bc0--df6fd412f1b7476994da5599e67d8106 e493e99481c94c488478c1f574b71402 RX(theta\u2082\u2081) df6fd412f1b7476994da5599e67d8106--e493e99481c94c488478c1f574b71402 aba98da96b7442c888f549f0e3dd30d9 X e493e99481c94c488478c1f574b71402--aba98da96b7442c888f549f0e3dd30d9 aba98da96b7442c888f549f0e3dd30d9--75aaa75fd28a470c94c087a06c0ee32e cc656ac9c80d4a4e8623e356cab17c47 aba98da96b7442c888f549f0e3dd30d9--cc656ac9c80d4a4e8623e356cab17c47 cc656ac9c80d4a4e8623e356cab17c47--a34f9b9730694ebf87d3725220a407ed 17eb7d78ca5641e29bc08ceb7bbe6ef1 68f7bea5da0c488380eea4151d6937e5 ed2b40f4f87f4dfe9a7b1c2aa4b0cedb--68f7bea5da0c488380eea4151d6937e5 83de104eadf74ff3a739a80252743a4e 3 313f6b4056fa4a9b870a29f28dca2b2e RX(theta\u2082) 68f7bea5da0c488380eea4151d6937e5--313f6b4056fa4a9b870a29f28dca2b2e c1e853bd71db4f50aa7bb338d68dd854 RY(theta\u2086) 313f6b4056fa4a9b870a29f28dca2b2e--c1e853bd71db4f50aa7bb338d68dd854 9260f092030641f0a6ed0e76642ef3c7 RX(theta\u2081\u2080) c1e853bd71db4f50aa7bb338d68dd854--9260f092030641f0a6ed0e76642ef3c7 66a452a7865b4f4887d5af6e37f70b0c 9260f092030641f0a6ed0e76642ef3c7--66a452a7865b4f4887d5af6e37f70b0c bca4cf0cbc0a4444ac440f7137d5bc00 X 66a452a7865b4f4887d5af6e37f70b0c--bca4cf0cbc0a4444ac440f7137d5bc00 bca4cf0cbc0a4444ac440f7137d5bc00--2de8db6ffdc74e078a60c4a7274644c6 f7392292edf64e19be23c004927c1687 RX(theta\u2081\u2084) bca4cf0cbc0a4444ac440f7137d5bc00--f7392292edf64e19be23c004927c1687 8b8b786b44eb4cee9254d7e5c065a12a RY(theta\u2081\u2088) f7392292edf64e19be23c004927c1687--8b8b786b44eb4cee9254d7e5c065a12a c5d0c7fb009c476d80f0db7945cfdbc7 RX(theta\u2082\u2082) 8b8b786b44eb4cee9254d7e5c065a12a--c5d0c7fb009c476d80f0db7945cfdbc7 36c9d1372a6e4a358299410d13900e2d c5d0c7fb009c476d80f0db7945cfdbc7--36c9d1372a6e4a358299410d13900e2d df1923a61b8d424fa819b81e4889c577 X 36c9d1372a6e4a358299410d13900e2d--df1923a61b8d424fa819b81e4889c577 df1923a61b8d424fa819b81e4889c577--cc656ac9c80d4a4e8623e356cab17c47 df1923a61b8d424fa819b81e4889c577--17eb7d78ca5641e29bc08ceb7bbe6ef1 d2d641502445424bb078ec310ec0b150 4ea75fa3fb0c4185b759e0465ef49d9e X 83de104eadf74ff3a739a80252743a4e--4ea75fa3fb0c4185b759e0465ef49d9e dd436ce3db97474ea96362920513b52f RX(theta\u2083) 4ea75fa3fb0c4185b759e0465ef49d9e--dd436ce3db97474ea96362920513b52f e7bb4f4e947b4753a4e11f0fc35952b7 RY(theta\u2087) dd436ce3db97474ea96362920513b52f--e7bb4f4e947b4753a4e11f0fc35952b7 53e7e930ca8749a893b0d80e64382af0 RX(theta\u2081\u2081) e7bb4f4e947b4753a4e11f0fc35952b7--53e7e930ca8749a893b0d80e64382af0 797f95266fda4a8baaa6786b6437bbd0 X 53e7e930ca8749a893b0d80e64382af0--797f95266fda4a8baaa6786b6437bbd0 797f95266fda4a8baaa6786b6437bbd0--66a452a7865b4f4887d5af6e37f70b0c a275d7b5f8794ebd80a22960aad88bc6 797f95266fda4a8baaa6786b6437bbd0--a275d7b5f8794ebd80a22960aad88bc6 7cc158564d2e4441844673fc96d4f75c RX(theta\u2081\u2085) a275d7b5f8794ebd80a22960aad88bc6--7cc158564d2e4441844673fc96d4f75c 5d9d42cc0d1c49b8ab381e0ddbb9cae0 RY(theta\u2081\u2089) 7cc158564d2e4441844673fc96d4f75c--5d9d42cc0d1c49b8ab381e0ddbb9cae0 8ca63d931bf644bdbe78215bb9d6ccff RX(theta\u2082\u2083) 5d9d42cc0d1c49b8ab381e0ddbb9cae0--8ca63d931bf644bdbe78215bb9d6ccff 7ca44b1fa8a94c099ba13401bcae5b54 X 8ca63d931bf644bdbe78215bb9d6ccff--7ca44b1fa8a94c099ba13401bcae5b54 7ca44b1fa8a94c099ba13401bcae5b54--36c9d1372a6e4a358299410d13900e2d 2fae2f9b2b8a4aa1b3b5b52ddefeffdf 7ca44b1fa8a94c099ba13401bcae5b54--2fae2f9b2b8a4aa1b3b5b52ddefeffdf 2fae2f9b2b8a4aa1b3b5b52ddefeffdf--d2d641502445424bb078ec310ec0b150  Several standard quantum states can be conveniently initialized in Qadence, both in statevector form as well as in block form as shown in following.</p>"},{"location":"content/state_init/#state-vector-initialization","title":"State vector initialization","text":"<p>Qadence offers a number of constructor functions for state vector preparation.</p> <pre><code>from qadence import uniform_state, zero_state, one_state\n\nn_qubits = 3\nbatch_size = 2\n\nuniform_state = uniform_state(n_qubits, batch_size)\nzero_state = zero_state(n_qubits, batch_size)\none_state = one_state(n_qubits, batch_size)\n</code></pre> <pre><code>Uniform state = \n\ntensor([[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n         0.3536+0.j],\n        [0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n         0.3536+0.j]])\nZero state = \n\ntensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nOne state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> <p>As already seen, product states can be easily created, even in batches:</p> <pre><code>from qadence import product_state, rand_product_state\n\n# From a bitsring \"100\"\nprod_state = product_state(\"100\", batch_size)\n\n# Or a random product state\nrand_state = rand_product_state(n_qubits, batch_size)\n</code></pre> <pre><code>Product state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n\nRandom state = \n\ntensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Creating a GHZ state:</p> <pre><code>from qadence import ghz_state\n\nghz = ghz_state(n_qubits, batch_size)\n</code></pre> <pre><code>GHZ state = \n\ntensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n         0.7071+0.j],\n        [0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n         0.7071+0.j]])\n</code></pre> <p>Creating a random state uniformly sampled from a Haar measure:</p> <pre><code>from qadence import random_state\n\nrand_haar_state = random_state(n_qubits, batch_size)\n</code></pre> <pre><code>Random state from Haar = \n\ntensor([[ 0.0210+1.3910e-01j,  0.5115-1.8703e-01j, -0.2232-1.9475e-01j,\n          0.0546-1.0278e-01j, -0.4123+3.4368e-01j,  0.0442-2.6168e-01j,\n         -0.1116+4.3343e-01j,  0.1530-2.6275e-03j],\n        [-0.2636+3.1462e-01j,  0.2914-3.6732e-01j, -0.1191-2.6621e-01j,\n          0.1736-8.2467e-02j, -0.1679+3.3491e-01j,  0.2364+3.1215e-04j,\n          0.0961+3.3518e-01j, -0.3834+1.5768e-01j]])\n</code></pre> <p>Custom initial states can then be passed to either <code>run</code>, <code>sample</code> and <code>expectation</code> through the <code>state</code> argument</p> <pre><code>from qadence import random_state, product_state, CNOT, run\n\ninit_state = product_state(\"10\")\nfinal_state = run(CNOT(0, 1), state=init_state)\n</code></pre> <pre><code>Final state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre>"},{"location":"content/state_init/#density-matrices-conversion","title":"Density matrices conversion","text":"<p>It is also possible to obtain density matrices from statevectors. They can be passed as inputs to quantum programs performing density matrix based operations such as noisy simulations, when the backend allows such as PyQTorch.</p> <pre><code>from qadence import product_state, density_mat\n\ninit_state = product_state(\"10\")\ninit_density_matrix = density_mat(init_state)\n\nfinal_density_matrix = run(CNOT(0, 1), state=init_density_matrix)\n</code></pre> <pre><code>Initial = DensityMatrix([[[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n                [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n                [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n                [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]])\nFinal = DensityMatrix([[[0.-0.j, 0.-0.j, 0.-0.j, 0.-0.j],\n                [0.-0.j, 0.-0.j, 0.-0.j, 0.-0.j],\n                [0.-0.j, 0.-0.j, 0.-0.j, 0.-0.j],\n                [0.-0.j, 0.-0.j, 0.-0.j, 1.-0.j]]])\n</code></pre>"},{"location":"content/state_init/#block-initialization","title":"Block initialization","text":"<p>Not all backends support custom statevector initialization, however previous utility functions have their counterparts to initialize the respective blocks:</p> <pre><code>from qadence import uniform_block, one_block\n\nn_qubits = 3\n\nuniform_block = uniform_block(n_qubits)\n\none_block = one_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u251c\u2500\u2500 H(1)\n\u2514\u2500\u2500 H(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>Similarly, for product states:</p> <pre><code>from qadence import product_block, rand_product_block\n\nproduct_block = product_block(\"100\")\n\nrand_product_block = rand_product_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 I(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 I(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>And GHZ states:</p> <pre><code>from qadence import ghz_block\n\nghz_block = ghz_block(n_qubits)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n    \u251c\u2500\u2500 CNOT(0, 1)\n    \u2514\u2500\u2500 CNOT(1, 2)\n</code></pre> <p>Initial state blocks can simply be chained at the start of a given circuit.</p>"},{"location":"content/state_init/#utility-functions","title":"Utility functions","text":"<p>Some state vector utility functions are also available. We can easily create the probability mass function of a given statevector using <code>torch.distributions.Categorical</code></p> <pre><code>from qadence import random_state, pmf\n\nn_qubits = 3\n\nstate = random_state(n_qubits)\ndistribution = pmf(state)\n</code></pre> <pre><code>Categorical(probs: torch.Size([1, 8]))\n</code></pre> <p>We can also check if a state is normalized:</p> <pre><code>from qadence import random_state, is_normalized\n\nstate = random_state(n_qubits)\nprint(is_normalized(state))\n</code></pre> <pre><code>True\n</code></pre> <p>Or normalize a state:</p> <pre><code>import torch\nfrom qadence import normalize, is_normalized\n\nstate = torch.tensor([[1, 1, 1, 1]], dtype = torch.cdouble)\nprint(normalize(state))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre>"},{"location":"content/time_dependent/","title":"Time-dependent generators","text":"<p>For use cases when the Hamiltonian of the system is time-dependent, Qadence provides a special parameter <code>TimeParameter(\"t\")</code> that denotes the explicit time dependence. Using this time parameter, one can define a parameterized block acting as the generator passed to <code>HamEvo</code> that encapsulates the required time dependence function.</p>"},{"location":"content/time_dependent/#noiseless-time-dependent-hamiltonian-evolution","title":"Noiseless time-dependent Hamiltonian evolution","text":"<pre><code>from qadence import X, Y, HamEvo, TimeParameter, FeatureParameter, run\nfrom pyqtorch.utils import SolverType\nimport torch\n\n# Simulation parameters\node_solver = SolverType.DP5_SE  # time-dependent Schrodinger equation solver method\nn_steps_hevo = 500  # integration time steps used by solver\n\n# Define block parameters\nt = TimeParameter(\"t\")\nomega_param = FeatureParameter(\"omega\")\n\n# Arbitrarily compose a time-dependent generator\ntd_generator = omega_param * (t * X(0) + t**2 * Y(1))\n\n# Create parameterized HamEvo block\nhamevo = HamEvo(td_generator, t)\n</code></pre> <p>Note that when using <code>HamEvo</code> with a time-dependent generator, the actual time parameter that was used to construct the generator must be passed for the second argument <code>parameter</code>.</p> <p>By default, the code above will initialize an internal parameter <code>FeatureParameter(\"duration\")</code> in the <code>HamEvo</code>. Alternatively, the <code>duration</code> argument can be used to rename this parameter, or to pass a fixed value directly. If no fixed value is passed, it must then be set in the <code>values</code> dictionary at runtime.</p> <p>Future improvements</p> <p>Currently it is only possible to pass a single value for the duration, and the only result obtained will be the one corresponding to the state at end of the integration. In the future we will change the interface to allow directly passing some array of save values to obtain expectation values or statevectors at intermediate steps during the evolution.</p> <pre><code>values = {\"omega\": torch.tensor(10.0), \"duration\": torch.tensor(1.0)}\n\nconfig = {\"ode_solver\": ode_solver, \"n_steps_hevo\": n_steps_hevo}\n\nout_state = run(hamevo, values = values, configuration = config)\n\nprint(out_state)\n</code></pre> <pre><code>tensor([[-0.2785+0.0000j, -0.0541+0.0000j,  0.0000-0.9414j,  0.0000-0.1827j]])\n</code></pre> <p>Note that Qadence makes no assumption on units. The unit of passed duration value \\(\\tau\\) must be aligned with the units of other parameters in the time-dependent generator so that the integral of generator \\(\\overset{\\tau}{\\underset{0}{\\int}}\\mathcal{\\hat{H}}(t){\\rm d}t\\) is dimensionless.</p>"},{"location":"content/time_dependent/#noisy-time-dependent-hamiltonian-evolution","title":"Noisy time-dependent Hamiltonian evolution","text":"<p>To perform noisy time-dependent Hamiltonian evolution, one needs to pass a list of noise operators to the <code>noise_operators</code> argument in <code>HamEvo</code>. They correspond to the jump operators used within the time-dependent Schrodinger equation solver method <code>SolverType.DP5_ME</code>:</p> <pre><code>from qadence import X, Y, HamEvo, TimeParameter, FeatureParameter, run\nfrom pyqtorch.utils import SolverType\nimport torch\n\n# Simulation parameters\node_solver = SolverType.DP5_ME  # time-dependent Schrodinger equation solver method\nn_steps_hevo = 500  # integration time steps used by solver\n\n# Define block parameters\nt = TimeParameter(\"t\")\nomega_param = FeatureParameter(\"omega\")\n\n# Arbitrarily compose a time-dependent generator\ntd_generator = omega_param * (t * X(0) + t**2 * Y(1))\n\n# Create parameterized HamEvo block\nnoise_operators = [X(i) for i in td_generator.qubit_support]\nhamevo = HamEvo(td_generator, t, noise_operators = noise_operators)\n\nvalues = {\"omega\": torch.tensor(10.0), \"duration\": torch.tensor(1.0)}\n\nconfig = {\"ode_solver\": ode_solver, \"n_steps_hevo\": n_steps_hevo}\n\nout_state = run(hamevo, values = values, configuration = config)\n\nprint(out_state)\n</code></pre>   DensityMatrix([[[0.2734+0.0000j, 0.0297+0.0000j, 0.0000-0.0227j, 0.0000-0.0025j],                 [0.0297+0.0000j, 0.1698+0.0000j, 0.0000-0.0025j, 0.0000-0.0141j],                 [0.0000+0.0227j, 0.0000+0.0025j, 0.3435+0.0000j, 0.0373+0.0000j],                 [0.0000+0.0025j, 0.0000+0.0141j, 0.0373+0.0000j, 0.2133+0.0000j]]])    <p>Noise operators definition</p> <p>Note it is not possible to define <code>noise_operators</code> with parametric operators. If you want to do so, we recommend obtaining the tensors via run and set <code>noise_operators</code> using <code>MatrixBlock</code>. Also, <code>noise_operators</code> should have the same or a subset of the qubit support of the <code>HamEvo</code> instance.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"getting_started/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"getting_started/CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"getting_started/CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in Qadence. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"getting_started/CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence, feel free to create an issue on qadence's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"getting_started/CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>We're excited that you're eager to contribute to Qadence. To contribute, fork the <code>main</code> branch of qadence repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/qadence</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/qadence.git\n</code></pre> <p>Next, navigate to your new qadence fork directory and mark the main qadence repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/qadence.git\n</code></pre>"},{"location":"getting_started/CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within qadence, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run qadence tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\npip install -e .\npytest\n</code></pre>"},{"location":"getting_started/CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful things for your workflow: linting and testing","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"getting_started/LICENSE/","title":"License","text":"<p>PASQAL OPEN-SOURCE SOFTWARE LICENSE AGREEMENT (MIT-derived)</p> <p>The author of the License is:   Pasqal, a Soci\u00e9t\u00e9 par Actions Simplifi\u00e9e (Simplified Joint Stock Company) registered under number 849 441 522 at the Registre du commerce et des soci\u00e9t\u00e9s (Trade and Companies Register) of Evry \u2013 France, headquartered at 24 rue \u00c9mile Baudot \u2013 91120 \u2013 Palaiseau \u2013 France, duly represented by its Pr\u00e9sident, M. Georges-Olivier REYMOND, Hereafter referred to as \u00ab the Licensor \u00bb</p> <ul> <li> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software (the \u201cLicensee\u201d) and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The Software is \u201cas is\u201d, without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and non-infringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise arising from, out of or in connection with the Software or the use or other dealings in the Software.</p> </li> <li> <p>If use of the Software leads to the necessary use of any patent of the Licensor and/or any of its Affiliates (defined as a company owned or controlled by the Licensor), the Licensee is granted a royalty-free license, in any country where such patent is in force, to use the object of such patent; or use the process covered by such patent,</p> </li> <li> <p>Such a patent license is granted for internal research or academic use of the Licensee's, which includes use by employees and students of the Licensee, acting on behalf of the Licensee, for research purposes only.</p> </li> <li> <p>The License is governed by the laws of France. Any dispute relating to the License, notably its execution, performance and/or termination shall be brought to, heard and tried by the Tribunal Judiciaire de Paris, regardless of the rules of jurisdiction in the matter.</p> </li> </ul>"},{"location":"getting_started/installation/","title":"Installation","text":""},{"location":"getting_started/installation/#requirements","title":"Requirements","text":"<p>Qadence is fully tested on Linux/MacOS operating systems. For Windows users, we recommend using WSL2 to install a Linux distribution of choice.</p>"},{"location":"getting_started/installation/#installation","title":"Installation","text":"<p>Qadence can be installed from PyPI with <code>pip</code> as follows:</p> <pre><code>pip install qadence\n</code></pre> <p>By default, this will also install PyQTorch, a differentiable state vector simulator which serves as the main numerical backend for Qadence.</p> <p>It is possible to install additional backends and the circuit visualization library using the following extras:</p> <ul> <li><code>visualization</code>: to display quantum circuits.</li> <li><code>pulser</code>: the Pulser backend for composing, simulating and executing pulse sequences for neutral-atom quantum devices (in development).</li> </ul> <p>To install other backends or the visualization tool, please use:</p> <pre><code>pip install \"qadence[pulser, visualization]\"\n</code></pre> <p>Note</p> <p>In order to correctly install the <code>visualization</code> extra, the <code>graphviz</code> package needs to be installed in your system:</p> <pre><code># on Ubuntu\nsudo apt install graphviz\n\n# on MacOS\nbrew install graphviz\n\n# via conda\nconda install python-graphviz\n</code></pre>"},{"location":"getting_started/installation/#install-from-source","title":"Install from source","text":"<p>We recommend to use the <code>hatch</code> environment manager to install <code>qadence</code> from source:</p> <pre><code>python -m pip install hatch\n\n# get into a shell with all the dependencies\npython -m hatch shell\n\n# run a command within the virtual environment with all the dependencies\npython -m hatch run python my_script.py\n</code></pre> <p>Warning</p> <p><code>hatch</code> will not combine nicely with other environment managers such Conda. If you want to use Conda, install it from source using <code>pip</code>:</p> <pre><code># within the Conda environment\npython -m pip install -e .\n</code></pre>"},{"location":"getting_started/installation/#citation","title":"Citation","text":"<p>If you use Qadence for a publication, we kindly ask you to cite our work using the following BibTex entry:</p> <pre><code>@article{qadence2024pasqal,\n  title = {Qadence: a differentiable interface for digital-analog programs.},\n  author={Dominik Seitz and Niklas Heim and Jo\u00e3o P. Moutinho and Roland Guichard and Vytautas Abramavicius and Aleksander Wennersteen and Gert-Jan Both and Anton Quelle and Caroline de Groot and Gergana V. Velikova and Vincent E. Elfving and Mario Dagrada},\n  journal={arXiv:2401.09915},\n  url = {https://github.com/pasqal-io/qadence},\n  year = {2024}\n}\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This section is undergoing changes and most of the information here will be reorganized.</p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"tutorials/advanced_tutorials/","title":"Advanced Tutorials","text":"<p>In this section, advanced programming concepts and implementations in Qadence are examplified.</p>"},{"location":"tutorials/advanced_tutorials/cloud-submission/","title":"Submission of Qadence Jobs to Pasqal Cloud","text":"<p>It is possible to submit quantum computational jobs to execute remotely on Pasqal's cloud platform from Qadence. This feature can only be used if you have an account on the cloud platform, which has access to the Qadence workload. The qadence module <code>qadence.pasqal_cloud_connection</code> offers functionality to specify the computation easily, upload the specification and retrieve the result when the computation has finished execution on the cloud platform. In this tutorial, a simple quantum circuit will be defined as an example to showcase the submission process for remote computations. The same process can be applied to run more complex quantum circuits on the cloud platform.</p> <p>Let's first define a very simple quantum circuit that creates a Bell state.</p> <pre><code>from qadence import CNOT, H, QuantumCircuit\n\ncircuit = QuantumCircuit(2, H(0), CNOT(0, 1))\n</code></pre> <p>If we want to upload this circuit to the cloud platform we need to follow 4 steps: - Authentication and connection to cloud - Defining workload specification - Submission - Retrieval of results</p>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#authentication-and-connection","title":"Authentication and connection","text":"<p>To setup a connection the cloud platform, use the <code>SDK</code> object present in <code>qadence.pasqal_cloud_connection</code>. The email and password are the ones used to login to the webportal. The project-id can be found in the webportal under \"Projects\".</p> <pre><code>from qadence.pasqal_cloud_connection import SDK\n\nconnection = SDK(\"john.doe@email.com\", \"my-password\", project_id=\"proj1\")\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#defining-workload-specification","title":"Defining workload specification","text":"<p>A workload is a quantum calculation to execute on a Pasqal cloud backend. To create a workload specification, we need some extra information on top the circuit itself. We need to specify the backend, chosen here to be PyQTorch. The cloud platform currently only supports PyQTorch. Moreover, the requested result type needs to be defined. Based on the workload specification, the appropriate run methods (<code>run</code>, <code>sample</code> or <code>expectation</code>) will be called by the <code>QuantumModel</code> by passing them through the enum value <code>ResultTypes</code> argument. Moreover, the requested result type needs to be defined. These are provided in a list, so that multiple result types can be requested in a single submission.</p> <pre><code>from qadence import BackendName\nfrom qadence.pasqal_cloud_connection import WorkloadSpec, ResultType\n\nworkload = WorkloadSpec(circuit, BackendName.PYQTORCH, [ResultType.SAMPLE, ResultType.RUN])\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#using-a-quantum-model","title":"Using a Quantum Model","text":"<p>If you already have your quantum computation defined as a <code>QuantumModel</code>, it is possible to create a workload specification directly from the model using <code>get_workload_spec</code>. Then, the circuit and backend specifications will be extracted from the model, the other values need to be provided as extra arguments.</p> <pre><code>from qadence import QuantumModel\nfrom qadence.pasqal_cloud_connection import get_workload_spec\n\nmodel = QuantumModel(circuit)\nworkload = get_workload_spec(model, [ResultType.SAMPLE])\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#observable-expectation-value","title":"Observable Expectation Value","text":"<p>For the result type <code>ResultType.EXPECTATION</code> it is mandatory to provide an observable to the workload specification. In the example below we use the trivial identity observable <code>I(0) @ I(1)</code>.</p> <pre><code>from qadence import I\n\nworkload = WorkloadSpec(circuit, BackendName.PYQTORCH, [ResultType.EXPECTATION], observable=I(0)*I(1))\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#parametric-circuits","title":"Parametric Circuits","text":"<p>In the case of a parametric circuit, i.e. a circuit that contains feature parameters or variational parameters, values for these parameters need to be provided. The parameter values are defined in a dictionary, where keys are the parameter name and values are parameter value passed as torch tensors. The parameter values are defined in a dictionary, where keys are the parameter name and values are parameter value passed as torch tensors. It is possible to set multiple values by using a 1-D tensor, to the parameters, in that case the computation is executed for each value in the tensor. A mix of 0-D and 1-D tensors can be provided to keep some parameters constant and others changed during this process. However, all 1-D tensors need to have the same length. An exception will be raised if the dimensions and lengths are invalid.</p> <pre><code>from torch import tensor\n\nparametric_circuit = ...\nparameter_values = {\"param1\": tensor(0), \"param2\": tensor([0, 1, 2]), \"param3\": tensor([5, 6, 7])}\nworkload = WorkloadSpec(parametric_circuit, BackendName.PYQTORCH, [ResultType.SAMPLE], parameter_values=parameter_values)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#submission","title":"Submission","text":"<p>Submission to the cloud platform is done very easily using the <code>submit_workload</code> function. The workload id will be provided by executing the function. This id is needed later, to request the status of the given workload.</p> <pre><code>from qadence.pasqal_cloud_connection import submit_workload\n\nworkload_id = submit_workload(connection, workload)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#check-workload-status","title":"Check Workload Status","text":"<p>The status of a workload can be: done, pending, running, paused, canceled, timed out or error. The <code>check_status</code> function can be used to see if the workload is finished already. If so, the results of the computation will be provided in a <code>WorkloadResult</code> object. The result of the computation itself can be found in the <code>result</code> attribute of this object. If the workload has not finished yet, or resulted in an error, <code>check_status</code> will raise an exception, either a <code>WorkloadStoppedError</code> or <code>WorkloadNotDoneError</code>.</p> <pre><code>from qadence.pasqal_cloud_connection import check_status\n\nworkload_result = check_status(connection, workload_id)\nprint(workload_result.result)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#retrieval-of-results","title":"Retrieval of Results","text":"<p>If you wish to wait for the workload to be finished, before moving further with your code, you can use the <code>get_result</code> function. This function checks in set intervals the status of the workload until the workload is finished or the function has timed out. The polling rate as well as the time out duration can be set optionally.</p> <pre><code>from qadence.pasqal_cloud_connection import get_result\n\nworkload_result = get_result(connection, workload_id, timeout=60, refresh_time=1)\nprint(workload_result.result)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/custom-models/","title":"Custom quantum models","text":"<p>In <code>qadence</code>, the <code>QuantumModel</code> is the central class point for executing <code>QuantumCircuit</code>s.  The idea of a <code>QuantumModel</code> is to decouple the backend execution from the management of circuit parameters and desired quantum computation output.</p> <p>In the following, we create a custom <code>QuantumModel</code> instance which introduces some additional optimizable parameters: *  an adjustable scaling factor in front of the observable to measured *  adjustable scale and shift factors to be applied to the model output before returning the result</p> <p>This can be easily done using PyTorch flexible model definition, and it will automatically work with the rest of <code>qadence</code> infrastructure.</p> <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit\n\n\nclass CustomQuantumModel(QuantumModel):\n\n    def __init__(self, circuit: QuantumCircuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\"):\n        super().__init__(circuit, observable=observable, backend=backend, diff_mode=diff_mode)\n\n        self.n_qubits = circuit.n_qubits\n\n        # define some additional parameters which will scale and shift (variationally) the\n        # output of the QuantumModel\n        # you can use all torch machinery for building those\n        self.scale_out = torch.nn.Parameter(torch.ones(1))\n        self.shift_out = torch.nn.Parameter(torch.ones(1))\n\n    # override the forward pass of the model\n    # the forward pass is the output of your QuantumModel and in this case\n    # it's the (scaled) expectation value of the total magnetization with\n    # a variable coefficient in front\n    def forward(self, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n\n        # scale the observable\n        res = self.expectation(values)\n\n        # scale and shift the result before returning\n        return self.shift_out + res * self.scale_out\n</code></pre> <p>The custom model can be used like any other <code>QuantumModel</code>: <pre><code>from qadence import Parameter, RX, CNOT, QuantumCircuit\nfrom qadence import chain, kron, hamiltonian_factory, Z\nfrom sympy import acos\n\ndef quantum_circuit(n_qubits):\n\n    x = Parameter(\"x\", trainable=False)\n    fm = kron(RX(i, acos(x) * (i+1)) for i in range(n_qubits))\n\n    ansatz = kron(RX(i, f\"theta{i}\") for i in range(n_qubits))\n    ansatz = chain(ansatz, CNOT(0, n_qubits-1))\n\n    block = chain(fm, ansatz)\n    block.tag = \"circuit\"\n    return QuantumCircuit(n_qubits, block)\n\nn_qubits = 4\nbatch_size = 10\ncircuit = quantum_circuit(n_qubits)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)  # Total magnetization\n\nmodel = CustomQuantumModel(circuit, observable, backend=\"pyqtorch\")\n\nvalues = {\"x\": torch.rand(batch_size)}\nres = model(values)\nprint(\"Model output: \", res)\nassert len(res) == batch_size\n</code></pre> <pre><code>Model output:  tensor([[-0.9083],\n        [ 0.8095],\n        [ 0.5893],\n        [-1.0076],\n        [-0.2930],\n        [-0.5265],\n        [-0.8755],\n        [ 1.4320],\n        [ 0.6845],\n        [-0.3349]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> </p>"},{"location":"tutorials/advanced_tutorials/custom-models/#quantum-model-with-wavefunction-overlaps","title":"Quantum model with wavefunction overlaps","text":"<p><code>QuantumModel</code>'s can also use different quantum operations in their forward pass, such as wavefunction overlaps described here. Beware that the resulting overlap tensor has to be differentiable to apply gradient-based optimization. This is only applicable to the <code>\"EXACT\"</code> overlap method.</p> <p>Here we show how to use overlap calculation when fitting a parameterized quantum circuit to act as a standard Hadamard gate.</p> <pre><code>from qadence import RY, RX, H, Overlap\n\n# create a quantum model which acts as an Hadamard gate after training\nclass LearnHadamard(QuantumModel):\n    def __init__(\n        self,\n        train_circuit: QuantumCircuit,\n        target_circuit: QuantumCircuit,\n        backend=\"pyqtorch\",\n    ):\n        super().__init__(circuit=train_circuit, backend=backend)\n        self.overlap_fn = Overlap(train_circuit, target_circuit, backend=backend, method=\"exact\", diff_mode='ad')\n\n    def forward(self):\n        return self.overlap_fn()\n\n    # compute the wavefunction of the associated train circuit\n    def wavefunction(self):\n        return model.overlap_fn.run({})\n\n\ntrain_circuit = QuantumCircuit(1, chain(RX(0, \"phi\"), RY(0, \"theta\")))\ntarget_circuit = QuantumCircuit(1, H(0))\n\nmodel = LearnHadamard(train_circuit, target_circuit)\n\n# get the overlap between model and target circuit wavefunctions\nprint(model())\n</code></pre> <pre><code>tensor([[0.7150]], grad_fn=&lt;UnsqueezeBackward0&gt;)\n</code></pre> <p>This model can then be trained with the standard Qadence helper functions.</p> <pre><code>from qadence import run\nfrom qadence.ml_tools import Trainer, TrainConfig\nTrainer.set_use_grad(True)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n\ndef loss_fn(model: LearnHadamard, _unused) -&gt; tuple[torch.Tensor, dict]:\n    loss = criterion(torch.tensor([[1.0]]), model())\n    return loss, {}\n\nconfig = TrainConfig(max_iter=2500)\ntrainer = Trainer(\n    model, optimizer, config, loss_fn\n)\nmodel, optimizer = trainer.fit()\n\nwf_target = run(target_circuit)\nassert torch.allclose(wf_target, model.wavefunction(), atol=1e-2)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/advanced_tutorials/differentiability/","title":"Differentiability","text":"<p>Many application in quantum computing and quantum machine learning more specifically requires the differentiation of a quantum circuit with respect to its parameters.</p> <p>In Qadence, we perform quantum computations via the <code>QuantumModel</code> interface. The derivative of the outputs of quantum models with respect to feature and variational parameters in the quantum circuit can be implemented in Qadence with two different modes:</p> <ul> <li>Automatic differentiation (AD) mode <sup>1</sup>. This mode allows to differentiation both <code>run()</code> and <code>expectation()</code> methods of the <code>QuantumModel</code> and it is the fastest available differentiation method. Under the hood, it is based on the PyTorch autograd engine wrapped by the <code>DifferentiableBackend</code> class. This mode is not working on quantum devices.</li> <li>Generalized parameter shift rule (GPSR) mode. This is general implementation of the well known parameter  shift rule algorithm <sup>2</sup> which works for arbitrary quantum operations <sup>3</sup>. This mode is only applicable to  the <code>expectation()</code> method of <code>QuantumModel</code> but it is compatible with execution or quantum devices.</li> </ul>"},{"location":"tutorials/advanced_tutorials/differentiability/#automatic-differentiation","title":"Automatic differentiation","text":"<p>Automatic differentiation <sup>1</sup> is a procedure to derive a complex function defined as a sequence of elementary mathematical operations in the form of a computer program. Automatic differentiation is a cornerstone of modern machine learning and a crucial ingredient of its recent successes. In its so-called reverse mode, it follows this sequence of operations in reverse order by systematically applying the chain rule to recover the exact value of derivative. Reverse mode automatic differentiation is implemented in Qadence leveraging the PyTorch <code>autograd</code> engine.</p> <p>Only available via the PyQTorch or Horqrux backends</p> <p>Currently, automatic differentiation mode is only available when the <code>pyqtorch</code> or <code>horqrux</code> backends are selected.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#generalized-parameter-shift-rule","title":"Generalized parameter shift rule","text":"<p>The generalized parameter shift rule implementation in Qadence was introduced in <sup>3</sup>. Here the standard parameter shift rules, which only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, was generalized to work with arbitrary generators of quantum operations.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\left\\{ \\lambda_n\\right\\}\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\(\\left\\{ \\Delta_s\\right\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> <p>\\(\\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation}\\)</p> <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> <p>\\(\\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation}\\)</p> <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#adjoint-differentiation","title":"Adjoint Differentiation","text":"<p>Qadence also offers a memory-efficient, non-device compatible alternative to automatic differentation, called 'Adjoint Differentiation' <sup>4</sup> and allows for precisely calculating the gradients of variational parameters in O(P) time and using O(1) state-vectors. Adjoint Differentation is currently only supported by the Torch Engine and allows for first-order derivatives only.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#usage","title":"Usage","text":""},{"location":"tutorials/advanced_tutorials/differentiability/#basics","title":"Basics","text":"<p>In Qadence, the differentiation modes can be selected via the <code>diff_mode</code> argument of the QuantumModel class. It either accepts a <code>DiffMode</code>(<code>DiffMode.GSPR</code>, <code>DiffMode.AD</code> or <code>DiffMode.ADJOINT</code>) or a string (<code>\"gpsr\"\"</code>, <code>\"ad\"</code> or <code>\"adjoint\"</code>). The code in the box below shows how to create <code>QuantumModel</code> instances with all available differentiation modes.</p> <pre><code>from qadence import (FeatureParameter, RX, Z, hea, chain,\n                    hamiltonian_factory, QuantumCircuit,\n                    QuantumModel, BackendName, DiffMode)\nimport torch\n\nn_qubits = 2\n\n# Define a symbolic parameter to differentiate with respect to\nx = FeatureParameter(\"x\")\n\nblock = chain(hea(n_qubits, 1), RX(0, x))\n\n# create quantum circuit\ncircuit = QuantumCircuit(n_qubits, block)\n\n# create total magnetization cost operator\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n\n# create models with AD, ADJOINT and GPSR differentiation engines\nmodel_ad = QuantumModel(circuit, obs,\n                        backend=BackendName.PYQTORCH,\n                        diff_mode=DiffMode.AD)\nmodel_adjoint = QuantumModel(circuit, obs,\n                        backend=BackendName.PYQTORCH,\n                        diff_mode=DiffMode.ADJOINT)\nmodel_gpsr = QuantumModel(circuit, obs,\n                          backend=BackendName.PYQTORCH,\n                          diff_mode=DiffMode.GPSR)\n\n# Create concrete values for the parameter we want to differentiate with respect to\nxs = torch.linspace(0, 2*torch.pi, 100, requires_grad=True)\nvalues = {\"x\": xs}\n\n# calculate function f(x)\nexp_val_ad = model_ad.expectation(values)\nexp_val_adjoint = model_adjoint.expectation(values)\nexp_val_gpsr = model_gpsr.expectation(values)\n\n# calculate derivative df/dx using the PyTorch\n# autograd engine\ndexpval_x_ad = torch.autograd.grad(\n    exp_val_ad, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_adjoint = torch.autograd.grad(\n    exp_val_adjoint, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_gpsr = torch.autograd.grad(\n    exp_val_gpsr, values[\"x\"], torch.ones_like(exp_val_gpsr), create_graph=True\n)[0]\n</code></pre> <p>We can plot the resulting derivatives and see that in both cases they coincide.</p> <pre><code>import matplotlib.pyplot as plt\n\n# plot f(x) and df/dx derivatives calculated using AD ,ADJOINT and GPSR\n# differentiation engines\nfig, ax = plt.subplots()\nax.scatter(xs.detach().numpy(),\n           exp_val_ad.detach().numpy(),\n           label=\"f(x)\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_ad.detach().numpy(),\n           label=\"df/dx AD\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_adjoint.detach().numpy(),\n           label=\"df/dx ADJOINT\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_gpsr.detach().numpy(),\n           s=5,\n           label=\"df/dx GPSR\")\nplt.legend()\n</code></pre> 2025-04-04T13:33:31.850337 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/advanced_tutorials/differentiability/#low-level-control-on-the-shift-values","title":"Low-level control on the shift values","text":"<p>In order to get a finer control over the GPSR differentiation engine we can use the low-level Qadence API to define a <code>DifferentiableBackend</code>.</p> <pre><code>from qadence.engines.torch import DifferentiableBackend\nfrom qadence.backends.pyqtorch import Backend as PyQBackend\n\n# define differentiable quantum backend\nquantum_backend = PyQBackend()\nconv = quantum_backend.convert(circuit, obs)\npyq_circ, pyq_obs, embedding_fn, params = conv\ndiff_backend = DifferentiableBackend(quantum_backend, diff_mode=DiffMode.GPSR, shift_prefac=0.2)\n\n# calculate function f(x)\nexpval = diff_backend.expectation(pyq_circ, pyq_obs, embedding_fn(params, values))\n</code></pre> <p>Here we passed an additional argument <code>shift_prefac</code> to the <code>DifferentiableBackend</code> instance that governs the magnitude of shifts \\(\\delta\\equiv\\alpha\\delta^\\prime\\) shown in equation (2) above. In this relation \\(\\delta^\\prime\\) is set internally and \\(\\alpha\\) is the value passed by <code>shift_prefac</code> and the resulting shift value \\(\\delta\\) is then used in all the following GPSR calculations.</p> <p>Tuning parameter \\(\\alpha\\) is useful to improve results when the generator \\(\\hat{G}\\) or the quantum operation is a dense matrix, for example a complex <code>HamEvo</code> operation; if many entries of this matrix are sufficiently larger than 0 the operation is equivalent to a strongly interacting system. In such case parameter \\(\\alpha\\) should be gradually lowered in order to achieve exact derivative values.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#low-level-differentiation-of-qadence-circuits-using-jax","title":"Low-level differentiation of qadence circuits using JAX","text":"<p>For users interested in using the <code>JAX</code> engine instead, we show how to run and differentiate qadence programs using the <code>horqrux</code> backend under qadence examples.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#references","title":"References","text":"<ol> <li> <p>A. G. Baydin et al., Automatic Differentiation in Machine Learning: a Survey \u21a9\u21a9</p> </li> <li> <p>Schuld et al., Evaluating analytic gradients on quantum hardware (2018). \u21a9</p> </li> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9\u21a9</p> </li> <li> <p>Tyson et al., Efficient calculation of gradients in classical simulations of variational quantum algorithms \u21a9</p> </li> </ol>"},{"location":"tutorials/advanced_tutorials/profiling-and-debugging/","title":"Profiling and debugging on CUDA devices","text":"<p>For this to work, you'll have to have the right to access perf counters on your machine (for example with sudo or inside a Docker container). See: https://docs.nvidia.com/deeplearning/frameworks/dlprof-user-guide/index.html.</p> <pre><code>$ pip install nvidia-pyindex\n$ pip install nvidia-dlprof[pytorch]\n</code></pre> <p>Make sure that your entrypoint is an executable script. That means that it must start with a she-bang on the top line, e.g. <pre><code>#!/bin/python\n</code></pre> and have execution rights <pre><code>$ chmod +x your_script.py\n</code></pre></p> <p>Lastly it's recommended to add <pre><code>import nvidia_dlprof_pytorch_nvtx\nnvidia_dlprof_pytorch_nvtx.init()\n</code></pre> To your script in the beginning enable extra annotations of PyTorch functions.</p> <p>You can then use dlprof to profile. <pre><code>dlprof --mode=pytorch your_script.py\n</code></pre></p> <pre><code>PYQ_LOG_LEVEL=info QADENCE_LOG_LEVEL=debug dlprof --mode=pytorch examples/backends/differentiable_backend.py\n</code></pre> <p>For example to achieve this through Docker we can start a session in the shell, also mounting our local Qadence version and PyQTorch (Both optional, but you probably need to mount your script at least) <pre><code>$ docker run --rm --gpus=1 --shm-size=1g --ulimit memlock=-1 \\\n --ulimit stack=67108864 -it -p8000:8000 -v./:/opt/qadence -v ../PyQ:/opt/pyqtorch pytorch:24.02-py3 bash\n</code></pre> (You may need to jump through extra hoops to make Docker access the GPUs if you have error messages like <code>docker: Error response from daemon: could not select device driver \"\" with capabilities: [[gpu]].</code>)</p> <p>After this you should have a shell inside the container and you can <pre><code>root@2a85826c4e7b:/workspace# cd /opt/qadence/\nroot@2a85826c4e7b:/opt/qadence# pip3 install -e .\nroot@2a85826c4e7b:/opt/qadence# pip3 install -e ../pyqtorch/\nroot@2a85826c4e7b:/opt/qadence# pip3 install nvidia-dlprof[pytorch]\nroot@2a85826c4e7b:/opt/qadence# PYQ_LOG_LEVEL=debug QADENCE_LOG_LEVEL=debug dlprof --mode=pytorch --nsys_opts=\"-t cuda,nvtx,cublas,cusparse,cusparse-verbose,cublas-verbose --force-overwrite true\" examples/models/quantum_model.py\n</code></pre></p> <p>Where we have <code>--force-overwrite true</code> to always store the latest profiling result (hence you must rename the file) if you wish to keep several. We add <code>cublas,cusparse,cusparse-verbose,cublas-verbose</code> do get more details about the numerical backend pacakges being used.</p>"},{"location":"tutorials/advanced_tutorials/projectors/","title":"Projector blocks","text":"<p>This section introduces the <code>ProjectorBlock</code> as an implementation for the quantum mechanical projection operation onto the subspace spanned by \\(|a\\rangle\\): \\(\\mathbb{\\hat{P}}=|a\\rangle \\langle a|\\). It evaluates the outer product for bras and kets expressed as bitstrings for a given qubit support. They have to possess matching lengths.</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence.operations import Projector  # Projector as an operation.\n\n# Define a projector for |1&gt; onto the qubit labelled 0.\nprojector_block = Projector(ket=\"1\", bra=\"1\", qubit_support=0)\n\n# As any block, the matrix representation can be retrieved.\nprojector_matrix = block_to_tensor(projector_block)\n</code></pre> <pre><code>projector matrix = tensor([[[0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j]]])\n</code></pre> <p>Other standard operations are expressed as projectors in Qadence. For instance, the number operator is the projector onto the 1-subspace, \\(N=|1\\rangle\\langle 1|\\).</p> <p>In fact, projectors can be used to compose any arbitrary operator. For example, the <code>CNOT</code> can be defined as \\(\\textrm{CNOT}(i,j)=|0\\rangle\\langle 0|_i\\otimes \\mathbb{I}_j+|1\\rangle\\langle 1|_i\\otimes X_j\\) and we can compare its matrix representation with the native one in Qadence:</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence import kron, I, X, CNOT\n\n# Define a projector for |0&gt; onto the qubit labelled 0.\nprojector0 = Projector(ket=\"0\", bra=\"0\", qubit_support=0)\n\n# Define a projector for |1&gt; onto the qubit labelled 0.\nprojector1 = Projector(ket=\"1\", bra=\"1\", qubit_support=0)\n\n# Construct the projector controlled CNOT.\nprojector_cnot = kron(projector0, I(1)) + kron(projector1, X(1))\n\n# Get the underlying unitary.\nprojector_cnot_matrix = block_to_tensor(projector_cnot)\n\n# Qadence CNOT unitary.\nqadence_cnot_matrix = block_to_tensor(CNOT(0,1))\n</code></pre> <pre><code>projector cnot matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\nqadence cnot matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> <p>Another example is the canonical SWAP unitary that can be defined as \\(SWAP=|00\\rangle\\langle 00|+|01\\rangle\\langle 10|+|10\\rangle\\langle 01|+|11\\rangle\\langle 11|\\). Indeed, it can be shown that their matricial representations are again identical:</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence import SWAP\n\n# Define all projectors.\nprojector00 = Projector(ket=\"00\", bra=\"00\", qubit_support=(0, 1))\nprojector01 = Projector(ket=\"01\", bra=\"10\", qubit_support=(0, 1))\nprojector10 = Projector(ket=\"10\", bra=\"01\", qubit_support=(0, 1))\nprojector11 = Projector(ket=\"11\", bra=\"11\", qubit_support=(0, 1))\n\n# Construct the SWAP gate.\nprojector_swap = projector00 + projector10 + projector01 + projector11\n\n# Get the underlying unitary.\nprojector_swap_matrix = block_to_tensor(projector_swap)\n\n# Qadence SWAP unitary.\nqadence_swap_matrix = block_to_tensor(SWAP(0,1))\n</code></pre> <pre><code>projector swap matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]]])\nqadence swap matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]]], grad_fn=&lt;UnsafeViewBackward0&gt;)\n</code></pre> <p>Warning</p> <p>Projectors are non-unitary operators, only supported by the PyQTorch backend.</p> <p>To examplify this point, let's run some non-unitary computation involving projectors.</p> <pre><code>from qadence import chain, run\nfrom qadence.operations import H, CNOT\n\n# Define a projector for |1&gt; onto the qubit labelled 1.\nprojector_block = Projector(ket=\"1\", bra=\"1\", qubit_support=1)\n\n# Some non-unitary computation.\nnon_unitary_block = chain(H(0), CNOT(0,1), projector_block)\n\n# Projected wavefunction becomes unnormalized\nprojected_wf = run(non_unitary_block)  # Run on PyQTorch.\n</code></pre> <pre><code>projected_wf = tensor([[0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre>"},{"location":"tutorials/development/architecture/","title":"Architecture and sharp bits","text":"<p>Qadence as a software library mixes functional and object-oriented programming. We do that by maintaining core objects and operating on them with functions.</p> <p>Furthermore, Qadence strives at keeping the lower level abstraction layers for automatic differentiation and quantum computation fully stateless while only the frontend layer which is the main user-facing interface is stateful.</p> <p>Code design philosopy</p> <p>Functional, stateless core with object-oriented, stateful user interface.</p>"},{"location":"tutorials/development/architecture/#abstraction-layers","title":"Abstraction layers","text":"<p>In Qadence there are 4 main objects spread across 3 different levels of abstraction:</p> <ul> <li> <p>Frontend layer: The user facing layer and encompasses two objects:</p> <ul> <li><code>QuantumCircuit</code>: A class representing an abstract quantum   circuit not tight not any particular framework. Parameters are represented symbolically using   <code>sympy</code> expressions.</li> <li><code>QuantumModel</code>: The models are higher-level abstraction   providing an interface for executing different kinds of common quantum computing models such   quantum neural networks (QNNs), quantum kernels etc.</li> </ul> </li> <li> <p>Differentiation layer: Intermediate layer has the purpose of integrating quantum   computation with a given automatic differentiation engine. It is meant to be purely stateless and   contains one object:</p> <ul> <li><code>DifferentiableBackend</code>:   An abstract class whose concrete implementation wraps a quantum backend and make it   automatically differentiable using different engines (e.g. PyTorch or Jax).   Note, that today only PyTorch is supported but there is plan to add also a Jax   differentiable backend which will require some changes in the base class implementation.</li> </ul> </li> <li> <p>Quantum layer: The lower-level layer which directly interfaces with quantum emulators   and processing units. It is meant to be purely stateless and it contains one base object which is   specialized for each supported backend:</p> <ul> <li><code>Backend</code>: An abstract class whose concrete implementation   enables the execution of quantum circuit with a variety of quantum backends (normally non   automatically differentiable by default) such as PyQTorch, or Pulser.</li> </ul> </li> </ul>"},{"location":"tutorials/development/architecture/#main-components","title":"Main components","text":""},{"location":"tutorials/development/architecture/#quantumcircuit","title":"<code>QuantumCircuit</code>","text":"<p>We consider <code>QuantumCircuit</code> to be an abstract object, i.e. it is not tied to any backend. However, it blocks are even more abstract. This is because we consider <code>QuantumCircuit</code>s \"real\", whereas the blocks are largely considered just syntax.</p> <p>Unitary <code>QuantumCircuits</code> (this encompasses digital, or gate-based, circuits as well as analog circuits) are constructed by [<code>PrimitiveBlocks</code>] using a syntax that allows you to execute them in sequence, dubbed <code>ChainBlock</code> in the code, or in parallel (i.e. at the same time) where applicable, dubbed <code>KronBlock</code> in the code. Notice that this differs from other packages by providing more control of the layout of the circuit than conventional packages like Qiskit, and from Yao where the blocks are the primary type.</p>"},{"location":"tutorials/development/architecture/#quantummodel","title":"<code>QuantumModel</code>","text":"<p><code>QuantumModel</code>s are meant to be the main entry point for quantum computations in <code>qadence</code>. In general, they take one or more quantum circuit as input and they wrap all the necessary boiler plate code to make the circuit executable and differentiable on the chosen backend.</p> <p>Models are meant to be specific for a certain kind of quantum problem or algorithm and you can easily create new ones starting from the base class <code>QuantumModel</code>, as explained in the custom model tutorial. Currently, Qadence offers a <code>QNN</code> model class which provides convenient methods to work with quantum neural networks with multi-dimensional inputs and outputs.</p>"},{"location":"tutorials/development/architecture/#differentiablebackend","title":"<code>DifferentiableBackend</code>","text":"<p>The differentiable backend is a thin wrapper which takes as input a <code>QuantumCircuit</code> instance and a chosen quantum backend and make the circuit execution routines (expectation value, overalap, etc.) differentiable. Qadence offers both a PyTorch and Jax differentiation engine.</p>"},{"location":"tutorials/development/architecture/#quantum-backend","title":"Quantum <code>Backend</code>","text":"<p>For execution the primary object is the <code>Backend</code>. Backends maintain the same user-facing interface, and internally connects to other libraries to execute circuits. Those other libraries can execute the code on QPUs and local or cloud-based emulators. The <code>Backends</code> use PyTorch tensors to represent data and leverages PyTorchs autograd to help compute derivatives of circuits.</p>"},{"location":"tutorials/development/architecture/#symbolic-parameters","title":"Symbolic parameters","text":"<p>To illustrate how parameters work in Qadence, let's consider the following simple block composed of just two rotations:</p> <pre><code>import sympy\nfrom qadence import Parameter, RX\n\nparam = Parameter(\"phi\", trainable=False)\nblock = RX(0, param) * RX(1, sympy.acos(param))\n</code></pre> <p>The rotation angles assigned to <code>RX</code> (and to any Qadence quantum operation) are defined as arbitrary expressions of <code>Parameter</code>'s. <code>Parameter</code> is a subclass of <code>sympy.Symbol</code>, thus fully interoperable with it.</p> <p>To assign values of the parameter <code>phi</code> in a quantum model, one should use a dictionary containing the a key with parameter name and the corresponding values values:</p> <pre><code>import torch\nfrom qadence import run\n\nvalues = {\"phi\": torch.rand(10)}\nwf = run(block, values=values)\n</code></pre> <p>This is the only interface for parameter assignment exposed to the user. Under the hood, parameters applied to every quantum operation are identified in different ways:</p> <ul> <li> <p>By default, with a stringified version of the <code>sympy</code> expression supplied to the quantum operation. Notice that multiple operations can have the same expression.</p> </li> <li> <p>In certain case, e.g. for constructing parameter shift rules, one must access a unique identifier of the parameter for each quantum operation. Therefore, Qadence also creates unique identifiers for each parametrized operation (see the <code>ParamMap</code> class).</p> </li> </ul> <p>By default, when one constructs a new backend, the parameter identifiers are the <code>sympy</code> expressions which are used when converting an abstract block into a native circuit for the chosen backend. However, one can use the unique identifiers as parameter names by setting the private flag <code>_use_gate_params</code> to <code>True</code> in the backend configuration <code>BackendConfiguration</code>. This is automatically set when PSR differentiation is selected (see next section for more details).</p> <p>You can see the logic for choosing the parameter identifier in <code>get_param_name</code>.</p>"},{"location":"tutorials/development/architecture/#differentiation-with-parameter-shift-rules-psr","title":"Differentiation with parameter shift rules (PSR)","text":"<p>In Qadence, parameter shift rules are applied by implementing a custom <code>torch.autograd.Function</code> class for PyTorch and the <code>custom_vjp</code> in the Jax Engine, respectively.</p> <p>A custom PyTorch <code>Function</code> looks like this:</p> <pre><code>import torch\nfrom torch.autograd import Function\n\nclass CustomFunction(Function):\n\n    # forward pass implementation giving the output of the module\n    @staticmethod\n    def forward(ctx, inputs: torch.Tensor, params: torch.Tensor):\n        ctx.save_for_backward(inputs, params)\n        ...\n\n    # backward pass implementation giving the derivative of the module\n    # with respect to the parameters. This must return the whole vector-jacobian\n    # product to integrate within the autograd engine\n    @staticmethod\n    def backward(ctx, grad_output: torch.Tensor):\n        inputs, params = ctx.saved_tensors\n        ...\n</code></pre> <p>The class <code>PSRExpectation</code> under <code>qadence.engines.torch.differentiable_expectation</code> implements parameter shift rules for all parameters using a custom function as the one above. There are a few implementation details to keep in mind if you want to modify the PSR code:</p> <ul> <li> <p>PyTorch <code>Function</code> only works with tensor arguments. Parameters in Qadence are passed around as   dictionaries with parameter names as keys and current parameter values (tensors)   as values. This works for both variational and feature parameters. However, the <code>Function</code> class   only work with PyTorch tensors as input, not dictionaries. Therefore, the forward pass of   <code>PSRExpectation</code> accepts one argument <code>param_keys</code> with the   parameter keys and a variadic positional argument <code>param_values</code> with the parameter values one by   one. The dictionary is reconstructed within the <code>forward()</code> pass body.</p> </li> <li> <p>Higher-order derivatives with PSR. Higher-order PSR derivatives can be tricky. Parameter shift   rules calls, under the hood, the <code>QuantumBackend</code> expectation value routine that usually yield a   non-differentiable output. Therefore, a second call to the backward pass would not work. However,   Qadence employs a very simple trick to make higher-order derivatives work: instead of using   directly the expectation value of the quantum backend, the PSR backward pass uses the PSR forward   pass itself as expectation value function (see the code below). In this way, multiple calls to the   backward pass are allowed since the <code>expectation_fn</code> routine is always differentiable by   definition. Notice that this implementation is simple but suboptimal since, in some corner cases,   higher-order derivates might include some repeated terms that, with this implementation, are   always recomputed.</p> </li> </ul> <pre><code># expectation value used in the PSR backward pass\ndef expectation_fn(params: dict[str, Tensor]) -&gt; Tensor:\n    return PSRExpectation.apply(\n        ctx.expectation_fn,\n        ctx.param_psrs,\n        params.keys(),\n        *params.values(),\n    )\n</code></pre> <ul> <li> <p>Operation parameters must be uniquely identified for PSR to work. Parameter shift rules work at the level of individual quantum operations. This means that, given a parameter <code>x</code>, one needs to sum the contributions from shifting the parameter values of all the operation where the parameter <code>x</code> appears. When constructing the PSR rules, one must access a unique parameter identifier for each operation even if the corresponding user-facing parameter is the same. Therefore, when PSR differentiation is selected, the flag <code>_use_gate_params</code> is automatically set to <code>True</code> in the backend configuration <code>BackendConfiguration</code> (see previous section).</p> </li> <li> <p>PSR must not be applied to observable parameters. In Qadence, Pauli observables can also be parametrized. However, the tunable parameters of observables are purely classical and should not be included in the differentiation with PSRs. However, the quantum expectation value depends on them, thus they still need to enter into the PSR evaluation. To solve this issue, the code sets the <code>requires_grad</code> attribute of all observable parameters to <code>False</code> when constructing the PSRs for the circuit as in the snippet below:</p> </li> </ul> <pre><code>for obs in observable:\n    for param_id, _ in uuid_to_eigen(obs).items():\n        param_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\n</code></pre>"},{"location":"tutorials/development/draw/","title":"<code>qadence.draw</code> example plots","text":"<p>Mostly for quick, manual checking of correct plotting output.</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\n</code></pre> %3 21f50c39b60748919f84df9961100dde 0 c95dfade2f6f417dbba09d240104abf3 X 21f50c39b60748919f84df9961100dde--c95dfade2f6f417dbba09d240104abf3 b5a31f4195e4485c8467d9bcf5944f74 1 8bc86726b8414a60afe964cbe9b21e62 c95dfade2f6f417dbba09d240104abf3--8bc86726b8414a60afe964cbe9b21e62 bb12106363cc4d2cafa28cdf15a95ec1 f15a38c330bf436bb597d80b3516b164 Y b5a31f4195e4485c8467d9bcf5944f74--f15a38c330bf436bb597d80b3516b164 f15a38c330bf436bb597d80b3516b164--bb12106363cc4d2cafa28cdf15a95ec1 <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\n\nb = chain(X(0), Y(0))\n</code></pre> %3 67dff4a9b1da42e09d0487afa97f93d8 0 934148860e35411dbcebfd184a664ade X 67dff4a9b1da42e09d0487afa97f93d8--934148860e35411dbcebfd184a664ade 906a8c3ed57c46f9a5e4187fcd0d0d93 Y 934148860e35411dbcebfd184a664ade--906a8c3ed57c46f9a5e4187fcd0d0d93 4eb47d49e8624e27b82fc923f116c74e 906a8c3ed57c46f9a5e4187fcd0d0d93--4eb47d49e8624e27b82fc923f116c74e <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\n\nb = chain(X(0), Y(1))\n</code></pre> %3 a9b0edc5eb02413eaa968354fc1f027a 0 5b30a2b7aaff4edc85535f231c44c1b5 X a9b0edc5eb02413eaa968354fc1f027a--5b30a2b7aaff4edc85535f231c44c1b5 5052166403ca42d893bc98040bd78ae1 1 34a932e5f28242a3b06db75fad51a641 5b30a2b7aaff4edc85535f231c44c1b5--34a932e5f28242a3b06db75fad51a641 5795817bcc194bbbae78a3b95d7152e8 34a932e5f28242a3b06db75fad51a641--5795817bcc194bbbae78a3b95d7152e8 f03fc7a924dd4b098877250d10756d7f 9a86ca5138bb4f039f5d7d5f5aaf81e7 5052166403ca42d893bc98040bd78ae1--9a86ca5138bb4f039f5d7d5f5aaf81e7 cda64fba18d74a1c928d58c342f7054e Y 9a86ca5138bb4f039f5d7d5f5aaf81e7--cda64fba18d74a1c928d58c342f7054e cda64fba18d74a1c928d58c342f7054e--f03fc7a924dd4b098877250d10756d7f <pre><code>from qadence import X, Y, add\nfrom qadence.draw import display\n\nb = add(X(0), Y(1), X(2))\n</code></pre> %3 cluster_754502922c164035bf624af6fdfac8cf a6d1694092d24794bd3e5d143ef26f29 0 c1631c85999c44879ba11aa91b74cef6 a6d1694092d24794bd3e5d143ef26f29--c1631c85999c44879ba11aa91b74cef6 2399bda3bf4244d0aeb5d05eeac97e86 1 583c8c80153147adb500c5f1d53037bb c1631c85999c44879ba11aa91b74cef6--583c8c80153147adb500c5f1d53037bb 13cf688a303d459e98ed6c49c587f4bc 78e173d3732d44338cdfe7cde72395f0 AddBlock 2399bda3bf4244d0aeb5d05eeac97e86--78e173d3732d44338cdfe7cde72395f0 35777ed4f9ce4559a65c73c0c7ddee42 2 78e173d3732d44338cdfe7cde72395f0--13cf688a303d459e98ed6c49c587f4bc cc7d1b0174b74ee4a0efbb49a6319902 713f217e5971456f987e0750aa720d26 35777ed4f9ce4559a65c73c0c7ddee42--713f217e5971456f987e0750aa720d26 713f217e5971456f987e0750aa720d26--cc7d1b0174b74ee4a0efbb49a6319902 <pre><code>from qadence import CNOT, RX, HamEvo, X, Y, Z, chain, kron\n\nrx = kron(RX(3,0.5), RX(2, \"x\"))\nrx.tag = \"rx\"\ngen = chain(Z(i) for i in range(4))\n\n# `chain` puts things in sequence\nblock = chain(\n    kron(X(0), Y(1), rx),\n    CNOT(2,3),\n    HamEvo(gen, 10)\n)\n</code></pre> %3 cluster_f5faadb81b374613996d04863e8b8f99 cluster_0c23d36e0ede45b39dac57aef435440b rx ff5ca9d84c084b67990c4818c4db5a80 0 71a1366af90941819dfefd8853a21718 X ff5ca9d84c084b67990c4818c4db5a80--71a1366af90941819dfefd8853a21718 45dc2cba98764d91b2d0ff9a077cac39 1 a012174d74e54108b293d7fb4c1a240f 71a1366af90941819dfefd8853a21718--a012174d74e54108b293d7fb4c1a240f c723bd6c216f4e86bcffdb2e527af86c a012174d74e54108b293d7fb4c1a240f--c723bd6c216f4e86bcffdb2e527af86c 076017f47fda487b808a8fe414114f4d c723bd6c216f4e86bcffdb2e527af86c--076017f47fda487b808a8fe414114f4d a411f082bd2b49f3b12a8f4cf4d4029a d51b0c9579ab4b3cb136f3f3d045f981 Y 45dc2cba98764d91b2d0ff9a077cac39--d51b0c9579ab4b3cb136f3f3d045f981 b98e04737a9b456babc339697d017d93 2 28cf48203c174280b663bfcaf1b6290b d51b0c9579ab4b3cb136f3f3d045f981--28cf48203c174280b663bfcaf1b6290b a8587c74aa784b849c95ba61f786f096 HamEvo 28cf48203c174280b663bfcaf1b6290b--a8587c74aa784b849c95ba61f786f096 a8587c74aa784b849c95ba61f786f096--a411f082bd2b49f3b12a8f4cf4d4029a 4e1b669a70b24c0183b0eb84fae6eaf0 87501d68125e4bf88fc362728bc45dd8 RX(x) b98e04737a9b456babc339697d017d93--87501d68125e4bf88fc362728bc45dd8 d9c7d1d0cae7480fb3e5ecc43aa0cbcf 3 f8c37c0eb2934a7ca8c6697e95a7f0b1 87501d68125e4bf88fc362728bc45dd8--f8c37c0eb2934a7ca8c6697e95a7f0b1 4a0382f41016414f82b761d0763126eb t = 10 f8c37c0eb2934a7ca8c6697e95a7f0b1--4a0382f41016414f82b761d0763126eb 4a0382f41016414f82b761d0763126eb--4e1b669a70b24c0183b0eb84fae6eaf0 3c09a369f1ad4bcdb03caa8c59325863 c5fd34122b8f45a5ae58636d49f39054 RX(0.5) d9c7d1d0cae7480fb3e5ecc43aa0cbcf--c5fd34122b8f45a5ae58636d49f39054 c6e33b9608a84c1f864065461f8f0f5d X c5fd34122b8f45a5ae58636d49f39054--c6e33b9608a84c1f864065461f8f0f5d c6e33b9608a84c1f864065461f8f0f5d--f8c37c0eb2934a7ca8c6697e95a7f0b1 6a9b260c116345da9f3d5415c9dbbf95 c6e33b9608a84c1f864065461f8f0f5d--6a9b260c116345da9f3d5415c9dbbf95 6a9b260c116345da9f3d5415c9dbbf95--3c09a369f1ad4bcdb03caa8c59325863 <pre><code>from qadence import feature_map, hea, chain\n\nblock = chain(feature_map(4, reupload_scaling=\"Tower\"), hea(4,2))\n</code></pre> %3 cluster_c518a45ef31644ee8ef1bec81b3df2da HEA cluster_1871d20634d94551b71d0cda7e1dfafb Tower Fourier FM b1c81387933e414183e7ee203c3eb79e 0 4afae8197b184e718b4307dfb1b5659b RX(1.0*phi) b1c81387933e414183e7ee203c3eb79e--4afae8197b184e718b4307dfb1b5659b e0ab402173d143d195a3d36ed7ef4553 1 4a8ae88343034e92ab526565d41bff37 RX(theta\u2080) 4afae8197b184e718b4307dfb1b5659b--4a8ae88343034e92ab526565d41bff37 a5d39b299cfc49a8903a65c9d86d9c78 RY(theta\u2084) 4a8ae88343034e92ab526565d41bff37--a5d39b299cfc49a8903a65c9d86d9c78 907ec5b832f84e41949ccc8fca7cf139 RX(theta\u2088) a5d39b299cfc49a8903a65c9d86d9c78--907ec5b832f84e41949ccc8fca7cf139 b88ed76fdc264c2bab2ceefc2ffc6654 907ec5b832f84e41949ccc8fca7cf139--b88ed76fdc264c2bab2ceefc2ffc6654 45b33214ac074071b3f22f8cf3a9f507 b88ed76fdc264c2bab2ceefc2ffc6654--45b33214ac074071b3f22f8cf3a9f507 de8ac35d9d10405a82192878ce057b52 RX(theta\u2081\u2082) 45b33214ac074071b3f22f8cf3a9f507--de8ac35d9d10405a82192878ce057b52 2dee006cd3074b709ae74b056aa86cc2 RY(theta\u2081\u2086) de8ac35d9d10405a82192878ce057b52--2dee006cd3074b709ae74b056aa86cc2 09e3d27c7a964a0cb030e6dc131b0094 RX(theta\u2082\u2080) 2dee006cd3074b709ae74b056aa86cc2--09e3d27c7a964a0cb030e6dc131b0094 59b7997a1c6546839d0ed55d032e78d5 09e3d27c7a964a0cb030e6dc131b0094--59b7997a1c6546839d0ed55d032e78d5 a34cd76a937a4db38bc0818833862e4e 59b7997a1c6546839d0ed55d032e78d5--a34cd76a937a4db38bc0818833862e4e 705ac507f5774595ad7369de1b29f998 a34cd76a937a4db38bc0818833862e4e--705ac507f5774595ad7369de1b29f998 54cf6d4706374e069f6958b008d60761 4792e2190c2f41188b44d75e75a46153 RX(2.0*phi) e0ab402173d143d195a3d36ed7ef4553--4792e2190c2f41188b44d75e75a46153 6db7a706a00044dbb8bdc8ebdb1c7e9f 2 b0d715b8cc96477ca108ddccf80c9def RX(theta\u2081) 4792e2190c2f41188b44d75e75a46153--b0d715b8cc96477ca108ddccf80c9def f61349f518cf4aadb37bc5378de16883 RY(theta\u2085) b0d715b8cc96477ca108ddccf80c9def--f61349f518cf4aadb37bc5378de16883 4a65698dba784868bb9293d0a3c12f48 RX(theta\u2089) f61349f518cf4aadb37bc5378de16883--4a65698dba784868bb9293d0a3c12f48 9c349078c312445dbce8a701cfd106ef X 4a65698dba784868bb9293d0a3c12f48--9c349078c312445dbce8a701cfd106ef 9c349078c312445dbce8a701cfd106ef--b88ed76fdc264c2bab2ceefc2ffc6654 f5a336f5388445298bb8d1d730cfb330 9c349078c312445dbce8a701cfd106ef--f5a336f5388445298bb8d1d730cfb330 a4605871399f4b0e80f9c4bc54605c9b RX(theta\u2081\u2083) f5a336f5388445298bb8d1d730cfb330--a4605871399f4b0e80f9c4bc54605c9b 05c8260bd90346f3b4a1327cdd4636ce RY(theta\u2081\u2087) a4605871399f4b0e80f9c4bc54605c9b--05c8260bd90346f3b4a1327cdd4636ce cb07a9f4d5084378b8a11e31279ea3d3 RX(theta\u2082\u2081) 05c8260bd90346f3b4a1327cdd4636ce--cb07a9f4d5084378b8a11e31279ea3d3 a91949d33fcd474da898592e50997885 X cb07a9f4d5084378b8a11e31279ea3d3--a91949d33fcd474da898592e50997885 a91949d33fcd474da898592e50997885--59b7997a1c6546839d0ed55d032e78d5 c2c888d989414346a5b0c1cdd6b1c769 a91949d33fcd474da898592e50997885--c2c888d989414346a5b0c1cdd6b1c769 c2c888d989414346a5b0c1cdd6b1c769--54cf6d4706374e069f6958b008d60761 b39721cd24e6457c96fcfe5892bdc761 7dd39d43a9914ee1ab75cac998bcf30c RX(3.0*phi) 6db7a706a00044dbb8bdc8ebdb1c7e9f--7dd39d43a9914ee1ab75cac998bcf30c 05108a0759204522be0a2d64530098bf 3 952a708df05f489daf41aa343705d423 RX(theta\u2082) 7dd39d43a9914ee1ab75cac998bcf30c--952a708df05f489daf41aa343705d423 0163b3472cd04a68a2a1c4e949678f12 RY(theta\u2086) 952a708df05f489daf41aa343705d423--0163b3472cd04a68a2a1c4e949678f12 da4ffa3118844708b92fabefbbb2a16d RX(theta\u2081\u2080) 0163b3472cd04a68a2a1c4e949678f12--da4ffa3118844708b92fabefbbb2a16d bd18bb45882c4f42bb1f5d90fad73f73 da4ffa3118844708b92fabefbbb2a16d--bd18bb45882c4f42bb1f5d90fad73f73 1bfaca61539c449bae1708d584d81616 X bd18bb45882c4f42bb1f5d90fad73f73--1bfaca61539c449bae1708d584d81616 1bfaca61539c449bae1708d584d81616--f5a336f5388445298bb8d1d730cfb330 14860c740785460b859bcfc37e260c3b RX(theta\u2081\u2084) 1bfaca61539c449bae1708d584d81616--14860c740785460b859bcfc37e260c3b bb088340dc234d0cabcefa95d8aae1d0 RY(theta\u2081\u2088) 14860c740785460b859bcfc37e260c3b--bb088340dc234d0cabcefa95d8aae1d0 47b07a3222404e5c8562e4501e2f9962 RX(theta\u2082\u2082) bb088340dc234d0cabcefa95d8aae1d0--47b07a3222404e5c8562e4501e2f9962 3ac0dc3870e24a7fad76ad4f74f242a1 47b07a3222404e5c8562e4501e2f9962--3ac0dc3870e24a7fad76ad4f74f242a1 871d13e558734ad6b8f85448ee5e5645 X 3ac0dc3870e24a7fad76ad4f74f242a1--871d13e558734ad6b8f85448ee5e5645 871d13e558734ad6b8f85448ee5e5645--c2c888d989414346a5b0c1cdd6b1c769 871d13e558734ad6b8f85448ee5e5645--b39721cd24e6457c96fcfe5892bdc761 5ce2149b33704beaa4c9209082837a0a ba815222a30c4cd0b55917d8ee366532 RX(4.0*phi) 05108a0759204522be0a2d64530098bf--ba815222a30c4cd0b55917d8ee366532 44c5edeeb0194ac2b50c0476530df0e2 RX(theta\u2083) ba815222a30c4cd0b55917d8ee366532--44c5edeeb0194ac2b50c0476530df0e2 d79d2370b27f4e7698f0164618fb7d0d RY(theta\u2087) 44c5edeeb0194ac2b50c0476530df0e2--d79d2370b27f4e7698f0164618fb7d0d 55b8a41a9eed44189db47109f71c4c86 RX(theta\u2081\u2081) d79d2370b27f4e7698f0164618fb7d0d--55b8a41a9eed44189db47109f71c4c86 0b7dec3cc3874c57b84f079bba8a2f7d X 55b8a41a9eed44189db47109f71c4c86--0b7dec3cc3874c57b84f079bba8a2f7d 0b7dec3cc3874c57b84f079bba8a2f7d--bd18bb45882c4f42bb1f5d90fad73f73 66926c2f48544cdcaf8770e598bf82d2 0b7dec3cc3874c57b84f079bba8a2f7d--66926c2f48544cdcaf8770e598bf82d2 ee367222b741461a8edd5712cb36fd6f RX(theta\u2081\u2085) 66926c2f48544cdcaf8770e598bf82d2--ee367222b741461a8edd5712cb36fd6f 70eb9bafe890440d80be167dc5b0712c RY(theta\u2081\u2089) ee367222b741461a8edd5712cb36fd6f--70eb9bafe890440d80be167dc5b0712c 08b819e8610e41e08d373b138cd73326 RX(theta\u2082\u2083) 70eb9bafe890440d80be167dc5b0712c--08b819e8610e41e08d373b138cd73326 b932aba988c0453a9b182f9e0ee85b3a X 08b819e8610e41e08d373b138cd73326--b932aba988c0453a9b182f9e0ee85b3a b932aba988c0453a9b182f9e0ee85b3a--3ac0dc3870e24a7fad76ad4f74f242a1 3c5178d7a62d4a289b384c48ba972fd6 b932aba988c0453a9b182f9e0ee85b3a--3c5178d7a62d4a289b384c48ba972fd6 3c5178d7a62d4a289b384c48ba972fd6--5ce2149b33704beaa4c9209082837a0a <pre><code>from qadence import QuantumModel, QuantumCircuit, total_magnetization, hea\n\nmodel = QuantumModel(QuantumCircuit(3, hea(3,2)), total_magnetization(3))\n</code></pre> %3 cluster_51a317e75ebc44068287e79298aa62a1 Obs. cluster_6cbd65e1945247dd8b47c718ba0a73b8 cluster_2b4388aa144b4c38914636ab76973e87 HEA d467bc16f254409d9c2b53d3aa085f33 0 4c4778f47fed46d580603b813d6e92b3 RX(theta\u2080) d467bc16f254409d9c2b53d3aa085f33--4c4778f47fed46d580603b813d6e92b3 2fd7cee97b314d7bbbc3b2c648a0c575 1 f12079da92404686a15a64435f099887 RY(theta\u2083) 4c4778f47fed46d580603b813d6e92b3--f12079da92404686a15a64435f099887 8c2cd970a33d4862867abc9ce45a0f39 RX(theta\u2086) f12079da92404686a15a64435f099887--8c2cd970a33d4862867abc9ce45a0f39 ace39e075293405fb16b5d95626d17a9 8c2cd970a33d4862867abc9ce45a0f39--ace39e075293405fb16b5d95626d17a9 6b8721fce24043d9aeb98302e488d36b ace39e075293405fb16b5d95626d17a9--6b8721fce24043d9aeb98302e488d36b ef0f030f0c744d578419c4c3e71da2dd RX(theta\u2089) 6b8721fce24043d9aeb98302e488d36b--ef0f030f0c744d578419c4c3e71da2dd 9ee915c05b6d4c63b308ddfb7ae0761e RY(theta\u2081\u2082) ef0f030f0c744d578419c4c3e71da2dd--9ee915c05b6d4c63b308ddfb7ae0761e 6238ca9be5904e53b16101c035620c15 RX(theta\u2081\u2085) 9ee915c05b6d4c63b308ddfb7ae0761e--6238ca9be5904e53b16101c035620c15 84213c74d23a4cb0b034789162e03db1 6238ca9be5904e53b16101c035620c15--84213c74d23a4cb0b034789162e03db1 e86ca6c77ed44966abc1640a948a4537 84213c74d23a4cb0b034789162e03db1--e86ca6c77ed44966abc1640a948a4537 07ad517888514b21b6a2b0152043e0d9 e86ca6c77ed44966abc1640a948a4537--07ad517888514b21b6a2b0152043e0d9 57498adb881741a88baaaf88bd9d0371 07ad517888514b21b6a2b0152043e0d9--57498adb881741a88baaaf88bd9d0371 763a036eafbb43408d81543bad54b566 0ca68004c35347ffbd8bb8034946cdf6 RX(theta\u2081) 2fd7cee97b314d7bbbc3b2c648a0c575--0ca68004c35347ffbd8bb8034946cdf6 9833d2424991404681f3afa33ecf6d2d 2 f1a7e4cfb0c345dfa4899f741bfdeb73 RY(theta\u2084) 0ca68004c35347ffbd8bb8034946cdf6--f1a7e4cfb0c345dfa4899f741bfdeb73 438a423b2ffe4d2e86f48e3de19e11f6 RX(theta\u2087) f1a7e4cfb0c345dfa4899f741bfdeb73--438a423b2ffe4d2e86f48e3de19e11f6 cb6fba63f01746b9b8aa80cf35a7b486 X 438a423b2ffe4d2e86f48e3de19e11f6--cb6fba63f01746b9b8aa80cf35a7b486 cb6fba63f01746b9b8aa80cf35a7b486--ace39e075293405fb16b5d95626d17a9 e2d80eb6f1ca4ff2898728661bae4b66 cb6fba63f01746b9b8aa80cf35a7b486--e2d80eb6f1ca4ff2898728661bae4b66 b191190a8919416280b0b3eaa3ef8289 RX(theta\u2081\u2080) e2d80eb6f1ca4ff2898728661bae4b66--b191190a8919416280b0b3eaa3ef8289 97bd6164d72d44178e8432289c9e1c65 RY(theta\u2081\u2083) b191190a8919416280b0b3eaa3ef8289--97bd6164d72d44178e8432289c9e1c65 5ebbe154205344859f1ab4bdb99e4967 RX(theta\u2081\u2086) 97bd6164d72d44178e8432289c9e1c65--5ebbe154205344859f1ab4bdb99e4967 e077056ec11b49bca57b05d552522473 X 5ebbe154205344859f1ab4bdb99e4967--e077056ec11b49bca57b05d552522473 e077056ec11b49bca57b05d552522473--84213c74d23a4cb0b034789162e03db1 f77418a120b247589eab27dd5659dd06 e077056ec11b49bca57b05d552522473--f77418a120b247589eab27dd5659dd06 43762e4ceb4a498daa7af46ac5fc6a8d AddBlock f77418a120b247589eab27dd5659dd06--43762e4ceb4a498daa7af46ac5fc6a8d 43762e4ceb4a498daa7af46ac5fc6a8d--763a036eafbb43408d81543bad54b566 eeb67e1601614b009922676de4a79ae5 bbf5a415cced449694011857720b007c RX(theta\u2082) 9833d2424991404681f3afa33ecf6d2d--bbf5a415cced449694011857720b007c 01a502cd12ff43999ed6edec7d170221 RY(theta\u2085) bbf5a415cced449694011857720b007c--01a502cd12ff43999ed6edec7d170221 e7394de036aa42ef87ff2f20903149d4 RX(theta\u2088) 01a502cd12ff43999ed6edec7d170221--e7394de036aa42ef87ff2f20903149d4 0b834c753dc149898d0415c6db359061 e7394de036aa42ef87ff2f20903149d4--0b834c753dc149898d0415c6db359061 9cf15a3636d4492da90ccd60d6b68c02 X 0b834c753dc149898d0415c6db359061--9cf15a3636d4492da90ccd60d6b68c02 9cf15a3636d4492da90ccd60d6b68c02--e2d80eb6f1ca4ff2898728661bae4b66 fb3277c5767941b9ba57fd077a8ceca9 RX(theta\u2081\u2081) 9cf15a3636d4492da90ccd60d6b68c02--fb3277c5767941b9ba57fd077a8ceca9 136b4e7c830949bdbd48db32f7b3ac44 RY(theta\u2081\u2084) fb3277c5767941b9ba57fd077a8ceca9--136b4e7c830949bdbd48db32f7b3ac44 cfc6c6191a024ad7b15c950ba4ddc4cd RX(theta\u2081\u2087) 136b4e7c830949bdbd48db32f7b3ac44--cfc6c6191a024ad7b15c950ba4ddc4cd 1873a18d3257474d99b8c1252dd83b83 cfc6c6191a024ad7b15c950ba4ddc4cd--1873a18d3257474d99b8c1252dd83b83 f2f4d5ddf32f4ec7be9ef4aa2b218efd X 1873a18d3257474d99b8c1252dd83b83--f2f4d5ddf32f4ec7be9ef4aa2b218efd f2f4d5ddf32f4ec7be9ef4aa2b218efd--f77418a120b247589eab27dd5659dd06 8c6463ccea394e2fbe8e4002d221adba f2f4d5ddf32f4ec7be9ef4aa2b218efd--8c6463ccea394e2fbe8e4002d221adba 8c6463ccea394e2fbe8e4002d221adba--eeb67e1601614b009922676de4a79ae5 <pre><code>from qadence import *\n\nb = chain(SWAP(0,1), SWAP(0,3))\n</code></pre> %3 14875bf5e9494e20bd2aab5a41b45207 0 7468bc71a4a84654afeea9d7bad7e7db 14875bf5e9494e20bd2aab5a41b45207--7468bc71a4a84654afeea9d7bad7e7db 709163f13c7844efaedafcb699067f86 1 9146b8cb5fc14f6dae5ac739aa67fd94 315cb5f1c26145be97f36e8e14a4893c 7468bc71a4a84654afeea9d7bad7e7db--315cb5f1c26145be97f36e8e14a4893c 2a34c6bf8f914352946d186edb0db23d 9146b8cb5fc14f6dae5ac739aa67fd94--2a34c6bf8f914352946d186edb0db23d d639d0ad1459413fb664c76332835b7f febf0ea7641d4fba939d5985d830eb2c 2a34c6bf8f914352946d186edb0db23d--febf0ea7641d4fba939d5985d830eb2c d1a8821ad42e435fadba41200c36cf8d d639d0ad1459413fb664c76332835b7f--d1a8821ad42e435fadba41200c36cf8d a3f387a17e244dd49bcdd5a91b4eff62 d398c9b4325b4528809b5293c0d3b9b7 709163f13c7844efaedafcb699067f86--d398c9b4325b4528809b5293c0d3b9b7 b57fbdcf37f749af8e544f727ff0e3ad 2 d398c9b4325b4528809b5293c0d3b9b7--9146b8cb5fc14f6dae5ac739aa67fd94 29e376c151ee449594d5a06f7cd76dcd 315cb5f1c26145be97f36e8e14a4893c--29e376c151ee449594d5a06f7cd76dcd 75a9c6254c804f928556e4a7720bbcc1 29e376c151ee449594d5a06f7cd76dcd--75a9c6254c804f928556e4a7720bbcc1 75a9c6254c804f928556e4a7720bbcc1--a3f387a17e244dd49bcdd5a91b4eff62 b1cea723bd4b4e5c9668107745789ca9 ecf518c39f8a4e6bb54b46dd2ff2499d b57fbdcf37f749af8e544f727ff0e3ad--ecf518c39f8a4e6bb54b46dd2ff2499d ea4a52de89124f749c89274b92327972 3 db8ba0a53e884ce5bd6d9da0018b7ede ecf518c39f8a4e6bb54b46dd2ff2499d--db8ba0a53e884ce5bd6d9da0018b7ede e84304e747704bafb48d2e93f584a3be db8ba0a53e884ce5bd6d9da0018b7ede--e84304e747704bafb48d2e93f584a3be 57befc3eb9eb47aa9aaa1e392fe61113 e84304e747704bafb48d2e93f584a3be--57befc3eb9eb47aa9aaa1e392fe61113 57befc3eb9eb47aa9aaa1e392fe61113--b1cea723bd4b4e5c9668107745789ca9 4fc79c6fb89b4dddbe1024c7d5075ef9 e7d361229d5c4e7d95cfe2b6c4aced20 ea4a52de89124f749c89274b92327972--e7d361229d5c4e7d95cfe2b6c4aced20 c773b22faa6c435aa1ccc2a0bdc9dedc e7d361229d5c4e7d95cfe2b6c4aced20--c773b22faa6c435aa1ccc2a0bdc9dedc 4604b5fd4224402ba204adce15ced842 c773b22faa6c435aa1ccc2a0bdc9dedc--4604b5fd4224402ba204adce15ced842 4604b5fd4224402ba204adce15ced842--d639d0ad1459413fb664c76332835b7f febf0ea7641d4fba939d5985d830eb2c--4fc79c6fb89b4dddbe1024c7d5075ef9 <pre><code>from qadence import *\n\nb = chain(CPHASE(0, 1, 0.5), CPHASE(0, 2, 0.5), CPHASE(0, 3, 0.5))\n</code></pre> %3 7edf7b3639a74656a2ec50ef9d2dd4fc 0 edf6a13be29441ff888ccde5030ead32 7edf7b3639a74656a2ec50ef9d2dd4fc--edf6a13be29441ff888ccde5030ead32 5ae4d96401e843378d07da133943367c 1 f2e270d4332a4d899e37a69ef82c13af edf6a13be29441ff888ccde5030ead32--f2e270d4332a4d899e37a69ef82c13af 3e794fe7dac44d05bca975075aadad83 f2e270d4332a4d899e37a69ef82c13af--3e794fe7dac44d05bca975075aadad83 ed30b5f759e7458bb65620e625c3fa29 3e794fe7dac44d05bca975075aadad83--ed30b5f759e7458bb65620e625c3fa29 93bbdab239b44777b9d7336a899522d4 eb3c438ccfe84a0db48a24b86d476518 PHASE(0.5) 5ae4d96401e843378d07da133943367c--eb3c438ccfe84a0db48a24b86d476518 6a68192bec6048b0a6ea394e19ee82a6 2 eb3c438ccfe84a0db48a24b86d476518--edf6a13be29441ff888ccde5030ead32 a514da35e716432982988bb8518166b9 eb3c438ccfe84a0db48a24b86d476518--a514da35e716432982988bb8518166b9 4fe6bfdc46414eb2a959d3def39b632a a514da35e716432982988bb8518166b9--4fe6bfdc46414eb2a959d3def39b632a 4fe6bfdc46414eb2a959d3def39b632a--93bbdab239b44777b9d7336a899522d4 ec9bd9e8135a4f4eb130f2daf48cbe98 5d199b2065344ee18c4b0e8a42ed1c02 6a68192bec6048b0a6ea394e19ee82a6--5d199b2065344ee18c4b0e8a42ed1c02 a44aeae174cf4b6d95c4179d90e72da3 3 feca53033fe54de385d119017933740c PHASE(0.5) 5d199b2065344ee18c4b0e8a42ed1c02--feca53033fe54de385d119017933740c feca53033fe54de385d119017933740c--f2e270d4332a4d899e37a69ef82c13af 09703874f90a4fbd88702e26c3bfe606 feca53033fe54de385d119017933740c--09703874f90a4fbd88702e26c3bfe606 09703874f90a4fbd88702e26c3bfe606--ec9bd9e8135a4f4eb130f2daf48cbe98 7855c3d209574cefb145ee4b6ef670b6 7c8cde33c19a4391aa8788412502cac1 a44aeae174cf4b6d95c4179d90e72da3--7c8cde33c19a4391aa8788412502cac1 ed7df4b292b243998c5b451662f7b0cb 7c8cde33c19a4391aa8788412502cac1--ed7df4b292b243998c5b451662f7b0cb c27af9caabdd403e898f140010eb2799 PHASE(0.5) ed7df4b292b243998c5b451662f7b0cb--c27af9caabdd403e898f140010eb2799 c27af9caabdd403e898f140010eb2799--3e794fe7dac44d05bca975075aadad83 c27af9caabdd403e898f140010eb2799--7855c3d209574cefb145ee4b6ef670b6"},{"location":"tutorials/development/draw/#developer-documentation","title":"Developer documentation","text":"<p>This section contains examples in pure graphviz that can be used to understand roughly what is done in the actual drawing backend.</p> <pre><code>import graphviz\n\nfont_name = \"Sans-Serif\"\nfont_size = \"8\"\n\ngraph_attr = {\n    \"rankdir\": \"LR\",  # LR = left to right, TB = top to bottom\n    \"nodesep\": \"0.1\",  # In inches, tells distance between nodes without edges\n    \"compound\": \"true\",  # Needed to draw properly edges in hamevo when content is hidden\n    \"splines\": \"false\",  # Needed to draw control gates vertical lines one over the other\n}  # These are the default values for graphs\n\nnode_attr = {\n    \"shape\": \"box\",  # 'box' for normal nodes, 'point' for control gates or 'plaintext' for starting nodes (the qubit label).\n    \"style\": \"rounded\",  # Unfortunately we can't specify the radius of the rounded, at least for this version\n    \"fontname\": font_name,\n    \"fontsize\": font_size,\n    \"width\": \"0.1\",  # In inches, it doesn't get tinier than the label font.\n    \"height\": \"0.1\"  # In inches, it doesn't get tinier than the label font.\n}  # These are the defaults values that can be overridden at node declaration.\n\ndefault_cluster_attr = {\n    \"fontname\": font_name,\n    \"fontsize\": font_size,\n    \"labelloc\": \"b\",  # location of cluster label. b as bottom, t as top\n    \"style\": \"rounded\"\n} # These are the defaults values that can be overridden at sub graph declaration\n\nhamevo_cluster_attr = {\n    \"label\": \"HamEvo(t=10)\"\n}\nhamevo_cluster_attr.update(default_cluster_attr)\n\nh = graphviz.Graph(graph_attr=graph_attr, node_attr=node_attr)\nh.node(\"Hello World!\")\nh\n</code></pre> <pre><code>\n</code></pre> <pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n\n# Add start and end nodes\nfor i in range(4):\n    h.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\n    h.node(f'e{i}', style='invis', group=f\"{i}\")\n\n# Add nodes\nh.node('X', group=\"0\")\nh.node('Y', group=\"1\")\n\n# Add hamevo and its nodes\nhamevo = graphviz.Graph(name='cluster_hamevo', graph_attr=hamevo_cluster_attr)\nfor i in range(4):\n    hamevo.node(f'z{i}', shape=\"box\", style=\"invis\", label=f'{i}', group=f\"{i}\")\nh.subgraph(hamevo)\n\n# Add rx gates cluster and its nodes\ncluster_attr = {\"label\": \"RX gates\"}\ncluster_attr.update(default_cluster_attr)\ncluster = graphviz.Graph(name=\"cluster_0\", graph_attr=cluster_attr)\ncluster.node('RX(x)', group=\"2\")\ncluster.node('RX(0.5)', group=\"3\")\nh.subgraph(cluster)\n\nh.node('cnot0', label='', shape='point', width='0.1', group='0')\nh.node('cnot1', label='X', group='1')\nh.node('cnot2', label='', shape='point', width='0.1', group='2')\nh.node('cnot3', label='', shape='point', width='0.1', group='3')\n\n# Add edges\nh.edge('s0', 'X')\nh.edge('X', 'cnot0')\nh.edge('cnot0', 'z0', lhead='cluster_hamevo')\nh.edge('z0', 'e0', ltail='cluster_hamevo')\nh.edge('s1', 'Y')\nh.edge('Y', 'cnot1')\nh.edge('cnot1', 'z1', lhead='cluster_hamevo')\nh.edge('z1', 'e1', ltail='cluster_hamevo')\nh.edge('s2', 'RX(x)')\nh.edge('RX(x)', 'cnot2')\nh.edge('cnot2', 'z2', lhead='cluster_hamevo')\nh.edge('z2', 'e2', ltail='cluster_hamevo')\nh.edge('s3', 'RX(0.5)')\nh.edge('RX(0.5)', 'cnot3')\nh.edge('cnot3', 'z3', lhead='cluster_hamevo')\nh.edge('z3', 'e3', ltail='cluster_hamevo')\nh.edge('cnot1', 'cnot0', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot2', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot3', constraint='false')  # constraint: false is needed to draw vertical edges\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/development/draw/#example-of-cluster-of-clusters","title":"Example of cluster of clusters","text":"<pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n\n# Define start and end nodes\nfor i in range(4):\n    h.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\n    h.node(f'e{i}', style='invis', group=f\"{i}\")\n\n# Define outer cluster\ncluster_attr = {\"label\": \"Outer cluster\"}\ncluster_attr.update(default_cluster_attr)\nouter_cluster = graphviz.Graph(name=\"cluster_outer\", graph_attr=cluster_attr)\n\n# Define inner cluster 1 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 1\"}\ncluster_attr.update(default_cluster_attr)\ninner1_cluster = graphviz.Graph(name=\"cluster_inner1\", graph_attr=cluster_attr)\ninner1_cluster.node(\"a0\", group=\"0\")\ninner1_cluster.node(\"a1\", group=\"1\")\nouter_cluster.subgraph(inner1_cluster)\n\n# Define inner cluster 2 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 2\"}\ncluster_attr.update(default_cluster_attr)\ninner2_cluster = graphviz.Graph(name=\"cluster_inner2\", graph_attr=cluster_attr)\ninner2_cluster.node(\"a2\", group=\"2\")\ninner2_cluster.node(\"a3\", group=\"3\")\nouter_cluster.subgraph(inner2_cluster)\n\n# This has to be done here, after inner clusters definitions\nh.subgraph(outer_cluster)\n\n# Define more nodes\nfor i in range(4):\n    h.node(f\"b{i}\", group=f\"{i}\")\n\nfor i in range(4):\n    h.edge(f's{i}', f'a{i}')\n    h.edge(f'a{i}', f'b{i}')\n    h.edge(f'b{i}', f'e{i}')\n\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/digital_analog_qc/","title":"Digital-Analog Quantum Computation","text":"<p>Digital-analog quantum computation (DAQC) is a universal quantum computing paradigm<sup>1</sup>, based on two primary computations:</p> <ul> <li>Fast single-qubit operations (digital).</li> <li>Multi-partite entangling operations acting on all qubits (analog).</li> </ul> <p>A promising quantum computing platform for the implementation of the DAQC paradigm is neutral-atoms, where both these computations are realizable.</p>"},{"location":"tutorials/digital_analog_qc/#digital-analog-emulation","title":"Digital-analog emulation","text":"<p>Qadence simplifies the execution of DAQC programs on either emulated or real devices by providing a simplified interface for customizing interactions and interfacing with pulse-level programming in <code>Pulser</code><sup>3</sup>.</p>"},{"location":"tutorials/digital_analog_qc/#digital-analog-transformation","title":"Digital-analog transformation","text":"<p>Furthermore, the essence of digital-analog computation is the ability to represent any analog operation, i.e. any arbitrary Hamiltonian, using an auxiliary device-amenable Hamiltonian, such as the ubiquitous Ising model<sup>2</sup>. This is at the core of the DAQC implementation in Qadence.</p>"},{"location":"tutorials/digital_analog_qc/#execution-on-rydberg-atom-arrays-with-restriced-addressability","title":"Execution on Rydberg atom arrays with restriced addressability","text":"<p>Finally, Qadence offers some convenience constructors and interfaces to execute programs compatible with a DAQC flavor featuring only a restricted access to individual qubit addressability with always-on interaction. This regime is common in currently available neutral atom quantum computers.</p>"},{"location":"tutorials/digital_analog_qc/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/analog-basics/","title":"Basic operations on neutral-atoms","text":"<p>Warning</p> <p>The digital-analog emulation framework is under construction and more changes to the interface may still occur.</p> <p>Qadence includes primitives for the construction of programs implemented on a set of interacting qubits. The goal is to build digital-analog programs that better represent the reality of interacting qubit platforms, such as neutral-atoms, while maintaining a simplified interface for users coming from a digital quantum computing background that may not be as familiar with pulse-level programming.</p> <p>To build the intuition for the interface in Qadence, it is important to go over some of the underlying physics. We can write a general Hamiltonian for a set of \\(n\\) interacting qubits as</p> \\[ \\mathcal{H} = \\sum_{i=0}^{n-1}\\left(\\mathcal{H}^\\text{d}_{i}(t) + \\sum_{j&lt;i}\\mathcal{H}^\\text{int}_{ij}\\right), \\] <p>where the driving Hamiltonian \\(\\mathcal{H}^\\text{d}_{i}\\) describes the pulses used to control single-qubit rotations, and the interaction Hamiltonian \\(\\mathcal{H}^\\text{int}_{ij}\\) describes the natural interaction between qubits.</p>"},{"location":"tutorials/digital_analog_qc/analog-basics/#rydberg-atoms","title":"Rydberg atoms","text":"<p>For the purpose of digital-analog emulation of neutral-atom systems in Qadence, we now consider a simplified time-independent global driving Hamiltonian, written as</p> \\[ \\mathcal{H}^\\text{d}_{i} = \\frac{\\Omega}{2}\\left(\\cos(\\phi) X_i - \\sin(\\phi) Y_i \\right) - \\delta N_i \\] <p>where \\(\\Omega\\) is the Rabi frequency, \\(\\delta\\) is the detuning, \\(\\phi\\) is the phase, \\(X_i\\) and \\(Y_i\\) are the standard Pauli operators, and \\(N_i=\\frac{1}{2}(I_i-Z_i)\\) is the number operator. This Hamiltonian allows arbitrary global single-qubit rotations to be written, meaning that the values set for \\((\\Omega,\\phi,\\delta)\\) are the same accross the qubit support.</p> <p>For the interaction term, Rydberg atoms typically allow both an Ising and an XY mode of operation. For now, we focus on the Ising interaction, where the Hamiltonian is written as</p> \\[ \\mathcal{H}^\\text{int}_{ij} = \\frac{C_6}{r_{ij}^6}N_iN_j \\] <p>where \\(r_{ij}\\) is the distance between atoms \\(i\\) and \\(j\\), and \\(C_6\\) is a coefficient depending on the specific Rydberg level of the excited state used in the computational logic states. A typical value for rydberg level of 60 is \\(C_6\\approx 866~[\\text{rad} . \\mu \\text{m}^6 / \\text{ns}]\\).</p> <p>For a given register of atoms prepared in some spatial coordinates, the Hamiltonians described will generate the dynamics of some unitary operation as</p> \\[ U(t, \\Omega, \\delta, \\phi) = \\exp(-i\\mathcal{H}t) \\] <p>where we specify the final parameter \\(t\\), the duration of the operation.</p> <p>Qadence uses the following units for user-specified parameters:</p> <ul> <li>Rabi frequency and detuning \\(\\Omega\\), \\(\\delta\\): \\([\\text{rad}/\\mu \\text{s}]\\)</li> <li>Phase \\(\\phi\\): \\([\\text{rad}]\\)</li> <li>Duration \\(t\\): \\([\\text{ns}]\\)</li> <li>Atom coordinates: \\([\\mu \\text{m}]\\)</li> </ul>"},{"location":"tutorials/digital_analog_qc/analog-basics/#in-practice","title":"In practice","text":"<p>Given the Hamiltonian description in the previous section, we will now go over a few examples of the standard operations available in Qadence.</p>"},{"location":"tutorials/digital_analog_qc/analog-basics/#arbitrary-rotation","title":"Arbitrary rotation","text":"<p>To start, we will exemplify the a general rotation on a set of atoms. To create an arbitrary register of atoms, we refer the user to the register creation tutorial. Below, we create a line register of three qubits with a separation of \\(8~\\mu\\text{m}\\). This is a typical value used in combination with a standard experimental setup of neutral atoms such that the interaction term in the Hamiltonian can effectively be used for computations.</p> <pre><code>from qadence import Register\n\nreg = Register.line(3, spacing=8.0)  # Atom spacing in \u03bcm\n</code></pre> <p>Currently, the most general rotation operation uses the <code>AnalogRot</code> operation, which essentially implements \\(U(t, \\Omega, \\delta, \\phi)\\) defined above.</p> <pre><code>from qadence import AnalogRot, PI\n\nrot_op = AnalogRot(\n    duration = 500., # [ns]\n    omega = PI, # [rad/\u03bcs]\n    delta = PI, # [rad/\u03bcs]\n    phase = PI, # [rad]\n)\n</code></pre> <p>Note that in the code above a specific qubit support is not defined. By default this operation applies a global rotation on all qubits. We can define a circuit using the 3-qubit register and run it in the pyqtorch backend:</p> <pre><code>from qadence import BackendName, run\n\nwf = run(reg, rot_op, backend = BackendName.PYQTORCH)\n\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4248-0.2411j, -0.1687+0.3156j, -0.1696+0.2676j, -0.2040-0.2671j,\n         -0.1687+0.3156j,  0.0014-0.2721j, -0.2040-0.2671j,  0.3034-0.1130j]])\n</code></pre> Under the hood of AnalogRot      To be fully explicit about what goes on under the hood of `AnalogRot`, we can look at the example     code below.      <pre><code>from qadence import BackendName, HamEvo, X, Y, N, add, run, PI\nfrom qadence.analog.constants import C6_DICT\nfrom math import cos, sin\n\n# Following the 3-qubit register above\nn_qubits = 3\ndx = 8.0\n\n# Parameters used in the AnalogRot\nduration = 500.\nomega = PI\ndelta = PI\nphase = PI\n\n# Building the terms in the driving Hamiltonian\nh_x = (omega / 2) * cos(phase) * add(X(i) for i in range(n_qubits))\nh_y = (-1.0 * omega / 2) * sin(phase) * add(Y(i) for i in range(n_qubits))\nh_n = -1.0 * delta * add(N(i) for i in range(n_qubits))\n\n# Building the interaction Hamiltonian\n\n# Dictionary of coefficient values for each Rydberg level, which is 60 by default\nc_6 = C6_DICT[60]\n\nh_int = c_6 * (\n    1/(dx**6) * (N(0)@N(1)) +\n    1/(dx**6) * (N(1)@N(2)) +\n    1/((2*dx)**6) * (N(0)@N(2))\n)\n\nhamiltonian = h_x + h_y + h_n + h_int\n\n# Convert duration to \u00b5s due to the units of the Hamiltonian\nexplicit_rot = HamEvo(hamiltonian, duration / 1000)\n\nwf = run(n_qubits, explicit_rot, backend = BackendName.PYQTORCH)\n\n# We get the same final wavefunction\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4248-0.2411j, -0.1687+0.3156j, -0.1696+0.2676j, -0.2040-0.2671j,\n         -0.1687+0.3156j,  0.0014-0.2721j, -0.2040-0.2671j,  0.3034-0.1130j]])\n</code></pre> <p>When sending the <code>AnalogRot</code> operation to the pyqtorch backend, Qadence automatically builds the correct Hamiltonian and the corresponding <code>HamEvo</code> operation with the added qubit interactions, as shown explicitly in the minimized section above. However, this operation is also supported in the Pulser backend, where the correct pulses are automatically created.</p> <pre><code>wf = run(\n    reg,\n    rot_op,\n    backend = BackendName.PULSER,\n)\n\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4253-0.2408j, -0.1688+0.3157j, -0.1698+0.2678j, -0.2044-0.2667j,\n         -0.1688+0.3157j,  0.0011-0.2721j, -0.2044-0.2667j,  0.3026-0.1137j]])\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#rx-ry-rz-rotations","title":"RX / RY / RZ rotations","text":"<p>The <code>AnalogRot</code> provides full control over the parameters of \\(\\mathcal{H}^\\text{d}\\), but users coming from a digital quantum computing background may be more familiar with the standard <code>RX</code>, <code>RY</code> and <code>RZ</code> rotations, also available in Qadence. For the emulated analog interface, Qadence provides alternative <code>AnalogRX</code>, <code>AnalogRY</code> and <code>AnalogRZ</code> operations which call <code>AnalogRot</code> under the hood to represent the rotations accross the respective axis.</p> <p>For a given angle of rotation \\(\\theta\\) provided to each of these operations, currently a set of hardcoded assumptions are made on the tunable Hamiltonian parameters:</p> \\[ \\begin{aligned} \\text{RX}:&amp; \\quad \\Omega = \\pi, \\quad \\delta = 0, \\quad \\phi = 0, \\quad t = (\\theta/\\Omega)\\times 10^3 \\\\ \\text{RY}:&amp; \\quad \\Omega = \\pi, \\quad \\delta = 0, \\quad \\phi = -\\pi/2, \\quad t = (\\theta/\\Omega)\\times 10^3 \\\\ \\text{RZ}:&amp; \\quad \\Omega = 0, \\quad \\delta = \\pi, \\quad \\phi = 0, \\quad t = (\\theta/\\delta)\\times 10^3 \\\\ \\end{aligned} \\] <p>Note that the \\(\\text{RZ}\\) operation as defined above includes a global phase compared to the standard \\(\\text{RZ}\\) rotation since it evolves \\(\\exp\\left(-i\\frac{\\theta}{2}\\frac{I-Z}{2}\\right)\\) instead of \\(\\exp\\left(-i\\frac{\\theta}{2}Z\\right)\\) given the detuning operator in \\(\\mathcal{H}^\\text{d}\\).</p> <p>Warning</p> <p>As shown above, the values of \\(\\Omega\\) and \\(\\delta\\) are currently hardcoded in these operators, and the effective angle of rotation is controlled by varying the duration of the evolution. Currently, the best way to overcome this is to use <code>AnalogRot</code> directly, but more general and convenient options will be provided soon in an improved interface.</p> <p>Below we exemplify the usage of <code>AnalogRX</code>:</p> <pre><code>from qadence import Register, BackendName\nfrom qadence import RX, AnalogRX, random_state, equivalent_state, kron, run, PI\n\nn_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\n# Rotation angle\ntheta = PI\n\n# Analog rotation using the Rydberg Hamiltonian\nrot_analog = AnalogRX(angle = theta)\n\n# Equivalent full-digital global rotation\nrot_digital = kron(RX(i, theta) for i in range(n_qubits))\n\n# Some random initial state\ninit_state = random_state(n_qubits)\n\n# Compare the final state using the full digital and the AnalogRX\nwf_analog_pyq = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\n\nwf_digital_pyq = run(\n    reg,\n    rot_digital,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_digital_pyq, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  False\n</code></pre> <p>As we can see, running a global <code>RX</code> or the <code>AnalogRX</code> does not result in equivalent states at the end, given that the digital <code>RX</code> operation does not include the interaction between the qubits. By setting <code>dx</code> very high in the code above the interaction will be less significant and the results will match.</p> <p>However, if we compare with the Pulser backend, we see that the results for <code>AnalogRX</code> are consistent with the expected results from a real device:</p> <pre><code>wf_analog_pulser = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PULSER,\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_analog_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#evolving-the-interaction-term","title":"Evolving the interaction term","text":"<p>Finally, besides applying specific qubit rotations, we can also choose to evolve only the interaction term \\(\\mathcal{H}^\\text{int}\\), equivalent to setting \\(\\Omega = \\delta = \\phi = 0\\). To do so, Qadence provides the function <code>AnalogInteraction</code> which does exactly this.</p> <pre><code>from qadence import Register, BackendName, random_state, equivalent_state, AnalogInteraction, run\n\nn_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\nduration = 1000.\nop = AnalogInteraction(duration = duration)\n\ninit_state = random_state(n_qubits)\n\nwf_pyq = run(reg, op, state = init_state, backend = BackendName.PYQTORCH)\nwf_pulser = run(reg, op, state = init_state, backend = BackendName.PULSER)\n\nbool_equiv = equivalent_state(wf_pyq, wf_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#device-specifications-in-qadence","title":"Device specifications in Qadence","text":"<p>As a way to control other specifications of the interacting Rydberg atoms, Qadence provides a <code>RydbergDevice</code> class, which is currently used for both the pyqtorch and the pulser backends. Below we initialize a Rydberg device showcasing all the possible options.</p> <pre><code>from qadence import RydbergDevice, DeviceType, Interaction, PI\n\ndevice_specs = RydbergDevice(\n    interaction=Interaction.NN, # Or Interaction.XY, supported only for pyqtorch\n    rydberg_level=60, # Integer value affecting the C_6 coefficient\n    coeff_xy=3700.00, # C_3 coefficient for the XY interaction\n    max_detuning=2 * PI * 4, # Max value for delta, currently only used in pulser\n    max_amp=2 * PI * 3, # Max value for omega, currently only used in pulser\n    pattern=None, # Semi-local addressing pattern, see the relevant tutorial\n    type=DeviceType.IDEALIZED, # Pulser device to which the qadence device is converted in that backend\n)\n</code></pre> <p>The values above are the defaults when simply running <code>device_specs = RydbergDevice()</code>. The convenience wrappers <code>IdealDevice()</code> or <code>RealisticDevice()</code> can also be used which simply change the <code>type</code> for the Pulser backend, but also allow an <code>AddressingPattern</code> passed in the <code>pattern</code> argument (see the relevant tutorial here).</p> <p>Warning</p> <p>Currently, the options above are not fully integrated in both backends and this class should mostly be used if a user wishes to experiment with a different <code>rydberg_level</code>, or to change the device type for the pulser backend.</p> <p>Planned features to add to the RydbergDevice include the definition of custom interaction functions, the control of other drive Hamiltonian parameters so that \\(\\Omega\\), \\(\\delta\\) and \\(\\phi\\) are not hardcoded when doing analog rotations, and the usage of the <code>max_detuning</code> and <code>max_amp</code> to control those respective parameters when training models in the pyqtorch backend.</p> <p>Finally, to change a given simulation, the device specifications are integrated in the Qadence <code>Register</code>. By default, all registers initialize an <code>IdealDevice()</code> under the hood. Below we run a quick test for a different rydberg level.</p> <pre><code>from qadence import Register, BackendName, random_state, equivalent_state, run\nfrom qadence import AnalogRX, RydbergDevice, PI\n\ndevice_specs = RydbergDevice(rydberg_level = 70)\n\nn_qubits_side = 2\nreg = Register.square(\n    n_qubits_side,\n    spacing = 8.0,\n    device_specs = device_specs\n)\n\nrot_analog = AnalogRX(angle = PI)\n\ninit_state = random_state(n_qubits = 4)\n\nwf_analog_pyq = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\nwf_analog_pulser = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PULSER\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_analog_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#technical-details","title":"Technical details","text":"<p>Warning</p> <p>The details described here are relevant in the current version but will be lifted soon for the next version of the emulated analog interface.</p> <p>In the previous section we have exemplified the main ingredients of the current user-facing functionalities of the emulated analog interface, and in the next tutorial on Quantum Circuit Learning we will exmplify its usage in a simple QML example. Here we specify some extra details of this interface.</p> <p>In the block system, all analog rotation operators initialize a <code>ConstantAnalogRotation</code> block, while the <code>AnalogInteraction</code> operation initializes an <code>InteractionBlock</code>. As we have shown, by default, these blocks use a global qubit support, which can be passed explicitly by setting <code>qubit_support = QubitSupportType.GLOBAL</code>. However, composing blocks using <code>kron</code> with local qubit supports and different durations is not allowed.</p> <pre><code>from qadence import AnalogRX, AnalogRY, Register, kron\n\ndx = 8.0\nreg = Register.from_coordinates([(0, 0), (dx, 0)])\n\n# Does not work (the angle affects the duration, as seen above):\nrot_0 = AnalogRX(angle = 1.0, qubit_support = (0,))\nrot_1 = AnalogRY(angle = 2.0, qubit_support = (1,))\n\ntry:\n    block = kron(rot_0, rot_1)\nexcept ValueError as error:\n    print(\"Error:\", error)\n\n# Works:\nrot_0 = AnalogRX(angle = 1.0, qubit_support = (0,))\nrot_1 = AnalogRY(angle = 1.0, qubit_support = (1,))\n\nblock = kron(rot_0, rot_1)\n</code></pre> <pre><code>Error: Kron'ed blocks have to have same duration.\n</code></pre> <p>Using <code>chain</code> is only supported between analog blocks with global qubit support:</p> <pre><code>from qadence import chain\n\nrot_0 = AnalogRX(angle = 1.0, qubit_support = \"global\")\nrot_1 = AnalogRY(angle = 2.0, qubit_support = \"global\")\n\nblock = chain(rot_0, rot_1)\n</code></pre> <p>The restrictions above only apply to the analog blocks, and analog and digital blocks can currently be composed.</p> <pre><code>from qadence import RX\n\nrot_0 = AnalogRX(angle = 1.0, qubit_support = \"global\")\nrot_1 = AnalogRY(angle = 2.0, qubit_support = (0,))\nrot_digital = RX(1, 1.0)\n\nblock_0 = chain(rot_0, rot_digital)\nblock_1 = kron(rot_1, rot_digital)\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-blocks-qcl/","title":"Fitting a function with analog blocks","text":"<p>Analog blocks can be parametrized in the usual Qadence manner. Like any other parameters, they can be optimized. The next snippet exemplifies the creation of an analog and parameterized ansatz to fit a simple function. First, define a register and feature map block. We again use a default spacing of \\(8~\\mu\\text{m}\\) as done in the basic tutorial.</p> <pre><code>from qadence import Register, FeatureParameter, chain\nfrom qadence import AnalogRX, AnalogRY, AnalogRZ, AnalogInteraction\nfrom sympy import acos\n\n# Line register\nn_qubits = 2\nregister = Register.line(n_qubits, spacing = 8.0)\n\n# The input feature x for the circuit to learn f(x)\nx = FeatureParameter(\"x\")\n\n# Feature map with a few global analog rotations\nfm = chain(\n    AnalogRX(x),\n    AnalogRY(2*x),\n    AnalogRZ(3*x),\n)\n</code></pre> <p>Next, we define the ansatz with parameterized rotations.</p> <pre><code>from qadence import hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel, BackendName, DiffMode\nfrom qadence import VariationalParameter\n\nt_0 = 1000. * VariationalParameter(\"t_0\")\nt_1 = 1000. * VariationalParameter(\"t_1\")\nt_2 = 1000. * VariationalParameter(\"t_2\")\n\n# Creating the ansatz with parameterized rotations and wait time\nansatz = chain(\n    AnalogRX(\"tht_0\"),\n    AnalogRY(\"tht_1\"),\n    AnalogRZ(\"tht_2\"),\n    AnalogInteraction(t_0),\n    AnalogRX(\"tht_3\"),\n    AnalogRY(\"tht_4\"),\n    AnalogRZ(\"tht_5\"),\n    AnalogInteraction(t_1),\n    AnalogRX(\"tht_6\"),\n    AnalogRY(\"tht_7\"),\n    AnalogRZ(\"tht_8\"),\n    AnalogInteraction(t_2),\n)\n</code></pre> <p>We define the measured observable as the total magnetization, and build the <code>QuantumModel</code>.</p> <pre><code># Total magnetization observable\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n\n# Defining the circuit and observable\ncircuit = QuantumCircuit(register, fm, ansatz)\n\nmodel = QuantumModel(\n    circuit,\n    observable = observable,\n    backend = BackendName.PYQTORCH,\n    diff_mode = DiffMode.AD\n)\n</code></pre> <p>Now we can define the function to fit as well as our training and test data.</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\n\n# Function to fit:\ndef f(x):\n    return x**2\n\nx_test = torch.linspace(-1.0, 1.0, steps=100)\ny_test = f(x_test)\n\nx_train = torch.linspace(-1.0, 1.0, steps=10)\ny_train = f(x_train)\n\n# Initial prediction from the model, to be visualized later\ny_pred_initial = model.expectation({\"x\": x_test}).detach()\n</code></pre> <p>Finally we define a simple loss function and training loop.</p> <pre><code>mse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ndef loss_fn(x_train, y_train):\n    out = model.expectation({\"x\": x_train})\n    loss = mse_loss(out.squeeze(), y_train)\n    return loss\n\nn_epochs = 200\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_fn(x_train, y_train)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And with the model trained we can plot the final results.</p> <pre><code>y_pred_final = model.expectation({\"x\": x_test}).detach()\n\nplt.plot(x_test, y_pred_initial, label = \"Initial prediction\")\nplt.plot(x_test, y_pred_final, label = \"Final prediction\")\nplt.scatter(x_train, y_train, label = \"Training points\")\n</code></pre> 2025-04-04T13:33:55.037261 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/analog-qubo/","title":"Solve a QUBO problem","text":"<p>In this notebook, we solve a quadratic unconstrained binary optimization (QUBO) problem with Qadence. QUBOs are very popular combinatorial optimization problems with a wide range of applications. Here, we solve the problem using the QAOA <sup>1</sup> variational algorithm by embedding the QUBO problem weights onto a register as standard for neutral atom quantum devices.</p> <p>Additional background information on QUBOs can be found here, directly solved using the pulse-level interface Pulser.</p>"},{"location":"tutorials/digital_analog_qc/analog-qubo/#define-and-solve-qubo","title":"Define and solve QUBO","text":"Pre-requisite: optimal register coordinates for embedding the QUBO problem <p>A basic ingredient for solving a QUBO problem with a neutral atom device is to embed the problem onto the atomic register. In short, embedding algorithms cast the problem onto a graph mapped onto the register by optimally finding atomic coordinates. A discussion on the embedding algorithms is beyond the scope of this tutorial and a simplified version taken from here is added below.</p> <pre><code>import numpy as np\nimport numpy.typing as npt\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\nfrom qadence import RydbergDevice\n\ndef qubo_register_coords(Q: np.ndarray, device: RydbergDevice) -&gt; list:\n    \"\"\"Compute coordinates for register.\"\"\"\n\n    def evaluate_mapping(new_coords, *args):\n        \"\"\"Cost function to minimize. Ideally, the pairwise\n        distances are conserved\"\"\"\n        Q, shape = args\n        new_coords = np.reshape(new_coords, shape)\n        interaction_coeff = device.coeff_ising\n        new_Q = squareform(interaction_coeff / pdist(new_coords) ** 6)\n        return np.linalg.norm(new_Q - Q)\n\n    shape = (len(Q), 2)\n    np.random.seed(0)\n    x0 = np.random.random(shape).flatten()\n    res = minimize(\n        evaluate_mapping,\n        x0,\n        args=(Q, shape),\n        method=\"Nelder-Mead\",\n        tol=1e-6,\n        options={\"maxiter\": 200000, \"maxfev\": None},\n    )\n    return [(x, y) for (x, y) in np.reshape(res.x, (len(Q), 2))]\n</code></pre> <p>With the embedding routine define above, we can translate a matrix defining a QUBO problem to a set of atom coordinates for the register. The QUBO problem is initially defined by a graph of weighted edges and a cost function to be optimized. The weighted edges are represented by a real-valued symmetric matrix <code>Q</code> which is used throughout the tutorial.</p> <pre><code>import torch\nfrom qadence import QuantumModel\n\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\n# QUBO problem weights (real-value symmetric matrix)\nQ = np.array(\n    [\n        [-10.0, 19.7365809, 19.7365809, 5.42015853, 5.42015853],\n        [19.7365809, -10.0, 20.67626392, 0.17675796, 0.85604541],\n        [19.7365809, 20.67626392, -10.0, 0.85604541, 0.17675796],\n        [5.42015853, 0.17675796, 0.85604541, -10.0, 0.32306662],\n        [5.42015853, 0.85604541, 0.17675796, 0.32306662, -10.0],\n    ]\n)\n\n# Loss function to guide the optimization routine\ndef loss(model: QuantumModel, *args) -&gt; tuple[torch.Tensor, dict]:\n    to_arr_fn = lambda bitstring: np.array(list(bitstring), dtype=int)\n    cost_fn = lambda arr: arr.T @ Q @ arr\n    samples = model.sample({}, n_shots=1000)[0]\n    cost_fn = sum(samples[key] * cost_fn(to_arr_fn(key)) for key in samples)\n    return torch.tensor(cost_fn / sum(samples.values())), {}\n</code></pre> <p>The QAOA algorithm needs a variational quantum circuit with optimizable parameters. For that purpose, we use a fully analog circuit composed of two global rotations per layer on different axes of the Bloch sphere. The first rotation corresponds to the mixing Hamiltonian and the second one to the embedding Hamiltonian <sup>1</sup>. In this setting, the embedding is realized by the appropriate register coordinates and the resulting qubit interaction. Details on the analog blocks used here can be found in the analog basics tutorial.</p> Rydberg level <p>The Rydberg level is set to 70. We initialize the weighted register graph from the QUBO definition similarly to what is done in the original tutorial, and set the device specifications with the updated Rydberg level.</p> <pre><code>from qadence import QuantumCircuit, Register, RydbergDevice\nfrom qadence import chain, AnalogRX, AnalogRZ\n\n# Device specification and atomic register\ndevice = RydbergDevice(rydberg_level=70)\n\nreg = Register.from_coordinates(\n    qubo_register_coords(Q, device), device_specs=device\n)\n\n# Analog variational quantum circuit\nlayers = 2\nblock = chain(*[AnalogRX(f\"t{i}\") * AnalogRZ(f\"s{i}\") for i in range(layers)])\ncircuit = QuantumCircuit(reg, block)\n</code></pre> <p>By initializing the <code>QuantumModel</code> with this circuit we can check the initial counts where no clear solution can be found.</p> <pre><code>model = QuantumModel(circuit)\ninitial_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> <pre><code>initial_counts = OrderedCounter({'00000': 101, '10000': 87, '01000': 75, '00110': 72, '00100': 70, '01010': 64, '01001': 62, '00101': 53, '00010': 51, '00011': 48, '01011': 46, '00001': 45, '10010': 45, '00111': 38, '10001': 34, '11000': 29, '10100': 18, '01100': 14, '01110': 11, '01111': 10, '10110': 7, '11001': 7, '11010': 6, '01101': 4, '10101': 2, '10011': 1})\n</code></pre> <p>Finally, we can proceed with the variational optimization. The cost function defined above is derived from bitstring computations and therefore non differentiable. We use Qadence ML facilities to run gradient-free optimizations using the <code>nevergrad</code> library.</p> <pre><code>from qadence.ml_tools import Trainer, TrainConfig, num_parameters\nimport nevergrad as ng\n\nTrainer.set_use_grad(False)\n\nconfig = TrainConfig(max_iter=100)\n\noptimizer = ng.optimizers.NGOpt(\n    budget=config.max_iter, parametrization=num_parameters(model)\n)\n\ntrainer = Trainer(model, optimizer, config, loss)\n\ntrainer.fit()\n\noptimal_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> <p>Finally, let's plot the solution. The expected bitstrings are marked in red.</p> <pre><code>import matplotlib.pyplot as plt\n\n# Known solutions to the QUBO problem.\nsolution_bitstrings = [\"01011\", \"00111\"]\n\ndef plot_distribution(C, ax, title):\n    C = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n    color_dict = {key: \"r\" if key in solution_bitstrings else \"b\" for key in C}\n    ax.set_xlabel(\"bitstrings\")\n    ax.set_ylabel(\"counts\")\n    ax.set_xticks([i for i in range(len(C.keys()))], C.keys(), rotation=90)\n    ax.bar(C.keys(), C.values(), color=color_dict.values())\n    ax.set_title(title)\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 4))\nplot_distribution(initial_counts, axs[0], \"Initial counts\")\nplot_distribution(optimal_counts, axs[1], \"Optimal counts\")\n</code></pre> 2025-04-04T13:33:58.956122 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/analog-qubo/#references","title":"References","text":"<ol> <li> <p>Edward Farhi, Jeffrey Goldstone, Sam Gutmann, A Quantum Approximate Optimization Algorithm, arXiv:1411.4028 (2014) \u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/","title":"<code>CNOT</code> with interacting qubits","text":"<p>Digital-analog quantum computing focuses on using single qubit digital gates combined with more complex and device-dependent analog interactions to represent quantum programs. This paradigm has been shown to be universal for quantum computation<sup>1</sup>. However, while this approach may have advantages when adapting quantum programs to real devices, known quantum algorithms are very often expressed in a fully digital paradigm. As such, it is also important to have concrete ways to transform from one paradigm to another.</p> <p>This tutorial will exemplify the DAQC transformation starting with the representation of a simple digital <code>CNOT</code> using the universality of the Ising Hamiltonian<sup>2</sup>.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#cnot-with-cphase","title":"<code>CNOT</code> with <code>CPHASE</code>","text":"<p>Let's look at a single example of how the digital-analog transformation can be used to perform a <code>CNOT</code> on two qubits inside a register of globally interacting qubits.</p> <p>First, note that the <code>CNOT</code> can be decomposed with two Hadamard and a <code>CPHASE</code> gate with \\(\\phi=\\pi\\):</p> <pre><code>import torch\nfrom qadence import chain, sample, product_state\n\nfrom qadence.draw import display\nfrom qadence import X, I, Z, H, N, CPHASE, CNOT, HamEvo, PI\n\nn_qubits = 2\n\n# CNOT gate\ncnot_gate = CNOT(0, 1)\n\n# CNOT decomposed\nphi = PI\ncnot_decomp = chain(H(1), CPHASE(0, 1, phi), H(1))\n\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample from CNOT gate and 100 shots = [OrderedCounter({'11': 100})]\nsample from decomposed CNOT gate and 100 shots = [OrderedCounter({'11': 100})]\n</code></pre> <p>The <code>CPHASE</code> matrix is diagonal, and can be implemented by exponentiating an Ising-like Hamiltonian, or generator,</p> \\[\\text{CPHASE}(i,j,\\phi)=\\text{exp}\\left(-i\\phi \\mathcal{H}_\\text{CP}(i, j)\\right)\\] \\[\\begin{aligned} \\mathcal{H}_\\text{CP}&amp;=-\\frac{1}{4}(I_i-Z_i)(I_j-Z_j)\\\\ &amp;=-N_iN_j \\end{aligned}\\] <p>where the number operator \\(N_i = \\frac{1}{2}(I_i-Z_i)=\\hat{n}_i\\) is used, leading to an Ising-like interaction \\(\\hat{n}_i\\hat{n}_j\\) realisable in neutral-atom systems. Let's rebuild the <code>CNOT</code> using this evolution.</p> <pre><code>from qadence import kron, block_to_tensor\n\n# Hamiltonian for the CPHASE gate\nh_cphase = (-1.0) * kron(N(0), N(1))\n\n# Exponentiating and time-evolving the Hamiltonian until t=phi.\ncphase_evo = HamEvo(h_cphase, phi)\n\n# Check that we have the CPHASE gate:\ncphase_matrix = block_to_tensor(CPHASE(0, 1, phi))\ncphase_evo_matrix = block_to_tensor(cphase_evo)\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix: True\n</code></pre> <p>Now that the <code>CPHASE</code> generator is checked, it can be applied to the <code>CNOT</code>:</p> <pre><code># CNOT with Hamiltonian Evolution\ncnot_evo = chain(\n    H(1),\n    cphase_evo,\n    H(1)\n)\n\n# Initialize state to check CNOTs sample outcomes.\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample cnot_gate = [OrderedCounter({'11': 100})]\nsample cnot_evo = [OrderedCounter({'11': 100})]\n</code></pre> <p>Thus, a <code>CNOT</code> gate can be created by combining a few single-qubit gates together with a two-qubit Ising interaction between the control and the target qubit which is the essence of the Ising transform proposed in the seminal DAQC paper<sup>2</sup> for \\(ZZ\\) interactions. In Qadence, both \\(ZZ\\) and \\(NN\\) interactions are supported.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#cnot-in-an-interacting-system-of-three-qubits","title":"<code>CNOT</code> in an interacting system of three qubits","text":"<p>Consider a simple experimental setup with \\(n=3\\) interacting qubits laid out in a triangular grid. For the sake of simplicity, all qubits interact with each other with an \\(NN\\)-Ising interaction of constant strength \\(g_\\text{int}\\). The Hamiltonian for the system can be written by summing interaction terms over all pairs:</p> \\[\\mathcal{H}_\\text{sys}=\\sum_{i=0}^{n}\\sum_{j=0}^{i-1}g_\\text{int}N_iN_j,\\] <p>which in this case leads to only three interaction terms,</p> \\[\\mathcal{H}_\\text{sys}=g_\\text{int}(N_0N_1+N_1N_2+N_0N_2)\\] <p>This generator can be easily built in Qadence:</p> <pre><code>from qadence import add, kron\nn_qubits = 3\n\n# Interaction strength.\ng_int = 1.0\n\n# Build a list of interactions.\ninteraction_list = []\nfor i in range(n_qubits):\n    for j in range(i):\n        interaction_list.append(g_int * kron(N(i), N(j)))\n\nh_sys = add(*interaction_list)\n</code></pre> <pre><code>h_sys = AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(2)\n\u2502       \u2514\u2500\u2500 N(0)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(1)\n</code></pre> <p>Now let's consider that the experimental system is fixed, and qubits can not be isolated one from another. The options are:</p> <ul> <li>Turn on or off the global system Hamiltonian.</li> <li>Perform local single-qubit rotations.</li> </ul> <p>To perform a fully digital <code>CNOT(0,1)</code>, the interacting control on qubit 0 and target on qubit 1 must be isolated from the third one to implement the gate directly. While this can be achieved for a three-qubit system, it becomes experimentally untractable when scaling the qubit count.</p> <p>However, this is not the case within the digital-analog paradigm. In fact, the two qubit Ising interaction required for the <code>CNOT</code> can be represented with a combination of the global system Hamiltonian and a specific set of single-qubit rotations. Full details about this transformation are to be found in the DAQC paper<sup>2</sup> but a more succint yet in-depth description takes place in the next section. It is conveniently available in Qadence by calling the <code>daqc_transform</code> function.</p> <p>In the most general sense, the <code>daqc_transform</code> function will return a circuit that represents the evolution of a target Hamiltonian \\(\\mathcal{H}_\\text{target}\\) (here the unitary of the gate) until a specified time \\(t_f\\) by using only the evolution of a build Hamiltonian \\(\\mathcal{H}_\\text{build}\\) (here \\(\\mathcal{H}_\\text{sys}\\)) together with local \\(X\\)-gates. In Qadence, <code>daqc_transform</code> is applicable for \\(\\mathcal{H}_\\text{target}\\) and \\(\\mathcal{H}_\\text{build}\\) composed only of \\(ZZ\\)- or \\(NN\\)-interactions. These generators are parsed by the <code>daqc_transform</code> function and the appropriate type is automatically determined together with the appropriate single-qubit detunings and global phases.</p> <p>Let's apply it for the <code>CNOT</code> implementation:</p> <pre><code>from qadence import daqc_transform, Strategy\n\n# Settings for the target CNOT operation\ni = 0  # Control qubit\nj = 1  # Target qubit\nk = 2  # The extra qubit\n\n# Define the target CNOT operation\n# by composing with identity on the extra qubit.\ncnot_target = kron(CNOT(i, j), I(k))\n\n# The two-qubit NN-Ising interaction term for the CPHASE\nh_int = (-1.0) * kron(N(i), N(j))\n\n# Transforming the two-qubit Ising interaction using only our system Hamiltonian\ntransformed_ising = daqc_transform(\n    n_qubits=3,        # Total number of qubits in the transformation\n    gen_target=h_int,  # The target Ising generator\n    t_f=PI,            # The target evolution time\n    gen_build=h_sys,   # The building block Ising generator to be used\n    strategy=Strategy.SDAQC,   # Currently only sDAQC is implemented\n    ignore_global_phases=False  # Global phases from mapping between Z and N\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_5f0c654ec3d0407a8ba450ef53d8b079 cluster_ede3a92abca04dac88d580c2c95e9c4e cluster_0b3e680695e2468c9cbae77f53f2365e cluster_cecdc38348d542e3a199404141081757 cluster_8e90a2a37d3a47bf82fd5f7c243a3872 cluster_063a29d8bd114e9baf93eed211d43a3a cluster_9f63ba290ae44c098d51d29d0272fdeb 4f9e44c5a5e44426bcf4181d82cb2e47 0 6160b50573e343eba7deaf0e67c0d03d HamEvo 4f9e44c5a5e44426bcf4181d82cb2e47--6160b50573e343eba7deaf0e67c0d03d d9c551dd32604ad4bb82cf8e09e09441 1 479f848945e449128625a798456e6c71 HamEvo 6160b50573e343eba7deaf0e67c0d03d--479f848945e449128625a798456e6c71 bf9276c234894285a5b6912fe42be97d HamEvo 479f848945e449128625a798456e6c71--bf9276c234894285a5b6912fe42be97d de10bac8eb164e61ac951d04dfd9a91a X bf9276c234894285a5b6912fe42be97d--de10bac8eb164e61ac951d04dfd9a91a 0729c7d36aee4d4baba3b89eb0ee15d2 HamEvo de10bac8eb164e61ac951d04dfd9a91a--0729c7d36aee4d4baba3b89eb0ee15d2 bb03df4a3cd14b37ad638623c46dab0a HamEvo 0729c7d36aee4d4baba3b89eb0ee15d2--bb03df4a3cd14b37ad638623c46dab0a 9ba391c38da647a7a08fc4641f0b0e8e X bb03df4a3cd14b37ad638623c46dab0a--9ba391c38da647a7a08fc4641f0b0e8e 234d0886bc854faca1c857579c27545e 9ba391c38da647a7a08fc4641f0b0e8e--234d0886bc854faca1c857579c27545e 423de0569b894cadb21b2d4a8968ec7c HamEvo 234d0886bc854faca1c857579c27545e--423de0569b894cadb21b2d4a8968ec7c 11408367f02047f39f8ffaed8823f240 HamEvo 423de0569b894cadb21b2d4a8968ec7c--11408367f02047f39f8ffaed8823f240 d800e2b93f3549729798f4af68b4682d 11408367f02047f39f8ffaed8823f240--d800e2b93f3549729798f4af68b4682d bf6864b5ba824d5e9db41d49e6e54ccb d800e2b93f3549729798f4af68b4682d--bf6864b5ba824d5e9db41d49e6e54ccb f479ca7b41dc4192992f60935ce835ae 221e0e2808f74d48a965455c295f9e0f t = -3.14 d9c551dd32604ad4bb82cf8e09e09441--221e0e2808f74d48a965455c295f9e0f 042971fb761d4d9e9313bcec906ee17c 2 f36117efd2284a01a1d3d5a0fe8a40a8 t = 3.142 221e0e2808f74d48a965455c295f9e0f--f36117efd2284a01a1d3d5a0fe8a40a8 f81fdb0058f3461cbf94a4c565dd1383 t = -3.14 f36117efd2284a01a1d3d5a0fe8a40a8--f81fdb0058f3461cbf94a4c565dd1383 4d8cbfdc2f2242b7ba71b44c19d867b2 f81fdb0058f3461cbf94a4c565dd1383--4d8cbfdc2f2242b7ba71b44c19d867b2 c734e8a4909f40f29b08f102a9b55087 t = 1.571 4d8cbfdc2f2242b7ba71b44c19d867b2--c734e8a4909f40f29b08f102a9b55087 e9b8bfb4c9c04efdb1f056ec48d02827 t = 1.571 c734e8a4909f40f29b08f102a9b55087--e9b8bfb4c9c04efdb1f056ec48d02827 1d5d296a30394ec0947bebe4b8ee6a27 e9b8bfb4c9c04efdb1f056ec48d02827--1d5d296a30394ec0947bebe4b8ee6a27 ce15f60a7b974723b5b052b3f8735626 X 1d5d296a30394ec0947bebe4b8ee6a27--ce15f60a7b974723b5b052b3f8735626 8c127514af584d44ab42c88751caee05 t = 1.571 ce15f60a7b974723b5b052b3f8735626--8c127514af584d44ab42c88751caee05 ef56ba00a7344846acd363613d2f0cae t = 1.571 8c127514af584d44ab42c88751caee05--ef56ba00a7344846acd363613d2f0cae bb41fafe9543448180482413e9ee1e8f X ef56ba00a7344846acd363613d2f0cae--bb41fafe9543448180482413e9ee1e8f bb41fafe9543448180482413e9ee1e8f--f479ca7b41dc4192992f60935ce835ae 44b3fc31d4bd41ab81dbfce12ca69841 c0a72720dbde44a1b1ef4dde925dc316 042971fb761d4d9e9313bcec906ee17c--c0a72720dbde44a1b1ef4dde925dc316 bb1c682fb42243d1847475cc0b8a3c65 c0a72720dbde44a1b1ef4dde925dc316--bb1c682fb42243d1847475cc0b8a3c65 fedd6fdf0c3f4fc9966f054d03690d9d bb1c682fb42243d1847475cc0b8a3c65--fedd6fdf0c3f4fc9966f054d03690d9d 1cb3c69ee63942e0a7965ba64a9ef960 X fedd6fdf0c3f4fc9966f054d03690d9d--1cb3c69ee63942e0a7965ba64a9ef960 d863a4465f79485f9eb9a3b35bbdaa6e 1cb3c69ee63942e0a7965ba64a9ef960--d863a4465f79485f9eb9a3b35bbdaa6e 7f2d2bcf77ec447590dc90202fb2e467 d863a4465f79485f9eb9a3b35bbdaa6e--7f2d2bcf77ec447590dc90202fb2e467 19d50577c5a046759485d1b8e4bfbced X 7f2d2bcf77ec447590dc90202fb2e467--19d50577c5a046759485d1b8e4bfbced 6bc66f2c2eae43cdb57047945bdedcbd X 19d50577c5a046759485d1b8e4bfbced--6bc66f2c2eae43cdb57047945bdedcbd 3051dd7251884d698a1e03668f99630d 6bc66f2c2eae43cdb57047945bdedcbd--3051dd7251884d698a1e03668f99630d 1a2150d54ac643fb95ad4937a4fdb45e 3051dd7251884d698a1e03668f99630d--1a2150d54ac643fb95ad4937a4fdb45e 7e1bc9debff3484d8a32142efb164ae1 X 1a2150d54ac643fb95ad4937a4fdb45e--7e1bc9debff3484d8a32142efb164ae1 7e1bc9debff3484d8a32142efb164ae1--44b3fc31d4bd41ab81dbfce12ca69841 <p>The output circuit displays three groups of system Hamiltonian evolutions which account for global-phases and single-qubit detunings related to the mapping between the \\(Z\\) and \\(N\\) operators. Optionally, global phases can be ignored.</p> <p>In general, the mapping of a \\(n\\)-qubit Ising Hamiltonian to another will require at most \\(n(n-1)\\) evolutions. The transformed circuit performs these evolutions for specific times that are computed from the solution of a linear system of equations involving the set of interactions in the target and build Hamiltonians.</p> <p>In this case, the mapping is exact when using the step-wise DAQC strategy (<code>Strategy.SDAQC</code>) available in Qadence. In banged DAQC (<code>Strategy.BDAQC</code>) the mapping is approximate, but easier to implement on a physical device with always-on interactions such as neutral-atom systems.</p> <p>Just as before, the transformed Ising circuit can be checked to exactly recover the <code>CPHASE</code> gate:</p> <pre><code># CPHASE on (i, j), Identity on third qubit:\ncphase_matrix = block_to_tensor(kron(CPHASE(i, j, phi), I(k)))\n\n# CPHASE using the transformed circuit:\ncphase_evo_matrix = block_to_tensor(transformed_ising)\n\n# Check that it implements the CPHASE.\n# Will fail if global phases are ignored.\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix : True\n</code></pre> <p>The <code>CNOT</code> gate can now finally be built:</p> <pre><code>from qadence import equivalent_state, run, sample\n\ncnot_daqc = chain(\n    H(j),\n    transformed_ising,\n    H(j)\n)\n\n# And finally apply the CNOT on a specific 3-qubit initial state:\ninit_state = product_state(\"101\")\n\n# Check we get an equivalent wavefunction\nwf_cnot = run(n_qubits, block=cnot_target, state=init_state)\nwf_daqc = run(n_qubits, block=cnot_daqc, state=init_state)\n\n# Visualize the CNOT bit-flip in samples.\n</code></pre> <pre><code>wf_cnot == wf_dacq : True\nsample cnot_target = [OrderedCounter({'111': 100})]\nsample cnot_dacq = [OrderedCounter({'111': 100})]\n</code></pre> <p>As one can see, a <code>CNOT</code> operation has been succesfully implemented on the desired target qubits by using only the global system as the building block Hamiltonian and single-qubit rotations. Decomposing a single digital gate into an Ising Hamiltonian serves as a proof of principle for the potential of this technique to represent universal quantum computation.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#technical-details-on-the-daqc-transformation","title":"Technical details on the DAQC transformation","text":"<ul> <li>The mapping between target generator and final circuit is performed by solving a linear system of size \\(n(n-1)\\) where \\(n\\) is the number of qubits, so it can be computed efficiently (i.e., with a polynomial cost in the number of qubits).</li> <li>The linear system to be solved is actually not invertible for \\(n=4\\) qubits. This is very specific edge case requiring a workaround, that is currently not yet implemented.</li> <li>As mentioned, the final circuit has at most \\(n(n-1)\\) slices, so there is at most a quadratic overhead in circuit depth.</li> </ul> <p>Finally, and most important to its usage:</p> <ul> <li>The target Hamiltonian should be sufficiently represented in the building block Hamiltonian.</li> </ul> <p>To illustrate this point, consider the following target and build Hamiltonians:</p> <pre><code># Interaction between qubits 0 and 1\ngen_target = 1.0 * (Z(0) @ Z(1))\n\n# Fixed interaction between qubits 1 and 2, and customizable between 0 and 1\ndef gen_build(g_int):\n    return g_int * (Z(0) @ Z(1)) + 1.0 * (Z(1) @ Z(2))\n</code></pre> <p>And now we perform the DAQC transform by setting <code>g_int=1.0</code>, exactly matching the target Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\n    n_qubits=3,\n    gen_target=gen_target,\n    t_f=1.0,\n    gen_build=gen_build(g_int=1.0),\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_d5a4f5a794d245bb8681ee8e7c100fec cluster_d3a155378c7844588f34c6da19c513c3 abf6c57704e14e50894f1e8d827459c2 0 6397861893544e479be1da64f6b8024a X abf6c57704e14e50894f1e8d827459c2--6397861893544e479be1da64f6b8024a 33e1f250a222470295bfbede61bcc3a5 1 a1410ecd052447dd85b25da541281c82 HamEvo 6397861893544e479be1da64f6b8024a--a1410ecd052447dd85b25da541281c82 7c7573e58c324105805af73aecf5d9b3 X a1410ecd052447dd85b25da541281c82--7c7573e58c324105805af73aecf5d9b3 0aebc350588b45a4b254ce63de4a74a9 7c7573e58c324105805af73aecf5d9b3--0aebc350588b45a4b254ce63de4a74a9 a317e7516d564bb1b02fd672f4a835b0 HamEvo 0aebc350588b45a4b254ce63de4a74a9--a317e7516d564bb1b02fd672f4a835b0 d0bca08db8d64e8c95895d9cb3b33de7 a317e7516d564bb1b02fd672f4a835b0--d0bca08db8d64e8c95895d9cb3b33de7 4fd7b797ac8c443da521128862eab73b d0bca08db8d64e8c95895d9cb3b33de7--4fd7b797ac8c443da521128862eab73b c534b7e7a207412382b008ae0e79b0ed 47981ab332a1458d8a857083284ea861 33e1f250a222470295bfbede61bcc3a5--47981ab332a1458d8a857083284ea861 cdeb76fec084448688bf009da5c85dab 2 6efe9431286749c6a3d2dbc09fe8263f t = -0.50 47981ab332a1458d8a857083284ea861--6efe9431286749c6a3d2dbc09fe8263f 899aa480434e41ce9392902ce700b6f8 6efe9431286749c6a3d2dbc09fe8263f--899aa480434e41ce9392902ce700b6f8 6382b567ed15487bb2d85d03645f33cf X 899aa480434e41ce9392902ce700b6f8--6382b567ed15487bb2d85d03645f33cf c7b473daedad42fdbe008c00f69e8293 t = -0.50 6382b567ed15487bb2d85d03645f33cf--c7b473daedad42fdbe008c00f69e8293 6618177ee3924c1cb1e060963db41a52 X c7b473daedad42fdbe008c00f69e8293--6618177ee3924c1cb1e060963db41a52 6618177ee3924c1cb1e060963db41a52--c534b7e7a207412382b008ae0e79b0ed c4af95834ce04592b3347227ec47ee3a 742f96162bbf4f95a4be2fbe0f0a17cd X cdeb76fec084448688bf009da5c85dab--742f96162bbf4f95a4be2fbe0f0a17cd fe4b26f56f5341cf89ffa0b0138041a2 742f96162bbf4f95a4be2fbe0f0a17cd--fe4b26f56f5341cf89ffa0b0138041a2 254ce6c33f4f40aebad49f21c5827851 X fe4b26f56f5341cf89ffa0b0138041a2--254ce6c33f4f40aebad49f21c5827851 121aaa4384be41e0aa21a2b125d80b39 X 254ce6c33f4f40aebad49f21c5827851--121aaa4384be41e0aa21a2b125d80b39 2d9402361ae34424b22e78f61ab1c8a5 121aaa4384be41e0aa21a2b125d80b39--2d9402361ae34424b22e78f61ab1c8a5 ec9152c634ee4202814f1c0b3f0b424b X 2d9402361ae34424b22e78f61ab1c8a5--ec9152c634ee4202814f1c0b3f0b424b ec9152c634ee4202814f1c0b3f0b424b--c4af95834ce04592b3347227ec47ee3a <p>Now, if the interaction between qubits 0 and 1 is weakened in the build Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\n    n_qubits=3,\n    gen_target=gen_target,\n    t_f=1.0,\n    gen_build=gen_build(g_int=0.001),\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_f8ea64e4a611424ea79974a7016a6b5b cluster_2d7c1c741bcc442aa2fd1969d7531951 9b2ace622cc540f8b610affd423f0a59 0 90a12d9b3c784126b4c3947c62da0f49 X 9b2ace622cc540f8b610affd423f0a59--90a12d9b3c784126b4c3947c62da0f49 d74483a92e8c47ab82ca1e082a1c46f7 1 88185d8d125a46c680fab4eb844e09c3 HamEvo 90a12d9b3c784126b4c3947c62da0f49--88185d8d125a46c680fab4eb844e09c3 cfb7e6f9259a40baac7f2ca172117021 X 88185d8d125a46c680fab4eb844e09c3--cfb7e6f9259a40baac7f2ca172117021 7f2817b1e4c84193b0189d2f9a57bf14 cfb7e6f9259a40baac7f2ca172117021--7f2817b1e4c84193b0189d2f9a57bf14 85a5d2e9fae045ceaaf2615996b1652d HamEvo 7f2817b1e4c84193b0189d2f9a57bf14--85a5d2e9fae045ceaaf2615996b1652d 44a5ade7ed854d909eb1e6557fd0aa78 85a5d2e9fae045ceaaf2615996b1652d--44a5ade7ed854d909eb1e6557fd0aa78 b958cd858fcb47f6abecff2a3ed359d0 44a5ade7ed854d909eb1e6557fd0aa78--b958cd858fcb47f6abecff2a3ed359d0 0196b4a798164171904fb7df7c54ba87 b48ae681fdf84ac4b610e1d693bb8b17 d74483a92e8c47ab82ca1e082a1c46f7--b48ae681fdf84ac4b610e1d693bb8b17 6419479a59df4a1985cab6fed006a112 2 9c8b7c6008164564ac4ded868368297d t = -500. b48ae681fdf84ac4b610e1d693bb8b17--9c8b7c6008164564ac4ded868368297d 75488e79b868492c8f2dca4ab74f2717 9c8b7c6008164564ac4ded868368297d--75488e79b868492c8f2dca4ab74f2717 22b03cb65ab04bae99ae0292ed9abd8f X 75488e79b868492c8f2dca4ab74f2717--22b03cb65ab04bae99ae0292ed9abd8f d164bf66695a405789b50f572d3ffc20 t = -500. 22b03cb65ab04bae99ae0292ed9abd8f--d164bf66695a405789b50f572d3ffc20 81499cf0cb564a57a7f53938fb02caaf X d164bf66695a405789b50f572d3ffc20--81499cf0cb564a57a7f53938fb02caaf 81499cf0cb564a57a7f53938fb02caaf--0196b4a798164171904fb7df7c54ba87 5e19fc9292f24c538d45be4534b85e07 0e0eb301c2ca4f86a711b08a1d0b297a X 6419479a59df4a1985cab6fed006a112--0e0eb301c2ca4f86a711b08a1d0b297a cf708dfd907c4f7f973194f9d59d464b 0e0eb301c2ca4f86a711b08a1d0b297a--cf708dfd907c4f7f973194f9d59d464b 933625926b104a968303dfec71fd3f94 X cf708dfd907c4f7f973194f9d59d464b--933625926b104a968303dfec71fd3f94 0bb4330103cb4352a9cb06309f45dc72 X 933625926b104a968303dfec71fd3f94--0bb4330103cb4352a9cb06309f45dc72 473986579f75450bb30cb82d30ce635f 0bb4330103cb4352a9cb06309f45dc72--473986579f75450bb30cb82d30ce635f 0148f3af26cf45268de20dfce7bd5bb2 X 473986579f75450bb30cb82d30ce635f--0148f3af26cf45268de20dfce7bd5bb2 0148f3af26cf45268de20dfce7bd5bb2--5e19fc9292f24c538d45be4534b85e07 <p>The times slices using the build Hamiltonian need now to evolve for much longer to represent the same interaction since it is not sufficiently represented in the building block Hamiltonian.</p> <p>In the limit where that interaction is not present, the transform will not work:</p> <pre><code>try:\n    transformed_ising = daqc_transform(\n        n_qubits=3,\n        gen_target=gen_target,\n        t_f=1.0,\n        gen_build=gen_build(g_int = 0.0),\n    )\nexcept ValueError as error:\n    print(\"Error:\", error)\n</code></pre> <pre><code>Error: Incompatible interactions between target and build Hamiltonians.\n</code></pre>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/","title":"Fitting a function with a Hamiltonian ansatz","text":"<p>In the analog QCL tutorial we used analog blocks to learn a function of interest. The analog blocks are a direct abstraction of device execution with global addressing. However, we may want to directly program an Hamiltonian-level ansatz to have a finer control on our model. In Qadence this can easily be done through digital-analog programs. In this tutorial we will solve a simple QCL problem with this approach.</p>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#setting-up-the-problem","title":"Setting up the problem","text":"<p>The example problem considered is to fit a function of interest in a specified range. Below we define and plot the function \\(f(x)=x^5\\).</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\n\n# Function to fit:\ndef f(x):\n    return x**5\n\nxmin = -1.0\nxmax = 1.0\nn_test = 100\n\nx_test = torch.linspace(xmin, xmax, steps = n_test)\ny_test = f(x_test)\n\nplt.plot(x_test, y_test)\nplt.xlim((-1.1, 1.1))\nplt.ylim((-1.1, 1.1))\n</code></pre> 2025-04-04T13:33:59.367041 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#digital-analog-ansatz","title":"Digital-Analog Ansatz","text":"<p>We start by defining the register of qubits. The topology we use now will define the interactions in the entangling Hamiltonian. As an example, we can define a rectangular lattice with 6 qubits.</p> <pre><code>from qadence import Register\n\nreg = Register.rectangular_lattice(\n    qubits_row = 3,\n    qubits_col = 2,\n)\n</code></pre> <p>Inspired by the Ising interaction mode of Rydberg atoms, we can now define an interaction Hamiltonian as \\(\\mathcal{H}_{ij}=\\frac{1}{r_{ij}^6}N_iN_j\\), where \\(N_i=(1/2)(I_i-Z_i)\\) is the number operator and and \\(r_{ij}\\) is the distance between qubits \\(i\\) and \\(j\\). We can easily instatiate this interaction Hamiltonian from the register information:</p> <pre><code>from qadence import N, add\n\ndef h_ij(i: int, j: int):\n    return N(i)@N(j)\n\nh_int = add(h_ij(*edge)/r**6 for edge, r in reg.edge_distances.items())\n</code></pre> <p>To build the digital-analog ansatz we can make use of the standard <code>hea</code> function by specifying we want to use the <code>Strategy.SDAQC</code> and passing the Hamiltonian we created as the entangler, as see in the QML constructors tutorial. The entangling operation will be replaced by the evolution of this Hamiltonian <code>HamEvo(h_int, t)</code>, where the time parameter <code>t</code> is considered to be a variational parameter at each layer.</p> <pre><code>from qadence import hea, Strategy, RX, RY\n\ndepth = 2\n\nda_ansatz = hea(\n    n_qubits = reg.n_qubits,\n    depth = depth,\n    operations = [RX, RY, RX],\n    entangler = h_int,\n    strategy = Strategy.SDAQC,\n)\n\nprint(html_string(da_ansatz))\n</code></pre> %3 cluster_8b01782529674870bfcfb526dd534484 cluster_1d33f7dc054d41c1be07dbad6445c2cf 3241feb8229546cba183f4f39ae99cc1 0 ad6ccc76f5094a028862a146bcb1ab8c RX(theta\u2080) 3241feb8229546cba183f4f39ae99cc1--ad6ccc76f5094a028862a146bcb1ab8c 0d5657f8863b40fdbdb4c54d6c184504 1 c33bee793b9d4b258d7cba97dc72ea1e RY(theta\u2086) ad6ccc76f5094a028862a146bcb1ab8c--c33bee793b9d4b258d7cba97dc72ea1e 2ac0b6dc603840babbea94eab1519f07 RX(theta\u2081\u2082) c33bee793b9d4b258d7cba97dc72ea1e--2ac0b6dc603840babbea94eab1519f07 bf05a8bb03d243a1a0438c7b4dd5a53c 2ac0b6dc603840babbea94eab1519f07--bf05a8bb03d243a1a0438c7b4dd5a53c 8708ac1bd6cb4d6f927c79ec345cd9f2 RX(theta\u2081\u2088) bf05a8bb03d243a1a0438c7b4dd5a53c--8708ac1bd6cb4d6f927c79ec345cd9f2 413d80bcd74c4d599efd72cfdbcca5c8 RY(theta\u2082\u2084) 8708ac1bd6cb4d6f927c79ec345cd9f2--413d80bcd74c4d599efd72cfdbcca5c8 1c4148fda96b4bbba28aaae36d52594b RX(theta\u2083\u2080) 413d80bcd74c4d599efd72cfdbcca5c8--1c4148fda96b4bbba28aaae36d52594b 1ee903c6425f44fdb094392108e08ceb 1c4148fda96b4bbba28aaae36d52594b--1ee903c6425f44fdb094392108e08ceb 749f87a37bd943419ccace6f2071e8d2 1ee903c6425f44fdb094392108e08ceb--749f87a37bd943419ccace6f2071e8d2 ddddaff4984d42b18a09a42d67d1c518 9cfdf20cef164d99a7077463f519825f RX(theta\u2081) 0d5657f8863b40fdbdb4c54d6c184504--9cfdf20cef164d99a7077463f519825f 26ec5087f19b42e7b9e81676363c1a69 2 1914e5ca5eaa423380b736b289fb74bf RY(theta\u2087) 9cfdf20cef164d99a7077463f519825f--1914e5ca5eaa423380b736b289fb74bf 8eeed3d09bd942d8b0108cd2e1ff829d RX(theta\u2081\u2083) 1914e5ca5eaa423380b736b289fb74bf--8eeed3d09bd942d8b0108cd2e1ff829d d823d42cf82b40a4be0bc29c1918417b 8eeed3d09bd942d8b0108cd2e1ff829d--d823d42cf82b40a4be0bc29c1918417b d100b9869b514f509d6bd899a6c5ead6 RX(theta\u2081\u2089) d823d42cf82b40a4be0bc29c1918417b--d100b9869b514f509d6bd899a6c5ead6 3a01407f23374499b8f610c6c879675e RY(theta\u2082\u2085) d100b9869b514f509d6bd899a6c5ead6--3a01407f23374499b8f610c6c879675e c11ccca1856f46c699aa4a527fdec1f8 RX(theta\u2083\u2081) 3a01407f23374499b8f610c6c879675e--c11ccca1856f46c699aa4a527fdec1f8 74d6a23f5fab4f29a52b46760cc7f869 c11ccca1856f46c699aa4a527fdec1f8--74d6a23f5fab4f29a52b46760cc7f869 74d6a23f5fab4f29a52b46760cc7f869--ddddaff4984d42b18a09a42d67d1c518 4672fe40722e4599bdd63d3bed9d76f1 b94f9f6fec12420cbd4e1c60a7614938 RX(theta\u2082) 26ec5087f19b42e7b9e81676363c1a69--b94f9f6fec12420cbd4e1c60a7614938 c7cafbcd1c47481baca625b7ed2c58b8 3 df86c6ed5a5c4aeabce9a6eac191bbf8 RY(theta\u2088) b94f9f6fec12420cbd4e1c60a7614938--df86c6ed5a5c4aeabce9a6eac191bbf8 15942cf2c1d14b07bf407956a4cf879d RX(theta\u2081\u2084) df86c6ed5a5c4aeabce9a6eac191bbf8--15942cf2c1d14b07bf407956a4cf879d b6b0be3b1adf4f1099508abc9a7ac9a3 HamEvo 15942cf2c1d14b07bf407956a4cf879d--b6b0be3b1adf4f1099508abc9a7ac9a3 a001dd858a7b48ab92e9bef895213e99 RX(theta\u2082\u2080) b6b0be3b1adf4f1099508abc9a7ac9a3--a001dd858a7b48ab92e9bef895213e99 1420f000c7d6472e94d70465e11f67b0 RY(theta\u2082\u2086) a001dd858a7b48ab92e9bef895213e99--1420f000c7d6472e94d70465e11f67b0 55bfa71617c6462388841bc05e9c3e0e RX(theta\u2083\u2082) 1420f000c7d6472e94d70465e11f67b0--55bfa71617c6462388841bc05e9c3e0e 7077d41b22df4d14a6de72f5ee33de53 HamEvo 55bfa71617c6462388841bc05e9c3e0e--7077d41b22df4d14a6de72f5ee33de53 7077d41b22df4d14a6de72f5ee33de53--4672fe40722e4599bdd63d3bed9d76f1 0593520fb0c54b32bd610cbf639d3991 c8040c5e8fe443558af2ee9044d752e6 RX(theta\u2083) c7cafbcd1c47481baca625b7ed2c58b8--c8040c5e8fe443558af2ee9044d752e6 472a10eb2aea42e29efe7276e8bb40b8 4 b8190da3c4c64464b658787d2b85507e RY(theta\u2089) c8040c5e8fe443558af2ee9044d752e6--b8190da3c4c64464b658787d2b85507e d693e6500bf34694b62ac0dd56b66f82 RX(theta\u2081\u2085) b8190da3c4c64464b658787d2b85507e--d693e6500bf34694b62ac0dd56b66f82 f832f5747a05408a82db07ee526fb1d6 t = theta_t\u2080 d693e6500bf34694b62ac0dd56b66f82--f832f5747a05408a82db07ee526fb1d6 4c0aaebc6c6c4d15887daa68688bed32 RX(theta\u2082\u2081) f832f5747a05408a82db07ee526fb1d6--4c0aaebc6c6c4d15887daa68688bed32 0f5cc753226d4516bc8d7108cd266376 RY(theta\u2082\u2087) 4c0aaebc6c6c4d15887daa68688bed32--0f5cc753226d4516bc8d7108cd266376 f09d64bf84a949a9844f83bb30c4e771 RX(theta\u2083\u2083) 0f5cc753226d4516bc8d7108cd266376--f09d64bf84a949a9844f83bb30c4e771 a9dd35bfb4cf4d72ba6df468e87fb9cb t = theta_t\u2081 f09d64bf84a949a9844f83bb30c4e771--a9dd35bfb4cf4d72ba6df468e87fb9cb a9dd35bfb4cf4d72ba6df468e87fb9cb--0593520fb0c54b32bd610cbf639d3991 17ebdc7626224f9cbc47421c06b8bbaf c2d17549bbc3465993d808064b4e12dd RX(theta\u2084) 472a10eb2aea42e29efe7276e8bb40b8--c2d17549bbc3465993d808064b4e12dd 4f34f411bdbb40898a998b7669d5d9e8 5 57cc5b51cdf442cbbf482b847cc6ac83 RY(theta\u2081\u2080) c2d17549bbc3465993d808064b4e12dd--57cc5b51cdf442cbbf482b847cc6ac83 4e6765f137204195ab9846b6f8c049f0 RX(theta\u2081\u2086) 57cc5b51cdf442cbbf482b847cc6ac83--4e6765f137204195ab9846b6f8c049f0 485a90054c2d40faa11cbabbfd3b62dc 4e6765f137204195ab9846b6f8c049f0--485a90054c2d40faa11cbabbfd3b62dc 27e6f5e59aa84260bfb60d33eef5e50a RX(theta\u2082\u2082) 485a90054c2d40faa11cbabbfd3b62dc--27e6f5e59aa84260bfb60d33eef5e50a a01cd07c8fa64b80b2d377e0a1147037 RY(theta\u2082\u2088) 27e6f5e59aa84260bfb60d33eef5e50a--a01cd07c8fa64b80b2d377e0a1147037 6d456ba576604818be9799fd0649d5c2 RX(theta\u2083\u2084) a01cd07c8fa64b80b2d377e0a1147037--6d456ba576604818be9799fd0649d5c2 93688f1eda584b78a144b4c258ea47ee 6d456ba576604818be9799fd0649d5c2--93688f1eda584b78a144b4c258ea47ee 93688f1eda584b78a144b4c258ea47ee--17ebdc7626224f9cbc47421c06b8bbaf 8d29fd0eaa4a4d949ef7128a6f58a60e 65622b41ec8b482c8a65a657906fa874 RX(theta\u2085) 4f34f411bdbb40898a998b7669d5d9e8--65622b41ec8b482c8a65a657906fa874 836970f48a2a42a4aaa099e994a22067 RY(theta\u2081\u2081) 65622b41ec8b482c8a65a657906fa874--836970f48a2a42a4aaa099e994a22067 705f00aa2d654980bec6e3a3088b43f0 RX(theta\u2081\u2087) 836970f48a2a42a4aaa099e994a22067--705f00aa2d654980bec6e3a3088b43f0 3ce2a70751ce4425a6c8360e099a45c2 705f00aa2d654980bec6e3a3088b43f0--3ce2a70751ce4425a6c8360e099a45c2 315d473d5c66489cbb6c8a3ccb92c0c7 RX(theta\u2082\u2083) 3ce2a70751ce4425a6c8360e099a45c2--315d473d5c66489cbb6c8a3ccb92c0c7 4bfaae82d5ad4b099f4d3cf2fe35f654 RY(theta\u2082\u2089) 315d473d5c66489cbb6c8a3ccb92c0c7--4bfaae82d5ad4b099f4d3cf2fe35f654 2705910550b148138b8b28d3ef6d4fa9 RX(theta\u2083\u2085) 4bfaae82d5ad4b099f4d3cf2fe35f654--2705910550b148138b8b28d3ef6d4fa9 81b4d1bf45124f6faf284578ed73026b 2705910550b148138b8b28d3ef6d4fa9--81b4d1bf45124f6faf284578ed73026b 81b4d1bf45124f6faf284578ed73026b--8d29fd0eaa4a4d949ef7128a6f58a60e"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#creating-the-quantummodel","title":"Creating the QuantumModel","text":"<p>The rest of the procedure is the same as any other Qadence workflow. We start by defining a feature map for input encoding and an observable for output decoding.</p> <pre><code>from qadence import feature_map, BasisSet, ReuploadScaling\nfrom qadence import Z, I\n\nfm = feature_map(\n    n_qubits = reg.n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Total magnetization\nobservable = add(Z(i) for i in range(reg.n_qubits))\n</code></pre> <p>And we have all the ingredients to initialize the <code>QuantumModel</code>:</p> <pre><code>from qadence import QuantumCircuit, QuantumModel\n\ncircuit = QuantumCircuit(reg, fm, da_ansatz)\n\nmodel = QuantumModel(circuit, observable = observable)\n</code></pre>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#training-the-model","title":"Training the model","text":"<p>We can now train the model. We use a set of 20 equally spaced training points.</p> <pre><code># Chebyshev FM does not accept x = -1, 1\nxmin = -0.99\nxmax = 0.99\nn_train = 20\n\nx_train = torch.linspace(xmin, xmax, steps = n_train)\ny_train = f(x_train)\n\n# Initial model prediction\ny_pred_initial = model.expectation({\"x\": x_test}).detach()\n</code></pre> <p>And we use a simple custom training loop.</p> <pre><code>criterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nn_epochs = 200\n\ndef loss_fn(x_train, y_train):\n    out = model.expectation({\"x\": x_train})\n    loss = criterion(out.squeeze(), y_train)\n    return loss\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_fn(x_train, y_train)\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#results","title":"Results","text":"<p>Finally we can plot the resulting trained model.</p> <pre><code>y_pred_final = model.expectation({\"x\": x_test}).detach()\n\nplt.plot(x_test, y_pred_initial, label = \"Initial prediction\")\nplt.plot(x_test, y_pred_final, label = \"Final prediction\")\nplt.scatter(x_train, y_train, label = \"Training points\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend()\nplt.xlim((-1.1, 1.1))\nplt.ylim((-1.1, 1.1))\n</code></pre> 2025-04-04T13:34:08.188112 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/","title":"Pulse-level programming with Pulser","text":"<p>Qadence offers a direct interface with Pulser<sup>1</sup>, an open-source pulse-level interface written in Python and specifically designed for programming neutral atom quantum computers.</p> <p>Using directly Pulser requires advanced knowledge on pulse-level programming and on how neutral atom devices work. Qadence abstracts this complexity out by using the familiar block-based interface for building pulse sequences in Pulser while leaving the possibility to directly manipulate them if required by, for instance, optimal pulse shaping.</p> <p>Note</p> <p>The Pulser backend is still experimental and the interface might change in the future. Please note that it does not support <code>DiffMode.AD</code>.</p> <p>Note</p> <p>With the Pulser backend, <code>qadence</code> simulations can be executed on the cloud emulators available on the PASQAL cloud platform. In order to do so, make to have valid credentials for the PASQAL cloud platform and use the following configuration for the Pulser backend:</p> <pre><code>config = {\n    \"cloud_configuration\": {\n        \"username\": \"&lt;changeme&gt;\",\n        \"password\": \"&lt;changeme&gt;\",\n        \"project_id\": \"&lt;changeme&gt;\",  # the project should have access to emulators\n        \"platform\": \"EMU_FREE\"  # choose between `EMU_TN` and `EMU_FREE`\n    }\n}\n</code></pre> <p>For inquiries and more details on the cloud credentials, please contact info@pasqal.com.</p>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#default-qubit-interaction","title":"Default qubit interaction","text":"<p>When simulating pulse sequences written using Pulser, the underlying constructed Hamiltonian is equivalent to a digital-analog quantum computing program (see digital-analog emulation for more details) with the following interaction term:</p> \\[ \\mathcal{H}_{\\textrm{int}} = \\sum_{i&lt;j} \\frac{C_6}{|R_i - R_j|^6} \\hat{n}_i \\hat{n}_j \\] <p>where \\(C_6\\) is an interaction strength coefficient dependent on the principal quantum number of chosen the neutral atom system, \\(R_i\\) are atomic positions in Cartesian coordinates and \\(\\hat{n} = \\frac{1-\\sigma^z_i}{2}\\) the number operator.</p> <p>Note</p> <p>The Ising interaction is always-on for all computations performed with the Pulser backend. It cannot be switched off.</p>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#available-quantum-operations","title":"Available quantum operations","text":"<p>Currently, the Pulser backend supports the following operations:</p> gate description trainable parameter <code>RX</code>, <code>RY</code> Single qubit rotations. Notice that the interaction is on and this affects the resulting gate fidelity. rotation angle <code>AnalogRX</code>, <code>AnalogRY</code>, <code>AnalogRZ</code> Span a single qubit rotation among the entire register. rotation angle <code>entangle</code> Fully entangle the register. interaction time <code>AnalogInteraction</code> An idle block to to free-evolve for a duration according to the interaction. free evolution time"},{"location":"tutorials/digital_analog_qc/pulser-basic/#sequence-the-bell-state-on-a-two-qubit-register","title":"Sequence the Bell state on a two qubit register","text":"<p>The next example illustrates how to create a pulse sequence to prepare a Bell state. This is a sequence of an entanglement operation, represented as an <code>entangle</code> gate (using <code>CZ</code> interactions) in the \\(X\\)-basis and a \\(Y\\) rotation for readout in the \\(Z\\)-basis:</p> <pre><code>from qadence import chain, entangle, RY\n\nbell_state = chain(\n   entangle(\"t\", qubit_support=(0,1)),\n   RY(0, \"y\"),\n)\n</code></pre> <pre><code>bell_state = ChainBlock(0,1)\n\u251c\u2500\u2500 AnalogEntanglement(t=0.9007440457171584, support=(0, 1))\n\u2514\u2500\u2500 RY(0) [params: ['y']]\n</code></pre> <p>Next, a <code>Register</code> with two qubits is combined with the resulting <code>ChainBlock</code> to form a circuit. Then, the <code>QuantumModel</code> converts the circuit into a proper parametrized pulse sequence with the Pulser backend. Supplying the parameter values allows to sample the pulse sequence outcome:</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom qadence import Register, QuantumCircuit, QuantumModel, PI\n\nregister = Register.line(2, spacing = 8.0)  # Two qubits with a distance of 8\u00b5m\ncircuit = QuantumCircuit(register, bell_state)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\n\nparams = {\n    \"t\": torch.tensor([1000]),  # ns\n    \"y\": torch.tensor([3*PI/2]),\n}\n\n# Return the final state vector\nfinal_vector = model.run(params)\n\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>final_vector = tensor([[-0.7114-0.0169j, -0.0338+0.0155j,  0.0110-0.0457j,  0.6631-0.2245j]])\nsample = Counter({'00': 27, '11': 23})\n</code></pre> <p>Plot the distribution:</p> <p><pre><code>\n</code></pre> 2025-04-04T13:34:08.378841 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/  One can visualise the pulse sequence with different parameters using the <code>assign_paramters</code> method.</p> <pre><code>model.assign_parameters(params).draw(show=False)\n</code></pre> 2025-04-04T13:34:08.470835 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#change-device-specifications","title":"Change device specifications","text":"<p>At variance with other backends, Pulser provides the concept of <code>Device</code>. A <code>Device</code> instance encapsulates all the properties for the definition of a real neutral atoms processor, including but not limited to the maximum laser amplitude for pulses, the maximum distance between two qubits and the maximum duration of the pulse. For more information, please check this tutorial.</p> <p>Qadence offers a simplified interface with only two devices which are detailed here:</p> <ul> <li><code>IDEALIZED</code> (default): ideal device which should be used only for testing purposes. It does not restrict the simulation of pulse sequences.</li> <li><code>REALISTIC</code>: device specification close to real neutral atom quantum processors.</li> </ul> <p>Note</p> <p>If you want to perform simulations closer to the specifications of real neutral atom machines, always select the <code>REALISTIC</code> device.</p> <p>One can use the <code>Configuration</code> of the Pulser backend to select the appropriate device:</p> <pre><code>from qadence import BackendName, DiffMode\nfrom qadence import RealisticDevice\n\n# Choose a realistic device\nregister = Register.line(2, spacing = 8.0, device_specs = RealisticDevice())\n\ncircuit = QuantumCircuit(register, bell_state)\n\nmodel = QuantumModel(\n    circuit,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR,\n)\n\nparams = {\n    \"t\": torch.tensor([1000]),  # ns\n    \"y\": torch.tensor([3*PI/2]),\n}\n\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>sample = Counter({'11': 26, '00': 24})\n</code></pre>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#create-a-custom-gate","title":"Create a custom gate","text":"<p>A major advantage of the block-based interface in Qadence is the ease to compose complex operations from a restricted set of primitive ones. In the following, a custom entanglement operation is used as an example.</p> <p>The operation consists of moving all the qubits to the \\(X\\)-basis. This is realized when the atomic interaction performs a controlled-\\(Z\\) operation during the free evolution. As seen before, this is implemented with the <code>AnalogInteraction</code> and <code>AnalogRY</code> blocks together with appropriate parameters.</p> <pre><code>from qadence import AnalogRY, chain, AnalogInteraction\n\n# Custom entanglement operation.\ndef my_entanglement(duration):\n    return chain(\n        AnalogRY(-PI / 2),\n        AnalogInteraction(duration)\n    )\n\nprotocol = chain(\n   my_entanglement(\"t\"),\n   RY(0, \"y\"),\n)\n\nregister = Register.line(2, spacing = 8.0)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\n\nparams = {\n    \"t\": torch.tensor([500]),  # ns\n    \"y\": torch.tensor([PI / 2]),\n}\n\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> 2025-04-04T13:34:08.825537 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#digital-analog-qnn-circuit","title":"Digital-analog QNN circuit","text":"<p>Finally, let's put all together by constructing a digital-analog version of a quantum neural network circuit with feature map and variational ansatz.</p> <pre><code>from qadence import kron, feature_map, BasisSet\nfrom qadence.operations import RX, RY, AnalogRX\n\nhea_one_layer = chain(\n    kron(RY(0, \"th00\"), RY(1, \"th01\")),\n    kron(RX(0, \"th10\"), RX(1, \"th11\")),\n    kron(RY(0, \"th20\"), RY(1, \"th21\")),\n    entangle(\"t\", qubit_support=(0,1)),\n)\n\nprotocol = chain(\n    feature_map(1, param=\"x\", fm_type=BasisSet.FOURIER),\n    hea_one_layer,\n    AnalogRX(PI/4)\n)\n\nregister = Register.line(2, spacing=8.0)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\n\nparams = {\n    \"x\": torch.tensor([0.8]), # rad\n    \"t\": torch.tensor([900]), # ns\n    \"th00\":  torch.rand(1), # rad\n    \"th01\":  torch.rand(1), # rad\n    \"th10\":  torch.rand(1), # rad\n    \"th11\":  torch.rand(1), # rad\n    \"th20\":  torch.rand(1), # rad\n    \"th21\":  torch.rand(1), # rad\n}\n\nmodel.assign_parameters(params).draw(draw_phase_area=True, show=False)\n</code></pre> 2025-04-04T13:34:08.954062 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#references","title":"References","text":"<ol> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/","title":"Restricted local addressability","text":""},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#physics-behind-semi-local-addressing-patterns","title":"Physics behind semi-local addressing patterns","text":"<p>Recall that in Qadence the general neutral-atom Hamiltonian for a set of \\(n\\) interacting qubits is given by expression</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm drive} + \\mathcal{H}_{\\rm int} = \\sum_{i=0}^{n-1}\\left(\\mathcal{H}^\\text{d}_{i}(t) + \\sum_{j&lt;i}\\mathcal{H}^\\text{int}_{ij}\\right) \\] <p>as is described in detail in the analog interface basics documentation.</p> <p>The driving Hamiltonian term in priciple can model any local single-qubit rotation by addressing each qubit individually. However, some neutral-atom devices offer restricted local addressability using devices called spatial light modulators (SLMs).</p> <p>We refer to this regime as semi-local addressability. In this regime, the individual qubit addressing is restricted to a pattern of targeted qubits which is kept fixed during the execution of the quantum circuit. More formally, the addressing pattern appears as an additional term in the neutral-atom Hamiltonian:</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm drive} + \\mathcal{H}_{\\rm int} + \\mathcal{H}_{\\rm local} \\] <p>where \\(\\mathcal{H}_{\\rm pattern}\\) is given by</p> \\[ \\mathcal{H}_{\\rm local} = \\sum_{i=0}^{n-1}\\left(-\\Delta w_i^{\\rm det} \\hat{n}_i + \\Gamma w_i^{\\rm drive} \\hat{\\sigma}^x_i\\right). \\] <p>Here \\(\\Delta\\) specifies the maximal negative detuning that each qubit in the register can be exposed to. The weight \\(w_i^{\\rm det}\\in [0, 1]\\) determines the actual value of detuning that \\(i\\)-th qubit feels and this way the detuning pattern is emulated. Similarly, for the amplitude pattern \\(\\Gamma\\) determines the maximal additional positive drive that acts on qubits. In this case the corresponding weights \\(w_i^{\\rm drive}\\) can vary in the interval \\([0, 1]\\).</p> <p>Using the detuning and amplitude patterns described above one can modify the behavior of a selected set of qubits, thus achieving semi-local addressing.</p> <p>Qadence implements semi-local addressing in two different flavors of increasing complexity: either as a circuit constructor or directly as a pattern added to the general evolution Hamiltonian described by the circuit.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#using-circuit-constructors","title":"Using circuit constructors","text":"<p>The <code>rydberg_hea</code> constructor routine allows to build a circuit instance implementing a basic version of the Hamiltonian evolution described above where both \\(\\Delta\\) and \\(\\tilde{\\Omega}\\) coefficients are considered constants. Furthemore, no global drive and detuning are explicitly added to the Hamiltonian. Therefore, the final Hamiltonian generator of the circuit reads as follows:</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm local}(w^{\\rm drive}, w^{\\rm det}) + \\mathcal{H}_{\\textrm{int}} \\] <p>This implementation does not perform any checks on the weights normalization, thus making it not realistic. This implies that global drive and detuning can be retrieved by appropriately choosing the weights.</p> <p>You can easily create a Rydberg hardware efficient ansatz implementing multiple layers of the evolution generated by the local addressing Hamiltonian:</p> \\[ \\mathcal{H}_{\\rm evo} = \\sum_j \\mathcal{H}_{\\textrm{local}}(w_{j}^{\\rm drive}, w_{j}^{\\rm det}) \\] <p>Notice that in real-device implementation, one layer only is usually achievable.</p> <pre><code>import qadence as qd\nfrom qadence import rydberg_hea, rydberg_hea_layer\n\nn_qubits = 4\nn_layers = 2\nregister = qd.Register.line(n_qubits)\n\n# ansatz constructor\n# the evolution time is parametrized for each layer of the evolution\nansatz = rydberg_hea(\n    register,\n    n_layers=n_layers,  # number of subsequent layers of Hamiltonian evolution\n    addressable_detuning=True,  # make the local detuning weights w_i^{det} as variational parameters\n    addressable_drive=True, # make the local drive weights w_i^{drv} as variational parameters\n    tunable_phase=True, # make the phase \\phi as a variational parameter\n)\n\n# alternatively, a single ansatz layer can also be created for\n# better flexibility\n\n# these can be variational parameters\ntevo_drive = 1.0  # evolution time for the locally addressed drive term\ntevo_det = 1.0 # evolution time for the locally addressed detuning term\ntevo_int = 1.0  # evolution time for the interaction term\n\n# these can be list of variational parameters\nweights_drive = [0.0, 0.25, 0.5, 0.25]\nweights_det = [0.0, 0.0, 0.5, 0.5]\n\nansatz_layer = rydberg_hea_layer(\n    register,\n    tevo_det,\n    tevo_drive,\n    tevo_int,\n    detunings=weights_det,\n    drives=weights_drive,\n)\n</code></pre> <pre><code>\n</code></pre> <p>This circuit constructor is meant to be used with fully differentiable backends such as <code>pyqtorch</code> and mainly for quick experimentation with neutral atom compatible ansatze.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#using-addressing-patterns","title":"Using addressing patterns","text":"<p>In Qadence semi-local addressing patterns can be created by either specifying fixed values for the weights of the qubits being addressed or defining them as trainable parameters that can be optimized later in some training loop. Semi-local addressing patterns can be defined with the <code>AddressingPattern</code> dataclass.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#fixed-weights","title":"Fixed weights","text":"<p>With fixed weights, detuning/amplitude addressing patterns can be defined in the following way:</p> <pre><code>import torch\nfrom qadence.analog import AddressingPattern\n\nn_qubits = 3\n\nw_det = {0: 0.9, 1: 0.5, 2: 1.0}\nw_amp = {0: 0.1, 1: 0.4, 2: 0.8}\ndet = 9.0\namp = 6.5\npattern = AddressingPattern(\n    n_qubits=n_qubits,\n    det=det,\n    amp=amp,\n    weights_det=w_det,\n    weights_amp=w_amp,\n)\n</code></pre> <p>If only detuning or amplitude pattern is needed - the corresponding weights for all qubits can be set to 0.</p> <p>The created addressing pattern can now be passed as an argument to any Qadence device class, or to the <code>IdealDevice</code> or <code>RealisticDevice</code> to make use of the pre-defined options in those devices,</p> <pre><code>import torch\nfrom qadence import (\n    AnalogRX,\n    AnalogRY,\n    BackendName,\n    DiffMode,\n    Parameter,\n    QuantumCircuit,\n    QuantumModel,\n    Register,\n    chain,\n    total_magnetization,\n    IdealDevice,\n    PI\n)\n\n# define register and circuit\nspacing = 8.0\nx = Parameter(\"x\")\nblock = chain(AnalogRX(3 * x), AnalogRY(0.5 * x))\n\ndevice_specs = IdealDevice(pattern = pattern)\n\nreg = Register.line(\n    n_qubits,\n    spacing=spacing,\n    device_specs=device_specs,\n)\n\ncirc = QuantumCircuit(reg, block)\n\nobs = total_magnetization(n_qubits)\n\nmodel_pyq = QuantumModel(\n    circuit=circ, observable=obs, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD\n)\n\n# calculate expectation value of the circuit for random input value\nvalue = {\"x\": 1.0 + torch.rand(1)}\nexpval_pyq = model_pyq.expectation(values = value)\n</code></pre>   Expectation value on PyQ:  tensor([1.8976])     <p>The same configuration can also be seamlessly used to create a model with the Pulser backend.</p> <pre><code>model_pulser = QuantumModel(\n    circuit=circ,\n    observable=obs,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR\n)\n\n# calculate expectation value of the circuit for same random input value\nexpval_pulser = model_pulser.expectation(values = value)\n</code></pre>   Expectation value on Pulser:  tensor([1.8952])     <p>Note that by default the addressing pattern terms are added to every analog operation in the circuit. However, it is possible to turn the addressing pattern off for specific operations by passing <code>add_pattern=False</code> in the operation. For example <code>AnalogRX(pi)</code> will get the extra addressing pattern term, but <code>AnalogRX(pi, add_pattern=False)</code> will not. This is currently only implemented for the PyQTorch backend. If an addressing pattern is specified for the Pulser backend, it will be added to all the blocks.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#trainable-weights","title":"Trainable weights","text":"<p>Note</p> <p>Trainable parameters currently are supported only by <code>pyqtorch</code> backend.</p> <p>Since both the maximum detuning/amplitude value of the addressing pattern and the corresponding weights can be user specified, they can be variationally used in some QML setting. This can be achieved by defining pattern weights as trainable <code>Parameter</code> instances or strings specifying weight names.</p> <pre><code>n_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\n# some random target function value\nf_value = torch.rand(1)\n\n# define trainable addressing pattern\nw_amp = {i: f\"w_amp{i}\" for i in range(n_qubits)}\nw_det = {i: f\"w_det{i}\" for i in range(n_qubits)}\namp = \"max_amp\"\ndet = \"max_det\"\n\npattern = AddressingPattern(\n    n_qubits=n_qubits,\n    det=det,\n    amp=amp,\n    weights_det=w_det,\n    weights_amp=w_amp,\n)\n\n# some fixed analog operation\nblock = AnalogRX(PI)\n\ndevice_specs = IdealDevice(pattern = pattern)\n\nreg = Register.line(\n    n_qubits,\n    spacing=spacing,\n    device_specs=device_specs,\n)\n\ncirc = QuantumCircuit(reg, block)\n\n# define quantum model\nobs = total_magnetization(n_qubits)\nmodel = QuantumModel(circuit=circ, observable=obs, backend=BackendName.PYQTORCH)\n\n# prepare for training\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nloss_criterion = torch.nn.MSELoss()\nn_epochs = 200\nloss_save = []\n\n# train model\nfor _ in range(n_epochs):\n    optimizer.zero_grad()\n    out = model.expectation()\n    loss = loss_criterion(f_value, out)\n    loss.backward()\n    optimizer.step()\n    loss_save.append(loss.item())\n\n# get final results\nf_value_model = model.expectation().detach()\n\nassert torch.isclose(f_value, f_value_model, atol=0.01)\n</code></pre>   The target function value:  tensor([0.8421]) The trained function value:  tensor([[0.8421]])    <p>Here, the expectation value of the circuit is fitted by varying the parameters of the addressing pattern.</p>"},{"location":"tutorials/qml/","title":"Variational quantum algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML)[^1] in particular are one of the main target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> (see here for more details) and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Furthermore, Qadence offers a wide range of utilities for helping building and researching quantum machine learning algorithms, including:</p> <ul> <li>a set of constructors for circuits commonly used in quantum machine learning such as feature maps and ansatze</li> <li>a set of tools for training and optimizing quantum neural networks and loading classical data into a QML algorithm</li> </ul>"},{"location":"tutorials/qml/#some-simple-examples","title":"Some simple examples","text":"<p>Qadence symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\n\nn_qubits = 4\n\n# Example feature map, also directly available with the `feature_map` function\nfp = qd.FeatureParameter(\"phi\")\nfm = qd.kron(RX(i, acos(fp)) for i in range(n_qubits))\n\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(fm, values=inputs)\n</code></pre> <pre><code>samples = OrderedCounter({'0001': 14, '0110': 11, '0000': 8, '0010': 8, '0100': 8, '0101': 8, '1011': 8, '1001': 7, '0011': 5, '0111': 4, '1000': 4, '1010': 4, '1100': 4, '1110': 4, '1111': 2, '1101': 1})\n</code></pre> <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle. This function will be further demonstrated in the QML constructors tutorial.</p> <p>Furthermore, Qadence is natively integrated with PyTorch automatic differentiation engine thus Qadence quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansatz (also explained here) and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, fm, ansatz)\nobservable = qd.kron(X(0), X(1))\n\nmodel = qd.QNN(circuit, observable)\n\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>True\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\n\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre> <pre><code>Quantum model output: \ntensor([[0.3909],\n        [0.1425],\n        [0.2557],\n        [0.1526],\n        [0.0645],\n        [0.0770],\n        [0.0471],\n        [0.0822],\n        [0.0470],\n        [0.3569]], grad_fn=&lt;CatBackward0&gt;)\n\nFirst-order derivative w.r.t. the feature parameter: \ntensor([ 0.2611,  0.5502, -3.8846,  0.5627,  0.3917,  0.4266,  0.3326,  0.4398,\n         0.3324, -0.9242], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>To run QML on real devices, Qadence offers generalized parameter shift rules (GPSR) <sup>1</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qd.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\n\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n</code></pre> <pre><code>First-order derivative w.r.t. the feature parameter: \ntensor([ 0.2611,  0.5502, -3.8846,  0.5627,  0.3917,  0.4266,  0.3326,  0.4398,\n         0.3324, -0.9242], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>See here for more details on how the parameter shift rules implementation works in Qadence.</p>"},{"location":"tutorials/qml/#references","title":"References","text":"<p>[^1] Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)</p> <ol> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/classification/","title":"Classification with QNN","text":"<p>In this tutorial we will show how to use Qadence to solve a basic classification task using a hybrid quantum-classical model composed of a QNN and classical layers.</p>"},{"location":"tutorials/qml/classification/#dataset","title":"Dataset","text":"<p>We will use the Iris dataset separated into training and testing sets. The task is to classify iris plants presented as a multivariate dataset of 4 features into 3 labels (Iris Setosa, Iris Versicolour, or Iris Virginica). When applying machine learning models, and particularly neural networks, it is recommended to normalize the data. As such, we use a common StandardScaler (we transform the data \\(x\\) to \\(z = (x - u) / s\\) where \\(u, s\\) are respectively the mean and standard deviation of the training samples).</p> <pre><code>import random\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom torch import Tensor\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom qadence import QNN, RX, FeatureParameter, QuantumCircuit, Z, chain, hea, kron\nfrom qadence.ml_tools import TrainConfig, Trainer\n\nclass IrisDataset(Dataset):\n    \"\"\"The Iris dataset split into a training set and a test set.\n\n    A StandardScaler is applied prior to applying models.\n    \"\"\"\n\n    def __init__(self):\n        X, y = load_iris(return_X_y=True)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n        self.scaler = StandardScaler()\n        self.scaler.fit(X_train)\n        self.X = torch.tensor(self.scaler.transform(X_train), requires_grad=False)\n        self.y = torch.tensor(y_train, requires_grad=False)\n\n        self.X_test = torch.tensor(self.scaler.transform(X_test), requires_grad=False)\n        self.y_test = torch.tensor(y_test, requires_grad=False)\n\n    def __getitem__(self, index) -&gt; tuple[Tensor, Tensor]:\n        return self.X[index], self.y[index]\n\n    def __len__(self) -&gt; int:\n        return len(self.y)\n\nn_features = 4  # sepal length, sepal width, petal length, petal width\nn_layers = 3\nn_neurons_final_linear_layer = 3\nn_epochs = 1000\nlr = 1e-1\ndataset = IrisDataset()\n\ndataloader = DataLoader(dataset, batch_size=20, shuffle=True)\n</code></pre>"},{"location":"tutorials/qml/classification/#hybrid-qnn","title":"Hybrid QNN","text":"<p>We set up the QNN part composed of multiple feature map layers, each followed by a variational layer. The type of variational layer we use is the hardware-efficient-ansatz (HEA). You can check the qml constructors tutorial to see how you can customize these components. The output will be the expectation value with respect to a \\(Z\\) observable on qubit \\(0\\). Then we add a simple linear layer serving as a classification head. This is equivalent to applying a weight matrix \\(W\\) and bias vector \\(b\\) to the output of the QNN denoted \\(o\\), \\(l = W * o + b\\). To obtain probabilities, we can apply the softmax function defined as: \\(p_i = \\exp(l_i) / \\sum_{j=1}^3 \\exp(l_i)\\). Note softmax is not applied during training with the cross-entropy loss.</p> <pre><code>feature_parameters = [FeatureParameter(f\"x_{i}\") for i in range(n_features)]\nfm_layer = RX(0, feature_parameters[0])\nfor q in range(1, n_features):\n    fm_layer = kron(fm_layer, RX(q, feature_parameters[q]))\n\nansatz_layers = [\n    hea(n_qubits=n_features, depth=1, param_prefix=f\"theta_{layer}\")\n    for layer in range(n_layers)\n]\nblocks = chain(fm_layer, ansatz_layers[0])\nfor layer in range(1, n_layers):\n    blocks = chain(blocks, fm_layer, ansatz_layers[layer])\n\nqc = QuantumCircuit(n_features, blocks)\nqnn = QNN(circuit=qc, observable=Z(0), inputs=[f\"x_{i}\" for i in range(n_features)])\nmodel = nn.Sequential(qnn, nn.Linear(1, n_neurons_final_linear_layer))\n</code></pre> <p>Below is a visualization of the QNN:</p> <pre><code>\n</code></pre> %3 cluster_be58adabc4864f4280b4c3bbc277edc5 HEA cluster_76b34ac672434ec4ab2a26296d7b1770 Obs. cluster_a04045b109d74b7ba82cd2b8aef369f6 HEA cluster_b55f3102e5474f8da311b227fd0b55b5 HEA 78d0c77e44034b7397e3c23a68b2f887 0 7664b9740713433fb1f9251c921845ca RX(x\u2080) 78d0c77e44034b7397e3c23a68b2f887--7664b9740713433fb1f9251c921845ca eaee8157198a465391aed6ef5468d418 1 79a9c58102664ff5971a17302dad1fa5 RX(theta\u2080\u2080) 7664b9740713433fb1f9251c921845ca--79a9c58102664ff5971a17302dad1fa5 ca074658ee604d2c8579fa1b679b423b RY(theta\u2080\u2084) 79a9c58102664ff5971a17302dad1fa5--ca074658ee604d2c8579fa1b679b423b 637dbd7178734cbcac726b86fe2b028e RX(theta\u2080\u2088) ca074658ee604d2c8579fa1b679b423b--637dbd7178734cbcac726b86fe2b028e a362e394d4624c7abd0af319c283a5d4 637dbd7178734cbcac726b86fe2b028e--a362e394d4624c7abd0af319c283a5d4 96caae3cebf441c0b5a1c844ffcf1b7d a362e394d4624c7abd0af319c283a5d4--96caae3cebf441c0b5a1c844ffcf1b7d 41c220df5c8c4e538410f3e91f5f971d RX(x\u2080) 96caae3cebf441c0b5a1c844ffcf1b7d--41c220df5c8c4e538410f3e91f5f971d f6434eac2e18453bae477720739b7917 RX(theta\u2081\u2080) 41c220df5c8c4e538410f3e91f5f971d--f6434eac2e18453bae477720739b7917 10e454fd7b6844dbab517a06e2b130dc RY(theta\u2081\u2084) f6434eac2e18453bae477720739b7917--10e454fd7b6844dbab517a06e2b130dc 22b35817ab9144f393bb1257a1e973c4 RX(theta\u2081\u2088) 10e454fd7b6844dbab517a06e2b130dc--22b35817ab9144f393bb1257a1e973c4 565cf6c96639480d826b325a44f475a9 22b35817ab9144f393bb1257a1e973c4--565cf6c96639480d826b325a44f475a9 4e715fb985384d6bbdb88b64c6b1e310 565cf6c96639480d826b325a44f475a9--4e715fb985384d6bbdb88b64c6b1e310 a18360c8be184f749060a47dd3e3385b RX(x\u2080) 4e715fb985384d6bbdb88b64c6b1e310--a18360c8be184f749060a47dd3e3385b 00ec25a6518c4579aa1f2f546de1f265 RX(theta\u2082\u2080) a18360c8be184f749060a47dd3e3385b--00ec25a6518c4579aa1f2f546de1f265 d233aa25e1404f199e3247b92ca06ff6 RY(theta\u2082\u2084) 00ec25a6518c4579aa1f2f546de1f265--d233aa25e1404f199e3247b92ca06ff6 0b35d9d5a9aa452da6bb3e6584ae5dad RX(theta\u2082\u2088) d233aa25e1404f199e3247b92ca06ff6--0b35d9d5a9aa452da6bb3e6584ae5dad fe85c407a1954c5db24fd10da9d4b791 0b35d9d5a9aa452da6bb3e6584ae5dad--fe85c407a1954c5db24fd10da9d4b791 6c208355a098457487676f01aee086d4 fe85c407a1954c5db24fd10da9d4b791--6c208355a098457487676f01aee086d4 a9fbef9d89b44dd8afa9291a5468b17e Z 6c208355a098457487676f01aee086d4--a9fbef9d89b44dd8afa9291a5468b17e 361cf78ea4a944cdb8ae623237f415b2 a9fbef9d89b44dd8afa9291a5468b17e--361cf78ea4a944cdb8ae623237f415b2 a4c459f4ecee4ac09396375bbcc035e8 f41ac59491f4444f895688cee38bc40c RX(x\u2081) eaee8157198a465391aed6ef5468d418--f41ac59491f4444f895688cee38bc40c 09a762479fb44ade81a2fb1ee873052a 2 51699cbd85744587829bf57a5075cfbe RX(theta\u2080\u2081) f41ac59491f4444f895688cee38bc40c--51699cbd85744587829bf57a5075cfbe 2faebee1466340a4bfa8090b91a6f8f6 RY(theta\u2080\u2085) 51699cbd85744587829bf57a5075cfbe--2faebee1466340a4bfa8090b91a6f8f6 e6f0e2ce04ca41d8841362ee79b67fb3 RX(theta\u2080\u2089) 2faebee1466340a4bfa8090b91a6f8f6--e6f0e2ce04ca41d8841362ee79b67fb3 515a72262bed47ff81a0a1c27e67aeb6 X e6f0e2ce04ca41d8841362ee79b67fb3--515a72262bed47ff81a0a1c27e67aeb6 515a72262bed47ff81a0a1c27e67aeb6--a362e394d4624c7abd0af319c283a5d4 314f441dc923484085d31e0d391a73f4 515a72262bed47ff81a0a1c27e67aeb6--314f441dc923484085d31e0d391a73f4 cfec683fa3144052ba70fdda88036576 RX(x\u2081) 314f441dc923484085d31e0d391a73f4--cfec683fa3144052ba70fdda88036576 69d5fe9c8ecc418faa192d080ba173b1 RX(theta\u2081\u2081) cfec683fa3144052ba70fdda88036576--69d5fe9c8ecc418faa192d080ba173b1 6e37efc6d6c44641a5be25f2ffd5b427 RY(theta\u2081\u2085) 69d5fe9c8ecc418faa192d080ba173b1--6e37efc6d6c44641a5be25f2ffd5b427 68fc2565089240139461fd26160498e2 RX(theta\u2081\u2089) 6e37efc6d6c44641a5be25f2ffd5b427--68fc2565089240139461fd26160498e2 d3f05bdeea0b4db882fe791e59e8f708 X 68fc2565089240139461fd26160498e2--d3f05bdeea0b4db882fe791e59e8f708 d3f05bdeea0b4db882fe791e59e8f708--565cf6c96639480d826b325a44f475a9 04407e6ada294795bf8a171a8fc538aa d3f05bdeea0b4db882fe791e59e8f708--04407e6ada294795bf8a171a8fc538aa d7e8f06b88b145b2ab364889156d369d RX(x\u2081) 04407e6ada294795bf8a171a8fc538aa--d7e8f06b88b145b2ab364889156d369d ccdbc6f2b06d4621b91497012d28de32 RX(theta\u2082\u2081) d7e8f06b88b145b2ab364889156d369d--ccdbc6f2b06d4621b91497012d28de32 e8ca421c8590493389c778ea8222be2e RY(theta\u2082\u2085) ccdbc6f2b06d4621b91497012d28de32--e8ca421c8590493389c778ea8222be2e 593ea529d16945adafd754a5d34828fe RX(theta\u2082\u2089) e8ca421c8590493389c778ea8222be2e--593ea529d16945adafd754a5d34828fe d5eb2645b85d46a59ab80f86baec2a0b X 593ea529d16945adafd754a5d34828fe--d5eb2645b85d46a59ab80f86baec2a0b d5eb2645b85d46a59ab80f86baec2a0b--fe85c407a1954c5db24fd10da9d4b791 91825a8ed77e4b2b96d45541429fe70c d5eb2645b85d46a59ab80f86baec2a0b--91825a8ed77e4b2b96d45541429fe70c 40b7f095dc5a41e78d29f7059b070a0d 91825a8ed77e4b2b96d45541429fe70c--40b7f095dc5a41e78d29f7059b070a0d 40b7f095dc5a41e78d29f7059b070a0d--a4c459f4ecee4ac09396375bbcc035e8 b9d99184ad484742b9ca1557b957b200 890f796e33ce4ddb88d05fdad065c552 RX(x\u2082) 09a762479fb44ade81a2fb1ee873052a--890f796e33ce4ddb88d05fdad065c552 40321bb1941146bd9ac37e01c75d816c 3 07094a35b617430caa2728e9f86af2c1 RX(theta\u2080\u2082) 890f796e33ce4ddb88d05fdad065c552--07094a35b617430caa2728e9f86af2c1 365cee6b48194c7a904e98524fd491b4 RY(theta\u2080\u2086) 07094a35b617430caa2728e9f86af2c1--365cee6b48194c7a904e98524fd491b4 d8bbb8a9f0624e688146151a0e1997c5 RX(theta\u2080\u2081\u2080) 365cee6b48194c7a904e98524fd491b4--d8bbb8a9f0624e688146151a0e1997c5 6373ebf580d94431b2c1b2fbfe784524 d8bbb8a9f0624e688146151a0e1997c5--6373ebf580d94431b2c1b2fbfe784524 69a2fb5a5ae44daa8210d0647c0c1060 X 6373ebf580d94431b2c1b2fbfe784524--69a2fb5a5ae44daa8210d0647c0c1060 69a2fb5a5ae44daa8210d0647c0c1060--314f441dc923484085d31e0d391a73f4 29ce3c61f7e94dacb3acb7f04e1a0026 RX(x\u2082) 69a2fb5a5ae44daa8210d0647c0c1060--29ce3c61f7e94dacb3acb7f04e1a0026 85816f088b274167b6c7fbe5b6e15fdb RX(theta\u2081\u2082) 29ce3c61f7e94dacb3acb7f04e1a0026--85816f088b274167b6c7fbe5b6e15fdb 5f79c70169094a82943702de04741a7f RY(theta\u2081\u2086) 85816f088b274167b6c7fbe5b6e15fdb--5f79c70169094a82943702de04741a7f 9bb6710da07d490694c06b5518c04d02 RX(theta\u2081\u2081\u2080) 5f79c70169094a82943702de04741a7f--9bb6710da07d490694c06b5518c04d02 3d6203dc77de49ffb4a1b5fae6991ae7 9bb6710da07d490694c06b5518c04d02--3d6203dc77de49ffb4a1b5fae6991ae7 69cf5b8edcb84ae1862a1beeacc1bb57 X 3d6203dc77de49ffb4a1b5fae6991ae7--69cf5b8edcb84ae1862a1beeacc1bb57 69cf5b8edcb84ae1862a1beeacc1bb57--04407e6ada294795bf8a171a8fc538aa febad808fda840bfb167f3c2738bec9f RX(x\u2082) 69cf5b8edcb84ae1862a1beeacc1bb57--febad808fda840bfb167f3c2738bec9f 6083eaaf324042608ee58e4746127fd4 RX(theta\u2082\u2082) febad808fda840bfb167f3c2738bec9f--6083eaaf324042608ee58e4746127fd4 85a72702c2cf4c7d9612b649c32ab4a6 RY(theta\u2082\u2086) 6083eaaf324042608ee58e4746127fd4--85a72702c2cf4c7d9612b649c32ab4a6 1d2ce72c1e744a3689f694cbbb3a90ef RX(theta\u2082\u2081\u2080) 85a72702c2cf4c7d9612b649c32ab4a6--1d2ce72c1e744a3689f694cbbb3a90ef 5cf71b231f304b8fb020b9a3eae197d4 1d2ce72c1e744a3689f694cbbb3a90ef--5cf71b231f304b8fb020b9a3eae197d4 0b2734d758be465da75234e1fe532a96 X 5cf71b231f304b8fb020b9a3eae197d4--0b2734d758be465da75234e1fe532a96 0b2734d758be465da75234e1fe532a96--91825a8ed77e4b2b96d45541429fe70c 8b617d5311d643208b7006d010e5d944 0b2734d758be465da75234e1fe532a96--8b617d5311d643208b7006d010e5d944 8b617d5311d643208b7006d010e5d944--b9d99184ad484742b9ca1557b957b200 c20f0698d95a4f5ab6e4c3669174e4c1 5eed620d40dc4d6f8449f4e68fef43aa RX(x\u2083) 40321bb1941146bd9ac37e01c75d816c--5eed620d40dc4d6f8449f4e68fef43aa 033644304bef4a59ae16961bfae071d6 RX(theta\u2080\u2083) 5eed620d40dc4d6f8449f4e68fef43aa--033644304bef4a59ae16961bfae071d6 253108cddfcf4202bbc66af6d2ff3a44 RY(theta\u2080\u2087) 033644304bef4a59ae16961bfae071d6--253108cddfcf4202bbc66af6d2ff3a44 9322518b0887471c9203b4545aa7c59e RX(theta\u2080\u2081\u2081) 253108cddfcf4202bbc66af6d2ff3a44--9322518b0887471c9203b4545aa7c59e 3680b69738cf437fadd4958fbe11581c X 9322518b0887471c9203b4545aa7c59e--3680b69738cf437fadd4958fbe11581c 3680b69738cf437fadd4958fbe11581c--6373ebf580d94431b2c1b2fbfe784524 aad5acc10cc1431483bed4bc47958aa6 3680b69738cf437fadd4958fbe11581c--aad5acc10cc1431483bed4bc47958aa6 1b91d2adebc84ab2a74d41540f2ff544 RX(x\u2083) aad5acc10cc1431483bed4bc47958aa6--1b91d2adebc84ab2a74d41540f2ff544 4717821326024749b0435f26580d977f RX(theta\u2081\u2083) 1b91d2adebc84ab2a74d41540f2ff544--4717821326024749b0435f26580d977f 262503cebf3c454991f9980ca7962fbe RY(theta\u2081\u2087) 4717821326024749b0435f26580d977f--262503cebf3c454991f9980ca7962fbe 524e88b7d24346a78e7352a86cf174b5 RX(theta\u2081\u2081\u2081) 262503cebf3c454991f9980ca7962fbe--524e88b7d24346a78e7352a86cf174b5 f0598a50e9ee4b5287ea566a30e463a1 X 524e88b7d24346a78e7352a86cf174b5--f0598a50e9ee4b5287ea566a30e463a1 f0598a50e9ee4b5287ea566a30e463a1--3d6203dc77de49ffb4a1b5fae6991ae7 75eb33db13d84875b949dbe1574efd04 f0598a50e9ee4b5287ea566a30e463a1--75eb33db13d84875b949dbe1574efd04 a8d6930870f1463bbbd0f466c9d2f8dc RX(x\u2083) 75eb33db13d84875b949dbe1574efd04--a8d6930870f1463bbbd0f466c9d2f8dc 636330495de04fa0b2a27bdc2e6455cf RX(theta\u2082\u2083) a8d6930870f1463bbbd0f466c9d2f8dc--636330495de04fa0b2a27bdc2e6455cf 3dd10f23479441929fc3304fa6944958 RY(theta\u2082\u2087) 636330495de04fa0b2a27bdc2e6455cf--3dd10f23479441929fc3304fa6944958 0bf392b96dc54b18b34a506c26c8b843 RX(theta\u2082\u2081\u2081) 3dd10f23479441929fc3304fa6944958--0bf392b96dc54b18b34a506c26c8b843 b31c7a64de054b6fbe587bf749454220 X 0bf392b96dc54b18b34a506c26c8b843--b31c7a64de054b6fbe587bf749454220 b31c7a64de054b6fbe587bf749454220--5cf71b231f304b8fb020b9a3eae197d4 be8e73619b5e446ba958c3d8888f5cef b31c7a64de054b6fbe587bf749454220--be8e73619b5e446ba958c3d8888f5cef 4a9d229035684dfd8f1b150fee1294d2 be8e73619b5e446ba958c3d8888f5cef--4a9d229035684dfd8f1b150fee1294d2 4a9d229035684dfd8f1b150fee1294d2--c20f0698d95a4f5ab6e4c3669174e4c1"},{"location":"tutorials/qml/classification/#training","title":"Training","text":"<p>Then we can set up the training part:</p> <pre><code>opt = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\ndef cross_entropy(model: nn.Module, data: Tensor) -&gt; tuple[Tensor, dict]:\n    x, y = data\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ntrain_config = TrainConfig(max_iter=n_epochs, print_every=10, create_subfolder_per_run=True)\nTrainer.set_use_grad(True)\ntrainer = Trainer(model=model, optimizer=opt, config=train_config, loss_fn=cross_entropy)\n\n\nres_train = trainer.fit(dataloader)\n</code></pre>"},{"location":"tutorials/qml/classification/#inference","title":"Inference","text":"<p>Finally, we can apply our model on the test set and check the score.</p> <pre><code>X_test, y_test = dataset.X_test, dataset.y_test\npreds_test = torch.argmax(torch.softmax(model(X_test), dim=1), dim=1)\naccuracy_test = (preds_test == y_test).type(torch.float32).mean()\n## Should reach higher than 0.9\n</code></pre>   Test Accuracy: 0.9200000166893005"},{"location":"tutorials/qml/config_qnn/","title":"Configuring a QNN","text":"<p>In <code>qadence</code>, the <code>QNN</code> is a variational quantum model that can potentially take multi-dimensional input.</p> <p>The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>The circuit has two parts, the feature map and the ansatz. The feature map is responsible for encoding the input data into the quantum state, while the ansatz is responsible for the variational part of the model. In addition, a third part of the QNN is the observables, which is (a list of) operators that are measured at the end of the circuit.</p> <p>In QML Constructors we have seen how to construct the feature map and the ansatz. In this tutorial, we will see how to do the same using configs.</p> <p>One convenient way to construct these three parts of the model is to use the config classes, namely, <code>ObservableConfig</code>, <code>FeatureMapConfig</code>, <code>AnsatzConfig</code>. These classes allow you to specify the type of circuit and the parameters of the circuit in a structured way.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-observable","title":"Defining the Observable","text":"<p>The model output is the expectation value of the defined observable(s). We use the <code>ObservableConfig</code> class to specify the observable.</p> <p>It can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings. Any Hamiltonian supported by <code>hamiltonian_factory</code> can be specified as an observable. For example, suppose we want to measure the Z operator:</p> <pre><code>from qadence import create_observable, ObservableConfig, Z\n\nobservable_config = ObservableConfig(\n    detuning=Z,\n    interaction = None,\n    scale = 2.0,\n    shift=-1.0,\n)\n\nobservable = create_observable(register=4, config=observable_config)\n</code></pre> %3 cluster_78ca81b7dd9b4d84ae39baf2ecda9a50 8abce43fa7cf4705b4db16fa92faf987 0 98172e2366df4f05b094d2cfec596eda 8abce43fa7cf4705b4db16fa92faf987--98172e2366df4f05b094d2cfec596eda ed32571644ca44a3bc72124b6e86f7d7 1 d4ffb51c06ac4449b1f1773f127fa4ff 98172e2366df4f05b094d2cfec596eda--d4ffb51c06ac4449b1f1773f127fa4ff 37093ceff62549f392372ce675698b7b 79b2594b92ed4d458028f023d0eb11a6 AddBlock ed32571644ca44a3bc72124b6e86f7d7--79b2594b92ed4d458028f023d0eb11a6 dc846cdfd408483584287b8f33c366f0 2 79b2594b92ed4d458028f023d0eb11a6--37093ceff62549f392372ce675698b7b 582564d439e847ab98971146b8931d60 789ee387afbf42098698a966a4a18c2e dc846cdfd408483584287b8f33c366f0--789ee387afbf42098698a966a4a18c2e 09acc2c7bd9c4925b3ea35a51eab30ea 3 789ee387afbf42098698a966a4a18c2e--582564d439e847ab98971146b8931d60 388f7579eaa142f9adb47fd02030a6bd fea8d2ef9c364c1aa7daf6002bdfac95 09acc2c7bd9c4925b3ea35a51eab30ea--fea8d2ef9c364c1aa7daf6002bdfac95 fea8d2ef9c364c1aa7daf6002bdfac95--388f7579eaa142f9adb47fd02030a6bd <p>We have specified the observable Hamiltonian to be one with \\(Z\\)-detuning. The result is linearly scaled by 2.0 and shifted by -1.0. The shift or the scale can optionally also be a VariationalParameter</p> <p>It is also possible to import some common Hamiltonians, such as <code>total_magnetization_config</code>, <code>zz_hamiltonian_config</code> and, <code>ising_hamiltonian_config</code>.</p> <p>For example, the total magnetization configuration:</p> <pre><code>from qadence import create_observable\nfrom qadence.constructors import total_magnetization_config\n\nobservable_total_magnetization  = create_observable(register=4, config=total_magnetization_config())\n</code></pre> <p>Alternatively, you can define the observable as a list of observables, in which case the QNN will output a list of values.</p>"},{"location":"tutorials/qml/config_qnn/#scaling-and-shifting-the-qnn-output","title":"Scaling and Shifting the QNN Output","text":"<p>For any observable, by appropriately choosing the scale \\(\\alpha\\) and shift \\(\\beta\\), you can constrain the QNN output within a desired range. This is particularly useful for normalizing measurements or ensuring that values remain within a meaningful interval for optimization. To accomplish this, you need to determine the maximum and minimum values that the QNN output can take. For an observable, these extreme values are the two extreme eigenvalues \\(\\lambda_{max}\\) and \\(\\lambda_{min}\\) of the concerned Hamiltonian. Using these values, you can set the scale \\(\\alpha\\) and shift \\(\\beta\\) so that the QNN output is mapped to a specific range \\([a,b]\\):</p> \\[\\alpha = \\frac{b-a}{\\lambda_{max}-\\lambda_{min}}\\] \\[\\beta = \\frac{a\\lambda_{max}-b\\lambda_{min}}{\\lambda_{max}-\\lambda_{min}}\\] <p>This transformation ensures that:</p> \\[ a \\leq \\alpha \\lambda + \\beta \\leq b,\\quad\\forall \\lambda \\in [\\lambda_{min},\\lambda_{max}] \\] <p>For full details on the <code>ObservableConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-feature-map","title":"Defining the Feature Map","text":"<p>Let us say we want to build a 4-qubit QNN that takes two inputs, namely, the \\(x\\) and the \\(y\\) coordinates of a point in the plane. We can use the <code>FeatureMapConfig</code> class to specify the feature map.</p> <pre><code>from qadence import BasisSet, chain, create_fm_blocks, FeatureMapConfig, ReuploadScaling\n\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs = [\"x\", \"y\"],\n    basis_set=BasisSet.CHEBYSHEV,\n    reupload_scaling=ReuploadScaling.TOWER,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\n\nfm_blocks = create_fm_blocks(register=4, config=fm_config)\nfeature_map = chain(*fm_blocks)\n</code></pre> %3 cluster_74a7435fbdeb42f79d09aa0ed6bcae1d Tower Chebyshev FM cluster_e16c89ad81f047ad92978d5c0ce5546e Tower Chebyshev FM c80a4669371e4c49a34eb2b07c361cd2 0 a94a3225f0f54ec8a0cf4f61611d73d8 RX(1.0*acos(x)) c80a4669371e4c49a34eb2b07c361cd2--a94a3225f0f54ec8a0cf4f61611d73d8 648a818bbdf049dfb1a1574852483b49 1 a61bcf05a1e04c28a0e017f8bdb9b942 a94a3225f0f54ec8a0cf4f61611d73d8--a61bcf05a1e04c28a0e017f8bdb9b942 7e7cf16c38ae48d98953cbe9f25d5af0 27001b91d098467682c58f5ec20fa8eb RX(2.0*acos(x)) 648a818bbdf049dfb1a1574852483b49--27001b91d098467682c58f5ec20fa8eb 4cbaf34a34e34476ab1a68bfac121c76 2 27001b91d098467682c58f5ec20fa8eb--7e7cf16c38ae48d98953cbe9f25d5af0 1bb395d24f71432a9413fe3bb150cf67 09eea5ce2644467097092a3d182166d9 RX(1.0*acos(2.0*y - 1.0)) 4cbaf34a34e34476ab1a68bfac121c76--09eea5ce2644467097092a3d182166d9 eaf6223be6464751a95ce04a2c140b31 3 09eea5ce2644467097092a3d182166d9--1bb395d24f71432a9413fe3bb150cf67 e2c8e5f53dd7474c945264767d08076f 3ce81beff3694e25bd3fb97df1f6c67c RX(2.0*acos(2.0*y - 1.0)) eaf6223be6464751a95ce04a2c140b31--3ce81beff3694e25bd3fb97df1f6c67c 3ce81beff3694e25bd3fb97df1f6c67c--e2c8e5f53dd7474c945264767d08076f <p>We have specified that the feature map should take two features, and have named the <code>FeatureParameter</code> \"x\" and \"y\" respectively. Both these parameters are encoded using the Chebyshev basis set, and the reupload scaling is set to <code>ReuploadScaling.TOWER</code>. One can optionally add the basis and the reupload scaling for each parameter separately.</p> <p>The <code>feature_range</code> parameter is a dictionary that specifies the range of values that each feature comes from. This is useful for scaling the input data to the range that the encoding function can handle. In default case, this range is mapped to the target range of the Chebyshev basis set which is \\([-1, 1]\\). One can also specify the target range for each feature separately.</p> <p>For full details on the <code>FeatureMapConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-ansatz","title":"Defining the Ansatz","text":"<p>The next part of the QNN is the ansatz. We use <code>AnsatzConfig</code> class to specify the type of ansatz.</p> <p>Let us say, we want to follow this feature map with 2 layers of hardware efficient ansatz.</p> <pre><code>from qadence import AnsatzConfig, AnsatzType, create_ansatz, Strategy\n\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nansatz = create_ansatz(register=4, config=ansatz_config)\n</code></pre> %3 f125584cbd874766bd75359f50bea5c4 0 2f617fe10aa94425a6f8698dd3fd8656 RX(theta\u2080) f125584cbd874766bd75359f50bea5c4--2f617fe10aa94425a6f8698dd3fd8656 53e9f3bf07864fd89961c1eaead22305 1 ff8e1f4d28b8440291d9a0eeaf5cdb52 RY(theta\u2084) 2f617fe10aa94425a6f8698dd3fd8656--ff8e1f4d28b8440291d9a0eeaf5cdb52 120afbba5c12404da9f5f3b79addfb0b RX(theta\u2088) ff8e1f4d28b8440291d9a0eeaf5cdb52--120afbba5c12404da9f5f3b79addfb0b 23601ecd9e1f4ea4959a2cdd6634ec57 120afbba5c12404da9f5f3b79addfb0b--23601ecd9e1f4ea4959a2cdd6634ec57 fb57dee8c1a34508825279d5576a4f3f 23601ecd9e1f4ea4959a2cdd6634ec57--fb57dee8c1a34508825279d5576a4f3f 77a77919f65f40c0ae94f661f7d0b5c2 RX(theta\u2081\u2082) fb57dee8c1a34508825279d5576a4f3f--77a77919f65f40c0ae94f661f7d0b5c2 25bedae0c12242358e30fbbac57460d9 RY(theta\u2081\u2086) 77a77919f65f40c0ae94f661f7d0b5c2--25bedae0c12242358e30fbbac57460d9 33fcab98146f4d35828550e3642de45d RX(theta\u2082\u2080) 25bedae0c12242358e30fbbac57460d9--33fcab98146f4d35828550e3642de45d 09997969a6904ed7934635c724997150 33fcab98146f4d35828550e3642de45d--09997969a6904ed7934635c724997150 f6f7b6dbb92f42b78c52af0b40971eb3 09997969a6904ed7934635c724997150--f6f7b6dbb92f42b78c52af0b40971eb3 c3bc730d05554bff8822ed324612217d f6f7b6dbb92f42b78c52af0b40971eb3--c3bc730d05554bff8822ed324612217d 0da5520fa69c42949688feb48174a349 fa15b6fd935c44dd888cef3fbb985409 RX(theta\u2081) 53e9f3bf07864fd89961c1eaead22305--fa15b6fd935c44dd888cef3fbb985409 2fb4f283b9f34fe0981c9bf7079b40b4 2 0ae54b1251f74f4d86a99b4557d6f90f RY(theta\u2085) fa15b6fd935c44dd888cef3fbb985409--0ae54b1251f74f4d86a99b4557d6f90f 20adaacea24340d4b852e2f30072fc7c RX(theta\u2089) 0ae54b1251f74f4d86a99b4557d6f90f--20adaacea24340d4b852e2f30072fc7c 4e0621febcc74f57bd45b87e4075d52f X 20adaacea24340d4b852e2f30072fc7c--4e0621febcc74f57bd45b87e4075d52f 4e0621febcc74f57bd45b87e4075d52f--23601ecd9e1f4ea4959a2cdd6634ec57 7ed95a6dd3874c6dab8d0be58c683477 4e0621febcc74f57bd45b87e4075d52f--7ed95a6dd3874c6dab8d0be58c683477 ae98a2ac072f41538a0275cb2e663932 RX(theta\u2081\u2083) 7ed95a6dd3874c6dab8d0be58c683477--ae98a2ac072f41538a0275cb2e663932 9237138f71254f8cb14e36119f148030 RY(theta\u2081\u2087) ae98a2ac072f41538a0275cb2e663932--9237138f71254f8cb14e36119f148030 c6075bf78679445e99e09a5383b4831e RX(theta\u2082\u2081) 9237138f71254f8cb14e36119f148030--c6075bf78679445e99e09a5383b4831e 8c21a3dbc6cc4dd888d0831d396c4023 X c6075bf78679445e99e09a5383b4831e--8c21a3dbc6cc4dd888d0831d396c4023 8c21a3dbc6cc4dd888d0831d396c4023--09997969a6904ed7934635c724997150 5c5ec98609c94701b1b9f877e35474a1 8c21a3dbc6cc4dd888d0831d396c4023--5c5ec98609c94701b1b9f877e35474a1 5c5ec98609c94701b1b9f877e35474a1--0da5520fa69c42949688feb48174a349 a4499e343f414cf7a17f1aaa246739d0 e7b1797fbaa346a4938a87038514120a RX(theta\u2082) 2fb4f283b9f34fe0981c9bf7079b40b4--e7b1797fbaa346a4938a87038514120a 9364665d5af147608d7cf8cf6e0a7cb9 3 45ab232069d24470b28742e6e817c5f1 RY(theta\u2086) e7b1797fbaa346a4938a87038514120a--45ab232069d24470b28742e6e817c5f1 49fba3f186794f77ab6c887ca38b0a71 RX(theta\u2081\u2080) 45ab232069d24470b28742e6e817c5f1--49fba3f186794f77ab6c887ca38b0a71 5bd64150344a495280dd76cbc451b645 49fba3f186794f77ab6c887ca38b0a71--5bd64150344a495280dd76cbc451b645 d0af0bbe3f924a63a4e6057373e8cf3a X 5bd64150344a495280dd76cbc451b645--d0af0bbe3f924a63a4e6057373e8cf3a d0af0bbe3f924a63a4e6057373e8cf3a--7ed95a6dd3874c6dab8d0be58c683477 8b7a6c6d106447fb8ba21df7653d67b9 RX(theta\u2081\u2084) d0af0bbe3f924a63a4e6057373e8cf3a--8b7a6c6d106447fb8ba21df7653d67b9 3bb164cdf56c4e44b956ede3f010cd75 RY(theta\u2081\u2088) 8b7a6c6d106447fb8ba21df7653d67b9--3bb164cdf56c4e44b956ede3f010cd75 16895ab39a2b4b3ab00e1c20acb231ee RX(theta\u2082\u2082) 3bb164cdf56c4e44b956ede3f010cd75--16895ab39a2b4b3ab00e1c20acb231ee 9d4124548a9e4e3284670a42f03d8f74 16895ab39a2b4b3ab00e1c20acb231ee--9d4124548a9e4e3284670a42f03d8f74 580a7ad70cb34cc5a5cead75dd6b8ffa X 9d4124548a9e4e3284670a42f03d8f74--580a7ad70cb34cc5a5cead75dd6b8ffa 580a7ad70cb34cc5a5cead75dd6b8ffa--5c5ec98609c94701b1b9f877e35474a1 580a7ad70cb34cc5a5cead75dd6b8ffa--a4499e343f414cf7a17f1aaa246739d0 82ea797d9c364424a206ab1dc49d48f9 6c8bed51d572438abac244366af0f5e9 RX(theta\u2083) 9364665d5af147608d7cf8cf6e0a7cb9--6c8bed51d572438abac244366af0f5e9 7db857f4fc884afeb065a35a1a37ae62 RY(theta\u2087) 6c8bed51d572438abac244366af0f5e9--7db857f4fc884afeb065a35a1a37ae62 949c05a532f04c4fa631bb863afdee02 RX(theta\u2081\u2081) 7db857f4fc884afeb065a35a1a37ae62--949c05a532f04c4fa631bb863afdee02 1b61be0119034bda94f9e163c16f353e X 949c05a532f04c4fa631bb863afdee02--1b61be0119034bda94f9e163c16f353e 1b61be0119034bda94f9e163c16f353e--5bd64150344a495280dd76cbc451b645 5dac929da6ba4e7396158f45c234e75e 1b61be0119034bda94f9e163c16f353e--5dac929da6ba4e7396158f45c234e75e a17d5ac839904356a2d9efa80e555e4a RX(theta\u2081\u2085) 5dac929da6ba4e7396158f45c234e75e--a17d5ac839904356a2d9efa80e555e4a 2642fd962df24ab293df26b7fc2f6e1c RY(theta\u2081\u2089) a17d5ac839904356a2d9efa80e555e4a--2642fd962df24ab293df26b7fc2f6e1c 88a730f0b60c4736b1ce7ec1688e72a9 RX(theta\u2082\u2083) 2642fd962df24ab293df26b7fc2f6e1c--88a730f0b60c4736b1ce7ec1688e72a9 56454ff1e8284eb4a5d0ae97aeb3c0a3 X 88a730f0b60c4736b1ce7ec1688e72a9--56454ff1e8284eb4a5d0ae97aeb3c0a3 56454ff1e8284eb4a5d0ae97aeb3c0a3--9d4124548a9e4e3284670a42f03d8f74 f414010df0aa4dc1828f2a7574bcd16d 56454ff1e8284eb4a5d0ae97aeb3c0a3--f414010df0aa4dc1828f2a7574bcd16d f414010df0aa4dc1828f2a7574bcd16d--82ea797d9c364424a206ab1dc49d48f9 <p>We have specified that the ansatz should have a depth of 2, and the ansatz type is \"hea\" (Hardware Efficient Ansatz). The ansatz strategy is set to \"digital\", which means digital gates are being used. One could alternatively use \"analog\" or \"rydberg\" as the ansatz strategy.</p> <p>For full details on the <code>AnsatzConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-qnn-from-the-configs","title":"Defining the QNN from the Configs","text":"<p>To build the QNN, we can now use the <code>QNN</code> class as a <code>QuantumModel</code> subtype. In addition to the feature map, ansatz and the observable configs, we can also specify options such as the <code>backend</code>, <code>diff_mode</code>, etc. For full details on the <code>QNN</code> class, see the API documentation or the documentation on the config constructor here.</p> <pre><code>from qadence import BackendName, DiffMode, QNN\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.AD,\n)\n</code></pre> %3 cluster_fbe1d0881c0646a089b6f8c00193021e Obs. cluster_712bd05b317a492d854d30d76e793b30 cluster_21f690d1820a4ca2be3952a6b3ecc6ac Tower Chebyshev FM cluster_3f9d9bc443b94f60912870299aedf4e3 Tower Chebyshev FM cluster_969a919dd4884750ae27434a270d7e1e HEA c1108cb41f9640c4bf67f2fbf91a830c 0 0bb3ca9218374f7fa5843ff5327a204d RX(1.0*acos(x)) c1108cb41f9640c4bf67f2fbf91a830c--0bb3ca9218374f7fa5843ff5327a204d 4d3561eca4dc4e3b875fd0b6e6695e1a 1 29ac571d14db4036845d53693351b71c RX(theta\u2080) 0bb3ca9218374f7fa5843ff5327a204d--29ac571d14db4036845d53693351b71c d4a3d9cac2af4d639cbca638a1728adb RY(theta\u2084) 29ac571d14db4036845d53693351b71c--d4a3d9cac2af4d639cbca638a1728adb 7873486ddb424c1796a061680c23fd1d RX(theta\u2088) d4a3d9cac2af4d639cbca638a1728adb--7873486ddb424c1796a061680c23fd1d 5f0efae9138e44a0b354fcd16021b309 7873486ddb424c1796a061680c23fd1d--5f0efae9138e44a0b354fcd16021b309 07edc6b962fb455680735876ef3cb113 5f0efae9138e44a0b354fcd16021b309--07edc6b962fb455680735876ef3cb113 9e5e923a3df248bca2a268e7e545e107 RX(theta\u2081\u2082) 07edc6b962fb455680735876ef3cb113--9e5e923a3df248bca2a268e7e545e107 4f2789d971934b66b3bb362b53aeb9ce RY(theta\u2081\u2086) 9e5e923a3df248bca2a268e7e545e107--4f2789d971934b66b3bb362b53aeb9ce 6afb8e7de4854726bdd1efb39d234979 RX(theta\u2082\u2080) 4f2789d971934b66b3bb362b53aeb9ce--6afb8e7de4854726bdd1efb39d234979 8e311a8cdca141f083845a9f4ee8f63d 6afb8e7de4854726bdd1efb39d234979--8e311a8cdca141f083845a9f4ee8f63d 0b26f47a96864a139c33a75a6d8cfc4d 8e311a8cdca141f083845a9f4ee8f63d--0b26f47a96864a139c33a75a6d8cfc4d c9fe40262abe4f92a9a672ce4ac4f050 0b26f47a96864a139c33a75a6d8cfc4d--c9fe40262abe4f92a9a672ce4ac4f050 07cc10b7359f4e4394903bd1be25628a c9fe40262abe4f92a9a672ce4ac4f050--07cc10b7359f4e4394903bd1be25628a d31f1304419143889af35f70e43b8a32 1f942af79f0342a9992609a6939e5f3d RX(2.0*acos(x)) 4d3561eca4dc4e3b875fd0b6e6695e1a--1f942af79f0342a9992609a6939e5f3d e127f751f21e4509870a2606987464df 2 e41375a3d3e14f66958afc1e753fb98d RX(theta\u2081) 1f942af79f0342a9992609a6939e5f3d--e41375a3d3e14f66958afc1e753fb98d e52c7092a5924a4c972be25998eb3af3 RY(theta\u2085) e41375a3d3e14f66958afc1e753fb98d--e52c7092a5924a4c972be25998eb3af3 a6983444cd2c40f288891df8c09062d8 RX(theta\u2089) e52c7092a5924a4c972be25998eb3af3--a6983444cd2c40f288891df8c09062d8 ea68e1ffb88e4e07a7441aca5909966f X a6983444cd2c40f288891df8c09062d8--ea68e1ffb88e4e07a7441aca5909966f ea68e1ffb88e4e07a7441aca5909966f--5f0efae9138e44a0b354fcd16021b309 19557b81ca634f6aa264881115f7f012 ea68e1ffb88e4e07a7441aca5909966f--19557b81ca634f6aa264881115f7f012 8336e8e4cd0542cbb15a94cf472ff1ee RX(theta\u2081\u2083) 19557b81ca634f6aa264881115f7f012--8336e8e4cd0542cbb15a94cf472ff1ee 15cc56aa68724f9885931bb213a55efa RY(theta\u2081\u2087) 8336e8e4cd0542cbb15a94cf472ff1ee--15cc56aa68724f9885931bb213a55efa 17f0021bd9324ef7917b280e59ead2c4 RX(theta\u2082\u2081) 15cc56aa68724f9885931bb213a55efa--17f0021bd9324ef7917b280e59ead2c4 d8d3136dd3f54801b764814fd5ada594 X 17f0021bd9324ef7917b280e59ead2c4--d8d3136dd3f54801b764814fd5ada594 d8d3136dd3f54801b764814fd5ada594--8e311a8cdca141f083845a9f4ee8f63d cbc2275bde884e3f8186203bb4d64c4e d8d3136dd3f54801b764814fd5ada594--cbc2275bde884e3f8186203bb4d64c4e 25706177a43c497dab3158e41d5747f8 AddBlock cbc2275bde884e3f8186203bb4d64c4e--25706177a43c497dab3158e41d5747f8 25706177a43c497dab3158e41d5747f8--d31f1304419143889af35f70e43b8a32 99e3d13073ac4f11ba3c6bf7d9fb8c6d 4d12a843310c46018b4d2d84913f5a8c RX(1.0*acos(2.0*y - 1.0)) e127f751f21e4509870a2606987464df--4d12a843310c46018b4d2d84913f5a8c 3c4ed183a3d54670af5e93ac4167ad53 3 ad4522a3765e4934a1d7f6b7313e0e6d RX(theta\u2082) 4d12a843310c46018b4d2d84913f5a8c--ad4522a3765e4934a1d7f6b7313e0e6d 0678029500b548cdbb3a4b439e7d1f9f RY(theta\u2086) ad4522a3765e4934a1d7f6b7313e0e6d--0678029500b548cdbb3a4b439e7d1f9f 848b868191c24f7290705edc50b6513d RX(theta\u2081\u2080) 0678029500b548cdbb3a4b439e7d1f9f--848b868191c24f7290705edc50b6513d 39136de9c6d2449bb387f5714f269024 848b868191c24f7290705edc50b6513d--39136de9c6d2449bb387f5714f269024 998c455b20d24a2f8255c3c3a6b51490 X 39136de9c6d2449bb387f5714f269024--998c455b20d24a2f8255c3c3a6b51490 998c455b20d24a2f8255c3c3a6b51490--19557b81ca634f6aa264881115f7f012 ec97d65633454767ba619025ae5ee19b RX(theta\u2081\u2084) 998c455b20d24a2f8255c3c3a6b51490--ec97d65633454767ba619025ae5ee19b 2c0226142671452c90aefca8f4178e3b RY(theta\u2081\u2088) ec97d65633454767ba619025ae5ee19b--2c0226142671452c90aefca8f4178e3b 358acefbfefc4070a215e533d9d17f46 RX(theta\u2082\u2082) 2c0226142671452c90aefca8f4178e3b--358acefbfefc4070a215e533d9d17f46 34af046bb03e493f900dd61beacd2285 358acefbfefc4070a215e533d9d17f46--34af046bb03e493f900dd61beacd2285 592eafc1d27140778dea4e44409f619b X 34af046bb03e493f900dd61beacd2285--592eafc1d27140778dea4e44409f619b 592eafc1d27140778dea4e44409f619b--cbc2275bde884e3f8186203bb4d64c4e cf54e536b12b44549f03d45ba0ee5865 592eafc1d27140778dea4e44409f619b--cf54e536b12b44549f03d45ba0ee5865 cf54e536b12b44549f03d45ba0ee5865--99e3d13073ac4f11ba3c6bf7d9fb8c6d 40b15f170e3c413d85813ec64a84646c 3e890879c9934b9d82f3fa8aad1a6ac7 RX(2.0*acos(2.0*y - 1.0)) 3c4ed183a3d54670af5e93ac4167ad53--3e890879c9934b9d82f3fa8aad1a6ac7 ed42a00cc7b04aed81031f2f8cb1971c RX(theta\u2083) 3e890879c9934b9d82f3fa8aad1a6ac7--ed42a00cc7b04aed81031f2f8cb1971c addf4e4b6bf540778a2c3ab07a0e2615 RY(theta\u2087) ed42a00cc7b04aed81031f2f8cb1971c--addf4e4b6bf540778a2c3ab07a0e2615 dab9ab8c9c614b43b6f23b781b249693 RX(theta\u2081\u2081) addf4e4b6bf540778a2c3ab07a0e2615--dab9ab8c9c614b43b6f23b781b249693 42c2facbea1e4669b4001b6f6fbf01de X dab9ab8c9c614b43b6f23b781b249693--42c2facbea1e4669b4001b6f6fbf01de 42c2facbea1e4669b4001b6f6fbf01de--39136de9c6d2449bb387f5714f269024 c362a331fc0d4644afb193c74b1095ce 42c2facbea1e4669b4001b6f6fbf01de--c362a331fc0d4644afb193c74b1095ce 5736060fe977495686c5ce72a1fe8b71 RX(theta\u2081\u2085) c362a331fc0d4644afb193c74b1095ce--5736060fe977495686c5ce72a1fe8b71 ab968ca0e88f4ff6822710d4244f98f1 RY(theta\u2081\u2089) 5736060fe977495686c5ce72a1fe8b71--ab968ca0e88f4ff6822710d4244f98f1 b6893f16a29d40dba26bfb5632a6ac02 RX(theta\u2082\u2083) ab968ca0e88f4ff6822710d4244f98f1--b6893f16a29d40dba26bfb5632a6ac02 363872b49f94401d9ae3fe3bf01b68fc X b6893f16a29d40dba26bfb5632a6ac02--363872b49f94401d9ae3fe3bf01b68fc 363872b49f94401d9ae3fe3bf01b68fc--34af046bb03e493f900dd61beacd2285 3c6e57fcb9ef46ce87cdfe89a3f76f59 363872b49f94401d9ae3fe3bf01b68fc--3c6e57fcb9ef46ce87cdfe89a3f76f59 c7c5ca9d0813430c9dd791701b5563e0 3c6e57fcb9ef46ce87cdfe89a3f76f59--c7c5ca9d0813430c9dd791701b5563e0 c7c5ca9d0813430c9dd791701b5563e0--40b15f170e3c413d85813ec64a84646c"},{"location":"tutorials/qml/dqc_1d/","title":"Solving a 1D ODE","text":"<p>In this tutorial we will show how to use Qadence to solve a basic 1D Ordinary Differential Equation (ODE) with a QNN using Differentiable Quantum Circuits (DQC) <sup>1</sup>.</p> <p>Consider the following non-linear ODE and boundary condition:</p> \\[ \\frac{df}{dx}= 5\\times(4x^3+x^2-2x-\\frac12), \\qquad f(0)=0 \\] <p>It admits an exact solution:</p> \\[ f(x)=5\\times(x^4+\\frac13x^3-x^2-\\frac12x) \\] <p>Our goal will be to find this solution for \\(x\\in[-1, 1]\\).</p> <pre><code>import torch\n\ndef dfdx_equation(x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Derivative as per the equation.\"\"\"\n    return 5*(4*x**3 + x**2 - 2*x - 0.5)\n</code></pre> <p>For the purpose of this tutorial, we will compute the derivative of the circuit using <code>torch.autograd</code>. The point of the DQC algorithm is to use differentiable circuits with parameter shift rules. In Qadence, PSR is implemented directly as custom overrides of the derivative function in the autograd engine, and thus we can later change the derivative method for the model itself if we wish.</p> <pre><code>def calc_deriv(outputs: torch.Tensor, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Compute a derivative of model that learns f(x), computes df/dx using torch.autograd.\"\"\"\n    grad = torch.autograd.grad(\n        outputs=outputs,\n        inputs=inputs,\n        grad_outputs = torch.ones_like(inputs),\n        create_graph = True,\n        retain_graph = True,\n    )[0]\n    return grad\n</code></pre>"},{"location":"tutorials/qml/dqc_1d/#defining-the-loss-function","title":"Defining the loss function","text":"<p>The essential part of solving this problem is to define the right loss function to represent our goal. In this case, we want to define a model that has the capacity to learn the target solution, and we want to minimize: - The derivative of this model in comparison with the exact derivative in the equation; - The output of the model at the boundary in comparison with the value for the boundary condition;</p> <p>We can write it like so:</p> <pre><code># Mean-squared error as the comparison criterion\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Loss function encoding the problem to solve.\"\"\"\n    # Equation loss\n    model_output = model(inputs)\n    deriv_model = calc_deriv(model_output, inputs)\n    deriv_exact = dfdx_equation(inputs)\n    ode_loss = criterion(deriv_model, deriv_exact)\n\n    # Boundary loss, f(0) = 0\n    boundary_model = model(torch.tensor([[0.0]]))\n    boundary_exact = torch.tensor([[0.0]])\n    boundary_loss = criterion(boundary_model, boundary_exact)\n\n    return ode_loss + boundary_loss\n</code></pre> <p>Different loss criterions could be considered, and we could also play with the balance between the sum of the two loss terms. For now, let's proceed with the definition above.</p> <p>Note that so far we have not used any quantum specific assumption, and we could in principle use the same loss function with a classical neural network.</p>"},{"location":"tutorials/qml/dqc_1d/#defining-a-qnn-with-qadence","title":"Defining a QNN with Qadence","text":"<p>Now, we can finally use Qadence to write a QNN. We will use a feature map to encode the input values, a trainable ansatz circuit, and an observable to measure as the output.</p> <pre><code>from qadence import feature_map, hea, chain\nfrom qadence import QNN, QuantumCircuit, Z\nfrom qadence.types import BasisSet, ReuploadScaling\n\nn_qubits = 3\ndepth = 3\n\n# Feature map\nfm = feature_map(\n    n_qubits = n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Ansatz\nansatz = hea(n_qubits = n_qubits, depth = depth)\n\n# Observable\nobservable = Z(0)\n\ncircuit = QuantumCircuit(n_qubits, chain(fm, ansatz))\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n</code></pre> <p>We used a Chebyshev feature map with a tower-like scaling of the input reupload, and a standard hardware-efficient ansatz. You can check the qml constructors tutorial to see how you can customize these components. In the observable, for now we consider the simple case of measuring the magnetization of the first qubit.</p> <pre><code>from qadence.draw import display\n\n# display(circuit)\n</code></pre> %3 cluster_87780c48c7b944a48cbefe8d137bae6e HEA cluster_7e0e11e75015471c841e633e64dedf38 Tower Chebyshev FM 3033b381ad5941b79a8f1ce6f1613343 0 9d1b16c893b1451d95abc0269a4f528a RX(1.0*acos(x)) 3033b381ad5941b79a8f1ce6f1613343--9d1b16c893b1451d95abc0269a4f528a 4cfe1ae75ec14a2f970e1ae80a1ce1dd 1 e3cfc0ef9e44479aadf32a812b189333 RX(theta\u2080) 9d1b16c893b1451d95abc0269a4f528a--e3cfc0ef9e44479aadf32a812b189333 7a1cf26f1bb64e98b1c3afe3c54a97de RY(theta\u2083) e3cfc0ef9e44479aadf32a812b189333--7a1cf26f1bb64e98b1c3afe3c54a97de 2a8ab0babc5e46f5aab95a36b8e2ba23 RX(theta\u2086) 7a1cf26f1bb64e98b1c3afe3c54a97de--2a8ab0babc5e46f5aab95a36b8e2ba23 6287e0f9d1584012948239b41aa6530b 2a8ab0babc5e46f5aab95a36b8e2ba23--6287e0f9d1584012948239b41aa6530b f43daaa33c5f4978b479ceacdb592809 6287e0f9d1584012948239b41aa6530b--f43daaa33c5f4978b479ceacdb592809 298fc064727745038ac0dd00b2b5c214 RX(theta\u2089) f43daaa33c5f4978b479ceacdb592809--298fc064727745038ac0dd00b2b5c214 ebb8d737782c4a298376d3bb8a7a793b RY(theta\u2081\u2082) 298fc064727745038ac0dd00b2b5c214--ebb8d737782c4a298376d3bb8a7a793b 7a5e1af96df948aa81a896511c3e1638 RX(theta\u2081\u2085) ebb8d737782c4a298376d3bb8a7a793b--7a5e1af96df948aa81a896511c3e1638 2c2229d1c84f49e19ef0d7432cf1742f 7a5e1af96df948aa81a896511c3e1638--2c2229d1c84f49e19ef0d7432cf1742f 9ce9010336b742eea32c0336ce947466 2c2229d1c84f49e19ef0d7432cf1742f--9ce9010336b742eea32c0336ce947466 2c90e6109739410794cbd54f01a1aeb5 RX(theta\u2081\u2088) 9ce9010336b742eea32c0336ce947466--2c90e6109739410794cbd54f01a1aeb5 e253f6a21ec1439e82d80165f54f127b RY(theta\u2082\u2081) 2c90e6109739410794cbd54f01a1aeb5--e253f6a21ec1439e82d80165f54f127b 483827643cf54910bdedc028ec279eb7 RX(theta\u2082\u2084) e253f6a21ec1439e82d80165f54f127b--483827643cf54910bdedc028ec279eb7 66fb16ac242e405787805e8fd869d83f 483827643cf54910bdedc028ec279eb7--66fb16ac242e405787805e8fd869d83f 45b3d58a04ce496e99c17d98f48ccbb8 66fb16ac242e405787805e8fd869d83f--45b3d58a04ce496e99c17d98f48ccbb8 3a8a9342ba7045b7956b019e83a762c8 45b3d58a04ce496e99c17d98f48ccbb8--3a8a9342ba7045b7956b019e83a762c8 3cdb84818de049d499edb237db4a3d6c 9d1672691a3441c0b5fb0cd86f776459 RX(2.0*acos(x)) 4cfe1ae75ec14a2f970e1ae80a1ce1dd--9d1672691a3441c0b5fb0cd86f776459 6ccd58178a4c423181dadec29ad060a6 2 f018ab30ed404248b2ae2f2cbe964947 RX(theta\u2081) 9d1672691a3441c0b5fb0cd86f776459--f018ab30ed404248b2ae2f2cbe964947 f1a56dab569d4aeab4a02d718fece8b1 RY(theta\u2084) f018ab30ed404248b2ae2f2cbe964947--f1a56dab569d4aeab4a02d718fece8b1 5fb2ced9da394997acb47c177b7d5591 RX(theta\u2087) f1a56dab569d4aeab4a02d718fece8b1--5fb2ced9da394997acb47c177b7d5591 9fefbe963ad74350b0e7f8403b92daac X 5fb2ced9da394997acb47c177b7d5591--9fefbe963ad74350b0e7f8403b92daac 9fefbe963ad74350b0e7f8403b92daac--6287e0f9d1584012948239b41aa6530b 837c3a02407a483bbd2e99249ead160f 9fefbe963ad74350b0e7f8403b92daac--837c3a02407a483bbd2e99249ead160f 7ace342d31724fe5932fda151878201c RX(theta\u2081\u2080) 837c3a02407a483bbd2e99249ead160f--7ace342d31724fe5932fda151878201c 743f0e0b94ce4238b3667456445cb28b RY(theta\u2081\u2083) 7ace342d31724fe5932fda151878201c--743f0e0b94ce4238b3667456445cb28b ccf2fda3a6c34ff49d5113500efb1d4e RX(theta\u2081\u2086) 743f0e0b94ce4238b3667456445cb28b--ccf2fda3a6c34ff49d5113500efb1d4e dd58c7002fd14bfc96aa3ea2028deba5 X ccf2fda3a6c34ff49d5113500efb1d4e--dd58c7002fd14bfc96aa3ea2028deba5 dd58c7002fd14bfc96aa3ea2028deba5--2c2229d1c84f49e19ef0d7432cf1742f a7812742acdc4c04af4c5619f6c8d8f0 dd58c7002fd14bfc96aa3ea2028deba5--a7812742acdc4c04af4c5619f6c8d8f0 0e93610151074042be1829ca9711156f RX(theta\u2081\u2089) a7812742acdc4c04af4c5619f6c8d8f0--0e93610151074042be1829ca9711156f 006d1dce179b4d1aa34acc425c96901b RY(theta\u2082\u2082) 0e93610151074042be1829ca9711156f--006d1dce179b4d1aa34acc425c96901b 643c61abef544d4c8363b56c88c2d2a6 RX(theta\u2082\u2085) 006d1dce179b4d1aa34acc425c96901b--643c61abef544d4c8363b56c88c2d2a6 4abced65b59b4ca39a53110402b5ea25 X 643c61abef544d4c8363b56c88c2d2a6--4abced65b59b4ca39a53110402b5ea25 4abced65b59b4ca39a53110402b5ea25--66fb16ac242e405787805e8fd869d83f 5bc74135a5014afbb0ccc1bdc46345fc 4abced65b59b4ca39a53110402b5ea25--5bc74135a5014afbb0ccc1bdc46345fc 5bc74135a5014afbb0ccc1bdc46345fc--3cdb84818de049d499edb237db4a3d6c 64070dca64724a75b81ab1a18c54cc6e de250a90fd7a4ed89125d171925f9558 RX(3.0*acos(x)) 6ccd58178a4c423181dadec29ad060a6--de250a90fd7a4ed89125d171925f9558 47b33a9da7fa4750b6db908a63978f36 RX(theta\u2082) de250a90fd7a4ed89125d171925f9558--47b33a9da7fa4750b6db908a63978f36 22b1f22b3a604fe1b1a93023eaa6954f RY(theta\u2085) 47b33a9da7fa4750b6db908a63978f36--22b1f22b3a604fe1b1a93023eaa6954f 1c123e3385e34156bc5d1641e91acefe RX(theta\u2088) 22b1f22b3a604fe1b1a93023eaa6954f--1c123e3385e34156bc5d1641e91acefe e288a914468c43c0b441153c2199f1fb 1c123e3385e34156bc5d1641e91acefe--e288a914468c43c0b441153c2199f1fb 6af8dfd51a35447396fa8129eb5d9987 X e288a914468c43c0b441153c2199f1fb--6af8dfd51a35447396fa8129eb5d9987 6af8dfd51a35447396fa8129eb5d9987--837c3a02407a483bbd2e99249ead160f d545298f104540a7afec05e3742fc3b6 RX(theta\u2081\u2081) 6af8dfd51a35447396fa8129eb5d9987--d545298f104540a7afec05e3742fc3b6 4a97ecb39abf4c17a19b716fd77722e2 RY(theta\u2081\u2084) d545298f104540a7afec05e3742fc3b6--4a97ecb39abf4c17a19b716fd77722e2 a732a525aea549afadbee3ef504e42c9 RX(theta\u2081\u2087) 4a97ecb39abf4c17a19b716fd77722e2--a732a525aea549afadbee3ef504e42c9 8e7e22b920dd4621948001239ca08804 a732a525aea549afadbee3ef504e42c9--8e7e22b920dd4621948001239ca08804 34ad093ce19742e2804643f376190361 X 8e7e22b920dd4621948001239ca08804--34ad093ce19742e2804643f376190361 34ad093ce19742e2804643f376190361--a7812742acdc4c04af4c5619f6c8d8f0 226ba70e8e16468aaa25462c68036a6c RX(theta\u2082\u2080) 34ad093ce19742e2804643f376190361--226ba70e8e16468aaa25462c68036a6c 7a77ecb24e534817bd8de5ba490d89d2 RY(theta\u2082\u2083) 226ba70e8e16468aaa25462c68036a6c--7a77ecb24e534817bd8de5ba490d89d2 e6ab71a9b9c24adeb1b17f8cb0d33ec2 RX(theta\u2082\u2086) 7a77ecb24e534817bd8de5ba490d89d2--e6ab71a9b9c24adeb1b17f8cb0d33ec2 742b9ad1eefc4438a70353f3c023927a e6ab71a9b9c24adeb1b17f8cb0d33ec2--742b9ad1eefc4438a70353f3c023927a a4eb93f612c14df8977a193e100da83c X 742b9ad1eefc4438a70353f3c023927a--a4eb93f612c14df8977a193e100da83c a4eb93f612c14df8977a193e100da83c--5bc74135a5014afbb0ccc1bdc46345fc a4eb93f612c14df8977a193e100da83c--64070dca64724a75b81ab1a18c54cc6e"},{"location":"tutorials/qml/dqc_1d/#training-the-model","title":"Training the model","text":"<p>Now that the model is defined we can proceed with the training. the <code>QNN</code> class can be used like any other <code>torch.nn.Module</code>. Here we write a simple training loop, but you can also look at the ml tools tutorial to use the convenience training functions that Qadence provides.</p> <p>To train the model, we will select a random set of collocation points uniformly distributed within \\(-1.0&lt; x &lt;1.0\\) and compute the loss function for those points.</p> <pre><code>n_epochs = 200\nn_points = 10\n\nxmin = -0.99\nxmax = 0.99\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data. We unsqueeze essentially making each batch have a single x value.\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>Note the values of \\(x\\) are only picked from \\(x\\in[-0.99, 0.99]\\) since we are using a Chebyshev feature map, and derivative of \\(\\text{acos}(x)\\) diverges at \\(-1\\) and \\(1\\).</p>"},{"location":"tutorials/qml/dqc_1d/#plotting-the-results","title":"Plotting the results","text":"<pre><code>import matplotlib.pyplot as plt\n\ndef f_exact(x: torch.Tensor) -&gt; torch.Tensor:\n    return 5*(x**4 + (1/3)*x**3 - x**2 - 0.5*x)\n\nx_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \" Trained model\")\n</code></pre> 2025-04-04T13:35:02.807858 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/ <p>Clearly, the result is not optimal.</p>"},{"location":"tutorials/qml/dqc_1d/#improving-the-solution","title":"Improving the solution","text":"<p>One point to consider when defining the QNN is the possible output range, which is bounded by the spectrum of the chosen observable. For the magnetization of a single qubit, this means that the output is bounded between -1 and 1, which we can clearly see in the plot.</p> <p>One option would be to define the observable as the total magnetization over all qubits, which would allow a range of -3 to 3.</p> <pre><code>from qadence import add\n\nobservable = add(Z(i) for i in range(n_qubits))\n\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And we again plot the result:</p> <pre><code>x_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \"Trained model\")\n</code></pre> 2025-04-04T13:35:10.687413 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/qml/dqc_1d/#references","title":"References","text":"<ol> <li> <p>Kyriienko et al., Solving nonlinear differential equations with differentiable quantum circuits. \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/qaoa/","title":"Solving MaxCut with QAOA","text":"<p>This tutorial shows how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA), first introduced by Farhi et al. in 2014 <sup>1</sup>.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a graph cut which partitions the nodes into two disjoint sets, such that the number of edges in the cut is maximized. This is a very common combinatorial optimization problem known to be computationally hard (NP-hard).</p> <p>The graph used for this tutorial is an unweighted graph randomly generated using the <code>networkx</code> library with a certain probability \\(p\\) of having an edge between two arbitrary nodes (known as Erd\u0151s\u2013R\u00e9nyi graph).</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\n\n# ensure reproducibility\nseed = 42\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Create random graph\nn_nodes = 4\nedge_prob = 0.8\ngraph = nx.gnp_random_graph(n_nodes, edge_prob)\n\nnx.draw(graph)\n</code></pre> 2025-04-04T13:35:10.792687 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[\\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p)\\] <p>where \\(p\\) is a given cut of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\). We will represent a cut \\(p\\) as a bitstring of length \\(N\\), where \\(N\\) is the number of nodes, and where the bit in position \\(i\\) shows to which partition node \\(i\\) belongs. We assign value 0 to one of the partitions defined by the cut and 1 to the other. Since this choice is arbitrary, every cut is represented by two bitstrings, e.g. \"0011\" and \"1100\" are equivalent.</p> <p>Since in this tutorial we are only dealing with small graphs, we can find the maximum cut by brute force to make sure QAOA works as intended. <pre><code># Function to calculate the cost associated with a cut\ndef calculate_cost(cut: str, graph: nx.graph) -&gt; float:\n    \"\"\"Returns the cost of a given cut (represented by a bitstring)\"\"\"\n    cost = 0\n    for edge in graph.edges():\n        (i, j) = edge\n        if cut[i] != cut[j]:\n            cost += 1\n    return cost\n\n\n# Function to get a binary representation of an int\nget_binary = lambda x, n: format(x, \"b\").zfill(n)\n\n# List of all possible cuts\nall_possible_cuts = [bin(k)[2:].rjust(n_nodes, \"0\") for k in range(2**n_nodes)]\n\n# List with the costs associated to each cut\nall_costs = [calculate_cost(cut, graph) for cut in all_possible_cuts]\n\n# Get the maximum cost\nmaxcost = max(all_costs)\n\n# Get all cuts that correspond to the maximum cost\nmaxcuts = [get_binary(i, n_nodes) for i, j in enumerate(all_costs) if j == maxcost]\nprint(f\"The maximum cut is represented by the bitstrings {maxcuts}, with a cost of {maxcost}\")\n</code></pre> <pre><code>The maximum cut is represented by the bitstrings ['0011', '0101', '0110', '1001', '1010', '1100'], with a cost of 4\n</code></pre> </p>"},{"location":"tutorials/qml/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>The Max-Cut problem can be solved by using the QAOA algorithm. QAOA belongs to the class of Variational Quantum Algorithms (VQAs), which means that its quantum circuit contains a certain number of parametrized quantum gates that need to be optimized with a classical optimizer. The QAOA circuit is composed of two operators:</p> <ul> <li>The cost operator \\(U_c\\): a circuit generated by the cost Hamiltonian which encodes the cost function described above into a quantum circuit. The solution to the optimization problem is encoded in the ground state of the cost Hamiltonian \\(H_c\\). The cost operator  is simply the evolution of the cost Hamiltonian parametrized by a variational parameter \\(\\gamma\\) so that \\(U_c = e^{i\\gamma H_c}.\\)</li> <li>The mixing operator \\(U_b\\): a simple set of single-qubit rotations with adjustable   angles which are tuned during the classical optimization loop to minimize the cost</li> </ul> <p>The cost Hamiltonian of the MaxCut problem can be written as:</p> \\[H_c = \\frac12 \\sum_{\\langle i,j\\rangle} (\\mathbb{1} - Z_iZ_j)\\] <p>where \\(\\langle i,j\\rangle\\) represents the edge between nodes \\(i\\) and \\(j\\). The solution of the MaxCut problem is encoded in the ground state of the above Hamiltonian.</p> <p>The QAOA quantum circuit consists of a number of layers, each layer containing a cost and a mixing operator. Below, the QAOA quantum circuit is defined using <code>qadence</code> operations. First, a layer of Hadamard gates is applied to all qubits to prepare the initial state \\(|+\\rangle ^{\\otimes n}\\). The cost operator of each layer can be built \"manually\", implementing the \\(e^{iZZ\\gamma}\\) terms with CNOTs and a \\(\\rm{RZ}(2\\gamma)\\) rotation, or it can also be automatically decomposed into digital single and two-qubits operations via the <code>.digital_decomposition()</code> method. The decomposition is exact since the Hamiltonian generator is diagonal.</p> <pre><code>from qadence import tag, kron, chain, RX, RZ, Z, H, CNOT, I, add\nfrom qadence import HamEvo, QuantumCircuit, Parameter\n\nn_qubits = graph.number_of_nodes()\nn_edges = graph.number_of_edges()\nn_layers = 6\n\n# Generate the cost Hamiltonian\nzz_ops = add(Z(edge[0]) @ Z(edge[1]) for edge in graph.edges)\ncost_ham = 0.5 * (n_edges * kron(I(i) for i in range(n_qubits)) - zz_ops)\n\n\n# QAOA circuit\ndef build_qaoa_circuit(n_qubits, n_layers, graph):\n    layers = []\n    # Layer of Hadamards\n    initial_layer = kron(H(i) for i in range(n_qubits))\n    layers.append(initial_layer)\n    for layer in range(n_layers):\n\n        # cost layer with digital decomposition\n        # cost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition(approximation=\"basic\")\n        cost_layer = []\n        for edge in graph.edges():\n            (q0, q1) = edge\n            zz_term = chain(\n                CNOT(q0, q1),\n                RZ(q1, Parameter(f\"g{layer}\")),\n                CNOT(q0, q1),\n            )\n            cost_layer.append(zz_term)\n        cost_layer = chain(*cost_layer)\n        cost_layer = tag(cost_layer, \"cost\")\n\n        # mixing layer with single qubit rotations\n        mixing_layer = kron(RX(i, f\"b{layer}\") for i in range(n_qubits))\n        mixing_layer = tag(mixing_layer, \"mixing\")\n\n        # putting all together in a single ChainBlock\n        layers.append(chain(cost_layer, mixing_layer))\n\n    final_b = chain(*layers)\n    return QuantumCircuit(n_qubits, final_b)\n\n\ncircuit = build_qaoa_circuit(n_qubits, n_layers, graph)\n\n# Print a single layer of the circuit\n</code></pre> %3 cluster_af4fafed509141bd92be6058f67e676e mixing cluster_a62f972847c24eb1809b4bb78aaff08d cost 8864cdae9858493b8d0870b6f01011ab 0 57840cf70164492388f320f7d2fb1936 H 8864cdae9858493b8d0870b6f01011ab--57840cf70164492388f320f7d2fb1936 c5f1f7624b494b77939b86f97b7f6b7b 1 2a078032d9234f58a61320ea5da27c9a 57840cf70164492388f320f7d2fb1936--2a078032d9234f58a61320ea5da27c9a 0f217efdbb3c4cd49e16c680293c54f8 2a078032d9234f58a61320ea5da27c9a--0f217efdbb3c4cd49e16c680293c54f8 174aac247eed479a9bee35f87ca844c9 0f217efdbb3c4cd49e16c680293c54f8--174aac247eed479a9bee35f87ca844c9 4c1d4e279e86431ba933f4bdc8dac38b 174aac247eed479a9bee35f87ca844c9--4c1d4e279e86431ba933f4bdc8dac38b a578c0abd9644a1eaf3da613f530fa83 4c1d4e279e86431ba933f4bdc8dac38b--a578c0abd9644a1eaf3da613f530fa83 eb464cdc0a9f4b4cb6c21a8292515a4a a578c0abd9644a1eaf3da613f530fa83--eb464cdc0a9f4b4cb6c21a8292515a4a 6b71a5de85f744e3b79d37dad299cd60 eb464cdc0a9f4b4cb6c21a8292515a4a--6b71a5de85f744e3b79d37dad299cd60 a58a8777c12c47c5a2013c89c451cdaa 6b71a5de85f744e3b79d37dad299cd60--a58a8777c12c47c5a2013c89c451cdaa 5d16fa5616324192ae2659a42997b0ae a58a8777c12c47c5a2013c89c451cdaa--5d16fa5616324192ae2659a42997b0ae c3b51c949d714afda884f60e77c85332 5d16fa5616324192ae2659a42997b0ae--c3b51c949d714afda884f60e77c85332 9ffdedbf8b284d6aa4873fd552ba66b8 c3b51c949d714afda884f60e77c85332--9ffdedbf8b284d6aa4873fd552ba66b8 cb17ef0ced1b46d0a4b81fed4848038f 9ffdedbf8b284d6aa4873fd552ba66b8--cb17ef0ced1b46d0a4b81fed4848038f 019be9a66165488692c7586636419774 cb17ef0ced1b46d0a4b81fed4848038f--019be9a66165488692c7586636419774 306f194040614f0aa9d97490ebd890dc 019be9a66165488692c7586636419774--306f194040614f0aa9d97490ebd890dc 6703d520d6284c2dab3ccf18aa3e3947 306f194040614f0aa9d97490ebd890dc--6703d520d6284c2dab3ccf18aa3e3947 86d0fee5154848ff935aa4f523b03869 6703d520d6284c2dab3ccf18aa3e3947--86d0fee5154848ff935aa4f523b03869 83a411cbea0b4a6cbbfac52672cffbc6 86d0fee5154848ff935aa4f523b03869--83a411cbea0b4a6cbbfac52672cffbc6 7174cfc0e0824b78b1d019fd8b337d90 83a411cbea0b4a6cbbfac52672cffbc6--7174cfc0e0824b78b1d019fd8b337d90 75fc9645bc254353bc685ae7d03a9f89 RX(b0) 7174cfc0e0824b78b1d019fd8b337d90--75fc9645bc254353bc685ae7d03a9f89 6aa9d5f157fd4747b67ba061685a26fe 75fc9645bc254353bc685ae7d03a9f89--6aa9d5f157fd4747b67ba061685a26fe cdbd82f76d7846b980fc3b626c3651ec e609a19613a84385abaa5686104f1889 H c5f1f7624b494b77939b86f97b7f6b7b--e609a19613a84385abaa5686104f1889 9a61bda3cb8a4d9681e4539d894693a9 2 5493b31d1b7e4d268e16f6ae006b0de2 X e609a19613a84385abaa5686104f1889--5493b31d1b7e4d268e16f6ae006b0de2 5493b31d1b7e4d268e16f6ae006b0de2--2a078032d9234f58a61320ea5da27c9a 408e9d0637c148bba339d3d72121f3b5 RZ(g0) 5493b31d1b7e4d268e16f6ae006b0de2--408e9d0637c148bba339d3d72121f3b5 6f13e2c2ca8e48a49173811c1013d046 X 408e9d0637c148bba339d3d72121f3b5--6f13e2c2ca8e48a49173811c1013d046 6f13e2c2ca8e48a49173811c1013d046--174aac247eed479a9bee35f87ca844c9 9a5ba1600b5645149e14d6fe2a13c35a 6f13e2c2ca8e48a49173811c1013d046--9a5ba1600b5645149e14d6fe2a13c35a da69d358beb147ffa2dc137a934ad64d 9a5ba1600b5645149e14d6fe2a13c35a--da69d358beb147ffa2dc137a934ad64d 307b5d98d02542b789b7fc4f173d9029 da69d358beb147ffa2dc137a934ad64d--307b5d98d02542b789b7fc4f173d9029 54cf4a73ce764e5e8e4366ff3fd0276c 307b5d98d02542b789b7fc4f173d9029--54cf4a73ce764e5e8e4366ff3fd0276c 5c53b88e231f435bb7e5793f92462a7d 54cf4a73ce764e5e8e4366ff3fd0276c--5c53b88e231f435bb7e5793f92462a7d 875c17827cb0428abcc6a9fe77e089e6 5c53b88e231f435bb7e5793f92462a7d--875c17827cb0428abcc6a9fe77e089e6 60675c03b655444c97c98df92cde3135 875c17827cb0428abcc6a9fe77e089e6--60675c03b655444c97c98df92cde3135 cf077f5abd6b42b4a1b42c1becae67a3 60675c03b655444c97c98df92cde3135--cf077f5abd6b42b4a1b42c1becae67a3 931df369290d4b75b1817da5dbe4f334 cf077f5abd6b42b4a1b42c1becae67a3--931df369290d4b75b1817da5dbe4f334 d58b7dd2494e42809bbcb7699dc8ec45 931df369290d4b75b1817da5dbe4f334--d58b7dd2494e42809bbcb7699dc8ec45 001859d564444186b348afae79aab503 d58b7dd2494e42809bbcb7699dc8ec45--001859d564444186b348afae79aab503 fde883895ee24851b81f88f363becf52 001859d564444186b348afae79aab503--fde883895ee24851b81f88f363becf52 36ac5d521283491285c41839a381dc09 fde883895ee24851b81f88f363becf52--36ac5d521283491285c41839a381dc09 04fdd8ea66104765a813e40fa5bfc0ab 36ac5d521283491285c41839a381dc09--04fdd8ea66104765a813e40fa5bfc0ab f226be1d7c2a4a5b910ca8e054023912 04fdd8ea66104765a813e40fa5bfc0ab--f226be1d7c2a4a5b910ca8e054023912 e85cec4952b14a38992f0d0cf58dab27 RX(b0) f226be1d7c2a4a5b910ca8e054023912--e85cec4952b14a38992f0d0cf58dab27 e85cec4952b14a38992f0d0cf58dab27--cdbd82f76d7846b980fc3b626c3651ec 31c8ef04465b446691677b677b130f39 7f8b4b3a80454ec3a9bf5fa23e9f1f03 H 9a61bda3cb8a4d9681e4539d894693a9--7f8b4b3a80454ec3a9bf5fa23e9f1f03 ad58b9eca4fd4d32bbac63f722b23b58 3 2d725a01467e47af9b47fe169205cbc1 7f8b4b3a80454ec3a9bf5fa23e9f1f03--2d725a01467e47af9b47fe169205cbc1 245e66eba72648c582bc904c5e7a71ab 2d725a01467e47af9b47fe169205cbc1--245e66eba72648c582bc904c5e7a71ab bae481783db2442685de640dff96734a 245e66eba72648c582bc904c5e7a71ab--bae481783db2442685de640dff96734a d6685af3f72643fbb1f7b86f0454de6e X bae481783db2442685de640dff96734a--d6685af3f72643fbb1f7b86f0454de6e d6685af3f72643fbb1f7b86f0454de6e--4c1d4e279e86431ba933f4bdc8dac38b d99c656e57a74888a41ff619628c6fab RZ(g0) d6685af3f72643fbb1f7b86f0454de6e--d99c656e57a74888a41ff619628c6fab abb5b4ed718c4550a46a7157df5c82bf X d99c656e57a74888a41ff619628c6fab--abb5b4ed718c4550a46a7157df5c82bf abb5b4ed718c4550a46a7157df5c82bf--eb464cdc0a9f4b4cb6c21a8292515a4a 08e00c563a804a049c41a20875d025d1 abb5b4ed718c4550a46a7157df5c82bf--08e00c563a804a049c41a20875d025d1 5d0199e82e3d4ba9baa1e9e70c40b5a8 08e00c563a804a049c41a20875d025d1--5d0199e82e3d4ba9baa1e9e70c40b5a8 7b9e33ce164d4734a64951bb99bc680b 5d0199e82e3d4ba9baa1e9e70c40b5a8--7b9e33ce164d4734a64951bb99bc680b 1d8cdfe92a094bbf844dcbe6d18e7a01 X 7b9e33ce164d4734a64951bb99bc680b--1d8cdfe92a094bbf844dcbe6d18e7a01 1d8cdfe92a094bbf844dcbe6d18e7a01--60675c03b655444c97c98df92cde3135 dfaa3ca7051c4dbe820be8996b8b7133 RZ(g0) 1d8cdfe92a094bbf844dcbe6d18e7a01--dfaa3ca7051c4dbe820be8996b8b7133 45b5f5f1a9ff4ac89df89ea88e518ec0 X dfaa3ca7051c4dbe820be8996b8b7133--45b5f5f1a9ff4ac89df89ea88e518ec0 45b5f5f1a9ff4ac89df89ea88e518ec0--931df369290d4b75b1817da5dbe4f334 ee039bf2155a49b8b00d4dfde40c3e70 45b5f5f1a9ff4ac89df89ea88e518ec0--ee039bf2155a49b8b00d4dfde40c3e70 cba09cfe3a8a406aa6960b2405407bfa ee039bf2155a49b8b00d4dfde40c3e70--cba09cfe3a8a406aa6960b2405407bfa ffe18ad01ce248e59a736b1955b88192 cba09cfe3a8a406aa6960b2405407bfa--ffe18ad01ce248e59a736b1955b88192 77a5b8297b24497481404738b8e57358 ffe18ad01ce248e59a736b1955b88192--77a5b8297b24497481404738b8e57358 a9ce22bbaeab4973bb71f10447ddae71 77a5b8297b24497481404738b8e57358--a9ce22bbaeab4973bb71f10447ddae71 2aea7b1dac334a73bdae7a4bb372ab43 a9ce22bbaeab4973bb71f10447ddae71--2aea7b1dac334a73bdae7a4bb372ab43 7627c83310574f32a63a37c91abed43d RX(b0) 2aea7b1dac334a73bdae7a4bb372ab43--7627c83310574f32a63a37c91abed43d 7627c83310574f32a63a37c91abed43d--31c8ef04465b446691677b677b130f39 7c670e97be4e4810a9690570a7b8a042 a0c80b11ddd24a6aaa07f6b89da13082 H ad58b9eca4fd4d32bbac63f722b23b58--a0c80b11ddd24a6aaa07f6b89da13082 fa47577afbfd4343a83549cf67f02901 a0c80b11ddd24a6aaa07f6b89da13082--fa47577afbfd4343a83549cf67f02901 7ecb8de64b0545a988acafb9714538e2 fa47577afbfd4343a83549cf67f02901--7ecb8de64b0545a988acafb9714538e2 39cee41c1c244a0496dd26c4ab789322 7ecb8de64b0545a988acafb9714538e2--39cee41c1c244a0496dd26c4ab789322 d5a554a3b4374e32a2d213ed818d3c15 39cee41c1c244a0496dd26c4ab789322--d5a554a3b4374e32a2d213ed818d3c15 91fba44d04ea4b969dc8554057de94fc d5a554a3b4374e32a2d213ed818d3c15--91fba44d04ea4b969dc8554057de94fc 4d9bc08ab2b34da1aa051d0423db64b6 91fba44d04ea4b969dc8554057de94fc--4d9bc08ab2b34da1aa051d0423db64b6 ab1c0e3e945548f0ba750c46293771a3 X 4d9bc08ab2b34da1aa051d0423db64b6--ab1c0e3e945548f0ba750c46293771a3 ab1c0e3e945548f0ba750c46293771a3--6b71a5de85f744e3b79d37dad299cd60 d4413bb2f1a943999e54eec4e3c90973 RZ(g0) ab1c0e3e945548f0ba750c46293771a3--d4413bb2f1a943999e54eec4e3c90973 55c70e50d0b44bdfb6398d60336d9b0b X d4413bb2f1a943999e54eec4e3c90973--55c70e50d0b44bdfb6398d60336d9b0b 55c70e50d0b44bdfb6398d60336d9b0b--5d16fa5616324192ae2659a42997b0ae 7748a13d0f40418687a8fc2e0ba3829c 55c70e50d0b44bdfb6398d60336d9b0b--7748a13d0f40418687a8fc2e0ba3829c c16a478ac0494eaca4dbbdc54dd7cfe4 7748a13d0f40418687a8fc2e0ba3829c--c16a478ac0494eaca4dbbdc54dd7cfe4 73045eec23ee479eaf543a64f2ca58a6 c16a478ac0494eaca4dbbdc54dd7cfe4--73045eec23ee479eaf543a64f2ca58a6 c03f14393ea94ce5992a5816062809ba X 73045eec23ee479eaf543a64f2ca58a6--c03f14393ea94ce5992a5816062809ba c03f14393ea94ce5992a5816062809ba--d58b7dd2494e42809bbcb7699dc8ec45 e862e990b73049e4a5ac4ff25a50676d RZ(g0) c03f14393ea94ce5992a5816062809ba--e862e990b73049e4a5ac4ff25a50676d b9a2b80d0d694deb8c2ea957aa32db06 X e862e990b73049e4a5ac4ff25a50676d--b9a2b80d0d694deb8c2ea957aa32db06 b9a2b80d0d694deb8c2ea957aa32db06--fde883895ee24851b81f88f363becf52 935e3c18978243b9aa13d6231f312509 X b9a2b80d0d694deb8c2ea957aa32db06--935e3c18978243b9aa13d6231f312509 935e3c18978243b9aa13d6231f312509--77a5b8297b24497481404738b8e57358 6a238a2ac8714f33a10d68945e630de7 RZ(g0) 935e3c18978243b9aa13d6231f312509--6a238a2ac8714f33a10d68945e630de7 9b8c39585b864d85b9dab1715b9bd972 X 6a238a2ac8714f33a10d68945e630de7--9b8c39585b864d85b9dab1715b9bd972 9b8c39585b864d85b9dab1715b9bd972--2aea7b1dac334a73bdae7a4bb372ab43 e2c514fa6a99478fae41c1ec81cc1661 RX(b0) 9b8c39585b864d85b9dab1715b9bd972--e2c514fa6a99478fae41c1ec81cc1661 e2c514fa6a99478fae41c1ec81cc1661--7c670e97be4e4810a9690570a7b8a042"},{"location":"tutorials/qml/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Given the QAOA circuit above, one can construct the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization.</p> <p>The loss function to be minimized reads:</p> \\[\\mathcal{L} =-\\langle \\psi | H_c| \\psi \\rangle= -\\frac12 \\sum_{\\langle i,j\\rangle}  \\left(1 - \\langle \\psi | Z_i Z_j | \\psi \\rangle \\right)\\] <p>where \\(|\\psi\\rangle(\\beta, \\gamma)\\) is the wavefunction obtained by running the QAQA quantum circuit and the sum runs over the edges of the graph \\(\\langle i,j\\rangle\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\n\ntorch.manual_seed(seed)\n\n\ndef loss_function(model: QuantumModel):\n    # The loss corresponds to the expectation\n    # value of the cost Hamiltonian\n    return -1.0 * model.expectation().squeeze()\n\n\n# initialize the parameters to random values\nmodel = QuantumModel(circuit, observable=cost_ham)\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n\n# train the model\nn_epochs = 100\nlr = 0.1\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_function(model)\n    loss.backward()\n    optimizer.step()\n    if (i + 1) % (n_epochs // 10) == 0:\n        print(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -2.1782381363858794\nMaxCut cost at iteration 10: 3.7470706807026417\nMaxCut cost at iteration 20: 3.8378810288930216\nMaxCut cost at iteration 30: 3.9424197899236133\nMaxCut cost at iteration 40: 3.9981256255766002\nMaxCut cost at iteration 50: 3.996470528508214\nMaxCut cost at iteration 60: 3.9991374608876606\nMaxCut cost at iteration 70: 3.9994678542919555\nMaxCut cost at iteration 80: 3.999872558672829\nMaxCut cost at iteration 90: 3.9999475834121063\nMaxCut cost at iteration 100: 3.9999793311641003\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p>"},{"location":"tutorials/qml/qaoa/#results","title":"Results","text":"<p>Given the trained quantum model, one needs to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph.</p> <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\n\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\n    colors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\n    labels[node] = \"A\" if int(b) == 0 else \"B\"\n\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 1001  2025-04-04T13:35:15.219897 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/qml/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/qml/qcl/","title":"Quantum circuit learning","text":"<p>This tutorial shows how to apply <code>qadence</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning<sup>1</sup> (QCL) algorithm.</p> <p>QCL is a supervised quantum machine learning algorithm that uses a parametrized quantum neural network to learn the behavior of an arbitrary mathematical function using a set of function values as training data. This tutorial shows how to fit the \\(\\sin(x)\\) function in the \\([-1, 1]\\) domain.</p> <p>In the following, train and test data are defined.</p> <pre><code>import torch\nfrom torch.utils.data import random_split\n\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndef qcl_training_data(\n    domain: tuple = (0, 2*torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n\n    start, end = domain\n\n    x_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\n    y_rand = torch.sin(x_rand)\n\n    return x_rand, y_rand\n\nx, y = qcl_training_data()\n\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\n\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre>"},{"location":"tutorials/qml/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>Total qubit magnetization is used as observable:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <p>In the following the observable, quantum circuit and corresponding QNN model are constructed.</p> <pre><code>import qadence as qd\n\nn_qubits = 4\n\n# create a simple feature map to encode the input data\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(qd.RX(i, feature_param) for i in range(n_qubits))\nfeature_map = qd.tag(feature_map, \"feature_map\")\n\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits)\nansatz = qd.tag(ansatz, \"ansatz\")\n\n# total qubit magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning=qd.Z)\n\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qd.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\n</code></pre> <pre><code>tensor([[ 0.0092],\n        [-0.0207],\n        [-0.4616],\n        [-0.1845],\n        [-0.3761],\n        [-0.1463],\n        [-0.4563],\n        [-0.0016],\n        [-0.3436],\n        [-0.4252]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable universal function approximator. Standard PyTorch code is used for training the QNN using a mean-square error loss, Adam optimizer. Training is performend on the GPU if available:</p> <pre><code>n_epochs = 100\nlr = 0.25\n\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\n\nprint(f\"Initial loss: {mse_loss(model(values=x_train), y_train)}\")\ny_pred_initial = model(values=x_test)\n\nfor i in range(n_epochs):\n\n    optimizer.zero_grad()\n\n    # given a `n_batch` number of input points and a `n_observables`\n    # number of input observables to measure, the QNN returns\n    # an output of the following shape: [n_batch x n_observables]\n    # given that there is only one observable, a squeeze is applied to get\n    # a 1-dimensional tensor\n    loss = mse_loss(model(values=x_train).squeeze(), y_train)\n    loss.backward()\n    optimizer.step()\n\n    if (i+1) % 20 == 0:\n        print(f\"Epoch {i+1} - Loss: {loss.item()}\")\n\nassert loss.item() &lt; 1e-3\n</code></pre> <pre><code>Initial loss: 0.6272721767455237\nEpoch 20 - Loss: 0.008173087377230498\nEpoch 40 - Loss: 0.0011247726222838813\nEpoch 60 - Loss: 0.0001415308609619855\nEpoch 80 - Loss: 2.3606578815826947e-05\nEpoch 100 - Loss: 2.503287372853267e-06\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p> <p>The quantum model is now trained on the training data points. To determine the quality of the results, one can check to see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\n\ny_pred = model({\"phi\": x_test})\n\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_test_np = y_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\n\nfig, _ = plt.subplots()\nplt.scatter(x_test_np, y_test_np, label=\"Test points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2025-04-04T13:35:19.674357 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/qml/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/ml_tools/CPU/","title":"Training on CPU with <code>Trainer</code>","text":"<p>This guide explains how to train models on CPU using <code>Trainer</code> from <code>qadence.ml_tools</code>, covering single-process and multi-processing setups.</p>"},{"location":"tutorials/qml/ml_tools/CPU/#understanding-arguments","title":"Understanding Arguments","text":"<ul> <li>nprocs: Number of processes to run. To enable multi-processing and launch separate processes, set nprocs &gt; 1.</li> <li>compute_setup: The computational setup used for training. Options include <code>cpu</code>, <code>gpu</code>, and <code>auto</code>.</li> </ul> <p>For more details on the advanced training options, please refer to TrainConfig Documentation</p>"},{"location":"tutorials/qml/ml_tools/CPU/#configuring-trainconfig-for-cpu-training","title":"Configuring <code>TrainConfig</code> for CPU Training","text":"<p>By adjusting <code>TrainConfig</code>, you can seamlessly switch between single and multi-core CPU training. To enable CPU-based training, update these fields in <code>TrainConfig</code>:</p>"},{"location":"tutorials/qml/ml_tools/CPU/#single-process-training-configuration","title":"Single-Process Training Configuration:","text":"<ul> <li><code>backend=\"cpu\"</code>: Ensures training runs on the CPU.</li> <li><code>nprocs=1</code>: Uses one CPU core.</li> </ul> <pre><code>train_config = TrainConfig(\n    compute_setup=\"cpu\",\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/CPU/#multi-processing-configuration","title":"Multi-Processing Configuration","text":"<ul> <li><code>backend=\"gloo\"</code>: Uses the Gloo backend for CPU multi-processing.</li> <li><code>nprocs=4</code>: Utilizes 4 CPU cores.</li> </ul> <pre><code>train_config = TrainConfig(\n    compute_setup=\"cpu\",\n    backend=\"gloo\",\n    nprocs=4,\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/CPU/#examples","title":"Examples","text":""},{"location":"tutorials/qml/ml_tools/CPU/#single-process-cpu-training-example","title":"Single-Process CPU Training Example","text":"<p>Single-Process Training: Simple and suitable for small datasets. Use <code>backend=\"cpu\"</code>.</p> <pre><code>import torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import TrainConfig, Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nTrainer.set_use_grad(True)\n\n# Dataset, Model, and Optimizer\nx = torch.linspace(0, 1, 100).reshape(-1, 1)\ny = torch.sin(2 * torch.pi * x)\ndataloader = DataLoader(TensorDataset(x, y), batch_size=16, shuffle=True)\nmodel = nn.Sequential(nn.Linear(1, 16), nn.ReLU(), nn.Linear(16, 1))\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# Single-Process Training Configuration\ntrain_config = TrainConfig(compute_setup=\"cpu\", max_iter=5, print_every=1)\n\n# Training\ntrainer = Trainer(model, optimizer, train_config, loss_fn=\"mse\", optimize_step=optimize_step)\ntrainer.fit(dataloader)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/qml/ml_tools/CPU/#multi-processing-cpu-training-example","title":"Multi-Processing CPU Training Example","text":"<p>Multi-Processing Training: Best for large datasets, utilizes multiple CPU processes. Use <code>backend=\"gloo\"</code> and set <code>nprocs</code>.</p> <pre><code>import torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import TrainConfig, Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nTrainer.set_use_grad(True)\n\n# __main__ is recommended.\nif __name__ == \"__main__\":\n    x = torch.linspace(0, 1, 100).reshape(-1, 1)\n    y = torch.sin(2 * torch.pi * x)\n    dataloader = DataLoader(TensorDataset(x, y), batch_size=16, shuffle=True)\n    model = nn.Sequential(nn.Linear(1, 16), nn.ReLU(), nn.Linear(16, 1))\n    optimizer = optim.SGD(model.parameters(), lr=0.01)\n\n    # Multi-Process Training Configuration\n    train_config = TrainConfig(\n        compute_setup=\"cpu\",\n        backend=\"gloo\",\n        nprocs=4,\n        max_iter=5,\n        print_every=1)\n\n    trainer = Trainer(model, optimizer, train_config, loss_fn=\"mse\", optimize_step=optimize_step)\n    trainer.fit(dataloader)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/GPU/","title":"Training on GPU with <code>Trainer</code>","text":"<p>This guide explains how to train models on GPU using <code>Trainer</code> from <code>qadence.ml_tools</code>, covering single-GPU, multi-GPU (single node), and multi-node multi-GPU setups.</p>"},{"location":"tutorials/qml/ml_tools/GPU/#understanding-arguments","title":"Understanding Arguments","text":"<ul> <li>nprocs: Number of processes to run. To enable multi-processing and launch separate processes, set nprocs &gt; 1.</li> <li>compute_setup: The computational setup used for training. Options include <code>cpu</code>, <code>gpu</code>, and <code>auto</code>.</li> </ul> <p>For more details on the advanced training options, please refer to TrainConfig Documentation</p>"},{"location":"tutorials/qml/ml_tools/GPU/#configuring-trainconfig-for-gpu-training","title":"Configuring <code>TrainConfig</code> for GPU Training","text":"<p>By adjusting <code>TrainConfig</code>, you can switch between single and multi-GPU training setups. Below are the key settings for each configuration:</p>"},{"location":"tutorials/qml/ml_tools/GPU/#single-gpu-training-configuration","title":"Single-GPU Training Configuration:","text":"<ul> <li><code>compute_setup</code>: Selected training setup. (<code>gpu</code> or <code>auto</code>)</li> <li><code>backend=\"nccl\"</code>: Optimized backend for GPU training.</li> <li><code>nprocs=1</code>: Uses one GPU. <pre><code>train_config = TrainConfig(\n    compute_setup=\"auto\",\n    backend=\"nccl\",\n    nprocs=1,\n)\n</code></pre></li> </ul>"},{"location":"tutorials/qml/ml_tools/GPU/#multi-gpu-single-node-training-configuration","title":"Multi-GPU (Single Node) Training Configuration:","text":"<ul> <li><code>compute_setup</code>: Selected training setup. (<code>gpu</code> or <code>auto</code>)</li> <li><code>backend=\"nccl\"</code>: Multi-GPU optimized backend.</li> <li><code>nprocs=2</code>: Utilizes 2 GPUs on a single node. <pre><code>train_config = TrainConfig(\n    compute_setup=\"auto\",\n    backend=\"nccl\",\n    nprocs=2,\n)\n</code></pre></li> </ul>"},{"location":"tutorials/qml/ml_tools/GPU/#multi-node-multi-gpu-training-configuration","title":"Multi-Node Multi-GPU Training Configuration:","text":"<ul> <li><code>compute_setup</code>: Selected training setup. (<code>gpu</code> or <code>auto</code>)</li> <li><code>backend=\"nccl\"</code>: Required for multi-node setups.</li> <li><code>nprocs=4</code>: Uses 4 GPUs across nodes. <pre><code>train_config = TrainConfig(\n    compute_setup=\"auto\",\n    backend=\"nccl\",\n    nprocs=4,\n)\n</code></pre></li> </ul>"},{"location":"tutorials/qml/ml_tools/GPU/#examples","title":"Examples","text":"<p>The following sections provide Python scripts and training approach scripts for each setup.</p> <p>Some organizations use SLURM to manage resources. Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. If you are using slurm, you can use the <code>Trainer</code> by submitting a batch script using sbatch. Further below, we also provide the sbatch scripts for each setup.</p> <p>You can also use <code>torchrun</code> to run the training process - which provides a superset of the functionality as <code>torch.distributed.launch</code>. Here you need to specify the torchrun arguments arguments to set up the distributed training setup. We also include the <code>torchrun</code> sbatch scripts for each setup below.</p>"},{"location":"tutorials/qml/ml_tools/GPU/#example-training-script-trainpy","title":"Example Training Script (<code>train.py</code>):","text":"<p>We are going to use the following training script for the examples below. Python Script: <pre><code>import torch\nimport argparse\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import TrainConfig, Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nTrainer.set_use_grad(True)\n\n# __main__ is recommended.\nif __name__ == \"__main__\":\n    # simple dataset for y = 2\u03c0x\n    x = torch.linspace(0, 1, 100).reshape(-1, 1)\n    y = torch.sin(2 * torch.pi * x)\n    dataloader = DataLoader(TensorDataset(x, y), batch_size=16, shuffle=True)\n    # Simple model with no hidden layer and ReLU activation to fit the data for y = 2\u03c0x\n    model = nn.Sequential(nn.Linear(1, 16), nn.ReLU(), nn.Linear(16, 1))\n    # SGD optimizer with 0.01 learning rate\n    optimizer = optim.SGD(model.parameters(), lr=0.01)\n\n    # TrainConfig\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--nprocs\", type=int,\n                        default=1, help=\"Number of processes (GPUs) to use.\")\n    parser.add_argument(\"--compute_setup\", type=str,\n                        default=\"auto\", choices=[\"cpu\", \"gpu\", \"auto\"], help=\"Computational Setup.\")\n    parser.add_argument(\"--backend\", type=str,\n                        default=\"nccl\", choices=[\"nccl\", \"gloo\", \"mpi\"], help=\"Distributed backend.\")\n    args = parser.parse_args()\n    train_config = TrainConfig(\n                                backend=args.backend,\n                                nprocs=args.nprocs,\n                                compute_setup=args.compute_setup,\n                                print_every=5,\n                                max_iter=50\n                            )\n\n    trainer = Trainer(model, optimizer, train_config, loss_fn=\"mse\", optimize_step=optimize_step)\n    trainer.fit(dataloader)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#1-single-gpu","title":"1. Single-GPU:","text":"<p>Simple and suitable for single-card setups. - Assuming that you have 1 node with 1 GPU.</p> <p>You can train by calling this on the head node. <pre><code>python3 train.py --backend nccl --nprocs 1\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#slurm","title":"SLURM","text":"<p>Slurm can be used to train to train the model. <pre><code>#!/bin/bash\n#SBATCH --job-name=single_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nsrun python3 train.py --backend nccl --nprocs 1\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#torchrun","title":"TORCHRUN","text":"<p>Torchrun takes care of setting the <code>nprocs</code> based on the cluster setup. We only need to specify to use the <code>compute_setup</code>, which can be either <code>auto</code> or <code>gpu</code>. - <code>nnodes</code> for torchrun should be the number of nodes - <code>nproc_per_node</code> should be equal to the number of GPUs per node.</p> <p>Note: We use the first node of the allocated resources on the cluster as the head node. However, any other node can also be chosen. <pre><code>#!/bin/bash\n#SBATCH --job-name=single_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\nexport LOGLEVEL=INFO\n\nsrun torchrun \\\n--nnodes 1 \\\n--nproc_per_node 1 \\\n--rdzv_id $RANDOM \\\n--rdzv_backend c10d \\\n--rdzv_endpoint $head_node_ip:29501 \\\ntrain.py --compute_setup auto\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#2-multi-gpu-single-node","title":"2. Multi-GPU (Single Node):","text":"<p>For high performance using multiple GPUs in one node. - Assuming that you have 1 node with 2 GPU. These numbers can be changed depending on user needs.</p> <p>You can train by simply calling this on the head node. <pre><code>python3 train.py --backend nccl --nprocs 2\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#slurm_1","title":"SLURM","text":"<p>Slurm can be used to train the model but also to dispatch the workload on multiple GPUs or CPUs. - Here, we should have one task per gpu. i.e. <code>ntasks</code> is equal to the number of nodes - <code>nprocs</code> should be equal to the total number of gpus (world_size). which is this case is 2.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nsrun python3 train.py --backend nccl --nprocs 2\n</code></pre>"},{"location":"tutorials/qml/ml_tools/GPU/#torchrun_1","title":"TORCHRUN","text":"<p>Torchrun takes care of setting the <code>nprocs</code> based on the cluster setup. We only need to specify to use the <code>compute_setup</code>, which can be either <code>auto</code> or <code>gpu</code>. - <code>nnodes</code> for torchrun should be the number of nodes - <code>nproc_per_node</code> should be equal to the number of GPUs per node.</p> <p>Note: We use the first node of the allocated resources on the cluster as the head node. However, any other node can also be chosen. <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\nexport LOGLEVEL=INFO\n\nsrun torchrun \\\n--nnodes 1 \\\n--nproc_per_node 2 \\\n--rdzv_id $RANDOM \\\n--rdzv_backend c10d \\\n--rdzv_endpoint $head_node_ip:29501 \\\ntrain.py --compute_setup auto\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#3-multi-node-multi-gpu","title":"3. Multi-Node Multi-GPU:","text":"<p>For high performance using multiple GPUs in multiple nodes. - Assuming that you have two nodes with two GPU each. These numbers can be customised on user needs.</p> <p>For multi-node, it is suggested to submit a sbatch script.</p>"},{"location":"tutorials/qml/ml_tools/GPU/#slurm_2","title":"SLURM","text":"<ul> <li>We should have one task per gpu. i.e. <code>ntasks</code> is equal to the number of nodes.</li> <li><code>nprocs</code> should be equal to the total number of gpus (world_size). which is this case is 4.</li> </ul> <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_node\n#SBATCH --nodes=2\n#SBATCH --ntasks=2\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nsrun python3 train.py --backend nccl --nprocs 4\n</code></pre>"},{"location":"tutorials/qml/ml_tools/GPU/#torchrun_2","title":"TORCHRUN","text":"<p>Torchrun takes care of setting the <code>nprocs</code> based on the cluster setup. We only need to specify to use the <code>compute_setup</code>, which can be either <code>auto</code> or <code>gpu</code>. - <code>nnodes</code> for torchrun should be the number of nodes - <code>nproc_per_node</code> should be equal to the number of GPUs per node.</p> <p>Note: We use the first node of the allocated resources on the cluster as the head node. However, any other node can also be chosen. <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_node\n#SBATCH --nodes=2\n#SBATCH --ntasks=2\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\nexport LOGLEVEL=INFO\n\nsrun torchrun \\\n--nnodes 2 \\\n--nproc_per_node 2 \\\n--rdzv_id $RANDOM \\\n--rdzv_backend c10d \\\n--rdzv_endpoint $head_node_ip:29501 \\\ntrain.py --compute_setup auto\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/","title":"Accelerator for Distributed Training","text":""},{"location":"tutorials/qml/ml_tools/accelerator_doc/#overview","title":"Overview","text":"<p>The <code>Accelerator</code> class is designed to simplify distributed training with PyTorch's API. It allows for efficient training across multiple GPUs or processes while handling device placement, data distribution, and model synchronization. It uses <code>DistDataParallel</code> and <code>DistributedSampler</code> in the background to correctly distribute the model and training data across processes and devices.</p> <p>This tutorial will guide you through setting up and using <code>Accelerator</code> for distributed training.</p>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#accelerator","title":"Accelerator","text":"<p>The <code>Accelerator</code> class manages the training environment and process distribution. Here\u2019s how you initialize it:</p> <pre><code>from qadence.ml_tools.train_utils import Accelerator\nimport torch\n\naccelerator = Accelerator(\n    nprocs=4,               # Number of processes (e.g., GPUs). Enables multiprocessing.\n    compute_setup=\"auto\",   # Automatically selects available compute devices\n    log_setup=\"cpu\",        # Logs on CPU to avoid memory overhead\n    dtype=torch.float32,    # Data type for numerical precision\n    backend=\"nccl\"          # Backend for communication\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#using-accelerator-with-trainer","title":"Using Accelerator with Trainer","text":"<p><code>Accelerator</code> is already integrated into the <code>Trainer</code> class from <code>qadence.ml_tools</code>, and <code>Trainer</code> can automatically distribute the training process based on the configurations provided in <code>TrainConfig</code>.</p> <pre><code>from qadence.ml_tools.trainer import Trainer\nfrom qadence.ml_tools import TrainConfig\n\nconfig = TrainConfig(nprocs=4)\n\ntrainer = Trainer(model, optimizer, config)\nmodel, optimizer = trainer.fit(dataloader)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#accelerator-features","title":"Accelerator features","text":"<p>The <code>Accelerator</code> also provides a <code>distribute()</code> function wrapper that simplifies running distributed training across multiple processes. This method can be used to prepare or wrap a function that needs to be distributed.</p> <ul> <li> <p><code>distribute()</code></p> <p>This method allows you to wrap your training function so it runs across multiple processes, handling rank management and process spawning automatically.</p> <p>Example Usage: <pre><code>distributed_fun = accelerator.distribute(fun)\ndistributed_fun(*args, **kwargs)\n</code></pre></p> <p>The <code>distribute()</code> function ensures that each process runs on a designated device and synchronizes properly, making it easier to scale training with minimal code modifications.</p> <p>NOTE: <code>fun</code> should be Pickleable: Using <code>distribute</code> on <code>fun</code> allows user to spawn multiple processes that run <code>fun</code> using <code>torch.multiprocessing</code>. As a requirment for <code>torch.multiprocessing</code>,<code>fun</code> should be pickleable. It can either be a bounded class method, or an unabounded method defined in <code>__main__</code>.</p> </li> </ul> <p>The <code>Accelerator</code> further offers these key methods: <code>prepare</code>, <code>prepare_batch</code>, and <code>all_reduce_dict</code>.</p> <ul> <li> <p><code>prepare()</code></p> <p>This method ensures that models, optimizers, and dataloaders are properly placed on the correct devices for distributed training. It wraps models into <code>DistributedDataParallel</code> and synchronizes parameters across processes.</p> <pre><code>model, optimizer, dataloader = accelerator.prepare(model,\n                                                    optimizer,\n                                                    dataloader)\n</code></pre> </li> <li> <p><code>prepare_batch()</code>     Moves data batches to the correct device and formats them properly for distributed training.</p> <pre><code>batch_data, batch_targets = accelerator.prepare(batch)\n</code></pre> </li> <li> <p><code>all_reduce_dict()</code>     Aggregates and synchronizes metrics across all processes during training. Note: This will cause a synchronization overhead and slow down the training processes.</p> <pre><code>metrics = {\"loss\": torch.tensor(1.0)}\nreduced_metrics = accelerator.all_reduce_dict(metrics)\nprint(reduced_metrics)\n</code></pre> </li> </ul>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#example","title":"Example","text":"<p>To launch distributed training across multiple GPUs/CPUs, use the following approach: Each batch should be moved to the correct device. The <code>prepare_batch()</code> method simplifies this process.</p>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#example-code-train_scriptpy","title":"Example Code (train_script.py):","text":"<pre><code>import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools.train_utils import Accelerator\n\n\ndef train_epoch(epochs, model, dataloader, optimizer, accelerator):\n\n    # Prepare model, optimizer, and dataloader for distributed training\n    model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n\n    # accelerator.rank will provide you the rank of the process.\n    if accelerator.rank == 0:\n        print(\"Prepared model of type: \", type(model))\n        print(\"Prepared optimizer of type: \", type(optimizer))\n        print(\"Prepared dataloader of type: \", type(dataloader))\n\n    model.train()\n    for epoch in range(epochs):\n        for batch in dataloader:\n\n            # Move batch to the correct device\n            batch = accelerator.prepare_batch(batch)\n\n            batch_data, batch_targets = batch\n            optimizer.zero_grad()\n            output = model(batch_data)\n            loss = torch.nn.functional.mse_loss(output, batch_targets)\n            loss.backward()\n            optimizer.step()\n        print(\"Rank: \", accelerator.rank, \" | Epoch: \", epoch, \" | Loss: \", loss.item())\n\nif __name__ == \"__main__\":\n    n_epochs = 10\n    model = nn.Sequential(\n        nn.Linear(10, 100),  # Input Layer\n        nn.ReLU(),  # Activation Function\n        nn.Linear(100, 1)  # Output Layer\n    )\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    # A random dataset with 10 features and a target to predict.\n    dataset = TensorDataset(torch.randn(100, 10), torch.randn(100, 1))\n    dataloader = DataLoader(dataset, batch_size=32)\n\n    accelerator = Accelerator(\n        nprocs=4,               # Number of processes (e.g., GPUs). Enables multiprocessing.\n        compute_setup=\"cpu\",    # or choose GPU\n        backend=\"gloo\"          # choose `nccl` for GPU\n    )\n\n    distributed_train_epoch = accelerator.distribute(train_epoch)\n    distributed_train_epoch(n_epochs, model, dataloader, optimizer, accelerator)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#running-distributed-training","title":"Running Distributed Training","text":"<p>The above example can be directly run on the terminal as following:</p> <pre><code>python train_script.py\n</code></pre> <ul> <li> <p>SLURM:</p> <p>To launch distributed training across multiple GPUs</p> <p>Inside an interactive <code>srun</code> session, you can directly use: <pre><code>python train_script.py\n</code></pre></p> <p>Or submit the following sbatch script: <pre><code>#!/bin/bash\n#SBATCH --job-name=MG_slurm\n#SBATCH --nodes=1\n#SBATCH --ntasks=1              # tasks = number of nodes\n#SBATCH --gpus-per-task=4       # same as nprocs\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=56G\n\nsrun python3 train_script.py\n</code></pre></p> </li> <li> <p>Torchrun:</p> <p>To run distributed training with <code>torchrun</code> <pre><code>#!/bin/bash\n#SBATCH --job-name=MG_torchrun\n#SBATCH --nodes=1\n#SBATCH --ntasks=1              # tasks = number of nodes\n#SBATCH --gpus-per-task=2       # same as nprocs\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=56G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\n\nsrun torchrun --nnodes 1 --nproc_per_node 2 --rdzv_id $RANDOM --rdzv_backend c10d --rdzv_endpoint $head_node_ip:29522 train_script.py\n</code></pre></p> </li> </ul>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#conclusion","title":"Conclusion","text":"<p>The <code>Accelerator</code> class simplifies distributed training by handling process management, device setup, and data distribution. By integrating it into your PyTorch training workflow, you can efficiently scale training across multiple devices with minimal code modifications.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/","title":"Callbacks for Trainer","text":"<p>Qadence <code>ml_tools</code> provides a powerful callback system for customizing various stages of the training process. With callbacks, you can monitor, log, save, and alter your training workflow efficiently. A <code>CallbackManager</code> is used with <code>Trainer</code> to execute the training process with defined callbacks. Following default callbacks are already provided in the <code>Trainer</code>.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#default-callbacks","title":"Default Callbacks","text":"<p>Below is a list of the default callbacks already implemented in the <code>CallbackManager</code> used with <code>Trainer</code>:</p> <ul> <li><code>train_start</code>: <code>PlotMetrics</code>, <code>SaveCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_epoch_end</code>: <code>SaveCheckpoint</code>, <code>PrintMetrics</code>, <code>PlotMetrics</code>, <code>WriteMetrics</code></li> <li><code>val_epoch_end</code>: <code>SaveBestCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_end</code>: <code>LogHyperparameters</code>, <code>LogModelTracker</code>, <code>WriteMetrics</code>, <code>SaveCheckpoint</code>, <code>PlotMetrics</code></li> </ul> <p>This guide covers how to define and use callbacks in <code>TrainConfig</code>, integrate them with the <code>Trainer</code> class, and create custom callbacks using hooks.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#1-built-in-callbacks","title":"1. Built-in Callbacks","text":"<p>Qadence ml_tools offers several built-in callbacks for common tasks like saving checkpoints, logging metrics, and tracking models. Below is an overview of each.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#11-printmetrics","title":"1.1. <code>PrintMetrics</code>","text":"<p>Prints metrics at specified intervals.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PrintMetrics\n\nprint_metrics_callback = PrintMetrics(on=\"val_batch_end\", called_every=100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[print_metrics_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#12-writemetrics","title":"1.2. <code>WriteMetrics</code>","text":"<p>Writes metrics to a specified logging destination.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import WriteMetrics\n\nwrite_metrics_callback = WriteMetrics(on=\"train_epoch_end\", called_every=50)\n\nconfig = TrainConfig(\n    max_iter=5000,\n    callbacks=[write_metrics_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#13-plotmetrics","title":"1.3. <code>PlotMetrics</code>","text":"<p>Plots metrics based on user-defined plotting functions.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PlotMetrics\n\nplot_metrics_callback = PlotMetrics(on=\"train_epoch_end\", called_every=100)\n\nconfig = TrainConfig(\n    max_iter=5000,\n    callbacks=[plot_metrics_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#14-loghyperparameters","title":"1.4. <code>LogHyperparameters</code>","text":"<p>Logs hyperparameters to keep track of training settings.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LogHyperparameters\n\nlog_hyper_callback = LogHyperparameters(on=\"train_start\", called_every=1)\n\nconfig = TrainConfig(\n    max_iter=1000,\n    callbacks=[log_hyper_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#15-savecheckpoint","title":"1.5. <code>SaveCheckpoint</code>","text":"<p>Saves model checkpoints at specified intervals.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveCheckpoint\n\nsave_checkpoint_callback = SaveCheckpoint(on=\"train_epoch_end\", called_every=100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[save_checkpoint_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#16-savebestcheckpoint","title":"1.6. <code>SaveBestCheckpoint</code>","text":"<p>Saves the best model checkpoint based on a validation criterion.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveBestCheckpoint\n\nsave_best_checkpoint_callback = SaveBestCheckpoint(on=\"val_epoch_end\", called_every=10)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[save_best_checkpoint_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#17-loadcheckpoint","title":"1.7. <code>LoadCheckpoint</code>","text":"<p>Loads a saved model checkpoint at the start of training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LoadCheckpoint\n\nload_checkpoint_callback = LoadCheckpoint(on=\"train_start\")\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[load_checkpoint_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#18-logmodeltracker","title":"1.8. <code>LogModelTracker</code>","text":"<p>Logs the model structure and parameters.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LogModelTracker\n\nlog_model_callback = LogModelTracker(on=\"train_end\")\n\nconfig = TrainConfig(\n    max_iter=1000,\n    callbacks=[log_model_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#19-lrschedulerstepdecay","title":"1.9. <code>LRSchedulerStepDecay</code>","text":"<p>Reduces the learning rate by a factor at regular intervals.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerStepDecay\n\nlr_step_decay = LRSchedulerStepDecay(on=\"train_epoch_end\", called_every=100, gamma=0.5)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[lr_step_decay]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#110-lrschedulercyclic","title":"1.10. <code>LRSchedulerCyclic</code>","text":"<p>Applies a cyclic learning rate schedule during training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCyclic\n\nlr_cyclic = LRSchedulerCyclic(on=\"train_batch_end\", called_every=1, base_lr=0.001, max_lr=0.01, step_size=2000)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[lr_cyclic]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#111-lrschedulercosineannealing","title":"1.11. <code>LRSchedulerCosineAnnealing</code>","text":"<p>Applies cosine annealing to the learning rate during training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCosineAnnealing\n\nlr_cosine = LRSchedulerCosineAnnealing(on=\"train_batch_end\", called_every=1, t_max=5000, min_lr=1e-6)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[lr_cosine]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#112-earlystopping","title":"1.12. <code>EarlyStopping</code>","text":"<p>Stops training when a monitored metric has not improved for a specified number of epochs.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(on=\"val_epoch_end\", called_every=1, monitor=\"val_loss\", patience=5, mode=\"min\")\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[early_stopping]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#113-gradientmonitoring","title":"1.13. <code>GradientMonitoring</code>","text":"<p>Logs gradient statistics (e.g., mean, standard deviation, max) during training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import GradientMonitoring\n\ngradient_monitoring = GradientMonitoring(on=\"train_batch_end\", called_every=10)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[gradient_monitoring]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#2-custom-callbacks","title":"2. Custom Callbacks","text":"<p>The base <code>Callback</code> class in Qadence allows defining custom behavior that can be triggered at specified events (e.g., start of training, end of epoch). You can set parameters such as when the callback runs (<code>on</code>), frequency of execution (<code>called_every</code>), and optionally define a <code>callback_condition</code>.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#defining-callbacks","title":"Defining Callbacks","text":"<p>There are two main ways to define a callback: 1. Directly providing a function in the <code>Callback</code> instance. 2. Subclassing the <code>Callback</code> class and implementing custom logic.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#example-1-providing-a-callback-function-directly","title":"Example 1: Providing a Callback Function Directly","text":"<pre><code>from qadence.ml_tools.callbacks import Callback\n\n# Define a custom callback function\ndef custom_callback_function(trainer, config, writer):\n    print(\"Executing custom callback.\")\n\n# Create the callback instance\ncustom_callback = Callback(\n    on=\"train_end\",\n    callback=custom_callback_function\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#example-2-subclassing-the-callback","title":"Example 2: Subclassing the Callback","text":"<pre><code>from qadence.ml_tools.callbacks import Callback\n\nclass CustomCallback(Callback):\n    def run_callback(self, trainer, config, writer):\n        print(\"Custom behavior in run_callback method.\")\n\n# Create the subclassed callback instance\ncustom_callback = CustomCallback(on=\"train_batch_end\", called_every=10)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#3-adding-callbacks-to-trainconfig","title":"3. Adding Callbacks to <code>TrainConfig</code>","text":"<p>To use callbacks in <code>TrainConfig</code>, add them to the <code>callbacks</code> list when configuring the training process.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveCheckpoint, PrintMetrics\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[\n        SaveCheckpoint(on=\"val_epoch_end\", called_every=50),\n        PrintMetrics(on=\"train_epoch_end\", called_every=100),\n    ]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#4-using-callbacks-with-trainer","title":"4. Using Callbacks with <code>Trainer</code>","text":"<p>The <code>Trainer</code> class in <code>qadence.ml_tools</code> provides built-in support for executing callbacks at various stages in the training process, managed through a callback manager. By default, several callbacks are added to specific hooks to automate common tasks, such as check-pointing, metric logging, and model tracking.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#default-callbacks_1","title":"Default Callbacks","text":"<p>Below is a list of the default callbacks and their assigned hooks:</p> <ul> <li><code>train_start</code>: <code>PlotMetrics</code>, <code>SaveCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_epoch_end</code>: <code>SaveCheckpoint</code>, <code>PrintMetrics</code>, <code>PlotMetrics</code>, <code>WriteMetrics</code></li> <li><code>val_epoch_end</code>: <code>SaveBestCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_end</code>: <code>LogHyperparameters</code>, <code>LogModelTracker</code>, <code>WriteMetrics</code>, <code>SaveCheckpoint</code>, <code>PlotMetrics</code></li> </ul> <p>These defaults handle common needs, but you can also add custom callbacks to any hook.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#example-adding-a-custom-callback","title":"Example: Adding a Custom Callback","text":"<p>To create a custom <code>Trainer</code> that includes a <code>PrintMetrics</code> callback executed specifically at the end of each epoch, follow the steps below.</p> <pre><code>from qadence.ml_tools.trainer import Trainer\nfrom qadence.ml_tools.callbacks import PrintMetrics\n\nclass CustomTrainer(Trainer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.print_metrics_callback = PrintMetrics(on=\"train_epoch_end\", called_every = 10)\n\n    def on_train_epoch_end(self, train_epoch_loss_metrics):\n        self.print_metrics_callback.run_callback(self)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/data_and_config/","title":"Data and Configurations","text":""},{"location":"tutorials/qml/ml_tools/data_and_config/#1-dataloaders","title":"1. Dataloaders","text":"<p>When using Qadence, you can supply classical data to a quantum machine learning algorithm by using a standard PyTorch <code>DataLoader</code> instance. Qadence also provides the <code>DictDataLoader</code> convenience class which allows to build dictionaries of <code>DataLoader</code>s instances and easily iterate over them.</p> <pre><code>import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import DictDataLoader, to_dataloader\n\n\ndef dataloader(data_size: int = 25, batch_size: int = 5, infinite: bool = False) -&gt; DataLoader:\n    x = torch.linspace(0, 1, data_size).reshape(-1, 1)\n    y = torch.sin(x)\n    return to_dataloader(x, y, batch_size=batch_size, infinite=infinite)\n\n\ndef dictdataloader(data_size: int = 25, batch_size: int = 5) -&gt; DictDataLoader:\n    dls = {}\n    for k in [\"y1\", \"y2\"]:\n        x = torch.rand(data_size, 1)\n        y = torch.sin(x)\n        dls[k] = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n    return DictDataLoader(dls)\n\n\n# iterate over standard DataLoader\nfor (x,y) in dataloader(data_size=6, batch_size=2):\n    print(f\"Standard {x = }\")\n\n# construct an infinite dataset which will keep sampling indefinitely\nn_epochs = 5\ndl = iter(dataloader(data_size=6, batch_size=2, infinite=True))\nfor _ in range(n_epochs):\n    (x, y) = next(dl)\n    print(f\"Infinite {x = }\")\n\n# iterate over DictDataLoader\nddl = dictdataloader()\ndata = next(iter(ddl))\nprint(f\"{data = }\")\n</code></pre> <pre><code>Standard x = tensor([[0.0000],\n        [0.2000]])\nStandard x = tensor([[0.4000],\n        [0.6000]])\nStandard x = tensor([[0.8000],\n        [1.0000]])\nInfinite x = tensor([[0.6000],\n        [0.2000]])\nInfinite x = tensor([[0.],\n        [1.]])\nInfinite x = tensor([[0.8000],\n        [0.4000]])\nInfinite x = tensor([[0.6000],\n        [0.2000]])\nInfinite x = tensor([[0.],\n        [1.]])\ndata = {'y1': [tensor([[0.3862],\n        [0.9580],\n        [0.9328],\n        [0.4022],\n        [0.6507]]), tensor([[0.3767],\n        [0.8180],\n        [0.8033],\n        [0.3915],\n        [0.6058]])], 'y2': [tensor([[0.4646],\n        [0.1700],\n        [0.6452],\n        [0.3723],\n        [0.6032]]), tensor([[0.4481],\n        [0.1692],\n        [0.6013],\n        [0.3637],\n        [0.5673]])]}\n</code></pre> <p>Note:     In case of <code>infinite</code>=True, the dataloader iterator will provide a random sample from the dataset.</p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#2-training-configuration","title":"2. Training Configuration","text":"<p>The <code>TrainConfig</code> class provides a comprehensive configuration setup for training quantam machine learning models in Qadence. This configuration includes settings for batch size, logging, check-pointing, validation, and additional custom callbacks that control the training process's granularity and flexibility.</p> <p>The <code>TrainConfig</code> tells <code>Trainer</code>  what batch_size should be used, how many epochs to train, in which intervals to print/log metrics and how often to store intermediate checkpoints. It is also possible to provide custom callback functions by instantiating a <code>Callback</code> with a function <code>callback</code>.</p> <p>For example of how to use the TrainConfig with <code>Trainer</code>, please see Examples in Trainer</p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#21-explanation-of-trainconfig-attributes","title":"2.1 Explanation of <code>TrainConfig</code> Attributes","text":"Attribute Type Default Description <code>max_iter</code> <code>int</code> <code>10000</code> Total number of training epochs. <code>batch_size</code> <code>int</code> <code>1</code> Batch size for training. <code>print_every</code> <code>int</code> <code>0</code> Frequency of console output. Set to <code>0</code> to disable. <code>write_every</code> <code>int</code> <code>0</code> Frequency of logging metrics. Set to <code>0</code> to disable. <code>plot_every</code> <code>int</code> <code>0</code> Frequency of plotting metrics. Set to <code>0</code> to disable. <code>checkpoint_every</code> <code>int</code> <code>0</code> Frequency of saving checkpoints. Set to <code>0</code> to disable. <code>val_every</code> <code>int</code> <code>0</code> Frequency of validation checks. Set to <code>0</code> to disable. <code>val_epsilon</code> <code>float</code> <code>1e-5</code> Threshold for validation improvement. <code>validation_criterion</code> <code>Callable</code> <code>None</code> Function for validating metric improvement. <code>trainstop_criterion</code> <code>Callable</code> <code>None</code> Function to stop training early. <code>callbacks</code> <code>list[Callback]</code> <code>[]</code> List of custom callbacks. <code>root_folder</code> <code>Path</code> <code>\"./qml_logs\"</code> Root directory for saving logs and checkpoints. <code>log_folder</code> <code>Path</code> <code>\"./qml_logs\"</code> Logging directory for saving logs and checkpoints. <code>log_model</code> <code>bool</code> <code>False</code> Enables model logging. <code>verbose</code> <code>bool</code> <code>True</code> Enables detailed logging. <code>tracking_tool</code> <code>ExperimentTrackingTool</code> <code>TENSORBOARD</code> Tool for tracking training metrics. <code>plotting_functions</code> <code>tuple</code> <code>()</code> Functions for plotting metrics. <code>hyperparams</code> <code>dict</code> <code>{}</code> Dictionary of hyperparameters <code>nprocs</code> <code>int</code> <code>1</code> Number of processes to use when spawning subprocesses; for multi-GPU setups, set this to the total number of GPUs. <code>compute_setup</code> <code>str</code> <code>\"cpu\"</code> Specifies the compute device: <code>\"auto\"</code>, <code>\"gpu\"</code>, or <code>\"cpu\"</code>. <code>backend</code> <code>str</code> <code>\"gloo\"</code> Backend for distributed training communication (e.g., <code>\"gloo\"</code>, <code>\"nccl\"</code>, or <code>\"mpi\"</code>). <code>log_setup</code> <code>str</code> <code>\"cpu\"</code> Device setup for logging; use <code>\"cpu\"</code> to avoid GPU conflicts <code>dtype</code> <code>dtype</code> or <code>None</code> <code>None</code> Data type for computations (e.g., <code>torch.float32</code>) <code>all_reduce_metrics</code> <code>bool</code> <code>False</code> If <code>True</code>, aggregates metrics (e.g., loss) across processes <pre><code>from qadence.ml_tools import OptimizeResult, TrainConfig\nfrom qadence.ml_tools.callbacks import Callback\n\nbatch_size = 5\nn_epochs = 100\n\nprint_parameters = lambda opt_res: print(opt_res.model.parameters())\ncondition_print = lambda opt_res: opt_res.loss &lt; 1.0e-03\nmodify_extra_opt_res = {\"n_epochs\": n_epochs}\ncustom_callback = Callback(on=\"train_end\", callback = print_parameters, callback_condition=condition_print, modify_optimize_result=modify_extra_opt_res, called_every=10,)\n\nconfig = TrainConfig(\n    root_folder=\"some_path/\",\n    max_iter=n_epochs,\n    checkpoint_every=100,\n    write_every=100,\n    batch_size=batch_size,\n    callbacks = [custom_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/data_and_config/#22-key-configuration-options-in-trainconfig","title":"2.2 Key Configuration Options in <code>TrainConfig</code>","text":""},{"location":"tutorials/qml/ml_tools/data_and_config/#iterations-and-batch-size","title":"Iterations and Batch Size","text":"<ul> <li><code>max_iter</code> (int): Specifies the total number of training iterations (epochs). For an <code>InfiniteTensorDataset</code>, each epoch contains one batch; for a <code>TensorDataset</code>, it contains <code>len(dataloader)</code> batches.</li> <li><code>batch_size</code> (int): Defines the number of samples processed in each training iteration.</li> </ul> <p>Example: <pre><code>config = TrainConfig(max_iter=2000, batch_size=32)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#training-parameters","title":"Training Parameters","text":"<ul> <li><code>print_every</code> (int): Controls how often loss and metrics are printed to the console.</li> <li><code>write_every</code> (int): Determines how frequently metrics are written to the tracking tool, such as TensorBoard or MLflow.</li> <li><code>checkpoint_every</code> (int): Sets the frequency for saving model checkpoints.</li> </ul> <p>Note: Set 0 to diable.</p> <p>Example: <pre><code>config = TrainConfig(print_every=100, write_every=50, checkpoint_every=50)\n</code></pre></p> <p>The user can provide either the <code>root_folder</code> or the <code>log_folder</code> for saving checkpoints and logging. When neither are provided, the default <code>root_folder</code> \"./qml_logs\" is used.</p> <ul> <li><code>root_folder</code> (Path): The root directory for saving checkpoints and logs. All training logs will be saved inside a subfolder in this root directory. (The path to these subfolders can be accessed using config._subfolders, and the current logging folder is config.log_folder)</li> <li><code>create_subfolder_per_run</code> (bool): Creates a unique subfolder for each training run within the specified folder.</li> <li><code>tracking_tool</code> (ExperimentTrackingTool): Specifies the tracking tool to log metrics, e.g., TensorBoard or MLflow.</li> <li><code>log_model</code> (bool): Enables logging of a serialized version of the model, which is useful for model versioning. Thi happens at the end of training.</li> </ul> <p>Note     - The user can also provide <code>log_folder</code> argument - which will only be used when <code>create_subfolder_per_run</code> = False.     -  <code>log_folder</code> (Path): The log folder used for saving checkpoints and logs.</p> <p>Example: <pre><code>config = TrainConfig(root_folder=\"path/to/checkpoints\", tracking_tool=ExperimentTrackingTool.MLFLOW, checkpoint_best_only=True)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#validation-parameters","title":"Validation Parameters","text":"<ul> <li><code>checkpoint_best_only</code> (bool): If set to <code>True</code>, saves checkpoints only when there is an improvement in the validation metric.</li> <li><code>val_every</code> (int): Frequency of validation checks. Setting this to <code>0</code> disables validation.</li> <li><code>val_epsilon</code> (float): A small threshold used to compare the current validation loss with previous best losses.</li> <li><code>validation_criterion</code> (Callable): A custom function to assess if the validation metric meets a specified condition.</li> </ul> <p>Example: <pre><code>config = TrainConfig(val_every=200, checkpoint_best_only = True, validation_criterion=lambda current, best: current &lt; best - 0.001)\n</code></pre></p> <p>If it is desired to only the save the \"best\" checkpoint, the following must be ensured:</p> <pre><code>(a) `checkpoint_best_only = True` is used while creating the configuration through `TrainConfig`,\n(b) `val_every` is set to a valid integer value (for example, `val_every = 10`) which controls the no. of iterations after which the validation data should be used to evaluate the model during training, which can also be set through `TrainConfig`,\n(c) a validation criterion is provided through the `validation_criterion`, set through `TrainConfig` to quantify the definition of \"best\", and\n(d) the validation dataloader passed to `Trainer` is of type `DataLoader`. In this case, it is expected that a validation dataloader is also provided along with the train dataloader since the validation data will be used to decide the \"best\" checkpoint.\n</code></pre> <p>The criterion used to decide the \"best\" checkpoint can be customized by <code>validation_criterion</code>, which should be a function that can take val_loss, best_loss, and val_epsilon arguments and return a boolean value (True or False) indicating whether some validation metric is satisfied or not. An example of a simple <code>validation_criterion</code> is: <pre><code>def validation_criterion(val_loss: float, best_val_loss: float, val_epsilon: float) -&gt; bool:\n    return val_loss &lt; (best_val_loss - val_epsilon)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#custom-callbacks","title":"Custom Callbacks","text":"<p><code>TrainConfig</code> supports custom callbacks that can be triggered at specific stages of training. The <code>callbacks</code> attribute accepts a list of callback instances, which allow for custom behaviors like early stopping or additional logging. See Callbacks for more details.</p> <ul> <li><code>callbacks</code> (list[Callback]): List of custom callbacks to execute during training.</li> </ul> <p>Example: <pre><code>from qadence.ml_tools.callbacks import Callback\n\ndef callback_fn(trainer, config, writer):\n    if trainer.opt_res.loss &lt; 0.001:\n        print(\"Custom Callback: Loss threshold reached!\")\n\ncustom_callback = Callback(on = \"train_epoch_end\", called_every = 10, callback_function = callback_fn )\n\nconfig = TrainConfig(callbacks=[custom_callback])\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#hyperparameters-and-plotting","title":"Hyperparameters and Plotting","text":"<ul> <li><code>hyperparams</code> (dict): A dictionary of hyperparameters (e.g., learning rate, regularization) to be tracked by the tracking tool.</li> <li><code>plot_every</code> (int): Determines how frequently plots are saved to the tracking tool, such as TensorBoard or MLflow.</li> <li><code>plotting_functions</code> (tuple[LoggablePlotFunction, ...]): Functions for in-training plotting of metrics or model state.</li> </ul> <p>Note: Please ensure that plotting_functions are provided when plot_every &gt; 0</p> <p>Example: <pre><code>config = TrainConfig(\n    plot_every=10,\n    hyperparams={\"learning_rate\": 0.001, \"batch_size\": 32},\n    plotting_functions=(plot_loss_function,)\n)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#advanced-distributed-training","title":"Advanced Distributed Training","text":"<ul> <li> <p><code>nprocs</code> (int): Specifies the number of processes to be used. For multi-GPU training, this should match the total number of GPUs available. When nprocs is greater than 1, <code>Trainer</code> spawns additional subprocesses for training. This is useful for parallel or distributed training setups.</p> </li> <li> <p><code>compute_setup</code> (str): Determines the compute device configuration: 1.<code>\"auto\"</code> (automatically selects GPU if available), 2. <code>\"gpu\"</code> - (forces GPU usage and errors if no GPU is detected), and 3. <code>\"cpu\"</code> (Forces the use of the CPU).</p> </li> <li> <p><code>backend</code> (str): Specifies the communication backend for distributed training. Common options are <code>\"gloo\"</code> (default), <code>\"nccl\"</code> (optimized for GPUs), or <code>\"mpi\"</code>, depending on your setup. It should be one of the backends supported by <code>torch.distributed</code>. For further details, please look at torch backends</p> </li> </ul> <p>Notes: - Logging Specific Callbacks: Logging is available only through the main process, i.e. process 0.  Model logging, plotting, logging metrics will only be performed for a single process, even if multiple processes are run. - Training with specific callbacks: Callbacks specific to training, e.g., <code>EarlyStopping</code>, <code>LRSchedulerStepDecay</code>, etc will be called from each process. - <code>PrintMetrics</code> (set through the <code>print_every</code> argument in <code>TrainCongig</code>) is available from all processes.</p> <p>Example: For CPU MultiProcessing <pre><code>config = TrainConfig(\n    compute_setup=\"cpu\",\n    nprocs=5,\n    backend=\"gloo\"\n)\n</code></pre></p> <p>Example: For GPU multiprocessing training <pre><code>config = TrainConfig(\n    compute_setup=\"gpu\",\n    nprocs=2, # World-size/Total number of GPUs\n    backend=\"nccl\"\n)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#precision-options","title":"Precision Options","text":"<ul> <li> <p><code>dtype</code> (dtype or None): Sets the numerical precision (data type) for computations. For instance, you can use <code>torch.float32</code> or <code>torch.float16</code> depending on your performance and precision needs. Both model parameters, and dataset will be of the provided precision.</p> <ul> <li>If not specified or None, the default torch precision (usually torch.float32) is used.</li> <li>If provided dtype is complex dtype, appropriate precision for the data and model parameters will be used as follows:</li> </ul> Data Type (<code>dtype</code>) Data Precision Model Precision Model Parameters Precision  (Real Part  &amp; Imaginary Part ) <code>torch.float16</code> 16-bit 16-bit N/A <code>torch.float32</code> 32-bit 32-bit N/A <code>torch.float64</code> 64-bit 64-bit N/A <code>torch.complex32</code> 16-bit 32-bit 16-bit <code>torch.complex64</code> 32-bit 64-bit 32-bit <code>torch.complex128</code> 64-bit 128-bit 64-bit <p>Complex Dtypes: Complex data types are useful for Quantum Neural Networks - such as <code>QNN</code> provided by qadence. The industry standard is to use <code>torch.complex128</code>, however, the user can also specify a lower precision (<code>torch.complex64</code> or  <code>torch.complex32</code>) for faster training.</p> </li> </ul> <p>Furthermore, the user can also utilize the following options:</p> <ul> <li> <p><code>log_setup</code> (str): Configures the device used for logging. Using <code>\"cpu\"</code> ensures logging runs on the CPU (which may avoid conflicts with GPU operations), while <code>\"auto\"</code> aligns logging with the compute device.</p> </li> <li> <p><code>all_reduce_metrics</code> (bool): When enabled, aggregates metrics (such as loss or accuracy) across all training processes to provide a unified summary, though it may introduce additional synchronization overhead.</p> </li> </ul>"},{"location":"tutorials/qml/ml_tools/data_and_config/#3-experiment-tracking-with-mlflow","title":"3. Experiment tracking with mlflow","text":"<p>Qadence allows to track runs and log hyperparameters, models and plots with tensorboard and mlflow. In the following, we demonstrate the integration with mlflow.</p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#mlflow-configuration","title":"mlflow configuration","text":"<p>We have control over our tracking configuration by setting environment variables. First, let's look at the tracking URI. For the purpose of this demo we will be working with a local database, in a similar fashion as described here, <pre><code>export MLFLOW_TRACKING_URI=sqlite:///mlruns.db\n</code></pre></p> <p>Qadence can also read the following two environment variables to define the mlflow experiment name and run name <pre><code>export MLFLOW_EXPERIMENT=test_experiment\nexport MLFLOW_RUN_NAME=run_0\n</code></pre></p> <p>If no tracking URI is provided, mlflow stores run information and artifacts in the local <code>./mlflow</code> directory and if no names are defined, the experiment and run will be named with random UUIDs.</p>"},{"location":"tutorials/qml/ml_tools/intro/","title":"Introduction to Qadence ML Tools","text":"<p>Welcome to the Qadence <code>ML Tools</code> documentation. This submodule is designed to streamline your machine learning workflows \u2014especially for quantum machine learning\u2014 by providing a set of robust tools for training, monitoring, and optimizing your models.</p>"},{"location":"tutorials/qml/ml_tools/intro/#what-this-documentation-is-about","title":"What this documentation is about","text":"<ul> <li> <p>Trainer Class   Learn how to leverage the versatile <code>Trainer</code> class to manage your training loops, handle data loading, and integrate with experiment tracking tools like TensorBoard and MLflow. Detailed guides cover:</p> <ul> <li>Setting up training on both GPUs and CPUs.</li> <li>Configuring single-process, multi-processing, and distributed training setups.</li> </ul> </li> <li> <p>Gradient Optimization Methods   Explore both gradient-based and gradient-free optimization strategies. Find examples demonstrating how to switch between these modes and how to use context managers for mixed optimization.</p> </li> <li> <p>Custom Loss Functions and Hooks   Discover how to define custom loss functions tailored to your tasks and use hooks to insert custom behaviors at various stages of the training process.</p> </li> <li> <p>Callbacks for Enhanced Training   Utilize built-in and custom callbacks to log metrics, save checkpoints, adjust learning rates, and more. This section explains how to integrate callbacks seamlessly into your training workflow.</p> </li> <li> <p>Experiment Tracking   Understand how to configure experiment tracking with tools such as TensorBoard and MLflow to monitor your model\u2019s progress and performance.</p> </li> </ul>"},{"location":"tutorials/qml/ml_tools/intro/#getting-started","title":"Getting Started","text":"<p>To dive in, explore the detailed sections below:</p> <ul> <li>Qadence Trainer Guide</li> <li>Training Configuration</li> <li>Callbacks for Trainer</li> <li>Accelerator for Distributed Training</li> <li>Training on GPU with Trainer</li> <li>Training on CPU with Trainer</li> </ul>"},{"location":"tutorials/qml/ml_tools/trainer/","title":"Qadence Trainer Guide","text":"<p>The <code>Trainer</code> class in <code>qadence.ml_tools</code> is a versatile tool designed to streamline the training of quantum machine learning models. It offers flexibility for both gradient-based and gradient-free optimization methods, supports custom loss functions, and integrates seamlessly with tracking tools like TensorBoard and MLflow. Additionally, it provides hooks for implementing custom behaviors during the training process.</p> <p>For training QML models, Qadence offers this out-of-the-box <code>Trainer</code> for optimizing differentiable models, e.g. <code>QNN</code>s and <code>QuantumModel</code>, containing either trainable and/or non-trainable parameters (see the parameters tutorial for detailed information about parameter types):</p>"},{"location":"tutorials/qml/ml_tools/trainer/#1-overview","title":"1. Overview","text":"<p>The <code>Trainer</code> class simplifies the training workflow by managing the training loop, handling data loading, and facilitating model evaluation. It is compatible with various optimization strategies and allows for extensive customization to meet specific training requirements.</p> <p>Example of initializing the <code>Trainer</code>:</p> <pre><code>from qadence.ml_tools import Trainer, TrainConfig\nfrom torch.optim import Adam\n\n# Initialize model and optimizer\nmodel = ...  # Define or load a quantum model here\noptimizer = Adam(model.parameters(), lr=0.01)\nconfig = TrainConfig(max_iter=100, print_every=10)\n\n# Initialize Trainer with model, optimizer, and configuration\ntrainer = Trainer(model=model, optimizer=optimizer, config=config)\n</code></pre> <p>Notes: <code>qadence</code> versions prior to 1.9.0 provided <code>train_with_grad</code> and <code>train_no_grad</code> functions, which are being replaced with <code>Trainer</code>. The user can transition as following. <pre><code>from qadence.ml_tools import train_with_grad\ntrain_with_grad(model=model, optimizer=optimizer, config=config, data = data)\n</code></pre> to <pre><code>from qadence.ml_tools import Trainer\ntrainer = Trainer(model=model, optimizer=optimizer, config=config)\ntrainer.fit(train_dataloader = data)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/trainer/#2-gradient-based-and-gradient-free-optimization","title":"2. Gradient-Based and Gradient-Free Optimization","text":"<p>The <code>Trainer</code> supports both gradient-based and gradient-free optimization methods. Default is gradient-based optimization.</p> <ul> <li>Gradient-Based Optimization: Utilizes optimizers from PyTorch's <code>torch.optim</code> module. This is the default behaviour of the <code>Trainer</code>, thus setting this is not necessary. However, it can be explicity mentioned as follows. Example of using gradient-based optimization:</li> </ul> <pre><code>from qadence.ml_tools import Trainer\n\n# set_use_grad(True) to enable gradient based training. This is the default behaviour of Trainer.\nTrainer.set_use_grad(True)\n</code></pre> <ul> <li>Gradient-Free Optimization: Employs optimization algorithms from the Nevergrad library.</li> </ul> <p>Example of using gradient-free optimization with Nevergrad:</p> <pre><code>from qadence.ml_tools import Trainer\n\n# set_use_grad(False) to disable gradient based training.\nTrainer.set_use_grad(False)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#using-context-managers-for-mixed-optimization","title":"Using Context Managers for Mixed Optimization","text":"<p>For cases requiring both optimization methods in a single training session, the <code>Trainer</code> class provides context managers to enable or disable gradients.</p> <pre><code># Temporarily switch to gradient-based optimization\nwith trainer.enable_grad_opt(optimizer):\n    print(\"Gradient Based Optimization\")\n    # trainer.fit(train_loader)\n\n# Switch to gradient-free optimization for specific steps\nwith trainer.disable_grad_opt(ng_optimizer):\n    print(\"Gradient Free Optimization\")\n    # trainer.fit(train_loader)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#3-custom-loss-functions","title":"3. Custom Loss Functions","text":"<p>Users can define custom loss functions tailored to their specific tasks. The <code>Trainer</code> accepts a <code>loss_fn</code> parameter, which should be a callable that takes the model and data as inputs and returns a tuple containing the loss tensor and a dictionary of metrics.</p> <p>Example of using a custom loss function:</p> <pre><code>import torch\nfrom itertools import count\ncnt = count()\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    x, y = data\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n</code></pre> <p>This custom loss function can be used in the trainer <pre><code>from qadence.ml_tools import Trainer, TrainConfig\nfrom torch.optim import Adam\n\n# Initialize model and optimizer\nmodel = ...  # Define or load a quantum model here\noptimizer = Adam(model.parameters(), lr=0.01)\nconfig = TrainConfig(max_iter=100, print_every=10)\n\ntrainer = Trainer(model=model, optimizer=optimizer, config=config, loss_fn=loss_fn)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/trainer/#4-hooks-for-custom-behavior","title":"4. Hooks for Custom Behavior","text":"<p>The <code>Trainer</code> class provides several hooks that enable users to inject custom behavior at different stages of the training process. These hooks are methods that can be overridden in a subclass to execute custom code. The available hooks include:</p> <ul> <li><code>on_train_start</code>: Called at the beginning of the training process.</li> <li><code>on_train_end</code>: Called at the end of the training process.</li> <li><code>on_train_epoch_start</code>: Called at the start of each training epoch.</li> <li><code>on_train_epoch_end</code>: Called at the end of each training epoch.</li> <li><code>on_train_batch_start</code>: Called at the start of each training batch.</li> <li><code>on_train_batch_end</code>: Called at the end of each training batch.</li> </ul> <p>Each \"start\" and \"end\" hook receives data and loss metrics as arguments. The specific values provided for these arguments depend on the training stage associated with the hook. The context of the training stage (e.g., training, validation, or testing) determines which metrics are relevant and how they are populated. For details of inputs on each hook, please review the documentation of <code>BaseTrainer</code>.</p> <pre><code>- Example of what inputs are provided to training hooks.\n\n    ```\n    def on_train_batch_start(self, batch: Tuple[torch.Tensor, ...] | None) -&gt; None:\n        \"\"\"\n        Called at the start of each training batch.\n\n        Args:\n            batch: A batch of data from the DataLoader. Typically a tuple containing\n                input tensors and corresponding target tensors.\n        \"\"\"\n        pass\n    ```\n    ```\n    def on_train_batch_end(self, train_batch_loss_metrics: Tuple[torch.Tensor, Any]) -&gt; None:\n        \"\"\"\n        Called at the end of each training batch.\n\n        Args:\n            train_batch_loss_metrics: Metrics for the training batch loss.\n                Tuple of (loss, metrics)\n        \"\"\"\n        pass\n    ```\n</code></pre> <p>Example of using a hook to log a message at the end of each epoch:</p> <pre><code>from qadence.ml_tools import Trainer\n\nclass CustomTrainer(Trainer):\n    def on_train_epoch_end(self, train_epoch_loss_metrics):\n        print(f\"End of epoch - Loss and Metrics: {train_epoch_loss_metrics}\")\n</code></pre> <p>Notes: Trainer offers inbuilt callbacks as well. Callbacks are mainly for logging/tracking purposes, but the above mentioned hooks are generic. The workflow for every train batch looks like: 1. perform on_train_batch_start callbacks, 2. call the on_train_batch_start hook, 3. do the batch training, 4. call the on_train_batch_end hook, and 5. perform on_train_batch_end callbacks.</p> <p>The use of <code>on_</code>{phase}<code>_start</code> and <code>on_</code>{phase}<code>_end</code> hooks is not specifically to add extra callbacks, but for any other generic pre/post processing. For example, reshaping input batch in case of RNNs/LSTMs, post processing loss and adding an extra metric. They could also be used to add more callbacks (which is not recommended - as we provide methods to add extra callbacks in the TrainCofig)</p>"},{"location":"tutorials/qml/ml_tools/trainer/#5-experiment-tracking-with-tensorboard-and-mlflow","title":"5. Experiment Tracking with TensorBoard and MLflow","text":"<p>The <code>Trainer</code> integrates with TensorBoard and MLflow for experiment tracking:</p> <ul> <li> <p>TensorBoard: Logs metrics and visualizations during training, allowing users to monitor the training process.</p> </li> <li> <p>MLflow: Tracks experiments, logs parameters, metrics, and artifacts, and provides a user-friendly interface for comparing different runs.</p> </li> </ul> <p>To utilize these tracking tools, the <code>Trainer</code> can be configured with appropriate writers that handle the logging of metrics and other relevant information during training.</p> <p>Example of using TensorBoard tracking:</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.types import ExperimentTrackingTool\n\n# Set up tracking with TensorBoard\nconfig = TrainConfig(max_iter=100, tracking_tool=ExperimentTrackingTool.TENSORBOARD)\n</code></pre> <p>Example of using MLflow tracking:</p> <pre><code>from qadence.types import ExperimentTrackingTool\n\n# Set up tracking with MLflow\nconfig = TrainConfig(max_iter=100, tracking_tool=ExperimentTrackingTool.MLFLOW)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#6-examples","title":"6. Examples","text":""},{"location":"tutorials/qml/ml_tools/trainer/#61-training-with-trainer-and-trainconfig","title":"6.1. Training with <code>Trainer</code> and <code>TrainConfig</code>","text":""},{"location":"tutorials/qml/ml_tools/trainer/#setup","title":"Setup","text":"<p>Let's do the necessary imports and declare a <code>DataLoader</code>. We can already define some hyperparameters here, including the seed for random number generators. mlflow can log hyperparameters with arbitrary types, for example the observable that we want to monitor (<code>Z</code> in this case, which has a <code>qadence.Operation</code> type).</p> <pre><code>import random\nfrom itertools import count\n\nimport numpy as np\nimport torch\nfrom matplotlib import pyplot as plt\nfrom matplotlib.figure import Figure\nfrom torch.nn import Module\nfrom torch.utils.data import DataLoader\n\nfrom qadence import hea, QuantumCircuit, Z\nfrom qadence.constructors import feature_map, hamiltonian_factory\nfrom qadence.ml_tools import Trainer, TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\nfrom qadence.ml_tools.utils import rand_featureparameters\nfrom qadence.ml_tools.models import QNN, QuantumModel\nfrom qadence.types import ExperimentTrackingTool\n\nhyperparams = {\n    \"seed\": 42,\n    \"batch_size\": 10,\n    \"n_qubits\": 2,\n    \"ansatz_depth\": 1,\n    \"observable\": Z,\n}\n\nnp.random.seed(hyperparams[\"seed\"])\ntorch.manual_seed(hyperparams[\"seed\"])\nrandom.seed(hyperparams[\"seed\"])\n\n\ndef dataloader(batch_size: int = 25) -&gt; DataLoader:\n    x = torch.linspace(0, 1, batch_size).reshape(-1, 1)\n    y = torch.cos(x)\n    return to_dataloader(x, y, batch_size=batch_size, infinite=True)\n</code></pre> <p>We continue with the regular QNN definition, together with the loss function and optimizer.</p> <pre><code>obs = hamiltonian_factory(register=hyperparams[\"n_qubits\"], detuning=hyperparams[\"observable\"])\n\ndata = dataloader(hyperparams[\"batch_size\"])\nfm = feature_map(hyperparams[\"n_qubits\"], param=\"x\")\n\nmodel = QNN(\n    QuantumCircuit(\n        hyperparams[\"n_qubits\"], fm, hea(hyperparams[\"n_qubits\"], hyperparams[\"ansatz_depth\"])\n    ),\n    observable=obs,\n    inputs=[\"x\"],\n)\n\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ninputs = rand_featureparameters(model, 1)\n\ndef loss_fn(model: QuantumModel, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    out = model.expectation(inputs)\n    loss = criterion(out, torch.rand(1))\n    return loss, {}\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#trainconfig-specifications","title":"<code>TrainConfig</code> specifications","text":"<p>Qadence offers different tracking options via <code>TrainConfig</code>. Here we use the <code>ExperimentTrackingTool</code> type to specify that we want to track the experiment with mlflow. Tracking with tensorboard is also possible. We can then indicate what and how often we want to track or log.</p> <p>For Training <code>write_every</code> controls the number of epochs after which the loss values is logged. Thanks to the <code>plotting_functions</code> and <code>plot_every</code>arguments, we are also able to plot model-related quantities throughout training. Notice that arbitrary plotting functions can be passed, as long as the signature is the same as <code>plot_fn</code> below. Finally, the trained model can be logged by setting <code>log_model=True</code>. Here is an example of plotting function and training configuration</p> <pre><code>def plot_fn(model: Module, iteration: int) -&gt; tuple[str, Figure]:\n    descr = f\"ufa_prediction_epoch_{iteration}.png\"\n    fig, ax = plt.subplots()\n    x = torch.linspace(0, 1, 100).reshape(-1, 1)\n    out = model.expectation(x)\n    ax.plot(x.detach().numpy(), out.detach().numpy())\n    return descr, fig\n\n\nconfig = TrainConfig(\n    root_folder=\"mlflow_demonstration\",\n    max_iter=10,\n    checkpoint_every=1,\n    plot_every=2,\n    write_every=1,\n    log_model=True,\n    tracking_tool=ExperimentTrackingTool.MLFLOW,\n    hyperparams=hyperparams,\n    plotting_functions=(plot_fn,),\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#training-and-inspecting","title":"Training and inspecting","text":"<p>Model training happens as usual <pre><code>trainer = Trainer(model, optimizer, config, loss_fn)\ntrainer.fit(train_dataloader=data)\n</code></pre></p> <p>After training , we can inspect our experiment via the mlflow UI <pre><code>mlflow ui --port 8080 --backend-store-uri sqlite:///mlruns.db\n</code></pre> In this case, since we're running on a local server, we can access the mlflow UI by navigating to http://localhost:8080/.</p>"},{"location":"tutorials/qml/ml_tools/trainer/#62-fitting-a-function-with-a-qnn-using-ml_tools","title":"6.2. Fitting a function with a QNN using <code>ml_tools</code>","text":"<p>In Quantum Machine Learning, the general consensus is to use <code>complex128</code> precision for states and operators and <code>float64</code> precision for parameters. This is also the convention which is used in <code>qadence</code>. However, for specific usecases, lower precision can greatly speed up training and reduce memory consumption. When using the <code>pyqtorch</code> backend, <code>qadence</code> offers the option to move a <code>QuantumModel</code> instance to a specific precision using the torch <code>to</code> syntax.</p> <p>Let's look at a complete example of how to use <code>Trainer</code> now. Here we perform a validation check during training and use a validation criterion that checks whether the validation loss in the current iteration has decreased compared to the lowest validation loss from all previous iterations. For demonstration, the train and the validation data are kept the same here. However, it is beneficial and encouraged to keep them distinct in practice to understand model's generalization capabilities.</p> <pre><code>from pathlib import Path\nimport torch\nfrom functools import reduce\nfrom operator import add\nfrom itertools import count\nimport matplotlib.pyplot as plt\n\nfrom qadence import Parameter, QuantumCircuit, Z\nfrom qadence import hamiltonian_factory, hea, feature_map, chain\nfrom qadence import QNN\nfrom qadence.ml_tools import  TrainConfig, Trainer, to_dataloader\n\nTrainer.set_use_grad(True)\n\nn_qubits = 4\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\n\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 100\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    x, y = data[0], data[1]\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ndef validation_criterion(\n    current_validation_loss: float, current_best_validation_loss: float, val_epsilon: float\n) -&gt; bool:\n    return current_validation_loss &lt;= current_best_validation_loss - val_epsilon\n\nn_epochs = 300\n\nconfig = TrainConfig(\n    max_iter=n_epochs,\n    batch_size=batch_size,\n    checkpoint_best_only=True,\n    val_every=10,  # The model will be run on the validation data after every `val_every` epochs.\n    validation_criterion=validation_criterion\n)\n\nfn = lambda x, degree: .05 * reduce(add, (torch.cos(i*x) + torch.sin(i*x) for i in range(degree)), 0.)\nx = torch.linspace(0, 10, batch_size).reshape(-1, 1)\ny = fn(x, 5)\n\ntrain_dataloader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\nval_dataloader =  to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\ntrainer = Trainer(model, optimizer, config, loss_fn=loss_fn,\n                    train_dataloader=train_dataloader, val_dataloader=val_dataloader)\ntrainer.fit()\n\nplt.clf()\nplt.plot(x.numpy(), y.numpy(), label='truth')\nplt.plot(x.numpy(), model(x).detach().numpy(), \"--\", label=\"final\", linewidth=3)\nplt.legend()\n</code></pre> 2025-04-04T13:35:31.616823 image/svg+xml Matplotlib v3.10.1, https://matplotlib.org/"},{"location":"tutorials/qml/ml_tools/trainer/#63-fitting-a-function-low-level-api","title":"6.3. Fitting a function - Low-level API","text":"<p>For users who want to use the low-level API of <code>qadence</code>, here an example written without <code>Trainer</code>.</p> <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence import QNN\nfrom qadence.ml_tools import TrainConfig\n\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\n\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nn_epochs=50\ncnt = count()\n\ntmp_path = Path(\"/tmp\")\n\nconfig = TrainConfig(\n    root_folder=tmp_path,\n    max_iter=n_epochs,\n    checkpoint_every=100,\n    write_every=100,\n    batch_size=batch_size,\n)\n\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\n\nfor i in range(n_epochs):\n    out = model(x)\n    loss = criterion(out, y)\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#64-performing-pre-training-exploratory-landscape-analysis-ela-with-information-content-ic","title":"6.4. Performing pre-training Exploratory Landscape Analysis (ELA) with Information Content (IC)","text":"<p>Before one embarks on training a model, one may wish to analyze the loss landscape to judge the trainability and catch vanishing gradient issues early. One way of doing this is made possible via calculating the Information Content of the loss landscape. This is done by discretizing the gradient in the loss landscapes and then calculating the information content therein. This serves as a measure of flatness or ruggedness of the loss landscape. Quantitatively, the information content allows us to get bounds on the average norm of the gradient in the loss landscape.</p> <p>Using the information content technique, we can get two types of bounds on the average of the norm of the gradient. 1. The bounds as achieved in the maximum Information Content regime: Gives us a lower and upper bound on the average norm of the gradient in case high Information Content is achieved. 2. The bounds as achieved in the sensitivity regime: Gives us an upper bound on the average norm of the gradient corresponding to the sensitivity IC achieved.</p> <p>Thus, we get 3 bounds. The upper and lower bounds for the maximum IC and the upper bound for the sensitivity IC.</p> <p>The <code>Trainer</code> class provides a method to calculate these gradient norms.</p> <pre><code>import torch\nfrom torch.optim.adam import Adam\n\nfrom qadence.constructors import ObservableConfig\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig, TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\nfrom qadence.ml_tools.models import QNN\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools.trainer import Trainer\nfrom qadence.operations.primitive import Z\n\nfm_config = FeatureMapConfig(num_features=1)\nansatz_config = AnsatzConfig(depth=4)\nobs_config = ObservableConfig(detuning=Z)\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=obs_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n)\n\noptimizer = Adam(qnn.parameters(), lr=0.001)\n\nbatch_size = 25\nx = torch.linspace(0, 1, 32).reshape(-1, 1)\ny = torch.sin(x)\ntrain_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\ntrain_config = TrainConfig(max_iter=100)\n\ntrainer = Trainer(\n    model=qnn,\n    optimizer=optimizer,\n    config=train_config,\n    loss_fn=\"mse\",\n    train_dataloader=train_loader,\n    optimize_step=optimize_step,\n)\n\n# Perform exploratory landscape analysis with Information Content\nic_sensitivity_threshold = 1e-4\nepsilons = torch.logspace(-2, 2, 10)\n\nmax_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound = (\n    trainer.get_ic_grad_bounds(\n        eta=ic_sensitivity_threshold,\n        epsilons=epsilons,\n    )\n)\n\nprint(\n    f\"Using maximum IC, the gradients are bound between {max_ic_lower_bound:.3f} and {max_ic_upper_bound:.3f}\\n\"\n)\nprint(\n    f\"Using sensitivity IC, the gradients are bounded above by {sensitivity_ic_upper_bound:.3f}\"\n)\n\n# Resume training as usual...\n\ntrainer.fit(train_loader)\n</code></pre>   Using maximum IC, the gradients are bound between 0.068 and 0.378  Using sensitivity IC, the gradients are bounded above by 1.173    <p>The <code>get_ic_grad_bounds</code> function returns a tuple containing a tuple containing the lower bound as achieved in maximum IC case, upper bound as achieved in maximum IC case, and the upper bound for the sensitivity IC case.</p> <p>The sensitivity IC bound is guaranteed to appear, while the usually much tighter bounds that we get via the maximum IC case is only meaningful in the case of the maximum achieved information content \\(H(\\epsilon)_{max} \\geq log_6(2)\\).</p>"},{"location":"tutorials/qml/ml_tools/trainer/#65-custom-train-loop","title":"6.5. Custom <code>train</code> loop","text":"<p>If you need custom training functionality that goes beyond what is available in <code>qadence.ml_tools.Trainer</code> you can write your own training loop based on the building blocks that are available in Qadence.</p> <p>A simplified version of Qadence's train loop is defined below. Feel free to copy it and modify at will.</p> <p>For logging we can use the <code>get_writer</code> from the <code>Writer Registry</code>. This will set up the default writer based on the experiment tracking tool. All writers from the <code>Writer Registry</code> offer <code>open</code>, <code>close</code>, <code>print_metrics</code>, <code>write_metrics</code>, <code>plot_metrics</code>, etc methods.</p> <pre><code>from typing import Callable, Union\n\nfrom torch.nn import Module\nfrom torch.optim import Optimizer\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom qadence.ml_tools.config import TrainConfig\nfrom qadence.ml_tools.data import DictDataLoader, data_to_device\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools.callbacks import get_writer\nfrom qadence.ml_tools.callbacks.saveload import load_checkpoint, write_checkpoint\n\n\ndef train(\n    model: Module,\n    data: DataLoader,\n    optimizer: Optimizer,\n    config: TrainConfig,\n    loss_fn: Callable,\n    device: str = \"cpu\",\n    optimize_step: Callable = optimize_step,\n    write_tensorboard: Callable = write_tensorboard,\n) -&gt; tuple[Module, Optimizer]:\n\n    # Move model to device before optimizer is loaded\n    model = model.to(device)\n\n    # load available checkpoint\n    init_iter = 0\n    if config.log_folder:\n        model, optimizer, init_iter = load_checkpoint(config.log_folder, model, optimizer)\n\n    # Initialize writer based on the tracking tool specified in the configuration\n    writer = get_writer(config.tracking_tool)  # Uses ExperimentTrackingTool to select writer\n    writer.open(config, iteration=init_iter)\n\n    dl_iter = iter(dataloader)\n\n    # outer epoch loop\n    for iteration in range(init_iter, init_iter + config.max_iter):\n        data = data_to_device(next(dl_iter), device)\n        loss, metrics = optimize_step(model, optimizer, loss_fn, data)\n\n        if iteration % config.print_every == 0 and config.verbose:\n            writer.print_metrics(OptimizeResult(iteration, model, optimizer, loss, metrics))\n\n        if iteration % config.write_every == 0:\n            writer.write(iteration, metrics)\n\n        if config.log_folder:\n            if iteration % config.checkpoint_every == 0:\n                write_checkpoint(config.log_folder, model, optimizer, iteration)\n\n    # Final writing and checkpointing\n    if config.log_folder:\n        write_checkpoint(config.log_folder, model, optimizer, iteration)\n    writer.write(iteration,metrics)\n    writer.close()\n\n    return model, optimizer\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#66-gradient-free-optimization-using-trainer","title":"6.6. Gradient-free optimization using <code>Trainer</code>","text":"<p>We can achieve gradient free optimization with <code>Trainer.set_use_grad(False)</code> or <code>trainer.disable_grad_opt(ng_optimizer)</code>. An example solving a QUBO using gradient free optimization based on <code>Nevergrad</code> optimizers and <code>Trainer</code> is shown in the analog QUBO Tutorial.</p>"},{"location":"tutorials/realistic_sims/","title":"Realistic simulations","text":"<p>This section describes how to perform realistic simulations in Qadence.</p>"},{"location":"tutorials/realistic_sims/measurements/","title":"Measurement protocols","text":"<p>Sample-based measurement protocols are fundamental tools for the prediction and estimation of a quantum state as the result of NISQ programs executions. Their resource efficient implementation is a current and active research field. Qadence offers two main measurement protocols: quantum state tomography and classical shadows.</p>"},{"location":"tutorials/realistic_sims/measurements/#quantum-state-tomography","title":"Quantum state tomography","text":"<p>The fundamental task of quantum state tomography is to learn an approximate classical description of an output quantum state described by a density matrix \\(\\rho\\), from repeated measurements of copies on a chosen basis. To do so, \\(\\rho\\) is expanded in a basis of observables (the tomography step) and for a given observable \\(\\hat{\\mathcal{O}}\\), the expectation value is calculated with \\(\\langle \\hat{\\mathcal{O}} \\rangle=\\textrm{Tr}(\\hat{\\mathcal{O}}\\rho)\\). A number of measurement repetitions in a suitable basis is then required to estimate \\(\\langle \\hat{\\mathcal{O}} \\rangle\\).</p> <p>The main drawback is the scaling in measurements for the retrieval of the classical expression for a \\(n\\)-qubit quantum state as \\(2^n \\times 2^n\\), together with a large amount of classical post-processing.</p> <p>For an observable expressed as a Pauli string \\(\\hat{\\mathcal{P}}\\), the expectation value for a state \\(|\\psi \\rangle\\) can be derived as:</p> \\[ \\langle \\hat{\\mathcal{P}} \\rangle=\\langle \\psi | \\hat{\\mathcal{P}} |\\psi \\rangle=\\langle \\psi | \\hat{\\mathcal{R}}^\\dagger \\hat{\\mathcal{D}} \\hat{\\mathcal{R}} |\\psi \\rangle \\] <p>The operator \\(\\hat{\\mathcal{R}}\\) diagonalizes \\(\\hat{\\mathcal{P}}\\) and rotates the state into an eigenstate in the computational basis. Therefore, \\(\\hat{\\mathcal{R}}|\\psi \\rangle=\\sum\\limits_{z}a_z|z\\rangle\\) and the expectation value can finally be expressed as:</p> \\[ \\langle \\hat{\\mathcal{P}} \\rangle=\\sum_{z,z'}\\langle z |\\bar{a}_z\\hat{\\mathcal{D}}a_{z'}|z'\\rangle = \\sum_{z}|a_z|^2(-1)^{\\phi_z(\\hat{\\mathcal{P}})} \\] <p>In Qadence, running a tomographical experiment is made simple by defining a <code>Measurements</code> object that captures all options for execution:</p> <pre><code>from torch import tensor\nfrom qadence import hamiltonian_factory, BackendName, DiffMode\nfrom qadence import Parameter, chain, kron, RX, RY, Z, QuantumCircuit, QuantumModel\nfrom qadence.measurements import Measurements\n\n# Define parameters for a circuit.\ntheta1 = Parameter(\"theta1\", trainable=False)\ntheta2 = Parameter(\"theta2\", trainable=False)\ntheta3 = Parameter(\"theta3\", trainable=False)\ntheta4 = Parameter(\"theta4\", trainable=False)\n\nblocks = chain(\n    kron(RX(0, theta1), RY(1, theta2)),\n    kron(RX(0, theta3), RY(1, theta4)),\n)\n\nvalues = {\n    \"theta1\": tensor([0.5]),\n    \"theta2\": tensor([1.5]),\n    \"theta3\": tensor([2.0]),\n    \"theta4\": tensor([2.5]),\n}\n\n# Create a circuit and an observable.\ncircuit = QuantumCircuit(2, blocks)\nobservable = hamiltonian_factory(2, detuning=Z)\n\n# Create a model.\nmodel = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.GPSR,\n)\n\n# Define a measurement protocol by passing the shot budget as an option.\ntomo_options = {\"n_shots\": 100000}\ntomo_measurement = Measurements(protocol=Measurements.TOMOGRAPHY, options=tomo_options)\n\n# Get the exact expectation value.\nexact_values = model.expectation(\n    values=values,\n)\n\n# Run the tomography experiment.\nestimated_values_tomo = model.expectation(\n    values=values,\n    measurement=tomo_measurement,\n)\n</code></pre> <pre><code>Exact expectation value = tensor([[-1.4548]])\nEstimated expectation value tomo = tensor([[-1.4591]])\n</code></pre>"},{"location":"tutorials/realistic_sims/measurements/#classical-shadows","title":"Classical shadows","text":"<p>Recently, a much less resource demanding protocol based on classical shadows has been proposed<sup>1</sup>. It combines ideas from shadow tomography<sup>2</sup> and randomized measurement protocols capable of learning a classical shadow of an unknown quantum state \\(\\rho\\). It relies on deliberately discarding the full classical characterization of the quantum state, and instead focuses on accurately predicting a restricted set of properties that provide efficient protocols for the study of the system.</p> <p>A random measurement consists of applying random unitary rotations before a fixed measurement on each copy of a state. Appropriately averaging over these measurements produces an efficient estimator for the expectation value of an observable. This protocol therefore creates a robust classical representation of the quantum state or classical shadow. The captured measurement information is then reuseable for multiple purposes, i.e. any observable expected value and available for noise mitigation postprocessing.</p> <p>A classical shadow is therefore an unbiased estimator of a quantum state \\(\\rho\\). Such an estimator is obtained with the following procedure<sup>1</sup>: first, apply a random unitary gate \\(U\\) to rotate the state: \\(\\rho \\rightarrow U \\rho U^\\dagger\\) and then perform a basis measurement to obtain a \\(n\\)-bit measurement \\(|\\hat{b}\\rangle \\in \\{0, 1\\}^n\\). Both unitary gates \\(U\\) and the measurement outcomes \\(|\\hat{b}\\rangle\\) are stored on a classical computer for postprocessing v \\(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U\\), a classical snapshot of the state \\(\\rho\\). The whole procedure can be seen as a quantum channel \\(\\mathcal{M}\\) that maps the initial unknown quantum state \\(\\rho\\) to the average result of the measurement protocol:</p> \\[ \\mathbb{E}[U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U] = \\mathcal{M}(\\rho) \\Rightarrow \\rho = \\mathbb{E}[\\mathcal{M}^{-1}(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U)] \\] <p>It is worth noting that the single classical snapshot \\(\\hat{\\rho}=\\mathcal{M}^{-1}(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U)\\) equals \\(\\rho\\) in expectation: \\(\\mathbb{E}[\\hat{\\rho}]=\\rho\\) despite \\(\\mathcal{M}^{-1}\\) not being a completely positive map. Repeating this procedure \\(N\\) times results in an array of \\(N\\) independent, classical snapshots of \\(\\rho\\) called the classical shadow:</p> \\[ S(\\rho, N) = \\{ \\hat{\\rho}_1=\\mathcal{M}^{-1}(U_1^\\dagger |\\hat{b}_1\\rangle\\langle \\hat{b}_1|U_1),\\cdots,\\hat{\\rho}_N=\\mathcal{M}^{-1}(U_N^\\dagger |\\hat{b}_N\\rangle\\langle \\hat{b}_N|U_N)\\} \\] <p>Along the same lines as the example before, estimating the expectation value using classical shadows in Qadence only requires to pass the right set of parameters to the <code>Measurements</code> object:</p> <pre><code># Classical shadows are defined up to some accuracy and confidence.\nshadow_options = {\"accuracy\": 0.1, \"confidence\": 0.1}  # Shadow size N=54400.\nshadow_measurement = Measurements(protocol=Measurements.SHADOW, options=shadow_options)\n\n# Run the experiment with classical shadows.\nestimated_values_shadow = model.expectation(\n    values=values,\n    measurement=shadow_measurement,\n)\n</code></pre> <pre><code>Estimated expectation value shadow = tensor([[-1.4762]])\n</code></pre>"},{"location":"tutorials/realistic_sims/measurements/#references","title":"References","text":"<ol> <li> <p>Hsin-Yuan Huang, Richard Kueng and John Preskill, Predicting Many Properties of a Quantum System from Very Few Measurements (2020) \u21a9\u21a9</p> </li> <li> <p>S. Aaronson. Shadow tomography of quantum states. In Proceedings of the 50th Annual A ACM SIGACT Symposium on Theory of Computing, STOC 2018, pages 325\u2013338, New York, NY, USA, 2018. ACM\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/realistic_sims/mitigation/","title":"Error mitigation","text":"<p>Beyond running noisy simulations, Qadence offers a number of noise mitigation techniques to achieve better accuracy of simulation outputs. Currently, mitigation addresses readout errors and depolarizing and dephasing noise for analog blocks.</p>"},{"location":"tutorials/realistic_sims/mitigation/#readout-error-mitigation","title":"Readout error mitigation","text":"<p>The complete implementation of the mitigation technique is to measure \\(T\\) and classically apply \\(T^{\u22121}\\) to measured probability distributions. However there are several limitations of this approach:</p> <ul> <li>The complete implementation requires \\(2^n\\) characterization experiments (probability measurements), which is not scalable. The classical processing of the calibration data is also inefficient.</li> <li>The matrix \\(T\\) may become singular for large \\(n\\), preventing direct inversion.</li> <li>The inverse \\(T^{\u22121}\\) might not be a stochastic matrix, meaning that it can produce negative corrected probabilities.</li> <li>The correction is not rigorously justified, so we cannot be sure that we are only removing SPAM errors and not otherwise corrupting an estimated probability distribution.</li> </ul> <p>Qadence relies on the assumption of uncorrelated readout errors:</p> \\[ T=T_1\\otimes T_2\\otimes \\dots \\otimes T_n \\] <p>for which the inversion is straightforward:</p> \\[ T^{-1}=T_1^{-1}\\otimes T_2^{-1}\\otimes \\dots \\otimes T_n^{-1} \\] <p>However, even for a reduced \\(n\\) the third limitation holds. This can be avoided by reformulating into a minimization problem<sup>1</sup>:</p> \\[ \\lVert Tp_{\\textrm{corr}}-p_{\\textrm{raw}}\\rVert_{2}^{2} \\] <p>subjected to physicality constraints \\(0 \\leq p_{corr}(x) \\leq 1\\) and \\(\\lVert p_{corr} \\rVert = 1\\). At this point, two methods are implemented to solve this problem. The first one relies on solving using standard optimization tools, the second on Maximum-Likelihood Estimation<sup>2</sup>. In Qadence, this can be user defined using the mitigation protocol:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\nfrom qadence.noise import NoiseHandler\nfrom qadence.mitigations import Mitigations\nfrom qadence.types import ReadOutOptimization, NoiseProtocol\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use:\nnoise = NoiseHandler(NoiseProtocol.READOUT.INDEPENDENT)\n# Define the mitigation method solving the minimization problem:\noptions={\"optimization_type\": ReadOutOptimization.CONSTRAINED}  # ReadOutOptimization.MLE for the alternative method.\nmitigation = Mitigations(protocol=Mitigations.READOUT, options=options)\n\n# Run noiseless, noisy and mitigated simulations.\nn_shots = 100\nnoiseless_samples = model.sample(n_shots=n_shots)\nnoisy_samples = model.sample(noise=noise, n_shots=n_shots)\nmitigated_samples = model.sample(\n    noise=noise, mitigation=mitigation, n_shots=n_shots\n)\n\nprint(f\"noiseless {noiseless_samples}\")\nprint(f\"noisy {noisy_samples}\")\nprint(f\"mitigated {mitigated_samples}\")\n</code></pre> <pre><code>noiseless [OrderedCounter({'00': 50, '10': 50})]\nnoisy [OrderedCounter({'00': 49, '10': 45, '01': 4, '11': 2})]\nmitigated [Counter({'11': 61, '10': 31, '01': 8})]\n</code></pre>"},{"location":"tutorials/realistic_sims/mitigation/#wip-zero-noise-extrapolation-for-analog-blocks","title":"[WIP] Zero-noise extrapolation for analog blocks","text":"<p>Zero-noise extrapolation (ZNE) is an error mitigation technique in which an expectation value is computed at different noise levels and, as a second step, the ideal expectation value is inferred by extrapolating the measured results to the zero-noise limit. In digital computing, this is typically implemented by \"folding\" the circuit and its dagger to artificially increase the noise through sequences of identities<sup>3</sup>. In the analog ZNE variation, analog blocks are time stretched to again artificially increase noise<sup>3</sup>.</p>"},{"location":"tutorials/realistic_sims/mitigation/#references","title":"References","text":"<ol> <li> <p>Michael R. Geller and Mingyu Sun, Efficient correction of multiqubit measurement errors, (2020) \u21a9</p> </li> <li> <p>Smolin et al., Maximum Likelihood, Minimum Effort, (2011) \u21a9</p> </li> <li> <p>Mitiq: What's the theory behind ZNE? \u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/realistic_sims/noise/","title":"Simulated errors","text":"<p>Running programs on NISQ devices often leads to partially useful results due to the presence of noise. In order to perform realistic simulations, a number of noise models (for digital operations, analog operations and simulated readout errors) are supported in Qadence through their implementation in backends and corresponding error mitigation techniques whenever possible.</p>"},{"location":"tutorials/realistic_sims/noise/#noisehandler","title":"NoiseHandler","text":"<p>Noise models can be defined via the <code>NoiseHandler</code>. It is a container of several noise instances which require to specify a <code>protocols</code> and a dictionary of <code>options</code> (or lists). The <code>protocol</code> field is to be instantiated from <code>NoiseProtocol</code>.</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\n\nanalog_noise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options={\"noise_probs\": 0.1})\ndigital_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.DEPOLARIZING, options={\"error_probability\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\n</code></pre> <pre><code>\n</code></pre> <p>One can also define a <code>NoiseHandler</code> passing a list of protocols and a list of options (careful with the order):</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\n\nprotocols = [NoiseProtocol.DIGITAL.DEPOLARIZING, NoiseProtocol.READOUT]\noptions = [{\"error_probability\": 0.1}, {\"error_probability\": 0.1, \"seed\": 0}]\n\nnoise_combination = NoiseHandler(protocols, options)\nprint(noise_combination)\n</code></pre> <pre><code>Noise(Depolarizing, {'error_probability': 0.1})\nNoise(&lt;enum 'ReadoutNoise'&gt;, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>One can also append to a <code>NoiseHandler</code> other <code>NoiseHandler</code> instances:</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\n\ndepo_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.DEPOLARIZING, options={\"error_probability\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\n\nnoise_combination = NoiseHandler(protocol=NoiseProtocol.DIGITAL.BITFLIP, options={\"error_probability\": 0.1})\nnoise_combination.append([depo_noise, readout_noise])\nprint(noise_combination)\n</code></pre> <pre><code>Noise(BitFlip, {'error_probability': 0.1})\nNoise(Depolarizing, {'error_probability': 0.1})\nNoise(Independent Readout, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>Finally, one can add directly a few pre-defined types using several <code>NoiseHandler</code> methods:</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\nnoise_combination = NoiseHandler(protocol=NoiseProtocol.DIGITAL.BITFLIP, options={\"error_probability\": 0.1})\nnoise_combination.digital_depolarizing({\"error_probability\": 0.1}).readout_independent({\"error_probability\": 0.1, \"seed\": 0})\nprint(noise_combination)\n</code></pre> <pre><code>Noise(BitFlip, {'error_probability': 0.1})\nNoise(Depolarizing, {'error_probability': 0.1})\nNoise(Independent Readout, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>NoiseHandler scope</p> <p>Note it is not possible to define a <code>NoiseHandler</code> instances with both digital and analog noises, both readout and analog noises, several analog noises, several readout noises, or a readout noise that is not the last defined protocol within <code>NoiseHandler</code>.</p>"},{"location":"tutorials/realistic_sims/noise/#readout-errors","title":"Readout errors","text":"<p>State Preparation and Measurement (SPAM) in the hardware is a major source of noise in the execution of quantum programs. They are typically described using confusion matrices of the form:</p> \\[ T(x|x')=\\delta_{xx'} \\] <p>Two types of readout protocols are available:</p> <ul> <li><code>NoiseProtocol.READOUT.INDEPENDENT</code> where each bit can be corrupted independently of each other.</li> <li><code>NoiseProtocol.READOUT.CORRELATED</code> where we can define of confusion matrix of corruption between each possible bitstrings.</li> </ul> <p>Qadence offers to simulate readout errors with the <code>NoiseHandler</code> to corrupt the output samples of a simulation, through execution via a <code>QuantumModel</code>:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use.\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT)\n\n# Run noiseless and noisy simulations.\nnoiseless_samples = model.sample(n_shots=100)\nnoisy_samples = model.sample(noise=noise, n_shots=100)\n</code></pre> <pre><code>noiseless = [OrderedCounter({'00': 51, '10': 49})]\nnoisy = [OrderedCounter({'00': 62, '10': 35, '11': 2, '01': 1})]\n</code></pre> <p>It is possible to pass options to the noise model. In the previous example, a noise matrix is implicitly computed from a uniform distribution.</p> <p>For <code>NoiseProtocol.READOUT.INDEPENDENT</code>, the <code>option</code> dictionary argument accepts the following options:</p> <ul> <li><code>seed</code>: defaulted to <code>None</code>, for reproducibility purposes</li> <li><code>error_probability</code>: If float, the same probability is applied to every bit. By default, this is 0.1.     If a 1D tensor with the number of elements equal to the number of qubits, a different probability can be set for each qubit. If a tensor of shape (n_qubits, 2, 2) is passed, that is a confusion matrix obtained from experiments, we extract the error_probability.     and do not compute internally the confusion matrix as in the other cases.</li> <li><code>noise_distribution</code>: defaulted to <code>WhiteNoise.UNIFORM</code>, for non-uniform noise distributions</li> </ul> <p>For <code>NoiseProtocol.READOUT.CORRELATED</code>, the <code>option</code> dictionary argument accepts the following options:</p> <ul> <li><code>confusion_matrix</code>: The square matrix representing \\(T(x|x')\\) for each possible bitstring of length <code>n</code> qubits. Should be of size (\\(2^n, 2^n\\)).</li> <li><code>seed</code>: defaulted to <code>None</code>, for reproducibility purposes</li> </ul> <p>Noisy simulations go hand-in-hand with measurement protocols discussed in the measurements section, to assess the impact of noise on expectation values. In this case, both measurement and noise protocols have to be defined appropriately. Please note that a noise protocol without a measurement protocol will be ignored for expectation values computations.</p> <pre><code>from qadence.measurements import Measurements\n\n# Define a noise model with options.\noptions = {\"error_probability\": 0.01}\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options=options)\n\n# Define a tomographical measurement protocol with options.\noptions = {\"n_shots\": 10000}\nmeasurement = Measurements(protocol=Measurements.TOMOGRAPHY, options=options)\n\n# Run noiseless and noisy simulations.\nnoiseless_exp = model.expectation(measurement=measurement)\nnoisy_exp = model.expectation(measurement=measurement, noise=noise)\n</code></pre> <pre><code>noiseless = tensor([[1.0102]], grad_fn=&lt;TransposeBackward0&gt;)\nnoisy = tensor([[0.9830]], grad_fn=&lt;TransposeBackward0&gt;)\n</code></pre>"},{"location":"tutorials/realistic_sims/noise/#analog-noisy-simulation","title":"Analog noisy simulation","text":"<p>At the moment, analog noisy simulations are only compatible with the Pulser backend. <pre><code>from qadence import DiffMode, NoiseHandler, QuantumModel\nfrom qadence.blocks import chain, kron\nfrom qadence.circuit import QuantumCircuit\nfrom qadence.operations import AnalogRX, AnalogRZ, Z\nfrom qadence.types import PI, BackendName, NoiseProtocol\n\n\nanalog_block = chain(AnalogRX(PI / 2.0), AnalogRZ(PI))\nobservable = Z(0) + Z(1)\ncircuit = QuantumCircuit(2, analog_block)\n\noptions = {\"noise_probs\": 0.1}\nnoise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options=options)\nmodel_noisy = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR,\n    noise=noise,\n)\nnoisy_expectation = model_noisy.expectation()\n</code></pre> <pre><code>noisy = tensor([[0.3597]])\n</code></pre> </p>"},{"location":"tutorials/realistic_sims/noise/#digital-noisy-simulation","title":"Digital noisy simulation","text":"<p>When dealing with programs involving only digital operations, several options are made available from PyQTorch via the <code>NoiseProtocol.DIGITAL</code>. One can define noisy digital operations as follows:</p> <pre><code>from qadence import NoiseProtocol, RX, run\nimport torch\n\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.2})\nop = RX(0, torch.pi, noise = noise)\n\nprint(run(op))\n</code></pre> <pre><code>DensityMatrix([[[0.2000+0.0000e+00j, 0.0000+3.6739e-17j],\n                [0.0000-3.6739e-17j, 0.8000+0.0000e+00j]]])\n</code></pre> <p>It is also possible to set a noise configuration to all gates within a block or circuit as follows:</p> <pre><code>from qadence import set_noise, chain\n\nn_qubits = 2\n\nblock = chain(RX(i, f\"theta_{i}\") for i in range(n_qubits))\n\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.1})\n\n# The function changes the block in place:\nset_noise(block, noise)\nprint(run(block))\n</code></pre> <pre><code>DensityMatrix([[[ 0.6502+0.0000j,  0.0000+0.0108j,  0.0000+0.2989j,\n                 -0.0050+0.0000j],\n                [ 0.0000-0.0108j,  0.0725+0.0000j,  0.0050+0.0000j,\n                  0.0000+0.0333j],\n                [ 0.0000-0.2989j,  0.0050+0.0000j,  0.2495+0.0000j,\n                  0.0000+0.0041j],\n                [-0.0050+0.0000j,  0.0000-0.0333j,  0.0000-0.0041j,\n                  0.0278+0.0000j]]])\n</code></pre> <p>There is an extra optional argument to specify the type of block we want to apply a noise configuration to. E.g., let's say we want to apply noise only to <code>X</code> gates, a <code>target_class</code> argument can be passed with the corresponding block:</p> <pre><code>from qadence import X\nblock = chain(RX(0, \"theta\"), X(0))\nset_noise(block, noise, target_class = X)\n\nfor block in block.blocks:\n    print(block.noise)\n</code></pre> <pre><code>None\nNoise(BitFlip, {'error_probability': 0.1})\n</code></pre>"}]}