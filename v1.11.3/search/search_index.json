{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api/blocks/","title":"Block system","text":"<p><code>qadence</code> offers a block-based system to construct quantum circuits in a flexible manner.</p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock","title":"<code>AbstractBlock(tag=None, __array_priority__=1000)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for both primitive and composite blocks.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>A human-readable name attached to the block type. Notice, this is the same for all the class instances so it cannot be used for identifying different blocks</p> <p> TYPE: <code>str</code> </p> <code>qubit_support</code> <p>The qubit support of the block expressed as a tuple of integers</p> <p> TYPE: <code>tuple[int, ...]</code> </p> <code>tag</code> <p>A tag identifying a particular instance of the block which can be used for identification and pretty printing</p> <p> TYPE: <code>str | None</code> </p> <code>eigenvalues</code> <p>The eigenvalues of the matrix representing the block. This is used mainly for primitive blocks and it's needed for generalized parameter shift rule computations. Currently unused.</p> <p> TYPE: <code>list[float] | None</code> </p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.is_identity","title":"<code>is_identity</code>  <code>property</code>","text":"<p>Identity predicate for blocks.</p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.n_qubits","title":"<code>n_qubits()</code>","text":"<p>The number of qubits in the whole system.</p> <p>A block acting on qubit N would has at least n_qubits &gt;= N + 1.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_qubits(self) -&gt; int:\n    \"\"\"The number of qubits in the whole system.\n\n    A block acting on qubit N would has at least n_qubits &gt;= N + 1.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.n_supports","title":"<code>n_supports()</code>","text":"<p>The number of qubits the block is acting on.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_supports(self) -&gt; int:\n    \"\"\"The number of qubits the block is acting on.\"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.qubit_support","title":"<code>qubit_support()</code>","text":"<p>The indices of the qubit(s) the block is acting on.</p> <p>Qadence uses the ordering [0..,N-1] for qubits.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef qubit_support(self) -&gt; Tuple[int, ...]:\n    \"\"\"The indices of the qubit(s) the block is acting on.\n\n    Qadence uses the ordering [0..,N-1] for qubits.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#primitive-blocks","title":"Primitive blocks","text":""},{"location":"api/blocks/#qadence.blocks.primitive.ControlBlock","title":"<code>ControlBlock(control, target_block, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The abstract ControlBlock.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    control: tuple[int, ...],\n    target_block: PrimitiveBlock,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.control = control\n    self.blocks = (target_block,)\n    self.target = target_block.qubit_support\n\n    # using tuple expansion because some control operations could\n    # have multiple targets, e.g. CSWAP\n    super().__init__((*control, *self.target), noise=noise)  # target_block.qubit_support[0]))\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricBlock","title":"<code>ParametricBlock(qubit_support, noise=None)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>Parameterized primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    qubit_support: tuple[int, ...],\n    noise: NoiseHandler | None = None,\n):\n    self._qubit_support = qubit_support\n    self._noise = noise\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricBlock.num_parameters","title":"<code>num_parameters()</code>  <code>abstractmethod</code>","text":"<p>The number of parameters required by the block.</p> <p>This is a class property since the number of parameters is defined automatically before instantiating the operation. Also, this could correspond to a larger number of actual user-facing parameters since any parameter expression is allowed</p> <p>Examples: - RX operation has 1 parameter - U operation has 3 parameters - HamEvo has 2 parameters (generator and time evolution)</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>@abstractmethod\ndef num_parameters(cls) -&gt; int:\n    \"\"\"The number of parameters required by the block.\n\n    This is a class property since the number of parameters is defined\n    automatically before instantiating the operation. Also, this could\n    correspond to a larger number of actual user-facing parameters\n    since any parameter expression is allowed\n\n    Examples:\n    - RX operation has 1 parameter\n    - U operation has 3 parameters\n    - HamEvo has 2 parameters (generator and time evolution)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricControlBlock","title":"<code>ParametricControlBlock(control, target_block, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The abstract parametrized ControlBlock.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    control: tuple[int, ...],\n    target_block: ParametricBlock,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.blocks = (target_block,)\n    self.control = control\n    self.parameters = target_block.parameters\n    super().__init__((*control, *target_block.qubit_support), noise=noise)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.PrimitiveBlock","title":"<code>PrimitiveBlock(qubit_support, noise=None)</code>","text":"<p>               Bases: <code>AbstractBlock</code></p> <p>Primitive blocks represent elementary unitary operations.</p> <p>Examples are single/multi-qubit gates or Hamiltonian evolution. See <code>qadence.operations</code> for a full list of primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    qubit_support: tuple[int, ...],\n    noise: NoiseHandler | None = None,\n):\n    self._qubit_support = qubit_support\n    self._noise = noise\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.PrimitiveBlock.digital_decomposition","title":"<code>digital_decomposition()</code>","text":"<p>Decomposition into purely digital gates.</p> <p>This method returns a decomposition of the Block in a combination of purely digital single-qubit and two-qubit 'gates', by manual/custom knowledge of how this can be done efficiently. :return:</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def digital_decomposition(self) -&gt; AbstractBlock:\n    \"\"\"Decomposition into purely digital gates.\n\n    This method returns a decomposition of the Block in a\n    combination of purely digital single-qubit and two-qubit\n    'gates', by manual/custom knowledge of how this can be done efficiently.\n    :return:\n    \"\"\"\n    return self\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ProjectorBlock","title":"<code>ProjectorBlock(ket, bra, qubit_support, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The abstract ProjectorBlock.</p> <p>Arguments:</p> <pre><code>ket (str): The ket given as a bitstring.\nbra (str): The bra given as a bitstring.\nqubit_support (int | tuple[int]): The qubit_support of the block.\n</code></pre> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    ket: str,\n    bra: str,\n    qubit_support: int | tuple[int, ...],\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    \"\"\"\n    Arguments:\n\n        ket (str): The ket given as a bitstring.\n        bra (str): The bra given as a bitstring.\n        qubit_support (int | tuple[int]): The qubit_support of the block.\n    \"\"\"\n    if isinstance(qubit_support, int):\n        qubit_support = (qubit_support,)\n    if len(bra) != len(ket):\n        raise ValueError(\n            \"Bra and ket must be bitstrings of same length in the 'Projector' definition.\"\n        )\n    elif len(bra) != len(qubit_support):\n        raise ValueError(\"Bra or ket must be of same length as the 'qubit_support'\")\n    for wf in [bra, ket]:\n        if not all(int(item) == 0 or int(item) == 1 for item in wf):\n            raise ValueError(\n                \"All qubits must be either in the '0' or '1' state\"\n                \" in the 'ProjectorBlock' definition.\"\n            )\n\n    self.ket = ket\n    self.bra = bra\n    super().__init__(qubit_support, noise=noise)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ScaleBlock","title":"<code>ScaleBlock(block, parameter)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>Scale blocks are created when multiplying a block by a number or parameter.</p> <p>Example: <pre><code>from qadence import X\n\nprint(X(0) * 2)\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 X(0)\n</code></pre> </p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, block: AbstractBlock, parameter: Any):\n    self.block = block\n    # TODO: more meaningful name like `scale`?\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    super().__init__(block.qubit_support)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.TimeEvolutionBlock","title":"<code>TimeEvolutionBlock(qubit_support, noise=None)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>Simple time evolution block with time-independent Hamiltonian.</p> <p>This class is just a convenience class which is used to label blocks which contains simple time evolution with time-independent Hamiltonian operators</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    qubit_support: tuple[int, ...],\n    noise: NoiseHandler | None = None,\n):\n    self._qubit_support = qubit_support\n    self._noise = noise\n</code></pre>"},{"location":"api/blocks/#analog-blocks","title":"Analog blocks","text":"<p>To learn how to use analog blocks and how to mix digital &amp; analog blocks, check out the digital-analog section of the documentation.</p> <p>Examples on how to use digital-analog blocks can be found in the *examples folder of the qadence repo:</p> <ul> <li>Fit a simple sinus: <code>examples/digital-analog/fit-sin.py</code></li> <li>Solve a QUBO: <code>examples/digital-analog/qubo.py</code></li> </ul>"},{"location":"api/blocks/#qadence.blocks.analog.AnalogChain","title":"<code>AnalogChain(blocks)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogComposite</code></p> <p>A chain of analog blocks.</p> <p>Needed because analog blocks require stricter validation than the general <code>ChainBlock</code>.</p> <p><code>AnalogChain</code>s can only be constructed from <code>AnalogKron</code> blocks or globally supported, primitive, analog blocks (like <code>InteractionBlock</code>s and <code>ConstantAnalogRotation</code>s).</p> <p>Automatically constructed by the <code>chain</code> function if only analog blocks are given.</p> <p>Example: <pre><code>from qadence import X, chain, AnalogInteraction\n\nb = chain(AnalogInteraction(200), AnalogInteraction(200))\nprint(type(b))  # this is an `AnalogChain`\n\nb = chain(X(0), AnalogInteraction(200))\nprint(type(b))  # this is a general `ChainBlock`\n</code></pre> <pre><code>&lt;class 'qadence.blocks.analog.AnalogChain'&gt;\n&lt;class 'qadence.blocks.composite.ChainBlock'&gt;\n</code></pre> </p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...]):\n    \"\"\"A chain of analog blocks.\n\n    Needed because analog blocks require\n    stricter validation than the general `ChainBlock`.\n\n    `AnalogChain`s can only be constructed from `AnalogKron` blocks or\n    _**globally supported**_, primitive, analog blocks (like `InteractionBlock`s and\n    `ConstantAnalogRotation`s).\n\n    Automatically constructed by the [`chain`][qadence.blocks.utils.chain]\n    function if only analog blocks are given.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, chain, AnalogInteraction\n\n    b = chain(AnalogInteraction(200), AnalogInteraction(200))\n    print(type(b))  # this is an `AnalogChain`\n\n    b = chain(X(0), AnalogInteraction(200))\n    print(type(b))  # this is a general `ChainBlock`\n    ```\n    \"\"\"\n    for b in blocks:\n        if not (isinstance(b, AnalogKron) or b.qubit_support.is_global):\n            raise ValueError(\"Only KronBlocks or global blocks can be chain'ed.\")\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.analog.AnalogKron","title":"<code>AnalogKron(blocks, interaction=Interaction.NN)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogComposite</code></p> <p>Stack analog blocks vertically (i.e. in time).</p> <p>Needed because analog require stricter validation than the general <code>KronBlock</code>.</p> <p><code>AnalogKron</code>s can only be constructed from non-global, analog blocks with the same duration.</p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...], interaction: Interaction = Interaction.NN):\n    \"\"\"Stack analog blocks vertically (i.e. in time).\n\n    Needed because analog require\n    stricter validation than the general `KronBlock`.\n\n    `AnalogKron`s can only be constructed from _**non-global**_, analog blocks\n    with the _**same duration**_.\n    \"\"\"\n    if len(blocks) == 0:\n        raise NotImplementedError(\"Empty KronBlocks not supported\")\n\n    self.blocks = blocks\n    self.interaction = interaction\n\n    qubit_support = QubitSupport()\n    duration = blocks[0].duration\n    for b in blocks:\n        if not isinstance(b, AnalogBlock):\n            raise ValueError(\"Can only kron `AnalgoBlock`s with other `AnalgoBlock`s.\")\n\n        if b.qubit_support == QubitSupport(\"global\"):\n            raise ValueError(\"Blocks with global support cannot be kron'ed.\")\n\n        if not qubit_support.is_disjoint(b.qubit_support):\n            raise ValueError(\"Make sure blocks act on distinct qubits!\")\n\n        if not np.isclose(evaluate(duration), evaluate(b.duration)):\n            raise ValueError(\"Kron'ed blocks have to have same duration.\")\n\n        qubit_support += b.qubit_support\n\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.analog.ConstantAnalogRotation","title":"<code>ConstantAnalogRotation(tag=None, __array_priority__=1000, _eigenvalues_generator=None, parameters=ParamMap(alpha=0.0, duration=1000.0, omega=0.0, delta=0.0, phase=0.0), qubit_support=QubitSupport('global'), add_pattern=True)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogBlock</code></p> <p>Implements a constant analog rotation with interaction dictated by the chosen Hamiltonian.</p> <pre><code>H/h = \u2211\u1d62(\u03a9/2 cos(\u03c6)*X\u1d62 - sin(\u03c6)*Y\u1d62 - \u03b4n\u1d62) + H\u1d62\u2099\u209c.\n</code></pre> <p>To construct this block you can use of the following convenience wrappers: - The general rotation operation <code>AnalogRot</code> - Shorthands for rotatins around an axis:   <code>AnalogRX</code>,   <code>AnalogRY</code>,   <code>AnalogRZ</code></p> <p>WARNING: do not use <code>ConstantAnalogRotation</code> with <code>alpha</code> as differentiable parameter - use the convenience wrappers mentioned above.</p>"},{"location":"api/blocks/#qadence.blocks.analog.InteractionBlock","title":"<code>InteractionBlock(tag=None, __array_priority__=1000, _eigenvalues_generator=None, parameters=ParamMap(duration=1000.0), qubit_support=QubitSupport('global'), add_pattern=True)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogBlock</code></p> <p>Free-evolution for the Hamiltonian interaction term of a register of qubits.</p> <p>In real interacting quantum devices, it means letting the system evolve freely according to the time-dependent Schrodinger equation. With emulators, this block is translated to an appropriate interaction Hamiltonian, for example, an Ising interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n</code></pre> <p>or an XY-interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2083/r\u2c7c\u2c7c\u00b3 (X\u1d62X\u2c7c + Z\u1d62Z\u2c7c)\n</code></pre> <p>with <code>n\u1d62 = (1-Z\u1d62)/2</code>.</p> <p>To construct, use the <code>AnalogInteraction</code> function.</p>"},{"location":"api/blocks/#composite-blocks","title":"Composite blocks","text":""},{"location":"api/blocks/#qadence.blocks.utils.chain","title":"<code>chain(*args)</code>","text":"<p>Chain blocks sequentially.</p> <p>On digital backends this can be interpreted loosely as a matrix mutliplication of blocks. In the analog case it chains blocks in time.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to chain. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator, List[AbstractBlock]]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>ChainBlock</p> <p>Example: <pre><code>from qadence import X, Y, chain\n\nb = chain(X(0), Y(0))\n\n# or use a generator\nb = chain(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def chain(*args: Union[AbstractBlock, Generator, List[AbstractBlock]]) -&gt; ChainBlock:\n    \"\"\"Chain blocks sequentially.\n\n    On digital backends this can be interpreted\n    loosely as a matrix mutliplication of blocks. In the analog case it chains\n    blocks in time.\n\n    Arguments:\n        *args: Blocks to chain. Can also be a generator.\n\n    Returns:\n        ChainBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, chain\n\n    b = chain(X(0), Y(0))\n\n    # or use a generator\n    b = chain(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    # ugly hack to use `AnalogChain` if we are dealing only with analog blocks\n    if len(args) and all(\n        isinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n    ):\n        return analog_chain(*args)  # type: ignore[return-value,arg-type]\n    return _construct(ChainBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.utils.kron","title":"<code>kron(*args)</code>","text":"<p>Stack blocks vertically.</p> <p>On digital backends this can be intepreted loosely as a kronecker product of blocks. In the analog case it executes blocks parallel in time.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to kron. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>KronBlock</p> <p>Example: <pre><code>from qadence import X, Y, kron\n\nb = kron(X(0), Y(1))\n\n# or use a generator\nb = kron(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def kron(*args: Union[AbstractBlock, Generator]) -&gt; KronBlock:\n    \"\"\"Stack blocks vertically.\n\n    On digital backends this can be intepreted\n    loosely as a kronecker product of blocks. In the analog case it executes\n    blocks parallel in time.\n\n    Arguments:\n        *args: Blocks to kron. Can also be a generator.\n\n    Returns:\n        KronBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, kron\n\n    b = kron(X(0), Y(1))\n\n    # or use a generator\n    b = kron(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    # ugly hack to use `AnalogKron` if we are dealing only with analog blocks\n    if len(args) and all(\n        isinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n    ):\n        return analog_kron(*args)  # type: ignore[return-value,arg-type]\n    return _construct(KronBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.utils.add","title":"<code>add(*args)</code>","text":"<p>Sums blocks.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to add. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>AddBlock</code> <p>AddBlock</p> <p>Example: <pre><code>from qadence import X, Y, add\n\nb = add(X(0), Y(0))\n\n# or use a generator\nb = add(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def add(*args: Union[AbstractBlock, Generator]) -&gt; AddBlock:\n    \"\"\"Sums blocks.\n\n    Arguments:\n        *args: Blocks to add. Can also be a generator.\n\n    Returns:\n        AddBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, add\n\n    b = add(X(0), Y(0))\n\n    # or use a generator\n    b = add(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    return _construct(AddBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.AddBlock","title":"<code>AddBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Adds blocks.</p> <p>Constructed via <code>add</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.ChainBlock","title":"<code>ChainBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Chains blocks sequentially.</p> <p>Constructed via <code>chain</code></p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.CompositeBlock","title":"<code>CompositeBlock(tag=None, __array_priority__=1000)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractBlock</code></p> <p>Block which composes multiple blocks into one larger block (which can again be composed).</p> <p>Composite blocks are constructed via <code>chain</code>, <code>kron</code>, and <code>add</code>.</p>"},{"location":"api/blocks/#qadence.blocks.composite.KronBlock","title":"<code>KronBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Stacks blocks horizontally.</p> <p>Constructed via <code>kron</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    if len(blocks) == 0:\n        raise NotImplementedError(\"Empty KronBlocks not supported\")\n\n    qubit_support = QubitSupport()\n    for b in blocks:\n        assert (\n            QubitSupportType.GLOBAL,\n        ) != b.qubit_support, \"Blocks with global support cannot be kron'ed.\"\n        assert qubit_support.is_disjoint(\n            b.qubit_support\n        ), \"Make sure blocks act on distinct qubits!\"\n        qubit_support += b.qubit_support\n\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#converting-blocks-to-matrices","title":"Converting blocks to matrices","text":""},{"location":"api/blocks/#qadence.blocks.block_to_tensor.block_to_tensor","title":"<code>block_to_tensor(block, values={}, qubit_support=None, use_full_support=False, tensor_type=TensorType.DENSE, endianness=Endianness.BIG, device=None)</code>","text":"<p>Convert a block into a torch tensor.</p> PARAMETER DESCRIPTION <code>block</code> <p>The block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>values</code> <p>A optional dict with values for parameters.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>qubit_support</code> <p>The qubit_support of the block.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>use_full_support</code> <p>True infers the total number of qubits.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tensor_type</code> <p>the target tensor type.</p> <p> TYPE: <code>TensorType</code> DEFAULT: <code>DENSE</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n\nblock = hea(2,2)\nprint(block_to_tensor(block))\n\n# In case you have a diagonal observable, you can use\nobs = hamiltonian_factory(2, detuning = Z)\nprint(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n</code></pre> <pre><code>tensor([[[ 0.0779+0.3887j, -0.1928-0.7401j, -0.3177+0.1461j, -0.3390+0.1439j],\n         [ 0.2518-0.3428j,  0.1032+0.3277j, -0.7339-0.0335j, -0.3626+0.1729j],\n         [-0.3946-0.5593j, -0.4412-0.1945j, -0.0559+0.0836j, -0.1823-0.5055j],\n         [-0.3998-0.1833j, -0.1863-0.1725j, -0.1637-0.5488j,  0.3316+0.5516j]]],\n       grad_fn=&lt;UnsafeViewBackward0&gt;)\ntensor(indices=tensor([[0, 3],\n                       [0, 3]]),\n       values=tensor([ 2.+0.j, -2.+0.j]),\n       size=(4, 4), nnz=2, layout=torch.sparse_coo)\n</code></pre> </p> Source code in <code>qadence/blocks/block_to_tensor.py</code> <pre><code>def block_to_tensor(\n    block: AbstractBlock,\n    values: dict[str, TNumber | torch.Tensor] = {},\n    qubit_support: tuple | None = None,\n    use_full_support: bool = False,\n    tensor_type: TensorType = TensorType.DENSE,\n    endianness: Endianness = Endianness.BIG,\n    device: torch.device = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Convert a block into a torch tensor.\n\n    Arguments:\n        block (AbstractBlock): The block to convert.\n        values (dict): A optional dict with values for parameters.\n        qubit_support (tuple): The qubit_support of the block.\n        use_full_support (bool): True infers the total number of qubits.\n        tensor_type (TensorType): the target tensor type.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n\n    block = hea(2,2)\n    print(block_to_tensor(block))\n\n    # In case you have a diagonal observable, you can use\n    obs = hamiltonian_factory(2, detuning = Z)\n    print(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n    ```\n    \"\"\"\n    from qadence.blocks import embedding\n\n    (ps, embed) = embedding(block)\n    values = embed(ps, values)\n    if tensor_type == TensorType.DENSE:\n        return _block_to_tensor_embedded(\n            block,\n            values,\n            qubit_support,\n            use_full_support,\n            endianness=endianness,\n            device=device,\n        )\n\n    elif tensor_type == TensorType.SPARSEDIAGONAL:\n        t = block_to_diagonal(block, values, endianness=endianness)\n        indices, values, size = torch.nonzero(t), t[t != 0], len(t)\n        indices = torch.stack((indices.flatten(), indices.flatten()))\n        return torch.sparse_coo_tensor(indices, values, (size, size))\n</code></pre>"},{"location":"api/constructors/","title":"Constructors for common quantum circuits","text":""},{"location":"api/constructors/#qadence.constructors.feature_maps.exp_fourier_feature_map","title":"<code>exp_fourier_feature_map(n_qubits, support=None, param='x', feature_range=None)</code>","text":"<p>Exponential fourier feature map.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the feature</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>name of feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'x'</code> </p> <code>feature_range</code> <p>min and max value of the feature, as floats in a Tuple</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def exp_fourier_feature_map(\n    n_qubits: int,\n    support: tuple[int, ...] = None,\n    param: str = \"x\",\n    feature_range: tuple[float, float] = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Exponential fourier feature map.\n\n    Args:\n        n_qubits: number of qubits in the feature\n        support: qubit support\n        param: name of feature `Parameter`\n        feature_range: min and max value of the feature, as floats in a Tuple\n    \"\"\"\n\n    if feature_range is None:\n        feature_range = (0.0, 2.0**n_qubits)\n\n    support = tuple(range(n_qubits)) if support is None else support\n    hlayer = kron(H(qubit) for qubit in support)\n    rlayer = feature_map(\n        n_qubits,\n        support=support,\n        param=param,\n        op=RZ,\n        fm_type=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.EXP,\n        feature_range=feature_range,\n        target_range=(0.0, 2 * PI),\n    )\n    rlayer.tag = None\n    return tag(chain(hlayer, rlayer), f\"ExpFourierFM({param})\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.feature_maps.feature_map","title":"<code>feature_map(n_qubits, support=None, param='phi', op=RX, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multiplier=None, param_prefix=None)</code>","text":"<p>Construct a feature map of a given type.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Number of qubits the feature map covers. Results in <code>support=range(n_qubits)</code>.</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>Puts one feature-encoding rotation gate on every qubit in <code>support</code>. n_qubits in this case specifies the total overall qubits of the circuit, which may be wider than the support itself, but not narrower.</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>Parameter of the feature map; you can pass a string or Parameter; it will be set as non-trainable (FeatureParameter) regardless.</p> <p> TYPE: <code>Parameter | str</code> DEFAULT: <code>'phi'</code> </p> <code>op</code> <p>Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.</p> <p> TYPE: <code>RotationTypes</code> DEFAULT: <code>RX</code> </p> <code>fm_type</code> <p>Basis set for data encoding; choose from <code>BasisSet.FOURIER</code> for Fourier encoding, or <code>BasisSet.CHEBYSHEV</code> for Chebyshev polynomials of the first kind.</p> <p> TYPE: <code>BasisSet | Callable | str</code> DEFAULT: <code>FOURIER</code> </p> <code>reupload_scaling</code> <p>how the feature map scales the data that is re-uploaded for each qubit. choose from <code>ReuploadScaling</code> enumeration or provide your own function with a single int as input and int or float as output.</p> <p> TYPE: <code>ReuploadScaling | Callable | str</code> DEFAULT: <code>CONSTANT</code> </p> <code>feature_range</code> <p>range of data that the input data provided comes from. Used to map input data to the correct domain of the feature-encoding function.</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>target_range</code> <p>range of data the data encoder assumes as the natural range. For example, in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*PI). Used to map data to the correct domain of the feature-encoding function.</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>multiplier</code> <p>overall multiplier; this is useful for reuploading the feature map serially with different scalings; can be a number or parameter/expression.</p> <p> TYPE: <code>Parameter | TParameter | None</code> DEFAULT: <code>None</code> </p> <code>param_prefix</code> <p>string prefix to create trainable parameters multiplying the feature parameter inside the feature-encoding function. Note that currently this does not take into account the domain of the feature-encoding function.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Example: <pre><code>from qadence import feature_map, BasisSet, ReuploadScaling\n\nfm = feature_map(3, fm_type=BasisSet.FOURIER)\nprint(f\"{fm = }\")\n\nfm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\nprint(f\"{fm = }\")\n\nfm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\nprint(f\"{fm = }\")\n</code></pre> <pre><code>fm = KronBlock(0,1,2) [tag: Constant Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nfm = KronBlock(0,1,2) [tag: Constant Chebyshev FM]\n\u251c\u2500\u2500 RX(0) [params: ['acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['acos(phi)']]\nfm = KronBlock(0,1,2) [tag: Tower Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['1_0*phi']]\n\u251c\u2500\u2500 RX(1) [params: ['2_0*phi']]\n\u2514\u2500\u2500 RX(2) [params: ['3_0*phi']]\n</code></pre> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def feature_map(\n    n_qubits: int,\n    support: tuple[int, ...] | None = None,\n    param: Parameter | str = \"phi\",\n    op: RotationTypes = RX,\n    fm_type: BasisSet | Callable | str = BasisSet.FOURIER,\n    reupload_scaling: ReuploadScaling | Callable | str = ReuploadScaling.CONSTANT,\n    feature_range: tuple[float, float] | None = None,\n    target_range: tuple[float, float] | None = None,\n    multiplier: Parameter | TParameter | None = None,\n    param_prefix: str | None = None,\n) -&gt; KronBlock:\n    \"\"\"Construct a feature map of a given type.\n\n    Arguments:\n        n_qubits: Number of qubits the feature map covers. Results in `support=range(n_qubits)`.\n        support: Puts one feature-encoding rotation gate on every qubit in `support`. n_qubits in\n            this case specifies the total overall qubits of the circuit, which may be wider than the\n            support itself, but not narrower.\n        param: Parameter of the feature map; you can pass a string or Parameter;\n            it will be set as non-trainable (FeatureParameter) regardless.\n        op: Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.\n        fm_type: Basis set for data encoding; choose from `BasisSet.FOURIER` for Fourier\n            encoding, or `BasisSet.CHEBYSHEV` for Chebyshev polynomials of the first kind.\n        reupload_scaling: how the feature map scales the data that is re-uploaded for each qubit.\n            choose from `ReuploadScaling` enumeration or provide your own function with a single\n            int as input and int or float as output.\n        feature_range: range of data that the input data provided comes from. Used to map input data\n            to the correct domain of the feature-encoding function.\n        target_range: range of data the data encoder assumes as the natural range. For example,\n            in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*PI).\n            Used to map data to the correct domain of the feature-encoding function.\n        multiplier: overall multiplier; this is useful for reuploading the feature map serially with\n            different scalings; can be a number or parameter/expression.\n        param_prefix: string prefix to create trainable parameters multiplying the feature parameter\n            inside the feature-encoding function. Note that currently this does not take into\n            account the domain of the feature-encoding function.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import feature_map, BasisSet, ReuploadScaling\n\n    fm = feature_map(3, fm_type=BasisSet.FOURIER)\n    print(f\"{fm = }\")\n\n    fm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\n    print(f\"{fm = }\")\n\n    fm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\n    print(f\"{fm = }\")\n    ```\n    \"\"\"\n\n    # Process input\n    if support is None:\n        support = tuple(range(n_qubits))\n    elif len(support) != n_qubits:\n        raise ValueError(\"Wrong qubit support supplied\")\n\n    if op not in ROTATIONS:\n        raise ValueError(\n            f\"Operation {op} not supported. \"\n            f\"Please provide one from {[rot.__name__ for rot in ROTATIONS]}.\"\n        )\n\n    scaled_fparam = fm_parameter_scaling(\n        fm_type, param, feature_range=feature_range, target_range=target_range\n    )\n\n    transform_func = fm_parameter_func(fm_type)\n\n    basis_tag = fm_type.value if isinstance(fm_type, BasisSet) else str(fm_type)\n    rs_func, rs_tag = fm_reupload_scaling_fn(reupload_scaling)\n\n    # Set overall multiplier\n    multiplier = 1 if multiplier is None else Parameter(multiplier)\n\n    # Build feature map\n    op_list = []\n    fparam = scaled_fparam\n    for i, qubit in enumerate(support):\n        if param_prefix is not None:\n            train_param = VariationalParameter(param_prefix + f\"_{i}\")\n            fparam = train_param * scaled_fparam\n        op_list.append(op(qubit, multiplier * rs_func(i) * transform_func(fparam)))\n    fm = kron(*op_list)\n\n    fm.tag = rs_tag + \" \" + basis_tag + \" FM\"\n\n    return fm\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hea.hea","title":"<code>hea(n_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the Hardware Efficient Ansatz (HEA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the HEA is applied</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy for the ansatz. One of the Strategy variants.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital and DigitalAnalog HEA.</p> <p> TYPE: <code>list</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c. Valid for only for Digital HEA.</p> <p> TYPE: <code>bool</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>SDAQC | Analog: Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The Hardware Efficient Ansatz (HEA) circuit.</p> <p>Examples: <pre><code>from qadence import RZ, RX\nfrom qadence import hea\n\n# create the circuit\nn_qubits, depth = 2, 4\nansatz = hea(\n    n_qubits=n_qubits,\n    depth=depth,\n    strategy=\"sDAQC\",\n    operations=[RZ,RX,RZ]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/constructors/hea.py</code> <pre><code>def hea(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    strategy: Strategy = Strategy.DIGITAL,\n    **strategy_args: Any,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Factory function for the Hardware Efficient Ansatz (HEA).\n\n    Args:\n        n_qubits: number of qubits in the circuit\n        depth: number of layers of the HEA\n        param_prefix: the base name of the variational parameters\n        support: qubit indices where the HEA is applied\n        strategy: Strategy for the ansatz. One of the Strategy variants.\n        **strategy_args: see below\n\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital and DigitalAnalog HEA.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c. Valid for only\n            for Digital HEA.\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - SDAQC | Analog: Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n\n    Returns:\n        The Hardware Efficient Ansatz (HEA) circuit.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import RZ, RX\n    from qadence import hea\n\n    # create the circuit\n    n_qubits, depth = 2, 4\n    ansatz = hea(\n        n_qubits=n_qubits,\n        depth=depth,\n        strategy=\"sDAQC\",\n        operations=[RZ,RX,RZ]\n    )\n    ```\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    hea_func_dict = {\n        Strategy.DIGITAL: hea_digital,\n        Strategy.SDAQC: hea_sDAQC,\n        Strategy.BDAQC: hea_bDAQC,\n        Strategy.ANALOG: hea_analog,\n    }\n\n    try:\n        hea_func = hea_func_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    hea_block: AbstractBlock = hea_func(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        **strategy_args,\n    )  # type: ignore\n\n    return hea_block\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hea.hea_digital","title":"<code>hea_digital(n_qubits, depth=1, param_prefix='theta', support=None, periodic=False, operations=[RX, RY, RX], entangler=CNOT)</code>","text":"<p>Construct the Digital Hardware Efficient Ansatz (HEA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the cricuit.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The digital Hardware Efficient Ansatz (HEA) circuit.</p> Source code in <code>qadence/constructors/hea.py</code> <pre><code>def hea_digital(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    periodic: bool = False,\n    operations: list[type[AbstractBlock]] = [RX, RY, RX],\n    entangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the Digital Hardware Efficient Ansatz (HEA).\n\n    Args:\n        n_qubits (int): number of qubits in the cricuit.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        support (tuple): qubit indices where the HEA is applied.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n\n    Returns:\n        The digital Hardware Efficient Ansatz (HEA) circuit.\n    \"\"\"\n    try:\n        if entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\n            raise ValueError(\n                \"Please provide a valid two-qubit entangler operation for digital HEA.\"\n            )\n    except TypeError:\n        raise ValueError(\"Please provide a valid two-qubit entangler operation for digital HEA.\")\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        periodic=periodic,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n    return tag(chain(*layers), \"HEA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hea.hea_sDAQC","title":"<code>hea_sDAQC(n_qubits, depth=1, param_prefix='theta', support=None, operations=[RX, RY, RX], entangler=None)</code>","text":"<p>Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers.</p> <p>It uses step-wise digital-analog computation.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>entangler</code> <p>Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The step-wise digital-analog Hardware Efficient Ansatz (sDA HEA) circuit.</p> Source code in <code>qadence/constructors/hea.py</code> <pre><code>def hea_sDAQC(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    operations: list[type[AbstractBlock]] = [RX, RY, RX],\n    entangler: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers.\n\n    It uses step-wise digital-analog computation.\n\n    Args:\n        n_qubits (int): number of qubits in the circuit.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        support (tuple): qubit indices where the HEA is applied.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        entangler (AbstractBlock): Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n\n    Returns:\n        The step-wise digital-analog Hardware Efficient Ansatz (sDA HEA) circuit.\n    \"\"\"\n\n    # TODO: Add qubit support\n    if entangler is None:\n        entangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n    try:\n        if not block_is_qubit_hamiltonian(entangler):\n            raise ValueError(\n                \"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n            )\n    except NotImplementedError:\n        raise ValueError(\n            \"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n        )\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_analog(\n        depth=depth,\n        param_prefix=param_prefix,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n    return tag(chain(*layers), \"HEA-sDA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.iia.identity_initialized_ansatz","title":"<code>identity_initialized_ansatz(n_qubits, depth=1, param_prefix='iia', strategy=Strategy.DIGITAL, rotations=[RX, RY], entangler=None, periodic=False)</code>","text":"<p>Identity block for barren plateau mitigation.</p> <p>The initial configuration of this block is equal to an identity unitary but can be trained in the same fashion as other ansatzes, reaching same level of expressivity.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>The base name of the variational parameter. Defaults to \"iia\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'iia'</code> </p> <code>strategy</code> <p>(Strategy) Strategy.DIGITAL for fully digital or Strategy.SDAQC for digital-analog.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>rotations</code> <p>single-qubit rotations with trainable parameters</p> <p> TYPE: <code>list of AbstractBlocks</code> DEFAULT: <code>[RX, RY]</code> </p> <code>entangler</code> <p>For Digital:     2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE.     Controlled rotations will have variational parameters on the rotation angles.     Defaults to CNOT. For Digital-analog:     Hamiltonian generator for the analog entangling layer.     Time parameter is considered variational.     Defaults to a global NN Hamiltonain.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. Valid only for digital.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The identity initialized ansatz circuit.</p> Source code in <code>qadence/constructors/iia.py</code> <pre><code>def identity_initialized_ansatz(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"iia\",\n    strategy: Strategy = Strategy.DIGITAL,\n    rotations: Any = [RX, RY],\n    entangler: Any = None,\n    periodic: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Identity block for barren plateau mitigation.\n\n    The initial configuration of this block is equal to an identity unitary\n    but can be trained in the same fashion as other ansatzes, reaching same level\n    of expressivity.\n\n    Args:\n        n_qubits: number of qubits in the block\n        depth: number of layers of the HEA\n        param_prefix (str):\n            The base name of the variational parameter. Defaults to \"iia\".\n        strategy: (Strategy)\n            Strategy.DIGITAL for fully digital or Strategy.SDAQC for digital-analog.\n        rotations (list of AbstractBlocks):\n            single-qubit rotations with trainable parameters\n        entangler (AbstractBlock):\n            For Digital:\n                2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE.\n                Controlled rotations will have variational parameters on the rotation angles.\n                Defaults to CNOT.\n            For Digital-analog:\n                Hamiltonian generator for the analog entangling layer.\n                Time parameter is considered variational.\n                Defaults to a global NN Hamiltonain.\n        periodic (bool): if the qubits should be linked periodically. Valid only for digital.\n\n    Returns:\n        The identity initialized ansatz circuit.\n    \"\"\"\n    initialized_layers = []\n    for layer in range(depth):\n        alpha = 2 * PI * torch.rand(n_qubits * len(rotations))\n        gamma = torch.zeros(n_qubits)\n        beta = -alpha\n\n        left_rotations = _rotations(\n            n_qubits=n_qubits,\n            layer=layer,\n            side=\"left\",\n            param_str=f\"{param_prefix}_\u03b1\",\n            values=alpha,\n            ops=rotations,\n        )\n\n        if strategy == Strategy.DIGITAL:\n            if entangler is None:\n                entangler = CNOT\n\n            if entangler not in [CNOT, CZ, CRZ, CRY, CRX, CPHASE]:\n                raise ValueError(\n                    \"Please provide a valid two-qubit entangler operation for digital IIA.\"\n                )\n\n            ent_param_prefix = f\"{param_prefix}_\u03b8_ent_\"\n            if not periodic:\n                left_entanglers = [\n                    chain(\n                        _entangler(\n                            control=n,\n                            target=n + 1,\n                            param_str=ent_param_prefix + f\"_{layer}{n}\",\n                            entangler=entangler,\n                        )\n                        for n in range(n_qubits - 1)\n                    )\n                ]\n            else:\n                left_entanglers = [\n                    chain(\n                        _entangler(\n                            control=n,\n                            target=(n + 1) % n_qubits,\n                            param_str=ent_param_prefix + f\"_{layer}{n}\",\n                            entangler=entangler,\n                        )\n                        for n in range(n_qubits)\n                    )\n                ]\n\n        elif strategy == Strategy.SDAQC:\n            if entangler is None:\n                entangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n\n            if not block_is_qubit_hamiltonian(entangler):\n                raise ValueError(\n                    \"Please provide a valid Pauli Hamiltonian generator for digital-analog IIA.\"\n                )\n\n            ent_param_prefix = f\"{param_prefix}_ent_t\"\n\n            left_entanglers = [\n                chain(\n                    _entangler_analog(\n                        param_str=f\"{ent_param_prefix}_{layer}\",\n                        generator=entangler,\n                    )\n                )\n            ]\n\n        else:\n            raise NotImplementedError\n\n        centre_rotations = [\n            kron(\n                RX(\n                    target=n,\n                    parameter=Parameter(name=f\"{param_prefix}_\u03b3\" + f\"_{layer}{n}\", value=gamma[n]),\n                )\n                for n in range(n_qubits)\n            )\n        ]\n\n        right_entanglers = reversed(*left_entanglers)\n\n        right_rotations = _rotations(\n            n_qubits=n_qubits,\n            layer=layer,\n            side=\"right\",\n            param_str=f\"{param_prefix}_\u03b2\",\n            values=beta,\n            ops=rotations,\n        )\n\n        krons = [\n            *left_rotations,\n            *left_entanglers,\n            *centre_rotations,\n            *right_entanglers,\n            *right_rotations,\n        ]\n\n        initialized_layers.append(tag(chain(*krons), tag=f\"BPMA-{layer}\"))\n\n    return chain(*initialized_layers)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.ala.ala","title":"<code>ala(n_qubits, m_block_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the alternating layer ansatz (ala).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit</p> <p> TYPE: <code>int</code> </p> <code>m_block_qubits</code> <p>number of qubits in the local entangling block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the alternating layer ansatz</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the ala is applied</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy for the ansatz. One of the Strategy variants.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital .</p> <p> TYPE: <code>list</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>SDAQC | BDAQC: Hamiltonian generator for the analog entangling     layer. Must be an m-qubit operator where m is the size of the     local entangling block. Defaults to a ZZ interaction.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The Alternating Layer Ansatz (ALA) circuit.</p> Source code in <code>qadence/constructors/ala.py</code> <pre><code>def ala(\n    n_qubits: int,\n    m_block_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    strategy: Strategy = Strategy.DIGITAL,\n    **strategy_args: Any,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Factory function for the alternating layer ansatz (ala).\n\n    Args:\n        n_qubits: number of qubits in the circuit\n        m_block_qubits: number of qubits in the local entangling block\n        depth: number of layers of the alternating layer ansatz\n        param_prefix: the base name of the variational parameters\n        support: qubit indices where the ala is applied\n        strategy: Strategy for the ansatz. One of the Strategy variants.\n        **strategy_args: see below\n\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital .\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - SDAQC | BDAQC: Hamiltonian generator for the analog entangling\n                layer. Must be an m-qubit operator where m is the size of the\n                local entangling block. Defaults to a ZZ interaction.\n\n    Returns:\n        The Alternating Layer Ansatz (ALA) circuit.\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    ala_func_dict = {\n        Strategy.DIGITAL: ala_digital,\n        Strategy.SDAQC: ala_sDAQC,\n        Strategy.BDAQC: ala_bDAQC,\n        Strategy.ANALOG: ala_analog,\n    }\n\n    try:\n        ala_func = ala_func_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    ala_block: AbstractBlock = ala_func(\n        n_qubits=n_qubits,\n        m_block_qubits=m_block_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        **strategy_args,\n    )  # type: ignore\n\n    return ala_block\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.ala.ala_digital","title":"<code>ala_digital(n_qubits, m_block_qubits, depth=1, param_prefix='theta', support=None, operations=[RX, RY], entangler=CNOT)</code>","text":"<p>Construct the digital alternating layer ansatz (ALA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the circuit.</p> <p> TYPE: <code>int</code> </p> <code>m_block_qubits</code> <p>number of qubits in the local entangling block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the ALA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indices where the ALA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY]</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The digital Alternating Layer Ansatz (ALA) circuit.</p> Source code in <code>qadence/constructors/ala.py</code> <pre><code>def ala_digital(\n    n_qubits: int,\n    m_block_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] | None = None,\n    operations: list[type[AbstractBlock]] = [RX, RY],\n    entangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the digital alternating layer ansatz (ALA).\n\n    Args:\n        n_qubits (int): number of qubits in the circuit.\n        m_block_qubits (int): number of qubits in the local entangling block.\n        depth (int): number of layers of the ALA.\n        param_prefix (str): the base name of the variational parameters\n        support (tuple): qubit indices where the ALA is applied.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n\n    Returns:\n        The digital Alternating Layer Ansatz (ALA) circuit.\n    \"\"\"\n\n    try:\n        if entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\n            raise ValueError(\n                \"Please provide a valid two-qubit entangler operation for digital ALA.\"\n            )\n    except TypeError:\n        raise ValueError(\"Please provide a valid two-qubit entangler operation for digital ALA.\")\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        support=support,\n        param_prefix=param_prefix,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_ala_block_digital(\n        n_qubits,\n        m_block_qubits,\n        param_prefix=param_prefix + \"_ent\",\n        depth=depth,\n        support=support,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n\n    return tag(chain(*layers), \"ALA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig","title":"<code>ObservableConfig(interaction=None, detuning=None, scale=1.0, shift=0.0, trainable_transform=None, tag=None)</code>  <code>dataclass</code>","text":"<p>ObservableConfig is a configuration class for defining the parameters of an observable Hamiltonian.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.detuning","title":"<code>detuning = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Single qubit detuning of the observable Hamiltonian.</p> <p>Accepts single-qubit operator N, X, Y, or Z.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.interaction","title":"<code>interaction = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The type of interaction.</p> Available options from the Interaction enum are <ul> <li>Interaction.ZZ</li> <li>Interaction.NN</li> <li>Interaction.XY</li> <li>Interaction.XYZ</li> </ul> <p>Alternatively, a custom interaction function can be defined.         Example:</p> <pre><code>        def custom_int(i: int, j: int):\n            return X(i) @ X(j) + Y(i) @ Y(j)\n\n        n_qubits = 2\n\n        observable_config = ObservableConfig(interaction=custom_int, scale = 1.0, shift = 0.0)\n        observable = create_observable(register=4, config=observable_config)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.scale","title":"<code>scale = 1.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The scale by which to multiply the output of the observable.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.shift","title":"<code>shift = 0.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The shift to add to the output of the observable.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the observable.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.trainable_transform","title":"<code>trainable_transform = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to have a trainable transformation on the output of the observable.</p> <p>If None, the scale and shift are numbers. If True, the scale and shift are VariationalParameter. If False, the scale and shift are FeatureParameter.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.hamiltonian_factory","title":"<code>hamiltonian_factory(register, interaction=None, detuning=None, interaction_strength=None, detuning_strength=None, random_strength=False, use_all_node_pairs=False)</code>","text":"<p>General Hamiltonian creation function.</p> <p>Can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings, both with arbitrary strength or parameterized.</p> PARAMETER DESCRIPTION <code>register</code> <p>register of qubits with a specific graph topology, or number of qubits. When passing a number of qubits a register with all-to-all connectivity is created.</p> <p> TYPE: <code>Register | int</code> </p> <code>interaction</code> <p>Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.</p> <p> TYPE: <code>Interaction | Callable | None</code> DEFAULT: <code>None</code> </p> <code>detuning</code> <p>single-qubit operator N, X, Y, or Z.</p> <p> TYPE: <code>TDetuning | None</code> DEFAULT: <code>None</code> </p> <code>interaction_strength</code> <p>list of values to be used as the interaction strength for each pair of qubits. Should be ordered following the order of <code>Register(n_qubits).edges</code>. Alternatively, some string \"x\" can be passed, which will create a parameterized interactions for each pair of qubits, each labelled as <code>\"x_ij\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>detuning_strength</code> <p>list of values to be used as the detuning strength for each qubit. Alternatively, some string \"x\" can be passed, which will create a parameterized detuning for each qubit, each labelled as <code>\"x_i\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>random_strength</code> <p>set random interaction and detuning strengths between -1 and 1.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_all_node_pairs</code> <p>computes an interaction term for every pair of nodes in the graph, independent of the edge topology in the register. Useful for defining Hamiltonians where the interaction strength decays with the distance.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>from qadence import hamiltonian_factory, Interaction, Register, Z\n\nn_qubits = 3\n\n# Constant total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n\n# Parameterized total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n\n# Random all-to-all XY Hamiltonian generator:\ngenerator = hamiltonian_factory(\n    n_qubits,\n    interaction = Interaction.XY,\n    random_strength = True,\n    )\n\n# Parameterized NN Hamiltonian generator with a square grid interaction topology:\nregister = Register.square(qubits_side = n_qubits)\ngenerator = hamiltonian_factory(\n    register,\n    interaction = Interaction.NN,\n    interaction_strength = \"theta\"\n    )\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def hamiltonian_factory(\n    register: Register | int,\n    interaction: Interaction | Callable | None = None,\n    detuning: TDetuning | None = None,\n    interaction_strength: TArray | str | None = None,\n    detuning_strength: TArray | str | None = None,\n    random_strength: bool = False,\n    use_all_node_pairs: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    General Hamiltonian creation function.\n\n    Can be used to create Hamiltonians with 2-qubit\n    interactions and single-qubit detunings, both with arbitrary strength or parameterized.\n\n    Arguments:\n        register: register of qubits with a specific graph topology, or number of qubits.\n            When passing a number of qubits a register with all-to-all connectivity\n            is created.\n        interaction: Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.\n        detuning: single-qubit operator N, X, Y, or Z.\n        interaction_strength: list of values to be used as the interaction strength for each\n            pair of qubits. Should be ordered following the order of `Register(n_qubits).edges`.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            interactions for each pair of qubits, each labelled as `\"x_ij\"`.\n        detuning_strength: list of values to be used as the detuning strength for each qubit.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            detuning for each qubit, each labelled as `\"x_i\"`.\n        random_strength: set random interaction and detuning strengths between -1 and 1.\n        use_all_node_pairs: computes an interaction term for every pair of nodes in the graph,\n            independent of the edge topology in the register. Useful for defining Hamiltonians\n            where the interaction strength decays with the distance.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import hamiltonian_factory, Interaction, Register, Z\n\n        n_qubits = 3\n\n        # Constant total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z)\n\n        # Parameterized total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n\n        # Random all-to-all XY Hamiltonian generator:\n        generator = hamiltonian_factory(\n            n_qubits,\n            interaction = Interaction.XY,\n            random_strength = True,\n            )\n\n        # Parameterized NN Hamiltonian generator with a square grid interaction topology:\n        register = Register.square(qubits_side = n_qubits)\n        generator = hamiltonian_factory(\n            register,\n            interaction = Interaction.NN,\n            interaction_strength = \"theta\"\n            )\n        ```\n    \"\"\"\n\n    if interaction is None and detuning is None:\n        raise ValueError(\"Please provide an interaction and/or detuning for the Hamiltonian.\")\n\n    # If number of qubits is given, creates all-to-all register\n    register = Register(register) if isinstance(register, int) else register\n\n    # Get interaction function\n    if interaction is not None:\n        if callable(interaction):\n            int_fn = interaction\n            try:\n                if not block_is_qubit_hamiltonian(interaction(0, 1)):\n                    raise ValueError(\"Custom interactions must be composed of Pauli operators.\")\n            except TypeError:\n                raise TypeError(\n                    \"Please use a custom interaction function signed with two integer parameters.\"\n                )\n        else:\n            int_fn = INTERACTION_DICT.get(interaction, None)  # type: ignore [arg-type]\n            if int_fn is None:\n                raise KeyError(f\"Interaction {interaction} not supported.\")\n\n    # Check single-qubit detuning\n    if (detuning is not None) and (detuning not in DETUNINGS):\n        raise TypeError(f\"Detuning of type {type(detuning)} not supported.\")\n\n    # Pre-process detuning and interaction strengths and update register\n    detuning_strength_array = _preprocess_strengths(\n        register, detuning_strength, \"nodes\", random_strength\n    )\n\n    edge_str = \"all_node_pairs\" if use_all_node_pairs else \"edges\"\n    interaction_strength_array = _preprocess_strengths(\n        register, interaction_strength, edge_str, random_strength\n    )\n\n    # Create single-qubit detunings:\n    single_qubit_terms: List[AbstractBlock] = []\n    if detuning is not None:\n        for strength, node in zip(detuning_strength_array, register.nodes):\n            single_qubit_terms.append(strength * detuning(node))\n\n    # Create two-qubit interactions:\n    two_qubit_terms: List[AbstractBlock] = []\n    edge_data = register.all_node_pairs if use_all_node_pairs else register.edges\n    if interaction is not None and int_fn is not None:\n        for strength, edge in zip(interaction_strength_array, edge_data):\n            two_qubit_terms.append(strength * int_fn(*edge))\n\n    return add(*single_qubit_terms, *two_qubit_terms)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_nn","title":"<code>interaction_nn(i, j)</code>","text":"<p>Ising NN interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_nn(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Ising NN interaction.\"\"\"\n    return N(i) @ N(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_xy","title":"<code>interaction_xy(i, j)</code>","text":"<p>XY interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xy(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"XY interaction.\"\"\"\n    return X(i) @ X(j) + Y(i) @ Y(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_xyz","title":"<code>interaction_xyz(i, j)</code>","text":"<p>Heisenberg XYZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xyz(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Heisenberg XYZ interaction.\"\"\"\n    return X(i) @ X(j) + Y(i) @ Y(j) + Z(i) @ Z(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_zz","title":"<code>interaction_zz(i, j)</code>","text":"<p>Ising ZZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_zz(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Ising ZZ interaction.\"\"\"\n    return Z(i) @ Z(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.qft.qft","title":"<code>qft(n_qubits, support=None, inverse=False, reverse_in=False, swaps_out=False, strategy=Strategy.DIGITAL, gen_build=None)</code>","text":"<p>The Quantum Fourier Transform.</p> <p>Depending on the application, user should be careful with qubit ordering in the input and output. This can be controlled with reverse_in and swaps_out arguments.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the QFT</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support to use</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>inverse</code> <p>True performs the inverse QFT</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reverse_in</code> <p>Reverses the input qubits to account for endianness</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>swaps_out</code> <p>Performs swaps on the output qubits to match the \"textbook\" QFT.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.sDAQC</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>gen_build</code> <p>building block Ising Hamiltonian for the DAQC transform. Defaults to constant all-to-all Ising.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import qft\n\nn_qubits = 3\n\nqft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/qft.py</code> <pre><code>def qft(\n    n_qubits: int,\n    support: tuple[int, ...] = None,\n    inverse: bool = False,\n    reverse_in: bool = False,\n    swaps_out: bool = False,\n    strategy: Strategy = Strategy.DIGITAL,\n    gen_build: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    The Quantum Fourier Transform.\n\n    Depending on the application, user should be careful with qubit ordering\n    in the input and output. This can be controlled with reverse_in and swaps_out\n    arguments.\n\n    Args:\n        n_qubits: number of qubits in the QFT\n        support: qubit support to use\n        inverse: True performs the inverse QFT\n        reverse_in: Reverses the input qubits to account for endianness\n        swaps_out: Performs swaps on the output qubits to match the \"textbook\" QFT.\n        strategy: Strategy.Digital or Strategy.sDAQC\n        gen_build: building block Ising Hamiltonian for the DAQC transform.\n            Defaults to constant all-to-all Ising.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import qft\n\n        n_qubits = 3\n\n        qft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n        ```\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    assert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\n\n    if reverse_in:\n        support = support[::-1]\n\n    qft_layer_dict = {\n        Strategy.DIGITAL: _qft_layer_digital,\n        Strategy.SDAQC: _qft_layer_sDAQC,\n        Strategy.BDAQC: _qft_layer_bDAQC,\n        Strategy.ANALOG: _qft_layer_analog,\n    }\n\n    try:\n        layer_func = qft_layer_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    qft_layers = reversed(range(n_qubits)) if inverse else range(n_qubits)\n\n    qft_circ = chain(\n        layer_func(\n            n_qubits=n_qubits, support=support, layer=layer, inverse=inverse, gen_build=gen_build\n        )  # type: ignore\n        for layer in qft_layers\n    )\n\n    if swaps_out:\n        swap_ops = [SWAP(support[i], support[n_qubits - i - 1]) for i in range(n_qubits // 2)]\n        qft_circ = chain(*swap_ops, qft_circ) if inverse else chain(qft_circ, *swap_ops)\n\n    return tag(qft_circ, tag=\"iQFT\") if inverse else tag(qft_circ, tag=\"QFT\")\n</code></pre>"},{"location":"api/constructors/#hardware-efficient-ansatz-for-rydberg-atom-arrays","title":"Hardware efficient ansatz for Rydberg atom arrays","text":""},{"location":"api/constructors/#qadence.constructors.rydberg_hea.rydberg_hea","title":"<code>rydberg_hea(register, n_layers=1, addressable_detuning=True, addressable_drive=False, tunable_phase=False, additional_prefix=None)</code>","text":"<p>Hardware efficient ansatz for neutral atom (Rydberg) platforms.</p> <p>This constructor implements a variational ansatz which is very close to what is implementable on 2nd generation PASQAL quantum devices. In particular, it implements evolution over a specific Hamiltonian which can be realized on the device. This Hamiltonian contains:</p> <ul> <li> <p>an interaction term given by the standard NN interaction and determined starting     from the positions in the input register: H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c</p> </li> <li> <p>a detuning term which corresponding to a n_i = (1+sigma_i^z)/2 applied to     all the qubits. If the <code>addressable_detuning</code> flag is set to True, the routine     effectively a local n_i = (1+sigma_i^z)/2 term in the     evolved Hamiltonian with a different coefficient for each atom. These     coefficients determine a local addressing pattern for the detuning on a subset     of the qubits. In this routine, the coefficients are variational parameters     and they will therefore be optimized at each optimizer step</p> </li> <li> <p>a drive term which corresponding to a sigma^x evolution operation applied to     all the qubits. If the <code>addressable_drive</code> flag is set to True, the routine     effectively a local sigma_i^x term in the evolved Hamiltonian with a different     coefficient for each atom. These coefficients determine a local addressing pattern     for the drive on a subset of the qubits. In this routine, the coefficients are     variational parameters and they will therefore be optimized at each optimizer step</p> </li> <li> <p>if the <code>tunable_phase</code> flag is set to True, the drive term is modified in the following     way: drive = cos(phi) * sigma^x - sin(phi) * sigma^y     The addressable pattern above is maintained and the phase is considered just as an     additional variational parameter which is optimized with the rest</p> </li> </ul> <p>Notice that, on real devices, the coefficients assigned to each qubit in both the detuning and drive patterns should be non-negative and they should always sum to 1. This is not the case for the implementation in this routine since the coefficients (weights) do not have any constraint. Therefore, this HEA is not completely realizable on neutral atom devices.</p> PARAMETER DESCRIPTION <code>register</code> <p>the input atomic register with Cartesian coordinates.</p> <p> TYPE: <code>Register</code> </p> <code>n_layers</code> <p>number layers in the HEA, each layer includes a drive, detuning and pure interaction pulses whose is a variational parameter</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>addressable_detuning</code> <p>whether to turn on the trainable semi-local addressing pattern on the detuning (n_i terms in the Hamiltonian)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>addressable_drive</code> <p>whether to turn on the trainable semi-local addressing pattern on the drive (sigma_i^x terms in the Hamiltonian)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tunable_phase</code> <p>whether to have a tunable phase to get both sigma^x and sigma^y rotations in the drive term. If False, only a sigma^x term will be included in the drive part of the Hamiltonian generator</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>additional_prefix</code> <p>an additional prefix to attach to the parameter names</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>The Rydberg HEA block</p> Source code in <code>qadence/constructors/rydberg_hea.py</code> <pre><code>def rydberg_hea(\n    register: qd.Register,\n    n_layers: int = 1,\n    addressable_detuning: bool = True,\n    addressable_drive: bool = False,\n    tunable_phase: bool = False,\n    additional_prefix: str = None,\n) -&gt; qd.blocks.ChainBlock:\n    \"\"\"Hardware efficient ansatz for neutral atom (Rydberg) platforms.\n\n    This constructor implements a variational ansatz which is very close to\n    what is implementable on 2nd generation PASQAL quantum devices. In particular,\n    it implements evolution over a specific Hamiltonian which can be realized on\n    the device. This Hamiltonian contains:\n\n    * an interaction term given by the standard NN interaction and determined starting\n        from the positions in the input register: H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n\n    * a detuning term which corresponding to a n_i = (1+sigma_i^z)/2 applied to\n        all the qubits. If the `addressable_detuning` flag is set to True, the routine\n        effectively a local n_i = (1+sigma_i^z)/2 term in the\n        evolved Hamiltonian with a different coefficient for each atom. These\n        coefficients determine a local addressing pattern for the detuning on a subset\n        of the qubits. In this routine, the coefficients are variational parameters\n        and they will therefore be optimized at each optimizer step\n\n    * a drive term which corresponding to a sigma^x evolution operation applied to\n        all the qubits. If the `addressable_drive` flag is set to True, the routine\n        effectively a local sigma_i^x term in the evolved Hamiltonian with a different\n        coefficient for each atom. These coefficients determine a local addressing pattern\n        for the drive on a subset of the qubits. In this routine, the coefficients are\n        variational parameters and they will therefore be optimized at each optimizer step\n\n    * if the `tunable_phase` flag is set to True, the drive term is modified in the following\n        way: drive = cos(phi) * sigma^x - sin(phi) * sigma^y\n        The addressable pattern above is maintained and the phase is considered just as an\n        additional variational parameter which is optimized with the rest\n\n    Notice that, on real devices, the coefficients assigned to each qubit in both the detuning\n    and drive patterns should be non-negative and they should always sum to 1. This is not the\n    case for the implementation in this routine since the coefficients (weights) do not have any\n    constraint. Therefore, this HEA is not completely realizable on neutral atom devices.\n\n    Args:\n        register: the input atomic register with Cartesian coordinates.\n        n_layers: number layers in the HEA, each layer includes a drive, detuning and\n            pure interaction pulses whose is a variational parameter\n        addressable_detuning: whether to turn on the trainable semi-local addressing pattern\n            on the detuning (n_i terms in the Hamiltonian)\n        addressable_drive: whether to turn on the trainable semi-local addressing pattern\n            on the drive (sigma_i^x terms in the Hamiltonian)\n        tunable_phase: whether to have a tunable phase to get both sigma^x and sigma^y rotations\n            in the drive term. If False, only a sigma^x term will be included in the drive part\n            of the Hamiltonian generator\n        additional_prefix: an additional prefix to attach to the parameter names\n\n    Returns:\n        The Rydberg HEA block\n    \"\"\"\n    n_qubits = register.n_qubits\n    prefix = \"\" if additional_prefix is None else \"_\" + additional_prefix\n\n    detunings = None\n    # add a detuning pattern locally addressing the atoms\n    if addressable_detuning:\n        detunings = [qd.VariationalParameter(f\"detmap_{j}\") for j in range(n_qubits)]\n\n    drives = None\n    # add a drive pattern locally addressing the atoms\n    if addressable_drive:\n        drives = [qd.VariationalParameter(f\"drivemap_{j}\") for j in range(n_qubits)]\n\n    phase = None\n    if tunable_phase:\n        phase = qd.VariationalParameter(\"phase\")\n\n    return chain(\n        rydberg_hea_layer(\n            register,\n            VariationalParameter(f\"At{prefix}_{layer}\"),\n            VariationalParameter(f\"Omega{prefix}_{layer}\"),\n            VariationalParameter(f\"wait{prefix}_{layer}\"),\n            detunings=detunings,\n            drives=drives,\n            phase=phase,\n        )\n        for layer in range(n_layers)\n    )\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.rydberg_hea.rydberg_hea_layer","title":"<code>rydberg_hea_layer(register, tevo_drive, tevo_det, tevo_wait, phase=None, detunings=None, drives=None, drive_scaling=1.0)</code>","text":"<p>A single layer of the Rydberg hardware efficient ansatz.</p> PARAMETER DESCRIPTION <code>register</code> <p>the input register with atomic coordinates needed to build the interaction.</p> <p> TYPE: <code>Register</code> </p> <code>tevo_drive</code> <p>a variational parameter for the duration of the drive term of the Hamiltonian generator, including optional semi-local addressing</p> <p> TYPE: <code>Parameter | float</code> </p> <code>tevo_det</code> <p>a variational parameter for the duration of the detuning term of the Hamiltonian generator, including optional semi-local addressing</p> <p> TYPE: <code>Parameter | float</code> </p> <code>tevo_wait</code> <p>a variational parameter for the duration of the waiting time with interaction only</p> <p> TYPE: <code>Parameter | float</code> </p> <code>phase</code> <p>a variational parameter representing the global phase. If None, the global phase is set to 0 which results in a drive term in sigma^x only. Otherwise both sigma^x and sigma^y terms will be present</p> <p> TYPE: <code>Parameter | float | None</code> DEFAULT: <code>None</code> </p> <code>detunings</code> <p>a list of parameters with the weights of the locally addressed detuning terms. These are variational parameters which are tuned by the optimizer</p> <p> TYPE: <code>list[Parameter] | list[float] | None</code> DEFAULT: <code>None</code> </p> <code>drives</code> <p>a list of parameters with the weights of the locally addressed drive terms. These are variational parameters which are tuned by the optimizer</p> <p> TYPE: <code>list[Parameter] | list[float] | None</code> DEFAULT: <code>None</code> </p> <code>drive_scaling</code> <p>a scaling term to be added to the drive Hamiltonian generator</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A block with a single layer of Rydberg HEA</p> Source code in <code>qadence/constructors/rydberg_hea.py</code> <pre><code>def rydberg_hea_layer(\n    register: qd.Register,\n    tevo_drive: Parameter | float,\n    tevo_det: Parameter | float,\n    tevo_wait: Parameter | float,\n    phase: Parameter | float | None = None,\n    detunings: list[Parameter] | list[float] | None = None,\n    drives: list[Parameter] | list[float] | None = None,\n    drive_scaling: float = 1.0,\n) -&gt; ChainBlock:\n    \"\"\"A single layer of the Rydberg hardware efficient ansatz.\n\n    Args:\n        register: the input register with atomic coordinates needed to build the interaction.\n        tevo_drive: a variational parameter for the duration of the drive term of\n            the Hamiltonian generator, including optional semi-local addressing\n        tevo_det: a variational parameter for the duration of the detuning term of the\n            Hamiltonian generator, including optional semi-local addressing\n        tevo_wait: a variational parameter for the duration of the waiting\n            time with interaction only\n        phase: a variational parameter representing the global phase. If None, the\n            global phase is set to 0 which results in a drive term in sigma^x only. Otherwise\n            both sigma^x and sigma^y terms will be present\n        detunings: a list of parameters with the weights of the locally addressed\n            detuning terms. These are variational parameters which are tuned by the optimizer\n        drives: a list of parameters with the weights of the locally addressed\n            drive terms. These are variational parameters which are tuned by the optimizer\n        drive_scaling: a scaling term to be added to the drive Hamiltonian generator\n\n    Returns:\n        A block with a single layer of Rydberg HEA\n    \"\"\"\n    n_qubits = register.n_qubits\n\n    drive_x = _amplitude_map(n_qubits, qd.X, weights=drives)\n    drive_y = _amplitude_map(n_qubits, qd.Y, weights=drives)\n    detuning = _amplitude_map(n_qubits, qd.N, weights=detunings)\n    interaction = hamiltonian_factory(register, qd.Interaction.NN)\n\n    # drive and interaction are not commuting thus they need to be\n    # added directly into the final Hamiltonian generator\n    if phase is not None:\n        generator = (\n            drive_scaling * sympy.cos(phase) * drive_x\n            - drive_scaling * sympy.sin(phase) * drive_y\n            + interaction\n        )\n    else:\n        generator = drive_scaling * drive_x + interaction\n\n    return chain(\n        qd.HamEvo(generator, tevo_drive),\n        # detuning and interaction are commuting, so they\n        # can be ordered arbitrarily and treated separately\n        qd.HamEvo(interaction, tevo_wait),\n        qd.HamEvo(detuning, tevo_det),\n    )\n</code></pre>"},{"location":"api/constructors/#the-daqc-transform","title":"The DAQC Transform","text":""},{"location":"api/constructors/#qadence.constructors.daqc.daqc.daqc_transform","title":"<code>daqc_transform(n_qubits, gen_target, t_f, gen_build=None, zero_tol=1e-08, strategy=Strategy.SDAQC, ignore_global_phases=False)</code>","text":"<p>Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian.</p> <p>The result is another fixed 2-body Hamiltonian.</p> <p>Reference for universality of 2-body Hamiltonians:</p> <p>-- https://arxiv.org/abs/quant-ph/0106064</p> <p>Based on the transformation for Ising (ZZ) interactions, as described in the paper</p> <p>-- https://arxiv.org/abs/1812.03637</p> <p>The transform translates a target weighted generator of the type:</p> <pre><code>`gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>To a circuit using analog evolutions with a fixed building block generator:</p> <pre><code>`gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>where <code>op = Z</code> or <code>op = N</code>.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>total number of qubits to use.</p> <p> TYPE: <code>int</code> </p> <code>gen_target</code> <p>target generator built with the structure above. The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>t_f</code> <p>total time for the gen_target evolution.</p> <p> TYPE: <code>float</code> </p> <code>gen_build</code> <p>fixed generator to act as a building block. Defaults to constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>zero_tol</code> <p>default \"zero\" for a missing interaction. Included for numerical reasons, see notes below.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>strategy</code> <p>sDAQC or bDAQC, following definitions in the reference paper.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>SDAQC</code> </p> <code>ignore_global_phases</code> <p>if <code>True</code> the transform does not correct the global phases coming from the mapping between ZZ and NN interactions.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Notes:</p> <pre><code>The paper follows an index convention of running from 1 to N. A few functions\nhere also use that convention to be consistent with the paper. However, for qadence\nrelated things the indices are converted to [0, N-1].\n\nThe case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\nThere is a workaround for this described in the paper, but it is currently not implemented.\n\nThe current implementation may result in evolution times that are both positive or\nnegative. In practice, both can be represented by simply changing the signs of the\ninteractions. However, for a real implementation where the interactions should remain\nfixed, the paper discusses a workaround that is not currently implemented.\n\nThe transformation works by representing each interaction in the target hamiltonian by\na set of evolutions using the build hamiltonian. As a consequence, some care must be\ntaken when choosing the build hamiltonian. Some cases:\n\n- The target hamiltonian can have any interaction, as long as it is sufficiently\nrepresented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\nis in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\nneeds to be in the build hamiltonian. This is checked when the generators are parsed.\n\n- The build hamiltonian can have any interaction, irrespectively of it being needed\nfor the target hamiltonian. This is especially useful for designing local operations\nthrough the repeated evolution of a \"global\" hamiltonian.\n\n- The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\nAny interaction strength smaller than `zero_tol` in the build hamiltonian will not be\nconsidered, and thus that interaction is missing.\n\n- The various ratios `g_jk / f_jk` will influence the time parameter for the various\nevolution slices, meaning that if there is a big discrepancy in the interaction strength\nfor a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\nevolutions with very large times.\n\n- A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\ntimes smaller than `zero_tol` will not be represented.\n</code></pre> <p>Examples:</p> <pre><code>from qadence import Z, N, daqc_transform\n\nn_qubits = 3\n\ngen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n\ngen_target = 0.1 * (Z(1)@Z(2))\n\nt_f = 2.0\n\ntransformed_circuit = daqc_transform(\n    n_qubits = n_qubits,\n    gen_target = gen_target,\n    t_f = t_f,\n    gen_build = gen_build,\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/daqc/daqc.py</code> <pre><code>def daqc_transform(\n    n_qubits: int,\n    gen_target: AbstractBlock,\n    t_f: float,\n    gen_build: AbstractBlock | None = None,\n    zero_tol: float = 1e-08,\n    strategy: Strategy = Strategy.SDAQC,\n    ignore_global_phases: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian.\n\n    The result is another fixed 2-body Hamiltonian.\n\n    Reference for universality of 2-body Hamiltonians:\n\n    -- https://arxiv.org/abs/quant-ph/0106064\n\n    Based on the transformation for Ising (ZZ) interactions, as described in the paper\n\n    -- https://arxiv.org/abs/1812.03637\n\n    The transform translates a target weighted generator of the type:\n\n        `gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n\n    To a circuit using analog evolutions with a fixed building block generator:\n\n        `gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n\n    where `op = Z` or `op = N`.\n\n    Args:\n        n_qubits: total number of qubits to use.\n        gen_target: target generator built with the structure above. The type\n            of the generator will be automatically evaluated when parsing.\n        t_f (float): total time for the gen_target evolution.\n        gen_build: fixed generator to act as a building block. Defaults to\n            constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type\n            of the generator will be automatically evaluated when parsing.\n        zero_tol: default \"zero\" for a missing interaction. Included for\n            numerical reasons, see notes below.\n        strategy: sDAQC or bDAQC, following definitions in the reference paper.\n        ignore_global_phases: if `True` the transform does not correct the global\n            phases coming from the mapping between ZZ and NN interactions.\n\n    Notes:\n\n        The paper follows an index convention of running from 1 to N. A few functions\n        here also use that convention to be consistent with the paper. However, for qadence\n        related things the indices are converted to [0, N-1].\n\n        The case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\n        There is a workaround for this described in the paper, but it is currently not implemented.\n\n        The current implementation may result in evolution times that are both positive or\n        negative. In practice, both can be represented by simply changing the signs of the\n        interactions. However, for a real implementation where the interactions should remain\n        fixed, the paper discusses a workaround that is not currently implemented.\n\n        The transformation works by representing each interaction in the target hamiltonian by\n        a set of evolutions using the build hamiltonian. As a consequence, some care must be\n        taken when choosing the build hamiltonian. Some cases:\n\n        - The target hamiltonian can have any interaction, as long as it is sufficiently\n        represented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\n        is in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\n        needs to be in the build hamiltonian. This is checked when the generators are parsed.\n\n        - The build hamiltonian can have any interaction, irrespectively of it being needed\n        for the target hamiltonian. This is especially useful for designing local operations\n        through the repeated evolution of a \"global\" hamiltonian.\n\n        - The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\n        Any interaction strength smaller than `zero_tol` in the build hamiltonian will not be\n        considered, and thus that interaction is missing.\n\n        - The various ratios `g_jk / f_jk` will influence the time parameter for the various\n        evolution slices, meaning that if there is a big discrepancy in the interaction strength\n        for a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\n        evolutions with very large times.\n\n        - A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\n        times smaller than `zero_tol` will not be represented.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import Z, N, daqc_transform\n\n        n_qubits = 3\n\n        gen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n\n        gen_target = 0.1 * (Z(1)@Z(2))\n\n        t_f = 2.0\n\n        transformed_circuit = daqc_transform(\n            n_qubits = n_qubits,\n            gen_target = gen_target,\n            t_f = t_f,\n            gen_build = gen_build,\n        )\n        ```\n    \"\"\"\n\n    ##################\n    # Input controls #\n    ##################\n\n    if strategy != Strategy.SDAQC:\n        raise NotImplementedError(\"Currently only the sDAQC transform is implemented.\")\n\n    if n_qubits == 4:\n        raise NotImplementedError(\"DAQC transform 4-qubit edge case not implemented.\")\n\n    if gen_build is None:\n        gen_build = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n\n    try:\n        if (not block_is_qubit_hamiltonian(gen_target)) or (\n            not block_is_qubit_hamiltonian(gen_build)\n        ):\n            raise ValueError(\n                \"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n            )\n    except NotImplementedError:\n        # Happens when block_is_qubit_hamiltonian is called on something that is not a block.\n        raise TypeError(\n            \"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n        )\n\n    #####################\n    # Generator parsing #\n    #####################\n\n    g_jk_target, mat_jk_target, target_type = _parse_generator(n_qubits, gen_target, 0.0)\n    g_jk_build, mat_jk_build, build_type = _parse_generator(n_qubits, gen_build, zero_tol)\n\n    # Get the global phase hamiltonian and single-qubit detuning hamiltonian\n    if build_type == GenDAQC.NN:\n        h_phase_build, h_sq_build = _nn_phase_and_detunings(n_qubits, mat_jk_build)\n\n    if target_type == GenDAQC.NN:\n        h_phase_target, h_sq_target = _nn_phase_and_detunings(n_qubits, mat_jk_target)\n\n    # Time re-scalings\n    if build_type == GenDAQC.ZZ and target_type == GenDAQC.NN:\n        t_star = t_f / 4.0\n    elif build_type == GenDAQC.NN and target_type == GenDAQC.ZZ:\n        t_star = 4.0 * t_f\n    else:\n        t_star = t_f\n\n    # Check if target Hamiltonian can be mapped with the build Hamiltonian\n    assert _check_compatibility(g_jk_target, g_jk_build, zero_tol)\n\n    ##################\n    # DAQC Transform #\n    ##################\n\n    # Section III A of https://arxiv.org/abs/1812.03637:\n\n    # Matrix M for the linear system, exemplified in Table I:\n    matrix_M = _build_matrix_M(n_qubits)\n\n    # Linear system mapping interaction ratios -&gt; evolution times.\n    t_slices = torch.linalg.solve(matrix_M, g_jk_target / g_jk_build) * t_star\n\n    # ZZ-DAQC with ZZ or NN build Hamiltonian\n    daqc_slices = []\n    for m in range(2, n_qubits + 1):\n        for n in range(1, m):\n            alpha = _ix_map(n_qubits, n, m)\n            t = t_slices[alpha - 1]\n            if abs(t) &gt; zero_tol:\n                if abs(t) &gt; (1 / (zero_tol**0.5)):\n                    logger.warning(\n                        \"\"\"\nTransformed circuit with very long evolution time.\nMake sure your target interactions are sufficiently\nrepresented in the build Hamiltonian.\"\"\"\n                    )\n                x_gates = kron(X(n - 1), X(m - 1))\n                analog_evo = HamEvo(gen_build, t)\n                # TODO: Fix repeated X-gates\n                if build_type == GenDAQC.NN:\n                    # Local detuning at each DAQC layer for NN build Hamiltonian\n                    sq_detuning_build = HamEvo(h_sq_build, t)\n                    daqc_slices.append(chain(x_gates, sq_detuning_build, analog_evo, x_gates))\n                elif build_type == GenDAQC.ZZ:\n                    daqc_slices.append(chain(x_gates, analog_evo, x_gates))\n\n    daqc_circuit = chain(*daqc_slices)\n\n    ########################\n    # Phases and Detunings #\n    ########################\n\n    if target_type == GenDAQC.NN:\n        # Local detuning given a NN target Hamiltonian\n        sq_detuning_target = HamEvo(h_sq_target, t_f).dagger()\n        daqc_circuit = chain(sq_detuning_target, daqc_circuit)\n\n    if not ignore_global_phases:\n        if build_type == GenDAQC.NN:\n            # Constant global phase given a NN build Hamiltonian\n            global_phase_build = HamEvo(h_phase_build, t_slices.sum())\n            daqc_circuit = chain(global_phase_build, daqc_circuit)\n\n        if target_type == GenDAQC.NN:\n            # Constant global phase and given a NN target Hamiltonian\n            global_phase_target = HamEvo(h_phase_target, t_f).dagger()\n            daqc_circuit = chain(global_phase_target, daqc_circuit)\n\n    return daqc_circuit\n</code></pre>"},{"location":"api/constructors/#some-utility-functions","title":"Some utility functions","text":""},{"location":"api/constructors/#qadence.constructors.utils.build_idx_fms","title":"<code>build_idx_fms(basis, fm_pauli, multivariate_strategy, n_features, n_qubits, reupload_scaling)</code>","text":"<p>Builds the index feature maps based on the given parameters.</p> PARAMETER DESCRIPTION <code>basis</code> <p>Type of basis chosen for the feature map.</p> <p> TYPE: <code>BasisSet</code> </p> <code>fm_pauli</code> <p>The chosen Pauli rotation type.</p> <p> TYPE: <code>PrimitiveBlock type</code> </p> <code>multivariate_strategy</code> <p>The strategy used for encoding the multivariate feature map.</p> <p> TYPE: <code>MultivariateStrategy</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>reupload_scaling</code> <p>The chosen scaling for the reupload.</p> <p> TYPE: <code>ReuploadScaling</code> </p> RETURNS DESCRIPTION <code>list[KronBlock]</code> <p>List[KronBlock]: The list of index feature maps.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def build_idx_fms(\n    basis: BasisSet,\n    fm_pauli: Type[RY],\n    multivariate_strategy: MultivariateStrategy,\n    n_features: int,\n    n_qubits: int,\n    reupload_scaling: ReuploadScaling,\n) -&gt; list[KronBlock]:\n    \"\"\"Builds the index feature maps based on the given parameters.\n\n    Args:\n        basis (BasisSet): Type of basis chosen for the feature map.\n        fm_pauli (PrimitiveBlock type): The chosen Pauli rotation type.\n        multivariate_strategy (MultivariateStrategy): The strategy used for encoding\n            the multivariate feature map.\n        n_features (int): The number of features.\n        n_qubits (int): The number of qubits.\n        reupload_scaling (ReuploadScaling): The chosen scaling for the reupload.\n\n    Returns:\n        List[KronBlock]: The list of index feature maps.\n    \"\"\"\n    idx_fms = []\n    for i in range(n_features):\n        target_qubits = get_fm_qubits(multivariate_strategy, i, n_qubits, n_features)\n        param = FeatureParameter(f\"x{i}\")\n        block = kron(\n            *[\n                fm_pauli(qubit, generator_prefactor(reupload_scaling, j) * basis_func(basis, param))\n                for j, qubit in enumerate(target_qubits)\n            ]\n        )\n        idx_fm = block\n        idx_fms.append(idx_fm)\n    return idx_fms\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.utils.generator_prefactor","title":"<code>generator_prefactor(reupload_scaling, qubit_index)</code>","text":"<p>Converts a spectrum string, e.g. tower or exponential.</p> <p>The result is the correct generator prefactor.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def generator_prefactor(reupload_scaling: ReuploadScaling, qubit_index: int) -&gt; float | int:\n    \"\"\"Converts a spectrum string, e.g. tower or exponential.\n\n    The result is the correct generator prefactor.\n    \"\"\"\n    conversion_dict: dict[str, float | int] = {\n        ReuploadScaling.CONSTANT: 1,\n        ReuploadScaling.TOWER: qubit_index + 1,\n        ReuploadScaling.EXP: 2 * PI / (2 ** (qubit_index + 1)),\n    }\n    return conversion_dict[reupload_scaling]\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.utils.get_fm_qubits","title":"<code>get_fm_qubits(multivariate_strategy, i, n_qubits, n_features)</code>","text":"<p>Returns the list of target qubits for the given feature map strategy and feature index.</p> PARAMETER DESCRIPTION <code>multivariate_strategy</code> <p>The strategy used for encoding the multivariate feature map.</p> <p> TYPE: <code>MultivariateStrategy</code> </p> <code>i</code> <p>The feature index.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Iterable</code> <p>List[int]: The list of target qubits.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the feature map strategy is not implemented.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def get_fm_qubits(\n    multivariate_strategy: MultivariateStrategy, i: int, n_qubits: int, n_features: int\n) -&gt; Iterable:\n    \"\"\"Returns the list of target qubits for the given feature map strategy and feature index.\n\n    Args:\n        multivariate_strategy (MultivariateStrategy): The strategy used for encoding\n            the multivariate feature map.\n        i (int): The feature index.\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of features.\n\n    Returns:\n        List[int]: The list of target qubits.\n\n    Raises:\n        ValueError: If the feature map strategy is not implemented.\n    \"\"\"\n    if multivariate_strategy == MultivariateStrategy.PARALLEL:\n        n_qubits_per_feature = int(n_qubits / n_features)\n        target_qubits = range(i * n_qubits_per_feature, (i + 1) * n_qubits_per_feature)\n    elif multivariate_strategy == MultivariateStrategy.SERIES:\n        target_qubits = range(0, n_qubits)\n    else:\n        raise ValueError(f\"Multivariate strategy {multivariate_strategy} not implemented.\")\n    return target_qubits\n</code></pre>"},{"location":"api/draw/","title":"Drawing","text":""},{"location":"api/draw/#drawing","title":"Drawing","text":""},{"location":"api/draw/#qadence.draw.display","title":"<code>display(x, qcd=None, layout='LR', theme='light', fill=True, **kwargs)</code>","text":"<p>Display a block, circuit, or quantum model.</p> <p>The <code>kwargs</code> are forwarded to the underlying <code>nx.Graph</code>, so you can e.g. specify the size of the resulting plot via <code>size=\"2,2\"</code> (see examples)</p> PARAMETER DESCRIPTION <code>x</code> <p><code>AbstractBlock</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <p> TYPE: <code>Any</code> </p> <code>qcd</code> <p>Circuit diagram to plot the block into.</p> <p> TYPE: <code>QuantumCircuitDiagram | Cluster | None</code> DEFAULT: <code>None</code> </p> <code>layout</code> <p>Can be either \"LR\" (left-right), or \"TB\" (top-bottom).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'LR'</code> </p> <code>theme</code> <p>Available themes are: [\"light\", \"dark\", \"black\", \"white\"].</p> <p> TYPE: <code>str</code> DEFAULT: <code>'light'</code> </p> <code>fill</code> <p>Whether to fill the passed <code>x</code> with identities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>kwargs</code> <p>Passed on to <code>nx.Graph</code></p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples: <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\ndisplay(b, size=\"1,1\", theme=\"dark\")\n</code></pre> </p> Source code in <code>qadence/draw/__init__.py</code> <pre><code>def display(\n    x: Any,\n    qcd: QuantumCircuitDiagram | Cluster | None = None,\n    layout: str = \"LR\",\n    theme: str = \"light\",\n    fill: bool = True,\n    **kwargs: Any,\n) -&gt; Graph:\n    \"\"\"Display a block, circuit, or quantum model.\n\n    The `kwargs` are forwarded to\n    the underlying `nx.Graph`, so you can e.g. specify the size of the resulting plot via\n    `size=\"2,2\"` (see examples)\n\n    Arguments:\n        x: `AbstractBlock`, `QuantumCircuit`, or `QuantumModel`.\n        qcd: Circuit diagram to plot the block into.\n        layout: Can be either \"LR\" (left-right), or \"TB\" (top-bottom).\n        theme: Available themes are: [\"light\", \"dark\", \"black\", \"white\"].\n        fill: Whether to fill the passed `x` with identities.\n        kwargs: Passed on to `nx.Graph`\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from qadence import X, Y, kron\n    from qadence.draw import display\n\n    b = kron(X(0), Y(1))\n    def display(*args, **kwargs): return args # markdown-exec: hide\n    display(b, size=\"1,1\", theme=\"dark\")\n    ```\n    \"\"\"\n    return make_diagram(x, **kwargs).show()\n</code></pre>"},{"location":"api/draw/#qadence.draw.savefig","title":"<code>savefig(x, filename, *args, **kwargs)</code>","text":"<p>Save a block, circuit, or quantum model to file. Accepts the same args/kwargs as <code>display</code>.</p> PARAMETER DESCRIPTION <code>x</code> <p><code>AbstractBlock</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <p> TYPE: <code>Any</code> </p> <code>filename</code> <p>Should end in svg/png.</p> <p> TYPE: <code>str</code> </p> <code>args</code> <p>Same as in <code>display</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>kwargs</code> <p>Same as in <code>display</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples: <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\nsavefig(b, \"test.svg\", size=\"1,1\", theme=\"dark\")\n</code></pre> </p> Source code in <code>qadence/draw/__init__.py</code> <pre><code>def savefig(x: Any, filename: str, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Save a block, circuit, or quantum model to file. Accepts the same args/kwargs as `display`.\n\n    Arguments:\n        x: `AbstractBlock`, `QuantumCircuit`, or `QuantumModel`.\n        filename: Should end in svg/png.\n        args: Same as in `display`.\n        kwargs: Same as in `display`.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from qadence import X, Y, kron\n    from qadence.draw import display\n\n    b = kron(X(0), Y(1))\n    def savefig(*args, **kwargs): return args # markdown-exec: hide\n    savefig(b, \"test.svg\", size=\"1,1\", theme=\"dark\")\n    ```\n    \"\"\"\n    make_diagram(x, *args, **kwargs).savefig(filename)\n</code></pre>"},{"location":"api/execution/","title":"Execution","text":""},{"location":"api/execution/#qadence.execution.expectation","title":"<code>expectation(x, observable, values=None, state=None, backend=BackendName.PYQTORCH, diff_mode=None, noise=None, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.expectation</code> method.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>observable</code> <p>Observable(s) w.r.t. which the expectation is computed.</p> <p> TYPE: <code>Union[list[AbstractBlock], AbstractBlock]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>Union[dict, None]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>Which differentiation mode to use.</p> <p> TYPE: <code>Union[DiffMode, str, None]</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> <pre><code>from qadence import RX, Z, Register, QuantumCircuit, expectation\n\nreg = Register(1)\nblock = RX(0, 0.5)\nobservable = Z(0)\ncirc = QuantumCircuit(reg, block)\n\n# You can compute the expectation for a\n# QuantumCircuit with a given observable.\nexpectation(circ, observable)\n\n# You can also use only a block.\n# In this case the register is constructed automatically to\n# Register.line(block.n_qubits)\nexpectation(block, observable)\n\n# Or a register and block\nexpectation(reg, block, observable)\n</code></pre> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef expectation(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    observable: Union[list[AbstractBlock], AbstractBlock],\n    values: Union[dict, None] = None,\n    state: Tensor = None,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: Union[DiffMode, str, None] = None,\n    noise: Union[NoiseHandler, None] = None,\n    endianness: Endianness = Endianness.BIG,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n    \"\"\"Convenience wrapper for the `QuantumModel.expectation` method.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        observable: Observable(s) w.r.t. which the expectation is computed.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        diff_mode: Which differentiation mode to use.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n\n    Returns:\n        A wavefunction\n\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import RX, Z, Register, QuantumCircuit, expectation\n\n    reg = Register(1)\n    block = RX(0, 0.5)\n    observable = Z(0)\n    circ = QuantumCircuit(reg, block)\n\n    # You can compute the expectation for a\n    # QuantumCircuit with a given observable.\n    expectation(circ, observable)\n\n    # You can also use only a block.\n    # In this case the register is constructed automatically to\n    # Register.line(block.n_qubits)\n    expectation(block, observable)\n\n    # Or a register and block\n    expectation(reg, block, observable)\n    ```\n    \"\"\"\n\n    raise ValueError(f\"Cannot execute {type(x)}\")\n</code></pre>"},{"location":"api/execution/#qadence.execution.run","title":"<code>run(x, *args, values=None, state=None, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.run</code> method.</p> <p>This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>Union[dict, None]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef run(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    *args: Any,\n    values: Union[dict, None] = None,\n    state: Tensor = None,\n    backend: BackendName = BackendName.PYQTORCH,\n    endianness: Endianness = Endianness.BIG,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n    \"\"\"Convenience wrapper for the `QuantumModel.run` method.\n\n     This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n\n    Returns:\n        A wavefunction\n    \"\"\"\n    raise ValueError(f\"Cannot run {type(x)}\")\n</code></pre>"},{"location":"api/execution/#qadence.execution.sample","title":"<code>sample(x, *args, values=None, state=None, n_shots=100, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, noise=None, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.sample</code> method.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>Union[dict, None]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Union[Tensor, None]</code> DEFAULT: <code>None</code> </p> <code>n_shots</code> <p>Number of shots per element in the batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>noise</code> <p>The noise model to use if any.</p> <p> TYPE: <code>Union[NoiseHandler, None]</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef sample(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    *args: Any,\n    values: Union[dict, None] = None,\n    state: Union[Tensor, None] = None,\n    n_shots: int = 100,\n    backend: BackendName = BackendName.PYQTORCH,\n    endianness: Endianness = Endianness.BIG,\n    noise: Union[NoiseHandler, None] = None,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; list[Counter]:\n    \"\"\"Convenience wrapper for the `QuantumModel.sample` method.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        n_shots: Number of shots per element in the batch.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        noise: The noise model to use if any.\n        configuration: The backend configuration.\n\n    Returns:\n        A list of Counter instances with the sample results\n    \"\"\"\n    raise ValueError(f\"Cannot sample from {type(x)}\")\n</code></pre>"},{"location":"api/ml_tools/","title":"QML tools","text":""},{"location":"api/ml_tools/#ml-tools","title":"ML Tools","text":"<p>This module implements a <code>Trainer</code> class for torch <code>Modules</code> and <code>QuantumModel</code>. It also implements the <code>QNN</code> class and callbacks that can be used with the trainer module.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer","title":"<code>Trainer(model, optimizer, config, loss_fn='mse', train_dataloader=None, val_dataloader=None, test_dataloader=None, optimize_step=optimize_step, max_batches=None)</code>","text":"<p>               Bases: <code>BaseTrainer</code></p> <p>Trainer class to manage and execute training, validation, and testing loops for a model (eg.</p> <p>QNN).</p> <p>This class handles the overall training process, including: - Managing epochs and steps - Handling data loading and batching - Computing and updating gradients - Logging and monitoring training metrics</p> ATTRIBUTE DESCRIPTION <code>current_epoch</code> <p>The current epoch number.</p> <p> TYPE: <code>int</code> </p> <code>global_step</code> <p>The global step across all epochs.</p> <p> TYPE: <code>int</code> </p> Inherited Attributes <p>use_grad (bool): Indicates if gradients are used for optimization. Default is True.</p> <p>model (nn.Module): The neural network model. optimizer (optim.Optimizer | NGOptimizer | None): The optimizer for training. config (TrainConfig): The configuration settings for training. train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data. val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data. test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.</p> <p>optimize_step (Callable): Function for performing an optimization step. loss_fn (Callable): loss function to use.</p> <p>num_training_batches (int): Number of training batches. num_validation_batches (int): Number of validation batches. num_test_batches (int): Number of test batches.</p> <p>state (str): Current state in the training process</p> <p>Default training routine <pre><code>for epoch in max_iter + 1:\n    # Training\n    for batch in train_batches:\n        train model\n    # Validation\n    if val_every % epoch == 0:\n        for batch in val_batches:\n            train model\n</code></pre></p> Notes <ul> <li>In case of InfiniteTensorDataset, number of batches = 1.</li> <li>In case of TensorDataset, number of batches are default.</li> <li>Training is run for max_iter + 1 epochs. Epoch 0 logs untrained model.</li> <li>Please look at the CallbackManager initialize_callbacks method to review the default     logging behavior.</li> </ul> <p>Examples:</p> <pre><code>import torch\nfrom torch.optim import SGD\nfrom qadence import (\n    feature_map,\n    hamiltonian_factory,\n    hea,\n    QNN,\n    QuantumCircuit,\n    TrainConfig,\n    Z,\n)\nfrom qadence.ml_tools.trainer import Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\n\n# Initialize the model\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=2)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\n\n# Set up the optimizer\noptimizer = SGD(model.parameters(), lr=0.001)\n\n# Use TrainConfig for configuring the training process\nconfig = TrainConfig(\n    max_iter=100,\n    print_every=10,\n    write_every=10,\n    checkpoint_every=10,\n    val_every=10\n)\n\n# Create the Trainer instance with TrainConfig\ntrainer = Trainer(\n    model=model,\n    optimizer=optimizer,\n    config=config,\n    loss_fn=\"mse\",\n    optimize_step=optimize_step\n)\n\nbatch_size = 25\nx = torch.linspace(0, 1, 32).reshape(-1, 1)\ny = torch.sin(x)\ntrain_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\nval_loader = to_dataloader(x, y, batch_size=batch_size, infinite=False)\n\n# Train the model\nmodel, optimizer = trainer.fit(train_loader, val_loader)\n</code></pre> <p>This also supports both gradient based and gradient free optimization. The default support is for gradient based optimization.</p> <p>Notes:</p> <ul> <li>set_use_grad() (class level):This method is used to set the global <code>use_grad</code> flag,     controlling whether the trainer uses gradient-based optimization. <pre><code># gradient based\nTrainer.set_use_grad(True)\n\n# gradient free\nTrainer.set_use_grad(False)\n</code></pre></li> <li>Context Managers (instance level):  <code>enable_grad_opt()</code> and <code>disable_grad_opt()</code> are     context managers that temporarily switch the optimization mode for specific code blocks.     This is useful when you want to mix gradient-based and gradient-free optimization     in the same training process. <pre><code># gradient based\nwith trainer.enable_grad_opt(optimizer):\n    trainer.fit()\n\n# gradient free\nwith trainer.disable_grad_opt(ng_optimizer):\n    trainer.fit()\n</code></pre></li> </ul> <p>Examples</p> <p>Gradient based optimization example Usage: <pre><code>from torch import optim\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nTrainer.set_use_grad(True)\ntrainer = Trainer(\n    model=model,\n    optimizer=optimizer,\n    config=config,\n    loss_fn=\"mse\"\n)\ntrainer.fit(train_loader, val_loader)\n</code></pre> or <pre><code>trainer = Trainer(\n    model=model,\n    config=config,\n    loss_fn=\"mse\"\n)\nwith trainer.enable_grad_opt(optimizer):\n    trainer.fit(train_loader, val_loader)\n</code></pre></p> <p>Gradient free optimization example Usage: <pre><code>import nevergrad as ng\nfrom qadence.ml_tools.parameters import num_parameters\nng_optimizer = ng.optimizers.NGOpt(\n                budget=config.max_iter, parametrization= num_parameters(model)\n                )\n\nTrainer.set_use_grad(False)\ntrainer = Trainer(\n    model=model,\n    optimizer=ng_optimizer,\n    config=config,\n    loss_fn=\"mse\"\n)\ntrainer.fit(train_loader, val_loader)\n</code></pre> or <pre><code>import nevergrad as ng\nfrom qadence.ml_tools.parameters import num_parameters\nng_optimizer = ng.optimizers.NGOpt(\n        budget=config.max_iter, parametrization= num_parameters(model)\n        )\n\ntrainer = Trainer(\n    model=model,\n    config=config,\n    loss_fn=\"mse\"\n)\nwith trainer.disable_grad_opt(ng_optimizer):\n    trainer.fit(train_loader, val_loader)\n</code></pre></p> <p>Initializes the Trainer class.</p> PARAMETER DESCRIPTION <code>model</code> <p>The PyTorch model to train.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The optimizer for training.</p> <p> TYPE: <code>Optimizer | Optimizer | None</code> </p> <code>config</code> <p>Training configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>Loss function used for training. If not specified, default mse loss will be used.</p> <p> TYPE: <code>str | Callable</code> DEFAULT: <code>'mse'</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for test data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>optimize_step</code> <p>Function to execute an optimization step.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>optimize_step</code> </p> <code>max_batches</code> <p>Maximum number of batches to process per epoch. This is only valid in case of finite TensorDataset dataloaders. if max_batches is not None, the maximum number of batches used will be min(max_batches, len(dataloader.dataset)) In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def __init__(\n    self,\n    model: nn.Module,\n    optimizer: optim.Optimizer | NGOptimizer | None,\n    config: TrainConfig,\n    loss_fn: str | Callable = \"mse\",\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n    optimize_step: Callable = optimize_step,\n    max_batches: int | None = None,\n):\n    \"\"\"\n    Initializes the Trainer class.\n\n    Args:\n        model (nn.Module): The PyTorch model to train.\n        optimizer (optim.Optimizer | NGOptimizer | None): The optimizer for training.\n        config (TrainConfig): Training configuration object.\n        loss_fn (str | Callable ): Loss function used for training.\n            If not specified, default mse loss will be used.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for test data.\n        optimize_step (Callable): Function to execute an optimization step.\n        max_batches (int | None): Maximum number of batches to process per epoch.\n            This is only valid in case of finite TensorDataset dataloaders.\n            if max_batches is not None, the maximum number of batches used will\n            be min(max_batches, len(dataloader.dataset))\n            In case of InfiniteTensorDataset only 1 batch per epoch is used.\n    \"\"\"\n    super().__init__(\n        model=model,\n        optimizer=optimizer,\n        config=config,\n        loss_fn=loss_fn,\n        optimize_step=optimize_step,\n        train_dataloader=train_dataloader,\n        val_dataloader=val_dataloader,\n        test_dataloader=test_dataloader,\n        max_batches=max_batches,\n    )\n    self.current_epoch: int = 0\n    self.global_step: int = 0\n    self._stop_training: torch.Tensor = torch.tensor(0, dtype=torch.int)\n    self.progress: Progress | None = None\n\n    # Integration with Accelerator:\n    self.accelerator = Accelerator(\n        backend=config.backend,\n        nprocs=config.nprocs,\n        compute_setup=config.compute_setup,\n        dtype=config.dtype,\n        log_setup=config.log_setup,\n    )\n    # Decorate the unbound Trainer.fit method with accelerator.distribute.\n    # We use __get__ to bind the decorated method to the current instance,\n    # ensuring that 'self' is passed only once when self.fit is called.\n    self.fit = self.accelerator.distribute(Trainer.fit).__get__(self, Trainer)  # type: ignore[method-assign]\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.build_optimize_result","title":"<code>build_optimize_result(result)</code>","text":"<p>Builds and stores the optimization result by calculating the average loss and metrics.</p> <p>Result (or loss_metrics) can have multiple formats: - <code>None</code> Indicates no loss or metrics data is provided. - <code>tuple[torch.Tensor, dict[str, Any]]</code> A single tuple containing the loss tensor     and metrics dictionary - at the end of batch. - <code>list[tuple[torch.Tensor, dict[str, Any]]]</code> A list of tuples for     multiple batches. - <code>list[list[tuple[torch.Tensor, dict[str, Any]]]]</code> A list of lists of tuples, where each inner list represents metrics across multiple batches within an epoch.</p> PARAMETER DESCRIPTION <code>result</code> <p>(None |     tuple[torch.Tensor, dict[Any, Any]] |     list[tuple[torch.Tensor, dict[Any, Any]]] |     list[list[tuple[torch.Tensor, dict[Any, Any]]]])         The loss and metrics data, which can have multiple formats</p> <p> TYPE: <code>None | tuple[Tensor, dict[Any, Any]] | list[tuple[Tensor, dict[Any, Any]]] | list[list[tuple[Tensor, dict[Any, Any]]]]</code> </p> RETURNS DESCRIPTION <code>None</code> <p>This method does not return anything. It sets <code>self.opt_result</code> with</p> <p> TYPE: <code>None</code> </p> <code>None</code> <p>the computed average loss and metrics.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def build_optimize_result(\n    self,\n    result: (\n        None\n        | tuple[torch.Tensor, dict[Any, Any]]\n        | list[tuple[torch.Tensor, dict[Any, Any]]]\n        | list[list[tuple[torch.Tensor, dict[Any, Any]]]]\n    ),\n) -&gt; None:\n    \"\"\"\n    Builds and stores the optimization result by calculating the average loss and metrics.\n\n    Result (or loss_metrics) can have multiple formats:\n    - `None` Indicates no loss or metrics data is provided.\n    - `tuple[torch.Tensor, dict[str, Any]]` A single tuple containing the loss tensor\n        and metrics dictionary - at the end of batch.\n    - `list[tuple[torch.Tensor, dict[str, Any]]]` A list of tuples for\n        multiple batches.\n    - `list[list[tuple[torch.Tensor, dict[str, Any]]]]` A list of lists of tuples,\n    where each inner list represents metrics across multiple batches within an epoch.\n\n    Args:\n        result: (None |\n                tuple[torch.Tensor, dict[Any, Any]] |\n                list[tuple[torch.Tensor, dict[Any, Any]]] |\n                list[list[tuple[torch.Tensor, dict[Any, Any]]]])\n                    The loss and metrics data, which can have multiple formats\n\n    Returns:\n        None: This method does not return anything. It sets `self.opt_result` with\n        the computed average loss and metrics.\n    \"\"\"\n    loss_metrics = result\n    if loss_metrics is None:\n        loss = None\n        metrics: dict[Any, Any] = {}\n    elif isinstance(loss_metrics, tuple):\n        # Single tuple case\n        loss, metrics = loss_metrics\n    else:\n        last_epoch: list[tuple[torch.Tensor, dict[Any, Any]]] = []\n        if isinstance(loss_metrics, list):\n            # Check if it's a list of tuples\n            if all(isinstance(item, tuple) for item in loss_metrics):\n                last_epoch = cast(list[tuple[torch.Tensor, dict[Any, Any]]], loss_metrics)\n            # Check if it's a list of lists of tuples\n            elif all(isinstance(item, list) for item in loss_metrics):\n                last_epoch = cast(\n                    list[tuple[torch.Tensor, dict[Any, Any]]],\n                    loss_metrics[-1] if loss_metrics else [],\n                )\n            else:\n                raise ValueError(\n                    \"Invalid format for result: Expected None, tuple, list of tuples,\"\n                    \" or list of lists of tuples.\"\n                )\n\n        if not last_epoch:\n            loss, metrics = None, {}\n        else:\n            # Compute the average loss over the batches\n            loss_tensor = torch.stack([loss_batch for loss_batch, _ in last_epoch])\n            avg_loss = loss_tensor.mean()\n\n            # Collect and average metrics for all batches\n            metric_keys = last_epoch[0][1].keys()\n            metrics_stacked: dict = {key: [] for key in metric_keys}\n\n            for _, metrics_batch in last_epoch:\n                for key in metric_keys:\n                    value = metrics_batch[key]\n                    metrics_stacked[key].append(value)\n\n            avg_metrics = {key: torch.stack(metrics_stacked[key]).mean() for key in metric_keys}\n\n            loss, metrics = avg_loss, avg_metrics\n\n    # Store the optimization result\n    self.opt_result = OptimizeResult(\n        self.current_epoch,\n        self.model,\n        self.optimizer,\n        loss,\n        metrics,\n        rank=self.accelerator.rank,\n        device=self.accelerator.execution.device,\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.fit","title":"<code>fit(train_dataloader=None, val_dataloader=None)</code>","text":"<p>Fits the model using the specified training configuration.</p> <p>The dataloaders can be provided to train on new datasets, or the default dataloaders provided in the trainer will be used.</p> PARAMETER DESCRIPTION <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple[Module, Optimizer]</code> <p>tuple[nn.Module, optim.Optimizer]: The trained model and optimizer.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def fit(\n    self,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; tuple[nn.Module, optim.Optimizer]:\n    \"\"\"\n    Fits the model using the specified training configuration.\n\n    The dataloaders can be provided to train on new datasets, or the default dataloaders\n    provided in the trainer will be used.\n\n    Args:\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n\n    Returns:\n        tuple[nn.Module, optim.Optimizer]: The trained model and optimizer.\n    \"\"\"\n    if train_dataloader is not None:\n        self.train_dataloader = train_dataloader\n    if val_dataloader is not None:\n        self.val_dataloader = val_dataloader\n\n    self._fit_setup()\n    self._train()\n    self._fit_end()\n    self.training_stage = TrainingStage(\"idle\")\n    return self.model, self.optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.get_ic_grad_bounds","title":"<code>get_ic_grad_bounds(eta, epsilons, variation_multiple=20, dataloader=None)</code>","text":"<p>Calculate the bounds on the gradient norm of the loss using Information Content.</p> PARAMETER DESCRIPTION <code>eta</code> <p>The sensitivity IC.</p> <p> TYPE: <code>float</code> </p> <code>epsilons</code> <p>The epsilons to use for thresholds to for discretization of the finite derivatives.</p> <p> TYPE: <code>Tensor</code> </p> <code>variation_multiple</code> <p>The number of sets of variational parameters to generate per each variational parameter. The number of variational parameters required for the statisctiacal analysis scales linearly with the amount of them present in the model. This is that linear factor.</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> <code>dataloader</code> <p>The dataloader for training data. A new dataloader can be provided, or the dataloader provided in the trinaer will be used. In case no dataloaders are provided at either places, it assumes that the model does not require any input data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple[float, float, float]</code> <p>tuple[float, float, float]: The max IC lower bound, max IC upper bound, and sensitivity IC upper bound.</p> <p>Examples:</p> <pre><code>import torch\nfrom torch.optim.adam import Adam\n\nfrom qadence.constructors import ObservableConfig\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig, TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\nfrom qadence.ml_tools.models import QNN\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools.trainer import Trainer\nfrom qadence.operations.primitive import Z\n\nfm_config = FeatureMapConfig(num_features=1)\nansatz_config = AnsatzConfig(depth=4)\nobs_config = ObservableConfig(detuning=Z)\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=obs_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n)\n\noptimizer = Adam(qnn.parameters(), lr=0.001)\n\nbatch_size = 25\nx = torch.linspace(0, 1, 32).reshape(-1, 1)\ny = torch.sin(x)\ntrain_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\ntrain_config = TrainConfig(max_iter=100)\n\ntrainer = Trainer(\n    model=qnn,\n    optimizer=optimizer,\n    config=train_config,\n    loss_fn=\"mse\",\n    train_dataloader=train_loader,\n    optimize_step=optimize_step,\n)\n\n# Perform exploratory landscape analysis with Information Content\nic_sensitivity_threshold = 1e-4\nepsilons = torch.logspace(-2, 2, 10)\n\nmax_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound = (\n    trainer.get_ic_grad_bounds(\n        eta=ic_sensitivity_threshold,\n        epsilons=epsilons,\n    )\n)\n\n# Resume training as usual...\n\ntrainer.fit(train_loader)\n</code></pre> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def get_ic_grad_bounds(\n    self,\n    eta: float,\n    epsilons: torch.Tensor,\n    variation_multiple: int = 20,\n    dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; tuple[float, float, float]:\n    \"\"\"\n    Calculate the bounds on the gradient norm of the loss using Information Content.\n\n    Args:\n        eta (float): The sensitivity IC.\n        epsilons (torch.Tensor): The epsilons to use for thresholds to for discretization of the\n            finite derivatives.\n        variation_multiple (int): The number of sets of variational parameters to generate per\n            each variational parameter. The number of variational parameters required for the\n            statisctiacal analysis scales linearly with the amount of them present in the\n            model. This is that linear factor.\n        dataloader (DataLoader | DictDataLoader | None): The dataloader for training data. A\n            new dataloader can be provided, or the dataloader provided in the trinaer will be\n            used. In case no dataloaders are provided at either places, it assumes that the\n            model does not require any input data.\n\n    Returns:\n        tuple[float, float, float]: The max IC lower bound, max IC upper bound, and sensitivity\n            IC upper bound.\n\n    Examples:\n        ```python\n        import torch\n        from torch.optim.adam import Adam\n\n        from qadence.constructors import ObservableConfig\n        from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig, TrainConfig\n        from qadence.ml_tools.data import to_dataloader\n        from qadence.ml_tools.models import QNN\n        from qadence.ml_tools.optimize_step import optimize_step\n        from qadence.ml_tools.trainer import Trainer\n        from qadence.operations.primitive import Z\n\n        fm_config = FeatureMapConfig(num_features=1)\n        ansatz_config = AnsatzConfig(depth=4)\n        obs_config = ObservableConfig(detuning=Z)\n\n        qnn = QNN.from_configs(\n            register=4,\n            obs_config=obs_config,\n            fm_config=fm_config,\n            ansatz_config=ansatz_config,\n        )\n\n        optimizer = Adam(qnn.parameters(), lr=0.001)\n\n        batch_size = 25\n        x = torch.linspace(0, 1, 32).reshape(-1, 1)\n        y = torch.sin(x)\n        train_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\n        train_config = TrainConfig(max_iter=100)\n\n        trainer = Trainer(\n            model=qnn,\n            optimizer=optimizer,\n            config=train_config,\n            loss_fn=\"mse\",\n            train_dataloader=train_loader,\n            optimize_step=optimize_step,\n        )\n\n        # Perform exploratory landscape analysis with Information Content\n        ic_sensitivity_threshold = 1e-4\n        epsilons = torch.logspace(-2, 2, 10)\n\n        max_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound = (\n            trainer.get_ic_grad_bounds(\n                eta=ic_sensitivity_threshold,\n                epsilons=epsilons,\n            )\n        )\n\n        # Resume training as usual...\n\n        trainer.fit(train_loader)\n        ```\n    \"\"\"\n    if not self._use_grad:\n        logger.warning(\n            \"Gradient norm bounds are only relevant when using a gradient based optimizer. \\\n                Currently the trainer is set to use a gradient-free optimizer.\"\n        )\n\n    dataloader = dataloader if dataloader is not None else self.train_dataloader\n\n    batch = next(iter(self._batch_iter(dataloader, num_batches=1)))\n\n    ic = InformationContent(self.model, self.loss_fn, batch, epsilons)\n\n    max_ic_lower_bound, max_ic_upper_bound = ic.get_grad_norm_bounds_max_IC()\n    sensitivity_ic_upper_bound = ic.get_grad_norm_bounds_sensitivity_IC(eta)\n\n    return max_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_test_batch","title":"<code>run_test_batch(batch)</code>","text":"<p>Runs a single test batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Batch of data from the DataLoader.</p> <p> TYPE: <code>tuple[Tensor, ...]</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, dict[str, Any]]</code> <p>tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"test_batch\")\ndef run_test_batch(\n    self, batch: tuple[torch.Tensor, ...]\n) -&gt; tuple[torch.Tensor, dict[str, Any]]:\n    \"\"\"\n    Runs a single test batch.\n\n    Args:\n        batch (tuple[torch.Tensor, ...]): Batch of data from the DataLoader.\n\n    Returns:\n        tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.\n    \"\"\"\n    with torch.no_grad():\n        loss_metrics = self.loss_fn(self.model, batch)\n    return self._modify_batch_end_loss_metrics(loss_metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_train_batch","title":"<code>run_train_batch(batch)</code>","text":"<p>Runs a single training batch, performing optimization.</p> <p>We use the step function to optimize the model based on use_grad.     use_grad = True entails gradient based optimization, for which we use     optimize_step function.     use_grad = False entails gradient free optimization, for which we use     update_ng_parameters function.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Batch of data from the DataLoader.</p> <p> TYPE: <code>tuple[Tensor, ...]</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, dict[str, Any]]</code> <p>tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch. tuple of (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"train_batch\")\ndef run_train_batch(\n    self, batch: tuple[torch.Tensor, ...]\n) -&gt; tuple[torch.Tensor, dict[str, Any]]:\n    \"\"\"\n    Runs a single training batch, performing optimization.\n\n    We use the step function to optimize the model based on use_grad.\n        use_grad = True entails gradient based optimization, for which we use\n        optimize_step function.\n        use_grad = False entails gradient free optimization, for which we use\n        update_ng_parameters function.\n\n    Args:\n        batch (tuple[torch.Tensor, ...]): Batch of data from the DataLoader.\n\n    Returns:\n        tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.\n            tuple of (loss, metrics)\n    \"\"\"\n\n    if self.use_grad:\n        # Perform gradient-based optimization\n        loss_metrics = self.optimize_step(\n            model=self.model,\n            optimizer=self.optimizer,\n            loss_fn=self.loss_fn,\n            xs=batch,\n            device=self.accelerator.execution.device,\n            dtype=self.accelerator.execution.data_dtype,\n        )\n    else:\n        # Perform optimization using Nevergrad\n        loss, metrics, ng_params = update_ng_parameters(\n            model=self.model,\n            optimizer=self.optimizer,\n            loss_fn=self.loss_fn,\n            data=batch,\n            ng_params=self.ng_params,  # type: ignore[arg-type]\n        )\n        self.ng_params = ng_params\n        loss_metrics = loss, metrics\n\n    return self._modify_batch_end_loss_metrics(loss_metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_training","title":"<code>run_training(dataloader)</code>","text":"<p>Runs the training for a single epoch, iterating over multiple batches.</p> PARAMETER DESCRIPTION <code>dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader</code> </p> RETURNS DESCRIPTION <code>list[tuple[Tensor, dict[str, Any]]]</code> <p>list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch. list                  -&gt; tuples Training Batches      -&gt; (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"train_epoch\")\ndef run_training(self, dataloader: DataLoader) -&gt; list[tuple[torch.Tensor, dict[str, Any]]]:\n    \"\"\"\n    Runs the training for a single epoch, iterating over multiple batches.\n\n    Args:\n        dataloader (DataLoader): DataLoader for training data.\n\n    Returns:\n        list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch.\n            list                  -&gt; tuples\n            Training Batches      -&gt; (loss, metrics)\n    \"\"\"\n    self.model.train()\n    train_epoch_loss_metrics = []\n\n    for batch in self._batch_iter(dataloader, self.num_training_batches):\n        self.on_train_batch_start(batch)\n        train_batch_loss_metrics = self.run_train_batch(batch)\n        if self.config.all_reduce_metrics:\n            train_batch_loss_metrics = self._aggregate_result(train_batch_loss_metrics)\n        train_epoch_loss_metrics.append(train_batch_loss_metrics)\n        self.on_train_batch_end(train_batch_loss_metrics)\n\n    return train_epoch_loss_metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_val_batch","title":"<code>run_val_batch(batch)</code>","text":"<p>Runs a single validation batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Batch of data from the DataLoader.</p> <p> TYPE: <code>tuple[Tensor, ...]</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, dict[str, Any]]</code> <p>tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"val_batch\")\ndef run_val_batch(self, batch: tuple[torch.Tensor, ...]) -&gt; tuple[torch.Tensor, dict[str, Any]]:\n    \"\"\"\n    Runs a single validation batch.\n\n    Args:\n        batch (tuple[torch.Tensor, ...]): Batch of data from the DataLoader.\n\n    Returns:\n        tuple[torch.Tensor, dict[str, Any]]: Loss and metrics for the batch.\n    \"\"\"\n    with torch.no_grad():\n        loss_metrics = self.loss_fn(self.model, batch)\n    return self._modify_batch_end_loss_metrics(loss_metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.run_validation","title":"<code>run_validation(dataloader)</code>","text":"<p>Runs the validation loop for a single epoch, iterating over multiple batches.</p> PARAMETER DESCRIPTION <code>dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader</code> </p> RETURNS DESCRIPTION <code>list[tuple[Tensor, dict[str, Any]]]</code> <p>list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch. list                  -&gt; tuples Validation Batches      -&gt; (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>@BaseTrainer.callback(\"val_epoch\")\ndef run_validation(self, dataloader: DataLoader) -&gt; list[tuple[torch.Tensor, dict[str, Any]]]:\n    \"\"\"\n    Runs the validation loop for a single epoch, iterating over multiple batches.\n\n    Args:\n        dataloader (DataLoader): DataLoader for validation data.\n\n    Returns:\n        list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch.\n            list                  -&gt; tuples\n            Validation Batches      -&gt; (loss, metrics)\n    \"\"\"\n    self.model.eval()\n    val_epoch_loss_metrics = []\n\n    for batch in self._batch_iter(dataloader, self.num_validation_batches):\n        self.on_val_batch_start(batch)\n        val_batch_loss_metrics = self.run_val_batch(batch)\n        if self.config.all_reduce_metrics:\n            val_batch_loss_metrics = self._aggregate_result(val_batch_loss_metrics)\n        val_epoch_loss_metrics.append(val_batch_loss_metrics)\n        self.on_val_batch_end(val_batch_loss_metrics)\n\n    return val_epoch_loss_metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.stop_training","title":"<code>stop_training()</code>","text":"<p>Helper function to indicate if the training should be stopped.</p> <p>We all_reduce the indicator across all processes to ensure all processes are stopped.</p> Notes <p>self._stop_training indicator indicates if the training should be stopped. 0 is continue. 1 is stop.</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def stop_training(self) -&gt; bool:\n    \"\"\"\n    Helper function to indicate if the training should be stopped.\n\n    We all_reduce the indicator across all processes to ensure all processes are stopped.\n\n    Notes:\n        self._stop_training indicator indicates if the training should be stopped.\n        0 is continue. 1 is stop.\n    \"\"\"\n    _stop_training = self.accelerator.all_reduce_dict(\n        {\"indicator\": self._stop_training}, op=\"max\"\n    )\n    return bool(_stop_training[\"indicator\"] &gt; 0)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.trainer.Trainer.test","title":"<code>test(test_dataloader=None)</code>","text":"<p>Runs the testing loop if a test DataLoader is provided.</p> <p>if the test_dataloader is not provided, default test_dataloader defined in the Trainer class is used.</p> PARAMETER DESCRIPTION <code>test_dataloader</code> <p>DataLoader for test data.</p> <p> TYPE: <code>DataLoader</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[tuple[Tensor, dict[str, Any]]]</code> <p>list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch. list                    -&gt; tuples Test Batches            -&gt; (loss, metrics)</p> Source code in <code>qadence/ml_tools/trainer.py</code> <pre><code>def test(self, test_dataloader: DataLoader = None) -&gt; list[tuple[torch.Tensor, dict[str, Any]]]:\n    \"\"\"\n    Runs the testing loop if a test DataLoader is provided.\n\n    if the test_dataloader is not provided, default test_dataloader defined\n    in the Trainer class is used.\n\n    Args:\n        test_dataloader (DataLoader): DataLoader for test data.\n\n    Returns:\n        list[tuple[torch.Tensor, dict[str, Any]]]: Loss and metrics for each batch.\n            list                    -&gt; tuples\n            Test Batches            -&gt; (loss, metrics)\n    \"\"\"\n    if test_dataloader is not None:\n        self.test_dataloader = test_dataloader\n\n    self.model.eval()\n    test_loss_metrics = []\n\n    for batch in self._batch_iter(test_dataloader, self.num_training_batches):\n        self.on_test_batch_start(batch)\n        loss_metrics = self.run_test_batch(batch)\n        test_loss_metrics.append(loss_metrics)\n        self.on_test_batch_end(loss_metrics)\n\n    return test_loss_metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig","title":"<code>AnsatzConfig(depth=1, ansatz_type=AnsatzType.HEA, ansatz_strategy=Strategy.DIGITAL, strategy_args=dict(), m_block_qubits=None, param_prefix='theta', tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.ansatz_strategy","title":"<code>ansatz_strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ansatz strategy.</p> <p><code>Strategy.DIGITAL</code> for fully digital ansatz. Required if <code>ansatz_type</code> is <code>AnsatzType.ALA</code>. <code>Strategy.SDAQC</code> for analog entangling block. Only available for <code>AnsatzType.HEA</code> or <code>AnsatzType.ALA</code>. <code>Strategy.RYDBERG</code> for fully rydberg hea ansatz. Only available for <code>AnsatzType.HEA</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.ansatz_type","title":"<code>ansatz_type = AnsatzType.HEA</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>What type of ansatz.</p> <p><code>AnsatzType.HEA</code> for Hardware Efficient Ansatz. <code>AnsatzType.IIA</code> for Identity Intialized Ansatz. <code>AnsatzType.ALA</code> for Alternating Layer Ansatz.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.depth","title":"<code>depth = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of layers of the ansatz.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.m_block_qubits","title":"<code>m_block_qubits = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The number of qubits in the local entangling block of an Alternating Layer Ansatz (ALA).</p> <p>Only used when <code>ansatz_type</code> is <code>AnsatzType.ALA</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.param_prefix","title":"<code>param_prefix = 'theta'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The base bame of the variational parameter.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.strategy_args","title":"<code>strategy_args = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A dictionary containing keyword arguments to the function creating the ansatz.</p> <p>Details about each below.</p> <p>For <code>Strategy.DIGITAL</code> strategy, accepts the following:     periodic (bool): if the qubits should be linked periodically.         periodic=False is not supported in emu-c.     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): 2-qubit entangling operation.         Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlld rotations         will have variational parameters on the rotation angles.         Defaults to CNOT</p> <p>For <code>Strategy.SDAQC</code> strategy, accepts the following:     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): Hamiltonian generator for the         analog entangling layer. Time parameter is considered variational.         Defaults to NN interaction.</p> <p>For <code>Strategy.RYDBERG</code> strategy, accepts the following:     addressable_detuning: whether to turn on the trainable semi-local addressing pattern         on the detuning (n_i terms in the Hamiltonian).         Defaults to True.     addressable_drive: whether to turn on the trainable semi-local addressing pattern         on the drive (sigma_i^x terms in the Hamiltonian).         Defaults to False.     tunable_phase: whether to have a tunable phase to get both sigma^x and sigma^y rotations         in the drive term. If False, only a sigma^x term will be included in the drive part         of the Hamiltonian generator.         Defaults to False.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the ansatz.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig","title":"<code>FeatureMapConfig(num_features=0, basis_set=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multivariate_strategy=MultivariateStrategy.PARALLEL, feature_map_strategy=Strategy.DIGITAL, param_prefix=None, num_repeats=0, operation=None, inputs=None, tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.basis_set","title":"<code>basis_set = BasisSet.FOURIER</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basis set for feature encoding.</p> <p>Takes qadence.BasisSet. Give a single BasisSet to use the same for all features. Give a dict of (str, BasisSet) where the key is the name of the variable and the value is the BasisSet to use for encoding that feature. BasisSet.FOURIER for Fourier encoding. BasisSet.CHEBYSHEV for Chebyshev encoding.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.feature_map_strategy","title":"<code>feature_map_strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Strategy for feature map.</p> <p>Accepts DIGITAL, ANALOG or RYDBERG. Defaults to DIGITAL. If the strategy is incompatible with the <code>operation</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.feature_range","title":"<code>feature_range = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data that the input data is assumed to come from.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the feature range to use for that feature.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.inputs","title":"<code>inputs = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List that indicates the order of variables of the tensors that are passed.</p> <p>Optional if a single feature is being encoded, required otherwise. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.multivariate_strategy","title":"<code>multivariate_strategy = MultivariateStrategy.PARALLEL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The encoding strategy in case of multi-variate function.</p> <p>Takes qadence.MultivariateStrategy. If PARALLEL, the features are encoded in one block of rotation gates with the register being split in sub-registers for each feature. If SERIES, the features are encoded sequentially using the full register for each feature, with an ansatz block between them. PARALLEL is allowed only for DIGITAL <code>feature_map_strategy</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.num_features","title":"<code>num_features = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature parameters to be encoded.</p> <p>Defaults to 0. Thus, no feature parameters are encoded.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.num_repeats","title":"<code>num_repeats = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature map layers repeated in the data reuploading step.</p> <p>If all features are to be repeated the same number of times, then can give a single <code>int</code>. For different number of repetitions for each feature, provide a dict of (str, int) where the key is the name of the variable and the value is the number of repetitions for that feature. This amounts to the number of additional reuploads. So if <code>num_repeats</code> is N, the data gets uploaded N+1 times. Defaults to no repetition.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.operation","title":"<code>operation = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of operation.</p> <p>Choose among the analog or digital rotations or a custom callable function returning an AnalogBlock instance. If the type of operation is incompatible with the <code>strategy</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.param_prefix","title":"<code>param_prefix = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String prefix to create trainable parameters in Feature Map.</p> <p>A string prefix to create trainable parameters multiplying the feature parameter inside the feature-encoding function. Note that currently this does not take into account the domain of the feature-encoding function. Defaults to <code>None</code> and thus, the feature map is not trainable. Note that this is separate from the name of the parameter. The user can provide a single prefix for all features, and it will be appended by appropriate feature name automatically.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.reupload_scaling","title":"<code>reupload_scaling = ReuploadScaling.CONSTANT</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Scaling for encoding the same feature on different qubits.</p> <p>Scaling used to encode the same feature on different qubits in the same layer of the feature maps. Takes qadence.ReuploadScaling. Give a single ReuploadScaling to use the same for all features. Give a dict of (str, ReuploadScaling) where the key is the name of the variable and the value is the ReuploadScaling to use for encoding that feature. ReuploadScaling.CONSTANT for constant scaling. ReuploadScaling.TOWER for linearly increasing scaling. ReuploadScaling.EXP for exponentially increasing scaling.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the feature map.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.target_range","title":"<code>target_range = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data the data encoder assumes as natural range.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the target range to use for that feature.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig","title":"<code>TrainConfig(max_iter=10000, print_every=0, write_every=0, checkpoint_every=0, plot_every=0, callbacks=lambda: list()(), log_model=False, root_folder=Path('./qml_logs'), create_subfolder_per_run=False, log_folder=Path('./'), checkpoint_best_only=False, val_every=0, val_epsilon=1e-05, validation_criterion=None, trainstop_criterion=None, batch_size=1, verbose=True, tracking_tool=ExperimentTrackingTool.TENSORBOARD, hyperparams=dict(), plotting_functions=tuple(), _subfolders=list(), nprocs=1, compute_setup='cpu', backend='gloo', log_setup='cpu', dtype=None, all_reduce_metrics=False)</code>  <code>dataclass</code>","text":"<p>Default configuration for the training process.</p> <p>This class provides default settings for various aspects of the training loop, such as logging, checkpointing, and validation. The default values for these fields can be customized when an instance of <code>TrainConfig</code> is created.</p> <p>Example: <pre><code>from qadence.ml_tools import TrainConfig\nc = TrainConfig(root_folder=\"/tmp/train\")\n</code></pre> <pre><code>TrainConfig(max_iter=10000, print_every=0, write_every=0, checkpoint_every=0, plot_every=0, callbacks=[], log_model=False, root_folder='/tmp/train', create_subfolder_per_run=False, log_folder=PosixPath('.'), checkpoint_best_only=False, val_every=0, val_epsilon=1e-05, validation_criterion=None, trainstop_criterion=None, batch_size=1, verbose=True, tracking_tool=&lt;ExperimentTrackingTool.TENSORBOARD: 'tensorboard'&gt;, hyperparams={}, plotting_functions=(), _subfolders=[], nprocs=1, compute_setup='cpu', backend='gloo', log_setup='cpu', dtype=None, all_reduce_metrics=False)\n</code></pre> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.all_reduce_metrics","title":"<code>all_reduce_metrics = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to aggregate metrics (e.g., loss, accuracy) across processes.</p> <p>When True, metrics from different training processes are averaged to provide a consolidated metrics. Note: Since aggregation requires synchronization/all_reduce operation, this can increase the  computation time significantly.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.backend","title":"<code>backend = 'gloo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Backend used for distributed training communication.</p> <p>The default is \"gloo\". Other options may include \"nccl\" - which is optimized for GPU-based training or \"mpi\", depending on your system and requirements. It should be one of the backends supported by <code>torch.distributed</code>. For further details, please look at torch backends</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.batch_size","title":"<code>batch_size = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The batch size to use when processing a list or tuple of torch.Tensors.</p> <p>This specifies how many samples are processed in each training iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.callbacks","title":"<code>callbacks = field(default_factory=lambda: list())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of callbacks to execute during training.</p> <p>Callbacks can be used for custom behaviors, such as early stopping, custom logging, or other actions triggered at specific events.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_best_only","title":"<code>checkpoint_best_only = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If <code>True</code>, checkpoints are only saved if there is an improvement in the.</p> <p>validation metric. This conserves storage by only keeping the best models.</p> <p>validation_criterion is required when this is set to True.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_every","title":"<code>checkpoint_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for saving model and optimizer checkpoints during training.</p> <p>Set to 0 to disable checkpointing. This helps in resuming training or recovering models. Note that setting checkpoint_best_only = True will disable this and only best checkpoints will be saved.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.compute_setup","title":"<code>compute_setup = 'cpu'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute device setup; options are \"auto\", \"gpu\", or \"cpu\".</p> <ul> <li>\"auto\": Automatically uses GPU if available; otherwise, falls back to CPU.</li> <li>\"gpu\": Forces GPU usage, raising an error if no CUDA device is available.</li> <li>\"cpu\": Forces the use of CPU regardless of GPU availability.</li> </ul>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.create_subfolder_per_run","title":"<code>create_subfolder_per_run = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to create a subfolder for each run, named <code>&lt;id&gt;_&lt;timestamp&gt;_&lt;PID&gt;</code>.</p> <p>This ensures logs and checkpoints from different runs do not overwrite each other, which is helpful for rapid prototyping. If <code>False</code>, training will resume from the latest checkpoint if one exists in the specified log folder.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.dtype","title":"<code>dtype = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Data type (precision) for computations.</p> <p>Both model parameters, and dataset will be of the provided precision.</p> <p>If not specified or None, the default torch precision (usually torch.float32) is used. If provided dtype is torch.complex128, model parameters will be torch.complex128, and data parameters will be torch.float64</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.hyperparams","title":"<code>hyperparams = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A dictionary of hyperparameters to be tracked.</p> <p>This can include learning rates, regularization parameters, or any other training-related configurations.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.log_folder","title":"<code>log_folder = Path('./')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The log folder for saving checkpoints and tensorboard logs.</p> <p>This stores the path where all logs and checkpoints are being saved for this training session. <code>log_folder</code> takes precedence over <code>root_folder</code>, but it is ignored if <code>create_subfolders_per_run=True</code> (in which case, subfolders will be spawned in the root folder).</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.log_model","title":"<code>log_model = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to log a serialized version of the model.</p> <p>When set to <code>True</code>, the model's state will be logged, useful for model versioning and reproducibility.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.log_setup","title":"<code>log_setup = 'cpu'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Logging device setup; options are \"auto\" or \"cpu\".</p> <ul> <li>\"auto\": Uses the same device for logging as for computation.</li> <li>\"cpu\": Forces logging to occur on the CPU. This can be useful to avoid potential conflicts with GPU processes.</li> </ul>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.max_iter","title":"<code>max_iter = 10000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of training iterations (epochs) to perform.</p> <p>This defines the total number of times the model will be updated.</p> <p>In case of InfiniteTensorDataset, each epoch will have 1 batch. In case of TensorDataset, each epoch will have len(dataloader) batches.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.nprocs","title":"<code>nprocs = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The number of processes to use for training when spawning subprocesses.</p> <p>For effective parallel processing, set this to a value greater than 1. - In case of Multi-GPU or Multi-Node-Multi-GPU setups, nprocs should be equal to the total number of GPUs across all nodes (world size), or total number of GPU to be used.</p> <p>If nprocs &gt; 1, multiple processes will be spawned for training. The training framework will launch additional processes (e.g., for distributed or parallel training). - For CPU setup, this will launch a true parallel processes - For GPU setup, this will launch a distributed training routine. This uses the DistributedDataParallel framework from PyTorch.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.plot_every","title":"<code>plot_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for generating and saving figures during training.</p> <p>Set to 0 to disable plotting.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.plotting_functions","title":"<code>plotting_functions = field(default_factory=tuple)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Functions used for in-training plotting.</p> <p>These are called to generate plots that are logged or saved at specified intervals.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.print_every","title":"<code>print_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for printing loss and metrics to the console during training.</p> <p>Set to 0 to disable this output, meaning that metrics and loss will not be printed during training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.root_folder","title":"<code>root_folder = Path('./qml_logs')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The root folder for saving checkpoints and tensorboard logs.</p> <p>The default path is \"./qml_logs\"</p> <p>This can be set to a specific directory where training artifacts are to be stored. Checkpoints will be saved inside a subfolder in this directory. Subfolders will be created based on <code>create_subfolder_per_run</code> argument.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.tracking_tool","title":"<code>tracking_tool = ExperimentTrackingTool.TENSORBOARD</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The tool used for tracking training progress and logging metrics.</p> <p>Options include tools like TensorBoard, which help visualize and monitor model training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.trainstop_criterion","title":"<code>trainstop_criterion = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A function to determine if the training process should stop based on a.</p> <p>specific stopping metric. If <code>None</code>, training continues until <code>max_iter</code> is reached.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.val_epsilon","title":"<code>val_epsilon = 1e-05</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A small safety margin used to compare the current validation loss with the.</p> <p>best previous validation loss. This is used to determine improvements in metrics.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.val_every","title":"<code>val_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for performing validation.</p> <p>If set to 0, validation is not performed. Note that metrics from validation are always written, regardless of the <code>write_every</code> setting. Note that initial validation happens at the start of training (when val_every &gt; 0)     For initial validation  - initial metrics are written.                             - checkpoint is saved (when checkpoint_best_only = False)</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.validation_criterion","title":"<code>validation_criterion = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A function to evaluate whether a given validation metric meets a desired condition.</p> <p>The validation_criterion has the following format: def validation_criterion(val_loss: float, best_val_loss: float, val_epsilon: float) -&gt; bool:     # process</p> <p>If <code>None</code>, no custom validation criterion is applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.verbose","title":"<code>verbose = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to print metrics and status messages during training.</p> <p>If <code>True</code>, detailed metrics and status updates will be displayed in the console.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.write_every","title":"<code>write_every = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Frequency (in epochs) for writing loss and metrics using the tracking tool during training.</p> <p>Set to 0 to disable this logging, which prevents metrics from being logged to the tracking tool. Note that the metrics will always be written at the end of training regardless of this setting.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.get_parameters","title":"<code>get_parameters(model)</code>","text":"<p>Retrieve all trainable model parameters in a single vector.</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a 1-dimensional tensor with the parameters</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def get_parameters(model: Module) -&gt; Tensor:\n    \"\"\"Retrieve all trainable model parameters in a single vector.\n\n    Args:\n        model (Module): the input PyTorch model\n\n    Returns:\n        Tensor: a 1-dimensional tensor with the parameters\n    \"\"\"\n    ps = [p.reshape(-1) for p in model.parameters() if p.requires_grad]\n    return torch.concat(ps)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.num_parameters","title":"<code>num_parameters(model)</code>","text":"<p>Return the total number of parameters of the given model.</p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def num_parameters(model: Module) -&gt; int:\n    \"\"\"Return the total number of parameters of the given model.\"\"\"\n    return len(get_parameters(model))\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.set_parameters","title":"<code>set_parameters(model, theta)</code>","text":"<p>Set all trainable parameters of a model from a single vector.</p> <p>Notice that this function assumes prior knowledge of right number of parameters in the model</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> <code>theta</code> <p>the parameters to assign</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def set_parameters(model: Module, theta: Tensor) -&gt; None:\n    \"\"\"Set all trainable parameters of a model from a single vector.\n\n    Notice that this function assumes prior knowledge of right number\n    of parameters in the model\n\n    Args:\n        model (Module): the input PyTorch model\n        theta (Tensor): the parameters to assign\n    \"\"\"\n\n    with torch.no_grad():\n        idx = 0\n        for ps in model.parameters():\n            if ps.requires_grad:\n                n = torch.numel(ps)\n                if ps.ndim == 0:\n                    ps[()] = theta[idx : idx + n]\n                else:\n                    ps[:] = theta[idx : idx + n].reshape(ps.size())\n                idx += n\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.optimize_step.optimize_step","title":"<code>optimize_step(model, optimizer, loss_fn, xs, device=None, dtype=None)</code>","text":"<p>Default Torch optimize step with closure.</p> <p>This is the default optimization step.</p> PARAMETER DESCRIPTION <code>model</code> <p>The input model to be optimized.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The chosen Torch optimizer.</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function that returns the loss value and a dictionary of metrics.</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>The input data. If None, it means the given model does not require any input data.</p> <p> TYPE: <code>dict | list | Tensor | None</code> </p> <code>device</code> <p>A target device to run computations on.</p> <p> TYPE: <code>device</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Data type for <code>xs</code> conversion.</p> <p> TYPE: <code>dtype</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor | float, dict | None]</code> <p>tuple[Tensor | float, dict | None]: A tuple containing the computed loss value and a dictionary with collected metrics.</p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def optimize_step(\n    model: Module,\n    optimizer: Optimizer,\n    loss_fn: Callable,\n    xs: dict | list | torch.Tensor | None,\n    device: torch.device = None,\n    dtype: torch.dtype = None,\n) -&gt; tuple[torch.Tensor | float, dict | None]:\n    \"\"\"Default Torch optimize step with closure.\n\n    This is the default optimization step.\n\n    Args:\n        model (Module): The input model to be optimized.\n        optimizer (Optimizer): The chosen Torch optimizer.\n        loss_fn (Callable): A custom loss function\n            that returns the loss value and a dictionary of metrics.\n        xs (dict | list | Tensor | None): The input data. If None, it means\n            the given model does not require any input data.\n        device (torch.device): A target device to run computations on.\n        dtype (torch.dtype): Data type for `xs` conversion.\n\n    Returns:\n        tuple[Tensor | float, dict | None]: A tuple containing the computed loss value\n            and a dictionary with collected metrics.\n    \"\"\"\n\n    loss, metrics = None, {}\n\n    def closure() -&gt; Any:\n        # NOTE: We need the nonlocal as we can't return a metric dict and\n        # because e.g. LBFGS calls this closure multiple times but for some\n        # reason the returned loss is always the first one...\n        nonlocal metrics, loss\n        optimizer.zero_grad()\n        loss, metrics = loss_fn(model, xs)\n        loss.backward(retain_graph=True)\n        return loss.item()\n\n    optimizer.step(closure)\n    # return the loss/metrics that are being mutated inside the closure...\n    return loss, metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.optimize_step.update_ng_parameters","title":"<code>update_ng_parameters(model, optimizer, loss_fn, data, ng_params)</code>","text":"<p>Update the model parameters using Nevergrad.</p> <p>This function integrates Nevergrad for derivative-free optimization.</p> PARAMETER DESCRIPTION <code>model</code> <p>The PyTorch model to be optimized.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>A Nevergrad optimizer instance.</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function that returns the loss value and a dictionary of metrics.</p> <p> TYPE: <code>Callable[[Module, Tensor | None], tuple[float, dict]]</code> </p> <code>data</code> <p>Input data for the model. If None, it means the model does not require input data.</p> <p> TYPE: <code>Tensor | None</code> </p> <code>ng_params</code> <p>The current set of parameters managed by Nevergrad.</p> <p> TYPE: <code>Array</code> </p> RETURNS DESCRIPTION <code>tuple[float, dict, Array]</code> <p>tuple[float, dict, ng.p.Array]: A tuple containing the computed loss value, a dictionary of metrics, and the updated Nevergrad parameters.</p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def update_ng_parameters(\n    model: Module,\n    optimizer: ng.optimizers.Optimizer,\n    loss_fn: Callable[[Module, torch.Tensor | None], tuple[float, dict]],\n    data: torch.Tensor | None,\n    ng_params: ng.p.Array,\n) -&gt; tuple[float, dict, ng.p.Array]:\n    \"\"\"Update the model parameters using Nevergrad.\n\n    This function integrates Nevergrad for derivative-free optimization.\n\n    Args:\n        model (Module): The PyTorch model to be optimized.\n        optimizer (ng.optimizers.Optimizer): A Nevergrad optimizer instance.\n        loss_fn (Callable[[Module, Tensor | None], tuple[float, dict]]): A custom loss function\n            that returns the loss value and a dictionary of metrics.\n        data (Tensor | None): Input data for the model. If None, it means the model does\n            not require input data.\n        ng_params (ng.p.Array): The current set of parameters managed by Nevergrad.\n\n    Returns:\n        tuple[float, dict, ng.p.Array]: A tuple containing the computed loss value,\n            a dictionary of metrics, and the updated Nevergrad parameters.\n    \"\"\"\n    loss, metrics = loss_fn(model, data)  # type: ignore[misc]\n    optimizer.tell(ng_params, float(loss))\n    ng_params = optimizer.ask()  # type: ignore[assignment]\n    params = promote_to_tensor(ng_params.value, requires_grad=False)\n    set_parameters(model, params)\n    return loss, metrics, ng_params\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.DictDataLoader","title":"<code>DictDataLoader(dataloaders)</code>  <code>dataclass</code>","text":"<p>This class only holds a dictionary of <code>DataLoader</code>s and samples from them.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.InfiniteTensorDataset","title":"<code>InfiniteTensorDataset(*tensors)</code>","text":"<p>               Bases: <code>IterableDataset</code></p> <p>Randomly sample points from the first dimension of the given tensors.</p> <p>Behaves like a normal torch <code>Dataset</code> just that we can sample from it as many times as we want.</p> <p>Examples: <pre><code>import torch\nfrom qadence.ml_tools.data import InfiniteTensorDataset\n\nx_data, y_data = torch.rand(5,2), torch.ones(5,1)\n# The dataset accepts any number of tensors with the same batch dimension\nds = InfiniteTensorDataset(x_data, y_data)\n\n# call `next` to get one sample from each tensor:\nxs = next(iter(ds))\n</code></pre> <pre><code>(tensor([0.9750, 0.7602]), tensor([1.]))\n</code></pre></p> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>def __init__(self, *tensors: Tensor):\n    \"\"\"Randomly sample points from the first dimension of the given tensors.\n\n    Behaves like a normal torch `Dataset` just that we can sample from it as\n    many times as we want.\n\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    import torch\n    from qadence.ml_tools.data import InfiniteTensorDataset\n\n    x_data, y_data = torch.rand(5,2), torch.ones(5,1)\n    # The dataset accepts any number of tensors with the same batch dimension\n    ds = InfiniteTensorDataset(x_data, y_data)\n\n    # call `next` to get one sample from each tensor:\n    xs = next(iter(ds))\n    print(str(xs)) # markdown-exec: hide\n    ```\n    \"\"\"\n    self.tensors = tensors\n    self.indices = list(range(self.tensors[0].size(0)))\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult","title":"<code>OptimizeResult(iteration, model, optimizer, loss=None, metrics=lambda: dict()(), extra=lambda: dict()(), rank=0, device='cpu')</code>  <code>dataclass</code>","text":"<p>OptimizeResult stores many optimization intermediate values.</p> <p>We store at a current iteration, the model, optimizer, loss values, metrics. An extra dict can be used for saving other information to be used for callbacks.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.device","title":"<code>device = 'cpu'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Device on which this result for calculated.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.extra","title":"<code>extra = field(default_factory=lambda: dict())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Extra dict for saving anything else to be used in callbacks.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.iteration","title":"<code>iteration</code>  <code>instance-attribute</code>","text":"<p>Current iteration number.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.loss","title":"<code>loss = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Loss value.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.metrics","title":"<code>metrics = field(default_factory=lambda: dict())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Metrics that can be saved during training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.model","title":"<code>model</code>  <code>instance-attribute</code>","text":"<p>Model at iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.optimizer","title":"<code>optimizer</code>  <code>instance-attribute</code>","text":"<p>Optimizer at iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.rank","title":"<code>rank = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rank of the process for which this result was generated.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.data_to_device","title":"<code>data_to_device(xs, *args, **kwargs)</code>","text":"<p>Utility method to move arbitrary data to 'device'.</p> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>@singledispatch\ndef data_to_device(xs: Any, *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"Utility method to move arbitrary data to 'device'.\"\"\"\n    raise ValueError(f\"Unable to move {type(xs)} with input args: {args} and kwargs: {kwargs}.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.to_dataloader","title":"<code>to_dataloader(*tensors, batch_size=1, infinite=False)</code>","text":"<p>Convert torch tensors an (infinite) Dataloader.</p> PARAMETER DESCRIPTION <code>*tensors</code> <p>Torch tensors to use in the dataloader.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>()</code> </p> <code>batch_size</code> <p>batch size of sampled tensors</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>infinite</code> <p>if <code>True</code>, the dataloader will keep sampling indefinitely even after the whole dataset was sampled once</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>import torch\nfrom qadence.ml_tools import to_dataloader\n\n(x, y, z) = [torch.rand(10) for _ in range(3)]\nloader = iter(to_dataloader(x, y, z, batch_size=5, infinite=True))\nprint(next(loader))\nprint(next(loader))\nprint(next(loader))\n</code></pre> <pre><code>[tensor([0.8499, 0.7041, 0.0603, 0.5398, 0.2357]), tensor([0.2391, 0.2211, 0.3944, 0.5225, 0.5483]), tensor([0.1385, 0.9408, 0.9767, 0.1692, 0.4859])]\n[tensor([0.0267, 0.1633, 0.4347, 0.6979, 0.8541]), tensor([0.2087, 0.4923, 0.2158, 0.0043, 0.1754]), tensor([0.2473, 0.0796, 0.8167, 0.8581, 0.9829])]\n[tensor([0.8499, 0.7041, 0.0603, 0.5398, 0.2357]), tensor([0.2391, 0.2211, 0.3944, 0.5225, 0.5483]), tensor([0.1385, 0.9408, 0.9767, 0.1692, 0.4859])]\n</code></pre> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>def to_dataloader(*tensors: Tensor, batch_size: int = 1, infinite: bool = False) -&gt; DataLoader:\n    \"\"\"Convert torch tensors an (infinite) Dataloader.\n\n    Arguments:\n        *tensors: Torch tensors to use in the dataloader.\n        batch_size: batch size of sampled tensors\n        infinite: if `True`, the dataloader will keep sampling indefinitely even after the whole\n            dataset was sampled once\n\n    Examples:\n\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    import torch\n    from qadence.ml_tools import to_dataloader\n\n    (x, y, z) = [torch.rand(10) for _ in range(3)]\n    loader = iter(to_dataloader(x, y, z, batch_size=5, infinite=True))\n    print(next(loader))\n    print(next(loader))\n    print(next(loader))\n    ```\n    \"\"\"\n    ds = InfiniteTensorDataset(*tensors) if infinite else TensorDataset(*tensors)\n    return DataLoader(ds, batch_size=batch_size)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN","title":"<code>QNN(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, inputs=None, input_diff_mode=InputDiffMode.AD)</code>","text":"<p>               Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs.</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN, Z\nfrom qadence import hea, feature_map, hamiltonian_factory, kron\n\n# create the circuit\nn_qubits, depth = 2, 4\nfm = kron(\n    feature_map(1, support=(0,), param=\"x\"),\n    feature_map(1, support=(1,), param=\"y\")\n)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning=Z)\n\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n\n# initialize and use the model\nqnn = QNN(circuit, obs, inputs=[\"x\", \"y\"])\ny = qnn(torch.rand(3, 2))\n</code></pre> <pre><code>tensor([[1.5648, 3.1296],\n        [1.7350, 3.4700],\n        [1.7590, 3.5180]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN.</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>The observable.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>inputs</code> <p>List that indicates the order of variables of the tensors that are passed to the model. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p> <p> TYPE: <code>list[Basic | str] | None</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode | str</code> DEFAULT: <code>AD</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    inputs: list[sympy.Basic | str] | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n):\n    \"\"\"Initialize the QNN.\n\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        observable: The observable.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        configuration: optional configuration for the backend\n        inputs: List that indicates the order of variables of the tensors that are passed\n            to the model. Given input tensors `xs = torch.rand(batch_size, input_size:=2)` a QNN\n            with `inputs=[\"t\", \"x\"]` will assign `t, x = xs[:,0], xs[:,1]`.\n        input_diff_mode: The differentiation mode for the input tensor.\n    \"\"\"\n    super().__init__(\n        circuit,\n        observable=observable,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        configuration=configuration,\n        noise=noise,\n    )\n    if self._observable is None:\n        raise ValueError(\"You need to provide at least one observable in the QNN constructor\")\n    if (inputs is not None) and (len(self.inputs) == len(inputs)):\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in inputs]  # type: ignore[union-attr]\n    elif (inputs is None) and len(self.inputs) &lt;= 1:\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in self.inputs]  # type: ignore[union-attr]\n    else:\n        raise ValueError(\n            \"\"\"\n            Your QNN has more than one input. Please provide a list of inputs in the order of\n            your tensor domain. For example, if you want to pass\n            `xs = torch.rand(batch_size, input_size:=3)` to you QNN, where\n            ```\n            t = x[:,0]\n            x = x[:,1]\n            y = x[:,2]\n            ```\n            you have to specify\n            ```\n            QNN(circuit, observable, inputs=[\"t\", \"x\", \"y\"])\n            ```\n            You can also pass a list of sympy symbols.\n        \"\"\"\n        )\n    self.format_to_dict = format_to_dict_fn(self.inputs)  # type: ignore[arg-type]\n    self.input_diff_mode = InputDiffMode(input_diff_mode)\n    if self.input_diff_mode == InputDiffMode.FD:\n        from qadence.backends.utils import finitediff\n\n        self.__derivative = finitediff\n    elif self.input_diff_mode == InputDiffMode.AD:\n        self.__derivative = _torch_derivative  # type: ignore[assignment]\n    else:\n        raise ValueError(f\"Unkown forward diff mode: {self.input_diff_mode}\")\n\n    self._model_configs: dict = dict()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of a QNN.</p> <p>When creating a QNN from a set of configurations, we print the configurations used. Otherwise, we use the default printing.</p> RETURNS DESCRIPTION <code>str | Any</code> <p>str | Any: A string representation of a QNN.</p> <p>Example: <pre><code>from qadence import QNN\nfrom qadence.constructors.hamiltonians import Interaction\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools.constructors import (\n    ObservableConfig,\n)\nfrom qadence.operations import Z\nfrom qadence.types import BackendName\n\nbackend = BackendName.PYQTORCH\nfm_config = FeatureMapConfig(num_features=1)\nansatz_config = AnsatzConfig()\nobservable_config = ObservableConfig(detuning=Z, interaction=Interaction.ZZ, scale=2)\n\nqnn = QNN.from_configs(\n    register=2,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=backend,\n)\n</code></pre> <pre><code>QNN(\nansatz_config = AnsatzConfig(depth=1, ansatz_type=&lt;AnsatzType.HEA: 'hea'&gt;, ansatz_strategy=&lt;Strategy.DIGITAL: 'Digital'&gt;, strategy_args={}, m_block_qubits=None, param_prefix='theta', tag=None)\nfm_config = FeatureMapConfig(num_features=1, basis_set={'x': &lt;BasisSet.FOURIER: 'Fourier'&gt;}, reupload_scaling={'x': &lt;ReuploadScaling.CONSTANT: 'Constant'&gt;}, feature_range={'x': None}, target_range={'x': None}, multivariate_strategy=&lt;MultivariateStrategy.PARALLEL: 'Parallel'&gt;, feature_map_strategy=&lt;Strategy.DIGITAL: 'Digital'&gt;, param_prefix=None, num_repeats={'x': 0}, operation=&lt;class 'qadence.operations.parametric.RX'&gt;, inputs=['x'], tag=None)\nregister = 2\nobservable_config = {'Obs.': '(2 * (Z(0) + Z(1) + (Z(0) \u2297 Z(1))))'}\n)\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def __str__(self) -&gt; str | Any:\n    \"\"\"Return a string representation of a QNN.\n\n    When creating a QNN from a set of configurations,\n    we print the configurations used. Otherwise, we use the default printing.\n\n    Returns:\n        str | Any: A string representation of a QNN.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import QNN\n    from qadence.constructors.hamiltonians import Interaction\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools.constructors import (\n        ObservableConfig,\n    )\n    from qadence.operations import Z\n    from qadence.types import BackendName\n\n    backend = BackendName.PYQTORCH\n    fm_config = FeatureMapConfig(num_features=1)\n    ansatz_config = AnsatzConfig()\n    observable_config = ObservableConfig(detuning=Z, interaction=Interaction.ZZ, scale=2)\n\n    qnn = QNN.from_configs(\n        register=2,\n        obs_config=observable_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n    )\n    print(qnn) # markdown-exec: hide\n    ```\n    \"\"\"\n    if bool(self._model_configs):\n        configs_str = \"\\n\".join(\n            (\n                k + \" = \" + str(self._model_configs[k])\n                for k in sorted(self._model_configs.keys())\n                if k != \"observable_config\"\n            )\n        )\n        observable_str = \"\"\n        if self._observable:\n            observable_str = f\"observable_config = {self.observables_to_expression()}\"\n\n        return f\"{type(self).__name__}(\\n{configs_str}\\n{observable_str}\\n)\"\n\n    return super().__str__()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.forward","title":"<code>forward(values=None, state=None, measurement=None, noise=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model.</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def forward(\n    self,\n    values: dict[str, Tensor] | Tensor = None,\n    state: Tensor | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    \"\"\"Forward pass of the model.\n\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n\n    Args:\n        values: the values of the feature parameters\n        state: Initial state.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\n    return self.expectation(\n        values, state=state, measurement=measurement, noise=noise, endianness=endianness\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.from_configs","title":"<code>from_configs(register, obs_config, fm_config=FeatureMapConfig(), ansatz_config=AnsatzConfig(), backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, input_diff_mode=InputDiffMode.AD)</code>  <code>classmethod</code>","text":"<p>Create a QNN from a set of configurations.</p> PARAMETER DESCRIPTION <code>register</code> <p>The number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>obs_config</code> <p>The configuration(s) for the observable(s).</p> <p> TYPE: <code>list[ObservableConfig] | ObservableConfig</code> </p> <code>fm_config</code> <p>The configuration for the feature map. Defaults to no feature encoding block.</p> <p> TYPE: <code>FeatureMapConfig</code> DEFAULT: <code>FeatureMapConfig()</code> </p> <code>ansatz_config</code> <p>The configuration for the ansatz. Defaults to a single layer of hardware efficient ansatz.</p> <p> TYPE: <code>AnsatzConfig</code> DEFAULT: <code>AnsatzConfig()</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices are 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Optional backend configuration.</p> <p> TYPE: <code>BackendConfiguration | dict</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode</code> DEFAULT: <code>AD</code> </p> RETURNS DESCRIPTION <code>QNN</code> <p>A QNN object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the observable configuration is not provided.</p> <p>Example: <pre><code>import torch\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools import QNN\nfrom qadence.constructors import ObservableConfig\nfrom qadence.operations import Z\nfrom qadence.types import (\n    AnsatzType, BackendName, BasisSet, ReuploadScaling, Strategy\n)\n\nregister = 4\nobs_config = ObservableConfig(\n    detuning=Z,\n    scale=5.0,\n    shift=0.0,\n    trainable_transform=None,\n)\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs=[\"x\", \"y\"],\n    basis_set=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.CONSTANT,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nqnn = QNN.from_configs(\n    register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n)\n\nx = torch.rand(2, 2)\ny = qnn(x)\n</code></pre> <pre><code>tensor([[3.4509],\n        [3.5612]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>@classmethod\ndef from_configs(\n    cls,\n    register: int | Register,\n    obs_config: Any,\n    fm_config: Any = FeatureMapConfig(),\n    ansatz_config: Any = AnsatzConfig(),\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n) -&gt; QNN:\n    \"\"\"Create a QNN from a set of configurations.\n\n    Args:\n        register (int | Register): The number of qubits or a register object.\n        obs_config (list[ObservableConfig] | ObservableConfig): The configuration(s)\n            for the observable(s).\n        fm_config (FeatureMapConfig): The configuration for the feature map.\n            Defaults to no feature encoding block.\n        ansatz_config (AnsatzConfig): The configuration for the ansatz.\n            Defaults to a single layer of hardware efficient ansatz.\n        backend (BackendName): The chosen quantum backend.\n        diff_mode (DiffMode): The differentiation engine to use. Choices are\n            'gpsr' or 'ad'.\n        measurement (Measurements): Optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator.\n        noise (Noise): A noise model to use.\n        configuration (BackendConfiguration | dict): Optional backend configuration.\n        input_diff_mode (InputDiffMode): The differentiation mode for the input tensor.\n\n    Returns:\n        A QNN object.\n\n    Raises:\n        ValueError: If the observable configuration is not provided.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools import QNN\n    from qadence.constructors import ObservableConfig\n    from qadence.operations import Z\n    from qadence.types import (\n        AnsatzType, BackendName, BasisSet, ReuploadScaling, Strategy\n    )\n\n    register = 4\n    obs_config = ObservableConfig(\n        detuning=Z,\n        scale=5.0,\n        shift=0.0,\n        trainable_transform=None,\n    )\n    fm_config = FeatureMapConfig(\n        num_features=2,\n        inputs=[\"x\", \"y\"],\n        basis_set=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.CONSTANT,\n        feature_range={\n            \"x\": (-1.0, 1.0),\n            \"y\": (0.0, 1.0),\n        },\n    )\n    ansatz_config = AnsatzConfig(\n        depth=2,\n        ansatz_type=AnsatzType.HEA,\n        ansatz_strategy=Strategy.DIGITAL,\n    )\n\n    qnn = QNN.from_configs(\n        register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n    )\n\n    x = torch.rand(2, 2)\n    y = qnn(x)\n    print(str(y)) # markdown-exec: hide\n    ```\n    \"\"\"\n    from .constructors import build_qnn_from_configs\n\n    qnn = build_qnn_from_configs(\n        register=register,\n        observable_config=obs_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        noise=noise,\n        configuration=configuration,\n        input_diff_mode=input_diff_mode,\n    )\n    qnn._model_configs = {\n        \"register\": register,\n        \"observable_config\": obs_config,\n        \"fm_config\": fm_config,\n        \"ansatz_config\": ansatz_config,\n    }\n    return qnn\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.derivative","title":"<code>derivative(ufa, x, derivative_indices)</code>","text":"<p>Compute derivatives w.r.t.</p> <p>inputs of a UFA with a single output. The <code>derivative_indices</code> specify which derivative(s) are computed.  E.g. <code>derivative_indices=(1,2)</code> would compute the a second order derivative w.r.t to the indices <code>1</code> and <code>2</code> of the input tensor.</p> PARAMETER DESCRIPTION <code>ufa</code> <p>The model for which we want to compute the derivative.</p> <p> TYPE: <code>Module</code> </p> <code>x</code> <p>(batch_size, input_size) input tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>derivative_indices</code> <p>Define which derivatives to compute.</p> <p> TYPE: <code>tuple</code> </p> <p>Examples: If we create a UFA with three inputs and denote the first, second, and third input with <code>x</code>, <code>y</code>, and <code>z</code> we can compute the following derivatives w.r.t to those inputs: <pre><code>import torch\nfrom qadence.ml_tools.models import derivative, QNN\nfrom qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\nfrom qadence.constructors.hamiltonians import ObservableConfig\nfrom qadence.operations import Z\n\nfm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\nansatz_config = AnsatzConfig()\nobs_config = ObservableConfig(detuning=Z)\n\nf = QNN.from_configs(\n    register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n)\ninputs = torch.rand(5,3,requires_grad=True)\n\n# df_dx\nderivative(f, inputs, (0,))\n\n# d2f_dydz\nderivative(f, inputs, (1,2))\n\n# d3fdy2dx\nderivative(f, inputs, (1,1,0))\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def derivative(ufa: torch.nn.Module, x: Tensor, derivative_indices: tuple[int, ...]) -&gt; Tensor:\n    \"\"\"Compute derivatives w.r.t.\n\n    inputs of a UFA with a single output. The\n    `derivative_indices` specify which derivative(s) are computed.  E.g.\n    `derivative_indices=(1,2)` would compute the a second order derivative w.r.t\n    to the indices `1` and `2` of the input tensor.\n\n    Arguments:\n        ufa: The model for which we want to compute the derivative.\n        x (Tensor): (batch_size, input_size) input tensor.\n        derivative_indices (tuple): Define which derivatives to compute.\n\n    Examples:\n    If we create a UFA with three inputs and denote the first, second, and third\n    input with `x`, `y`, and `z` we can compute the following derivatives w.r.t\n    to those inputs:\n    ```py exec=\"on\" source=\"material-block\"\n    import torch\n    from qadence.ml_tools.models import derivative, QNN\n    from qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\n    from qadence.constructors.hamiltonians import ObservableConfig\n    from qadence.operations import Z\n\n    fm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\n    ansatz_config = AnsatzConfig()\n    obs_config = ObservableConfig(detuning=Z)\n\n    f = QNN.from_configs(\n        register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n    )\n    inputs = torch.rand(5,3,requires_grad=True)\n\n    # df_dx\n    derivative(f, inputs, (0,))\n\n    # d2f_dydz\n    derivative(f, inputs, (1,2))\n\n    # d3fdy2dx\n    derivative(f, inputs, (1,1,0))\n    ```\n    \"\"\"\n    assert ufa.out_features == 1, \"Can only call `derivative` on models with 1D output.\"\n    return ufa._derivative(x, derivative_indices)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.format_to_dict_fn","title":"<code>format_to_dict_fn(inputs=[])</code>","text":"<p>Format an input tensor into the format required by the forward pass.</p> <p>The tensor is assumed to have dimensions: n_batches x in_features where in_features corresponds to the number of input features of the QNN</p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def format_to_dict_fn(\n    inputs: list[sympy.Symbol | str] = [],\n) -&gt; Callable[[Tensor | ParamDictType], ParamDictType]:\n    \"\"\"Format an input tensor into the format required by the forward pass.\n\n    The tensor is assumed to have dimensions: n_batches x in_features where in_features\n    corresponds to the number of input features of the QNN\n    \"\"\"\n    in_features = len(inputs)\n\n    def tensor_to_dict(values: Tensor | ParamDictType) -&gt; ParamDictType:\n        if isinstance(values, Tensor):\n            values = values.reshape(-1, 1) if len(values.size()) == 1 else values\n            if not values.shape[1] == in_features:\n                raise ValueError(\n                    f\"Model expects in_features={in_features} but got {values.shape[1]}.\"\n                )\n            values = {fparam.name: values[:, inputs.index(fparam)] for fparam in inputs}  # type: ignore[union-attr]\n        return values\n\n    return tensor_to_dict\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback","title":"<code>Callback(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>Base class for defining various training callbacks.</p> ATTRIBUTE DESCRIPTION <code>on</code> <p>The event on which to trigger the callback. Must be a valid on value from: [\"train_start\", \"train_end\",     \"train_epoch_start\", \"train_epoch_end\", \"train_batch_start\",     \"train_batch_end\",\"val_epoch_start\", \"val_epoch_end\",     \"val_batch_start\", \"val_batch_end\", \"test_batch_start\",     \"test_batch_end\"]</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>callback</code> <p>The function to call if the condition is met.</p> <p> TYPE: <code>CallbackFunction | None</code> </p> <code>callback_condition</code> <p>Condition to check before calling.</p> <p> TYPE: <code>CallbackConditionFunction | None</code> </p> <code>modify_optimize_result</code> <p>Function to modify <code>OptimizeResult</code>.</p> <p> TYPE: <code>CallbackFunction | dict[str, Any] | None</code> </p> <p>A callback can be defined in two ways:</p> <ol> <li>By providing a callback function directly in the base class:    This is useful for simple callbacks that don't require subclassing.</li> </ol> <p>Example:    <pre><code>from qadence.ml_tools.callbacks import Callback\n\ndef custom_callback_function(trainer, config, writer):\n    print(\"Custom callback executed.\")\n\ncustom_callback = Callback(\n    on=\"train_end\",\n    called_every=5,\n    callback=custom_callback_function\n)\n</code></pre> <pre><code>\n</code></pre> </p> <ol> <li>By inheriting and implementing the <code>run_callback</code> method:    This is suitable for more complex callbacks that require customization.</li> </ol> <p>Example:    <pre><code>from qadence.ml_tools.callbacks import Callback\nclass CustomCallback(Callback):\n    def run_callback(self, trainer, config, writer):\n        print(\"Custom behavior in the inherited run_callback method.\")\n\ncustom_callback = CustomCallback(on=\"train_end\", called_every=10)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback.on","title":"<code>on</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the TrainingStage.</p> RETURNS DESCRIPTION <code>TrainingStage</code> <p>TrainingStage for the callback</p> <p> TYPE: <code>TrainingStage | str</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback.__call__","title":"<code>__call__(when, trainer, config, writer)</code>","text":"<p>Executes the callback if conditions are met.</p> PARAMETER DESCRIPTION <code>when</code> <p>The event when the callback is triggered.</p> <p> TYPE: <code>str</code> </p> <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Result of the callback function if executed.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __call__(\n    self, when: TrainingStage, trainer: Any, config: TrainConfig, writer: BaseWriter\n) -&gt; Any:\n    \"\"\"Executes the callback if conditions are met.\n\n    Args:\n        when (str): The event when the callback is triggered.\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n\n    Returns:\n        Any: Result of the callback function if executed.\n    \"\"\"\n    opt_result = trainer.opt_result\n    if self.on == when:\n        if opt_result:\n            opt_result = self.modify_optimize_result(opt_result)\n        if self._should_call(when, opt_result):\n            return self.run_callback(trainer, config, writer)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.Callback.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Executes the defined callback.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Result of the callback execution.</p> <p> TYPE: <code>Any</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If not implemented in subclasses.</p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Executes the defined callback.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n\n    Returns:\n        Any: Result of the callback execution.\n\n    Raises:\n        NotImplementedError: If not implemented in subclasses.\n    \"\"\"\n    if self.callback is not None:\n        return self.callback(trainer, config, writer)\n    raise NotImplementedError(\"Subclasses should override the run_callback method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.EarlyStopping","title":"<code>EarlyStopping(on, called_every, monitor, patience=5, mode='min')</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Stops training when a monitored metric has not improved for a specified number of epochs.</p> <p>This callback monitors a specified metric (e.g., validation loss or accuracy). If the metric does not improve for a given patience period, training is stopped.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>EarlyStopping</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import EarlyStopping\n\n# Create an instance of the EarlyStopping callback\nearly_stopping = EarlyStopping(on=\"val_epoch_end\",\n                               called_every=1,\n                               monitor=\"val_loss\",\n                               patience=5,\n                               mode=\"min\")\n\nconfig = TrainConfig(\n    max_iter=10000,\n    print_every=1000,\n    callbacks=[early_stopping]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the EarlyStopping callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback (e.g., \"val_epoch_end\").</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>monitor</code> <p>The metric to monitor (e.g., \"val_loss\" or \"train_loss\"). All metrics returned by optimize step are available to monitor. Please add \"val_\" and \"train_\" strings at the start of the metric name.</p> <p> TYPE: <code>str</code> </p> <code>patience</code> <p>Number of iterations to wait for improvement. Default is 5.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>mode</code> <p>Whether to minimize (\"min\") or maximize (\"max\") the metric. Default is \"min\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'min'</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self, on: str, called_every: int, monitor: str, patience: int = 5, mode: str = \"min\"\n):\n    \"\"\"Initializes the EarlyStopping callback.\n\n    Args:\n        on (str): The event to trigger the callback (e.g., \"val_epoch_end\").\n        called_every (int): Frequency of callback calls in terms of iterations.\n        monitor (str): The metric to monitor (e.g., \"val_loss\" or \"train_loss\").\n            All metrics returned by optimize step are available to monitor.\n            Please add \"val_\" and \"train_\" strings at the start of the metric name.\n        patience (int, optional): Number of iterations to wait for improvement. Default is 5.\n        mode (str, optional): Whether to minimize (\"min\") or maximize (\"max\") the metric.\n            Default is \"min\".\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.monitor = monitor\n    self.patience = patience\n    self.mode = mode\n    self.best_value = float(\"inf\") if mode == \"min\" else -float(\"inf\")\n    self.counter = 0\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.EarlyStopping.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Monitors the metric and stops training if no improvement is observed.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Monitors the metric and stops training if no improvement is observed.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    current_value = trainer.opt_result.metrics.get(self.monitor)\n    if current_value is None:\n        raise ValueError(f\"Metric '{self.monitor}' is not available in the trainer's metrics.\")\n\n    if (self.mode == \"min\" and current_value &lt; self.best_value) or (\n        self.mode == \"max\" and current_value &gt; self.best_value\n    ):\n        self.best_value = current_value\n        self.counter = 0\n    else:\n        self.counter += 1\n\n    if self.counter &gt;= self.patience:\n        logger.info(\n            f\"EarlyStopping: No improvement in '{self.monitor}' for {self.patience} epochs. \"\n            \"Stopping training.\"\n        )\n        trainer._stop_training.fill_(1)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.GradientMonitoring","title":"<code>GradientMonitoring(on, called_every=1)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Logs gradient statistics (e.g., mean, standard deviation, max) during training.</p> <p>This callback monitors and logs statistics about the gradients of the model parameters to help debug or optimize the training process.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>GradientMonitoring</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import GradientMonitoring\n\n# Create an instance of the GradientMonitoring callback\ngradient_monitoring = GradientMonitoring(on=\"train_batch_end\", called_every=10)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    print_every=1000,\n    callbacks=[gradient_monitoring]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the GradientMonitoring callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback (e.g., \"train_batch_end\").</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int = 1):\n    \"\"\"Initializes the GradientMonitoring callback.\n\n    Args:\n        on (str): The event to trigger the callback (e.g., \"train_batch_end\").\n        called_every (int): Frequency of callback calls in terms of iterations.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.GradientMonitoring.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Logs gradient statistics.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Logs gradient statistics.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        gradient_stats = {}\n        for name, param in trainer.model.named_parameters():\n            if param.grad is not None:\n                grad = param.grad\n                gradient_stats.update(\n                    {\n                        name + \"_mean\": grad.mean().item(),\n                        name + \"_std\": grad.std().item(),\n                        name + \"_max\": grad.max().item(),\n                        name + \"_min\": grad.min().item(),\n                    }\n                )\n\n        writer.write(trainer.opt_result.iteration, gradient_stats)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCosineAnnealing","title":"<code>LRSchedulerCosineAnnealing(on, called_every, t_max, min_lr=0.0)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Applies cosine annealing to the learning rate during training.</p> <p>This callback decreases the learning rate following a cosine curve, starting from the initial learning rate and annealing to a minimum (min_lr).</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LRSchedulerCosineAnnealing</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCosineAnnealing\n\n# Create an instance of the LRSchedulerCosineAnnealing callback\nlr_cosine = LRSchedulerCosineAnnealing(on=\"train_batch_end\",\n                                       called_every=1,\n                                       t_max=5000,\n                                       min_lr=1e-6)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback\n    callbacks=[lr_cosine]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the LRSchedulerCosineAnnealing callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>t_max</code> <p>The total number of iterations for one annealing cycle.</p> <p> TYPE: <code>int</code> </p> <code>min_lr</code> <p>The minimum learning rate. Default is 0.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int, t_max: int, min_lr: float = 0.0):\n    \"\"\"Initializes the LRSchedulerCosineAnnealing callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n        t_max (int): The total number of iterations for one annealing cycle.\n        min_lr (float, optional): The minimum learning rate. Default is 0.0.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.t_max = t_max\n    self.min_lr = min_lr\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCosineAnnealing.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Adjusts the learning rate using cosine annealing.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Adjusts the learning rate using cosine annealing.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    for param_group in trainer.optimizer.param_groups:\n        max_lr = param_group[\"lr\"]\n        new_lr = (\n            self.min_lr\n            + (max_lr - self.min_lr)\n            * (1 + math.cos(math.pi * trainer.opt_result.iteration / self.t_max))\n            / 2\n        )\n        param_group[\"lr\"] = new_lr\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCyclic","title":"<code>LRSchedulerCyclic(on, called_every, base_lr, max_lr, step_size)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Applies a cyclic learning rate schedule during training.</p> <p>This callback oscillates the learning rate between a minimum (base_lr) and a maximum (max_lr) over a defined cycle length (step_size). The learning rate follows a triangular wave pattern.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LRSchedulerCyclic</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCyclic\n\n# Create an instance of the LRSchedulerCyclic callback\nlr_cyclic = LRSchedulerCyclic(on=\"train_batch_end\",\n                              called_every=1,\n                              base_lr=0.001,\n                              max_lr=0.01,\n                              step_size=2000)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback\n    callbacks=[lr_cyclic]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the LRSchedulerCyclic callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>base_lr</code> <p>The minimum learning rate.</p> <p> TYPE: <code>float</code> </p> <code>max_lr</code> <p>The maximum learning rate.</p> <p> TYPE: <code>float</code> </p> <code>step_size</code> <p>Number of iterations for half a cycle.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int, base_lr: float, max_lr: float, step_size: int):\n    \"\"\"Initializes the LRSchedulerCyclic callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n        base_lr (float): The minimum learning rate.\n        max_lr (float): The maximum learning rate.\n        step_size (int): Number of iterations for half a cycle.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.base_lr = base_lr\n    self.max_lr = max_lr\n    self.step_size = step_size\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerCyclic.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Adjusts the learning rate cyclically.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Adjusts the learning rate cyclically.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    cycle = trainer.opt_result.iteration // (2 * self.step_size)\n    x = abs(trainer.opt_result.iteration / self.step_size - 2 * cycle - 1)\n    scale = max(0, (1 - x))\n    new_lr = self.base_lr + (self.max_lr - self.base_lr) * scale\n    for param_group in trainer.optimizer.param_groups:\n        param_group[\"lr\"] = new_lr\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerStepDecay","title":"<code>LRSchedulerStepDecay(on, called_every, gamma=0.5)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Reduces the learning rate by a factor at regular intervals.</p> <p>This callback adjusts the learning rate by multiplying it with a decay factor after a specified number of iterations. The learning rate is updated as:     lr = lr * gamma</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LRSchedulerStepDecay</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerStepDecay\n\n# Create an instance of the LRSchedulerStepDecay callback\nlr_step_decay = LRSchedulerStepDecay(on=\"train_epoch_end\",\n                                     called_every=100,\n                                     gamma=0.5)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback\n    callbacks=[lr_step_decay]\n)\n</code></pre> <pre><code>\n</code></pre> </p> <p>Initializes the LRSchedulerStepDecay callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> <code>gamma</code> <p>The decay factor applied to the learning rate. A value &lt; 1 reduces the learning rate over time. Default is 0.5.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.5</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int, gamma: float = 0.5):\n    \"\"\"Initializes the LRSchedulerStepDecay callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n        gamma (float, optional): The decay factor applied to the learning rate.\n            A value &lt; 1 reduces the learning rate over time. Default is 0.5.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.gamma = gamma\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LRSchedulerStepDecay.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Runs the callback to apply step decay to the learning rate.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; None:\n    \"\"\"\n    Runs the callback to apply step decay to the learning rate.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter): The writer object for logging.\n    \"\"\"\n    for param_group in trainer.optimizer.param_groups:\n        param_group[\"lr\"] *= self.gamma\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LoadCheckpoint","title":"<code>LoadCheckpoint(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to load a model checkpoint.</p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LoadCheckpoint.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Loads a model checkpoint.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result of loading the checkpoint.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Loads a model checkpoint.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n\n    Returns:\n        Any: The result of loading the checkpoint.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        folder = config.log_folder\n        model = trainer.model\n        optimizer = trainer.optimizer\n        device = trainer.accelerator.execution.log_device\n        return load_checkpoint(folder, model, optimizer, device=device)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogHyperparameters","title":"<code>LogHyperparameters(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to log hyperparameters using the writer.</p> <p>The <code>LogHyperparameters</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>LogHyperparameters</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LogHyperparameters\n\n# Create an instance of the LogHyperparameters callback\nlog_hyper_callback = LogHyperparameters(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[log_hyper_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogHyperparameters.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Logs hyperparameters using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Logs hyperparameters using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        hyperparams = config.hyperparams\n        writer.log_hyperparams(hyperparams)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogModelTracker","title":"<code>LogModelTracker(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to log the model using the writer.</p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.LogModelTracker.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Logs the model using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Logs the model using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        model = trainer.model\n        writer.log_model(\n            model, trainer.train_dataloader, trainer.val_dataloader, trainer.test_dataloader\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PlotMetrics","title":"<code>PlotMetrics(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to plot metrics using the writer.</p> <p>The <code>PlotMetrics</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>PlotMetrics</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PlotMetrics\n\n# Create an instance of the PlotMetrics callback\nplot_metrics_callback = PlotMetrics(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[plot_metrics_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PlotMetrics.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Plots metrics using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Plots metrics using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        opt_result = trainer.opt_result\n        plotting_functions = config.plotting_functions\n        writer.plot(trainer.model, opt_result.iteration, plotting_functions)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PrintMetrics","title":"<code>PrintMetrics(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to print metrics using the writer.</p> <p>The <code>PrintMetrics</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>PrintMetrics</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PrintMetrics\n\n# Create an instance of the PrintMetrics callback\nprint_metrics_callback = PrintMetrics(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[print_metrics_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.PrintMetrics.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Prints metrics using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Prints metrics using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    opt_result = trainer.opt_result\n    writer.print_metrics(opt_result)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveBestCheckpoint","title":"<code>SaveBestCheckpoint(on, called_every)</code>","text":"<p>               Bases: <code>SaveCheckpoint</code></p> <p>Callback to save the best model checkpoint based on a validation criterion.</p> <p>Initializes the SaveBestCheckpoint callback.</p> PARAMETER DESCRIPTION <code>on</code> <p>The event to trigger the callback.</p> <p> TYPE: <code>str</code> </p> <code>called_every</code> <p>Frequency of callback calls in terms of iterations.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(self, on: str, called_every: int):\n    \"\"\"Initializes the SaveBestCheckpoint callback.\n\n    Args:\n        on (str): The event to trigger the callback.\n        called_every (int): Frequency of callback calls in terms of iterations.\n    \"\"\"\n    super().__init__(on=on, called_every=called_every)\n    self.best_loss = float(\"inf\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveBestCheckpoint.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Saves the checkpoint if the current loss is better than the best loss.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Saves the checkpoint if the current loss is better than the best loss.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        opt_result = trainer.opt_result\n        if config.validation_criterion and config.validation_criterion(\n            opt_result.loss, self.best_loss, config.val_epsilon\n        ):\n            self.best_loss = opt_result.loss\n\n            folder = config.log_folder\n            model = trainer.model\n            optimizer = trainer.optimizer\n            opt_result = trainer.opt_result\n            write_checkpoint(folder, model, optimizer, \"best\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveCheckpoint","title":"<code>SaveCheckpoint(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to save a model checkpoint.</p> <p>The <code>SaveCheckpoint</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>SaveCheckpoint</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveCheckpoint\n\n# Create an instance of the SaveCheckpoint callback\nsave_checkpoint_callback = SaveCheckpoint(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[save_checkpoint_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.SaveCheckpoint.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Saves a model checkpoint.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Saves a model checkpoint.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        folder = config.log_folder\n        model = trainer.model\n        optimizer = trainer.optimizer\n        opt_result = trainer.opt_result\n        write_checkpoint(folder, model, optimizer, opt_result.iteration)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.WriteMetrics","title":"<code>WriteMetrics(on='idle', called_every=1, callback=None, callback_condition=None, modify_optimize_result=None)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to write metrics using the writer.</p> <p>The <code>WriteMetrics</code> callback can be added to the <code>TrainConfig</code> callbacks as a custom user defined callback.</p> <p>Example Usage in <code>TrainConfig</code>: To use <code>WriteMetrics</code>, include it in the <code>callbacks</code> list when setting up your <code>TrainConfig</code>: <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import WriteMetrics\n\n# Create an instance of the WriteMetrics callback\nwrite_metrics_callback = WriteMetrics(on = \"val_batch_end\", called_every = 100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    # Print metrics every 1000 training epochs\n    print_every=1000,\n    # Add the custom callback that runs every 100 val_batch_end\n    callbacks=[write_metrics_callback]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def __init__(\n    self,\n    on: str | TrainingStage = \"idle\",\n    called_every: int = 1,\n    callback: CallbackFunction | None = None,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n):\n    if not isinstance(called_every, int):\n        raise ValueError(\"called_every must be a positive integer or 0\")\n\n    self.callback: CallbackFunction | None = callback\n    self.on: str | TrainingStage = on\n    self.called_every: int = called_every\n    self.callback_condition = (\n        callback_condition if callback_condition else Callback.default_callback\n    )\n\n    if isinstance(modify_optimize_result, dict):\n        self.modify_optimize_result = lambda opt_res: Callback.modify_opt_res_dict(\n            opt_res, modify_optimize_result\n        )\n    else:\n        self.modify_optimize_result = (\n            modify_optimize_result\n            if modify_optimize_result\n            else Callback.modify_opt_res_default\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.callback.WriteMetrics.run_callback","title":"<code>run_callback(trainer, config, writer)</code>","text":"<p>Writes metrics using the writer.</p> PARAMETER DESCRIPTION <code>trainer</code> <p>The training object.</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>writer</code> <p>The writer object for logging.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/callback.py</code> <pre><code>def run_callback(self, trainer: Any, config: TrainConfig, writer: BaseWriter) -&gt; Any:\n    \"\"\"Writes metrics using the writer.\n\n    Args:\n        trainer (Any): The training object.\n        config (TrainConfig): The configuration object.\n        writer (BaseWriter ): The writer object for logging.\n    \"\"\"\n    if trainer.accelerator.rank == 0:\n        opt_result = trainer.opt_result\n        writer.write(opt_result.iteration, opt_result.metrics)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer","title":"<code>BaseTrainer(model, optimizer, config, loss_fn='mse', optimize_step=optimize_step, train_dataloader=None, val_dataloader=None, test_dataloader=None, max_batches=None)</code>","text":"<p>Base class for training machine learning models using a given optimizer.</p> <p>The base class implements contextmanager for gradient based/free optimization, properties, property setters, input validations, callback decorator generator, and empty hooks for different training steps.</p> This class provides <ul> <li>Context managers for enabling/disabling gradient-based optimization</li> <li>Properties for managing models, optimizers, and dataloaders</li> <li>Input validations and a callback decorator generator</li> <li>Config and callback managers using the provided <code>TrainConfig</code></li> </ul> ATTRIBUTE DESCRIPTION <code>use_grad</code> <p>Indicates if gradients are used for optimization. Default is True.</p> <p> TYPE: <code>bool</code> </p> <code>model</code> <p>The neural network model.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The optimizer for training.</p> <p> TYPE: <code>Optimizer | Optimizer | None</code> </p> <code>config</code> <p>The configuration settings for training.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> </p> <code>optimize_step</code> <p>Function for performing an optimization step.</p> <p> TYPE: <code>Callable</code> </p> <code>loss_fn</code> <p>loss function to use. Default loss function used is 'mse'</p> <p> TYPE: <code>Callable | str ]</code> </p> <code>num_training_batches</code> <p>Number of training batches. In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int</code> </p> <code>num_validation_batches</code> <p>Number of validation batches. In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int</code> </p> <code>num_test_batches</code> <p>Number of test batches. In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int</code> </p> <code>state</code> <p>Current state in the training process</p> <p> TYPE: <code>str</code> </p> <p>Initializes the BaseTrainer.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to train.</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The optimizer for training.</p> <p> TYPE: <code>Optimizer | Optimizer | None</code> </p> <code>config</code> <p>The TrainConfig settings for training.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>The loss function to use. str input to be specified to use a default loss function. currently supported loss functions: 'mse', 'cross_entropy'. If not specified, default mse loss will be used.</p> <p> TYPE: <code>str | Callable</code> DEFAULT: <code>'mse'</code> </p> <code>train_dataloader</code> <p>DataLoader for training data. If the model does not need data to evaluate loss, no dataset should be provided.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>Dataloader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>max_batches</code> <p>Maximum number of batches to process per epoch. This is only valid in case of finite TensorDataset dataloaders. if max_batches is not None, the maximum number of batches used will be min(max_batches, len(dataloader.dataset)) In case of InfiniteTensorDataset only 1 batch per epoch is used.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def __init__(\n    self,\n    model: nn.Module,\n    optimizer: optim.Optimizer | NGOptimizer | None,\n    config: TrainConfig,\n    loss_fn: str | Callable = \"mse\",\n    optimize_step: Callable = optimize_step,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n    max_batches: int | None = None,\n):\n    \"\"\"\n    Initializes the BaseTrainer.\n\n    Args:\n        model (nn.Module): The model to train.\n        optimizer (optim.Optimizer | NGOptimizer | None): The optimizer\n            for training.\n        config (TrainConfig): The TrainConfig settings for training.\n        loss_fn (str | Callable): The loss function to use.\n            str input to be specified to use a default loss function.\n            currently supported loss functions: 'mse', 'cross_entropy'.\n            If not specified, default mse loss will be used.\n        train_dataloader (Dataloader | DictDataLoader | None): DataLoader for training data.\n            If the model does not need data to evaluate loss, no dataset\n            should be provided.\n        val_dataloader (Dataloader | DictDataLoader | None): DataLoader for validation data.\n        test_dataloader (Dataloader | DictDataLoader | None): DataLoader for testing data.\n        max_batches (int | None): Maximum number of batches to process per epoch.\n            This is only valid in case of finite TensorDataset dataloaders.\n            if max_batches is not None, the maximum number of batches used will\n            be min(max_batches, len(dataloader.dataset))\n            In case of InfiniteTensorDataset only 1 batch per epoch is used.\n    \"\"\"\n    self._model: nn.Module\n    self._optimizer: optim.Optimizer | NGOptimizer | None\n    self._config: TrainConfig\n    self._train_dataloader: DataLoader | DictDataLoader | None = None\n    self._val_dataloader: DataLoader | DictDataLoader | None = None\n    self._test_dataloader: DataLoader | DictDataLoader | None = None\n\n    self.config = config\n    self.model = model\n    self.optimizer = optimizer\n    self.max_batches = max_batches\n\n    self.num_training_batches: int\n    self.num_validation_batches: int\n    self.num_test_batches: int\n\n    self.train_dataloader = train_dataloader\n    self.val_dataloader = val_dataloader\n    self.test_dataloader = test_dataloader\n\n    self.loss_fn: Callable = get_loss_fn(loss_fn)\n    self.optimize_step: Callable = optimize_step\n    self.ng_params: ng.p.Array\n    self.training_stage: TrainingStage = TrainingStage(\"idle\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.config","title":"<code>config</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the training configuration.</p> RETURNS DESCRIPTION <code>TrainConfig</code> <p>The configuration object.</p> <p> TYPE: <code>TrainConfig</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.model","title":"<code>model</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the model if set, otherwise raises an error.</p> RETURNS DESCRIPTION <code>Module</code> <p>nn.Module: The model.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.optimizer","title":"<code>optimizer</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the optimizer if set, otherwise raises an error.</p> RETURNS DESCRIPTION <code>Optimizer | Optimizer | None</code> <p>optim.Optimizer | NGOptimizer | None: The optimizer.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.test_dataloader","title":"<code>test_dataloader</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the test DataLoader, validating its type.</p> RETURNS DESCRIPTION <code>DataLoader</code> <p>The DataLoader for testing data.</p> <p> TYPE: <code>DataLoader</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.train_dataloader","title":"<code>train_dataloader</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the training DataLoader, validating its type.</p> RETURNS DESCRIPTION <code>DataLoader</code> <p>The DataLoader for training data.</p> <p> TYPE: <code>DataLoader</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.use_grad","title":"<code>use_grad</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the optimization framework for the trainer.</p> <p>use_grad = True : Gradient based optimization use_grad = False : Gradient free optimization</p> RETURNS DESCRIPTION <code>bool</code> <p>Bool value for using gradient.</p> <p> TYPE: <code>bool</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.val_dataloader","title":"<code>val_dataloader</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the validation DataLoader, validating its type.</p> RETURNS DESCRIPTION <code>DataLoader</code> <p>The DataLoader for validation data.</p> <p> TYPE: <code>DataLoader</code> </p>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.callback","title":"<code>callback(phase)</code>  <code>staticmethod</code>","text":"<p>Decorator for executing callbacks before and after a phase.</p> <p>Phase are different hooks during the training. list of valid phases is defined in Callbacks. We also update the current state of the training process in the callback decorator.</p> PARAMETER DESCRIPTION <code>phase</code> <p>The phase for which the callback is executed (e.g., \"train\", \"train_epoch\", \"train_batch\").</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>The decorated function.</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@staticmethod\ndef callback(phase: str) -&gt; Callable:\n    \"\"\"\n    Decorator for executing callbacks before and after a phase.\n\n    Phase are different hooks during the training. list of valid\n    phases is defined in Callbacks.\n    We also update the current state of the training process in\n    the callback decorator.\n\n    Args:\n        phase (str): The phase for which the callback is executed (e.g., \"train\",\n            \"train_epoch\", \"train_batch\").\n\n    Returns:\n        Callable: The decorated function.\n    \"\"\"\n\n    def decorator(method: Callable) -&gt; Callable:\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -&gt; Any:\n            start_event = f\"{phase}_start\"\n            end_event = f\"{phase}_end\"\n\n            self.training_stage = TrainingStage(start_event)\n            self.callback_manager.run_callbacks(trainer=self)\n            result = method(self, *args, **kwargs)\n\n            self.training_stage = TrainingStage(end_event)\n            # build_optimize_result method is defined in the trainer.\n            self.build_optimize_result(result)\n            self.callback_manager.run_callbacks(trainer=self)\n\n            return result\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.disable_grad_opt","title":"<code>disable_grad_opt(optimizer=None)</code>","text":"<p>Context manager to temporarily disable gradient-based optimization.</p> PARAMETER DESCRIPTION <code>optimizer</code> <p>The Nevergrad optimizer to use. If no optimizer is provided, default optimizer for trainer object will be used.</p> <p> TYPE: <code>Optimizer</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@contextmanager\ndef disable_grad_opt(self, optimizer: NGOptimizer | None = None) -&gt; Iterator[None]:\n    \"\"\"\n    Context manager to temporarily disable gradient-based optimization.\n\n    Args:\n        optimizer (NGOptimizer): The Nevergrad optimizer to use.\n            If no optimizer is provided, default optimizer for trainer\n            object will be used.\n    \"\"\"\n    original_mode = self.use_grad\n    original_optimizer = self._optimizer\n    try:\n        self.use_grad = False\n        self.callback_manager.use_grad = False\n        self.optimizer = optimizer if optimizer else self.optimizer\n        yield\n    finally:\n        self.use_grad = original_mode\n        self.callback_manager.use_grad = original_mode\n        self.optimizer = original_optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.enable_grad_opt","title":"<code>enable_grad_opt(optimizer=None)</code>","text":"<p>Context manager to temporarily enable gradient-based optimization.</p> PARAMETER DESCRIPTION <code>optimizer</code> <p>The PyTorch optimizer to use. If no optimizer is provided, default optimizer for trainer object will be used.</p> <p> TYPE: <code>Optimizer</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@contextmanager\ndef enable_grad_opt(self, optimizer: optim.Optimizer | None = None) -&gt; Iterator[None]:\n    \"\"\"\n    Context manager to temporarily enable gradient-based optimization.\n\n    Args:\n        optimizer (optim.Optimizer): The PyTorch optimizer to use.\n            If no optimizer is provided, default optimizer for trainer\n            object will be used.\n    \"\"\"\n    original_mode = self.use_grad\n    original_optimizer = self._optimizer\n    try:\n        self.use_grad = True\n        self.callback_manager.use_grad = True\n        self.optimizer = optimizer if optimizer else self.optimizer\n        yield\n    finally:\n        self.use_grad = original_mode\n        self.callback_manager.use_grad = original_mode\n        self.optimizer = original_optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_test_batch_end","title":"<code>on_test_batch_end(test_batch_loss_metrics)</code>","text":"<p>Called at the end of each testing batch.</p> PARAMETER DESCRIPTION <code>test_batch_loss_metrics</code> <p>Metrics for the testing batch loss. tuple of (loss, metrics)</p> <p> TYPE: <code>tuple[Tensor, Any]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_test_batch_end(self, test_batch_loss_metrics: tuple[torch.Tensor, Any]) -&gt; None:\n    \"\"\"\n    Called at the end of each testing batch.\n\n    Args:\n        test_batch_loss_metrics: Metrics for the testing batch loss.\n            tuple of (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_test_batch_start","title":"<code>on_test_batch_start(batch)</code>","text":"<p>Called at the start of each testing batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>A batch of data from the DataLoader. Typically a tuple containing input tensors and corresponding target tensors.</p> <p> TYPE: <code>tuple[Tensor, ...] | None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_test_batch_start(self, batch: tuple[torch.Tensor, ...] | None) -&gt; None:\n    \"\"\"\n    Called at the start of each testing batch.\n\n    Args:\n        batch: A batch of data from the DataLoader. Typically a tuple containing\n            input tensors and corresponding target tensors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_batch_end","title":"<code>on_train_batch_end(train_batch_loss_metrics)</code>","text":"<p>Called at the end of each training batch.</p> PARAMETER DESCRIPTION <code>train_batch_loss_metrics</code> <p>Metrics for the training batch loss. tuple of (loss, metrics)</p> <p> TYPE: <code>tuple[Tensor, Any]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_batch_end(self, train_batch_loss_metrics: tuple[torch.Tensor, Any]) -&gt; None:\n    \"\"\"\n    Called at the end of each training batch.\n\n    Args:\n        train_batch_loss_metrics: Metrics for the training batch loss.\n            tuple of (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_batch_start","title":"<code>on_train_batch_start(batch)</code>","text":"<p>Called at the start of each training batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>A batch of data from the DataLoader. Typically a tuple containing input tensors and corresponding target tensors.</p> <p> TYPE: <code>tuple[Tensor, ...] | None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_batch_start(self, batch: tuple[torch.Tensor, ...] | None) -&gt; None:\n    \"\"\"\n    Called at the start of each training batch.\n\n    Args:\n        batch: A batch of data from the DataLoader. Typically a tuple containing\n            input tensors and corresponding target tensors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_end","title":"<code>on_train_end(train_losses, val_losses=None)</code>","text":"<p>Called at the end of training.</p> PARAMETER DESCRIPTION <code>train_losses</code> <p>Metrics for the training losses. list    -&gt; list                  -&gt; tuples Epochs  -&gt; Training Batches      -&gt; (loss, metrics)</p> <p> TYPE: <code>list[list[tuple[Tensor, Any]]]</code> </p> <code>val_losses</code> <p>Metrics for the validation losses. list    -&gt; list                  -&gt; tuples Epochs  -&gt; Validation Batches    -&gt; (loss, metrics)</p> <p> TYPE: <code>list[list[tuple[Tensor, Any]]] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_end(\n    self,\n    train_losses: list[list[tuple[torch.Tensor, Any]]],\n    val_losses: list[list[tuple[torch.Tensor, Any]]] | None = None,\n) -&gt; None:\n    \"\"\"\n    Called at the end of training.\n\n    Args:\n        train_losses (list[list[tuple[torch.Tensor, Any]]]):\n            Metrics for the training losses.\n            list    -&gt; list                  -&gt; tuples\n            Epochs  -&gt; Training Batches      -&gt; (loss, metrics)\n        val_losses (list[list[tuple[torch.Tensor, Any]]] | None):\n            Metrics for the validation losses.\n            list    -&gt; list                  -&gt; tuples\n            Epochs  -&gt; Validation Batches    -&gt; (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_epoch_end","title":"<code>on_train_epoch_end(train_epoch_loss_metrics)</code>","text":"<p>Called at the end of each training epoch.</p> PARAMETER DESCRIPTION <code>train_epoch_loss_metrics</code> <p>Metrics for the training epoch losses. list                  -&gt; tuples Training Batches      -&gt; (loss, metrics)</p> <p> TYPE: <code>list[tuple[Tensor, Any]]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_epoch_end(self, train_epoch_loss_metrics: list[tuple[torch.Tensor, Any]]) -&gt; None:\n    \"\"\"\n    Called at the end of each training epoch.\n\n    Args:\n        train_epoch_loss_metrics: Metrics for the training epoch losses.\n            list                  -&gt; tuples\n            Training Batches      -&gt; (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_epoch_start","title":"<code>on_train_epoch_start()</code>","text":"<p>Called at the start of each training epoch.</p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_epoch_start(self) -&gt; None:\n    \"\"\"Called at the start of each training epoch.\"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_train_start","title":"<code>on_train_start()</code>","text":"<p>Called at the start of training.</p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_train_start(self) -&gt; None:\n    \"\"\"Called at the start of training.\"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_batch_end","title":"<code>on_val_batch_end(val_batch_loss_metrics)</code>","text":"<p>Called at the end of each validation batch.</p> PARAMETER DESCRIPTION <code>val_batch_loss_metrics</code> <p>Metrics for the validation batch loss. tuple of (loss, metrics)</p> <p> TYPE: <code>tuple[Tensor, Any]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_batch_end(self, val_batch_loss_metrics: tuple[torch.Tensor, Any]) -&gt; None:\n    \"\"\"\n    Called at the end of each validation batch.\n\n    Args:\n        val_batch_loss_metrics: Metrics for the validation batch loss.\n            tuple of (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_batch_start","title":"<code>on_val_batch_start(batch)</code>","text":"<p>Called at the start of each validation batch.</p> PARAMETER DESCRIPTION <code>batch</code> <p>A batch of data from the DataLoader. Typically a tuple containing input tensors and corresponding target tensors.</p> <p> TYPE: <code>tuple[Tensor, ...] | None</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_batch_start(self, batch: tuple[torch.Tensor, ...] | None) -&gt; None:\n    \"\"\"\n    Called at the start of each validation batch.\n\n    Args:\n        batch: A batch of data from the DataLoader. Typically a tuple containing\n            input tensors and corresponding target tensors.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_epoch_end","title":"<code>on_val_epoch_end(val_epoch_loss_metrics)</code>","text":"<p>Called at the end of each validation epoch.</p> PARAMETER DESCRIPTION <code>val_epoch_loss_metrics</code> <p>Metrics for the validation epoch loss. list                    -&gt; tuples Validation Batches      -&gt; (loss, metrics)</p> <p> TYPE: <code>list[tuple[Tensor, Any]]</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_epoch_end(self, val_epoch_loss_metrics: list[tuple[torch.Tensor, Any]]) -&gt; None:\n    \"\"\"\n    Called at the end of each validation epoch.\n\n    Args:\n        val_epoch_loss_metrics: Metrics for the validation epoch loss.\n            list                    -&gt; tuples\n            Validation Batches      -&gt; (loss, metrics)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.on_val_epoch_start","title":"<code>on_val_epoch_start()</code>","text":"<p>Called at the start of each validation epoch.</p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>def on_val_epoch_start(self) -&gt; None:\n    \"\"\"Called at the start of each validation epoch.\"\"\"\n    pass\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.base_trainer.BaseTrainer.set_use_grad","title":"<code>set_use_grad(value)</code>  <code>classmethod</code>","text":"<p>Sets the global use_grad flag.</p> PARAMETER DESCRIPTION <code>value</code> <p>Whether to use gradient-based optimization.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>qadence/ml_tools/train_utils/base_trainer.py</code> <pre><code>@classmethod\ndef set_use_grad(cls, value: bool) -&gt; None:\n    \"\"\"\n    Sets the global use_grad flag.\n\n    Args:\n        value (bool): Whether to use gradient-based optimization.\n    \"\"\"\n    if not isinstance(value, bool):\n        raise TypeError(\"use_grad must be a boolean value.\")\n    cls._use_grad = value\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter","title":"<code>BaseWriter</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for experiment tracking writers.</p> METHOD DESCRIPTION <code>open</code> <p>Opens the writer and sets up the logging environment.</p> <code>close</code> <p>Closes the writer and finalizes any ongoing logging processes.</p> <code>print_metrics</code> <p>Prints metrics and loss in a formatted manner.</p> <code>write</code> <p>Writes the optimization results to the tracking tool.</p> <code>log_hyperparams</code> <p>Logs the hyperparameters to the tracking tool.</p> <code>plot</code> <p>Logs model plots using provided plotting functions.</p> <code>log_model</code> <p>Logs the model and any relevant information.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.close","title":"<code>close()</code>  <code>abstractmethod</code>","text":"<p>Closes the writer and finalizes logging.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef close(self) -&gt; None:\n    \"\"\"Closes the writer and finalizes logging.\"\"\"\n    raise NotImplementedError(\"Writers must implement a close method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.log_hyperparams","title":"<code>log_hyperparams(hyperparams)</code>  <code>abstractmethod</code>","text":"<p>Logs hyperparameters.</p> PARAMETER DESCRIPTION <code>hyperparams</code> <p>A dictionary of hyperparameters to log.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef log_hyperparams(self, hyperparams: dict) -&gt; None:\n    \"\"\"\n    Logs hyperparameters.\n\n    Args:\n        hyperparams (dict): A dictionary of hyperparameters to log.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a log_hyperparams method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.log_model","title":"<code>log_model(model, train_dataloader=None, val_dataloader=None, test_dataloader=None)</code>  <code>abstractmethod</code>","text":"<p>Logs the model and associated data.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to log.</p> <p> TYPE: <code>Module</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef log_model(\n    self,\n    model: Module,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; None:\n    \"\"\"\n    Logs the model and associated data.\n\n    Args:\n        model (Module): The model to log.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a log_model method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.open","title":"<code>open(config, iteration=None)</code>  <code>abstractmethod</code>","text":"<p>Opens the writer and prepares it for logging.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object containing settings for logging.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>iteration</code> <p>The iteration step to start logging from. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef open(self, config: TrainConfig, iteration: int | None = None) -&gt; Any:\n    \"\"\"\n    Opens the writer and prepares it for logging.\n\n    Args:\n        config: Configuration object containing settings for logging.\n        iteration (int, optional): The iteration step to start logging from.\n            Defaults to None.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement an open method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.plot","title":"<code>plot(model, iteration, plotting_functions)</code>  <code>abstractmethod</code>","text":"<p>Logs plots of the model using provided plotting functions.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to plot.</p> <p> TYPE: <code>Module</code> </p> <code>iteration</code> <p>The current iteration number.</p> <p> TYPE: <code>int</code> </p> <code>plotting_functions</code> <p>Functions used to generate plots.</p> <p> TYPE: <code>tuple[PlottingFunction, ...]</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef plot(\n    self,\n    model: Module,\n    iteration: int,\n    plotting_functions: tuple[PlottingFunction, ...],\n) -&gt; None:\n    \"\"\"\n    Logs plots of the model using provided plotting functions.\n\n    Args:\n        model (Module): The model to plot.\n        iteration (int): The current iteration number.\n        plotting_functions (tuple[PlottingFunction, ...]): Functions used to\n            generate plots.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a plot method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.print_metrics","title":"<code>print_metrics(result)</code>","text":"<p>Prints the metrics and loss in a readable format.</p> PARAMETER DESCRIPTION <code>result</code> <p>The optimization results to display.</p> <p> TYPE: <code>OptimizeResult</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def print_metrics(self, result: OptimizeResult) -&gt; None:\n    \"\"\"Prints the metrics and loss in a readable format.\n\n    Args:\n        result (OptimizeResult): The optimization results to display.\n    \"\"\"\n\n    # Find the key in result.metrics that contains \"loss\" (case-insensitive)\n    loss_key = next((k for k in result.metrics if \"loss\" in k.lower()), None)\n    initial = f\"P {result.rank: &gt;2}|{result.device: &lt;7}| Iteration {result.iteration: &gt;7}| \"\n    if loss_key:\n        loss_value = result.metrics[loss_key]\n        msg = initial + f\"{loss_key.title()}: {loss_value:.7f} -\"\n    else:\n        msg = initial + f\"Loss: None -\"\n    msg += \" \".join([f\"{k}: {v:.7f}\" for k, v in result.metrics.items() if k != loss_key])\n    print(msg)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.BaseWriter.write","title":"<code>write(iteration, metrics)</code>  <code>abstractmethod</code>","text":"<p>Logs the results of the current iteration.</p> PARAMETER DESCRIPTION <code>iteration</code> <p>The current training iteration.</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>A dictionary of metrics to log, where keys are metric names             and values are the corresponding metric values.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>@abstractmethod\ndef write(self, iteration: int, metrics: dict) -&gt; None:\n    \"\"\"\n    Logs the results of the current iteration.\n\n    Args:\n        iteration (int): The current training iteration.\n        metrics (dict): A dictionary of metrics to log, where keys are metric names\n                        and values are the corresponding metric values.\n    \"\"\"\n    raise NotImplementedError(\"Writers must implement a write method.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter","title":"<code>MLFlowWriter()</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for logging to MLflow.</p> ATTRIBUTE DESCRIPTION <code>run</code> <p>The active MLflow run.</p> <p> TYPE: <code>Run</code> </p> <code>mlflow</code> <p>The MLflow module.</p> <p> TYPE: <code>ModuleType</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def __init__(self) -&gt; None:\n    try:\n        from mlflow.entities import Run\n    except ImportError:\n        raise ImportError(\n            \"mlflow is not installed. Please install qadence with the mlflow feature: \"\n            \"`pip install qadence[mlflow]`.\"\n        )\n\n    self.run: Run\n    self.mlflow: ModuleType\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.close","title":"<code>close()</code>","text":"<p>Closes the MLflow run.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Closes the MLflow run.\"\"\"\n    if self.run:\n        self.mlflow.end_run()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.get_signature_from_dataloader","title":"<code>get_signature_from_dataloader(model, dataloader)</code>","text":"<p>Infers the signature of the model based on the input data from the dataloader.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to use for inference.</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>DataLoader for model inputs.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Optional[Any]: The inferred signature, if available.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def get_signature_from_dataloader(\n    self, model: Module, dataloader: DataLoader | DictDataLoader | None\n) -&gt; Any:\n    \"\"\"\n    Infers the signature of the model based on the input data from the dataloader.\n\n    Args:\n        model (Module): The model to use for inference.\n        dataloader (DataLoader | DictDataLoader |  None): DataLoader for model inputs.\n\n    Returns:\n        Optional[Any]: The inferred signature, if available.\n    \"\"\"\n    from mlflow.models import infer_signature\n\n    if dataloader is None:\n        return None\n\n    xs: InputData\n    xs, *_ = next(iter(dataloader))\n    preds = model(xs)\n\n    if isinstance(xs, Tensor):\n        xs = xs.detach().cpu().numpy()\n        preds = preds.detach().cpu().numpy()\n        return infer_signature(xs, preds)\n\n    return None\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.log_hyperparams","title":"<code>log_hyperparams(hyperparams)</code>","text":"<p>Logs hyperparameters to MLflow.</p> PARAMETER DESCRIPTION <code>hyperparams</code> <p>A dictionary of hyperparameters to log.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_hyperparams(self, hyperparams: dict) -&gt; None:\n    \"\"\"\n    Logs hyperparameters to MLflow.\n\n    Args:\n        hyperparams (dict): A dictionary of hyperparameters to log.\n    \"\"\"\n    if self.mlflow:\n        self.mlflow.log_params(hyperparams)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.log_model","title":"<code>log_model(model, train_dataloader=None, val_dataloader=None, test_dataloader=None)</code>","text":"<p>Logs the model and its signature to MLflow using the provided data loaders.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to log.</p> <p> TYPE: <code>Module</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_model(\n    self,\n    model: Module,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; None:\n    \"\"\"\n    Logs the model and its signature to MLflow using the provided data loaders.\n\n    Args:\n        model (Module): The model to log.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.\n    \"\"\"\n    if not self.mlflow:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n\n    signatures = self.get_signature_from_dataloader(model, train_dataloader)\n    self.mlflow.pytorch.log_model(model, artifact_path=\"model\", signature=signatures)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.open","title":"<code>open(config, iteration=None)</code>","text":"<p>Opens the MLflow writer and initializes an MLflow run.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object containing settings for logging.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>iteration</code> <p>The iteration step to start logging from. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>mlflow</code> <p>The MLflow module instance.</p> <p> TYPE: <code>ModuleType | None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def open(self, config: TrainConfig, iteration: int | None = None) -&gt; ModuleType | None:\n    \"\"\"\n    Opens the MLflow writer and initializes an MLflow run.\n\n    Args:\n        config: Configuration object containing settings for logging.\n        iteration (int, optional): The iteration step to start logging from.\n            Defaults to None.\n\n    Returns:\n        mlflow: The MLflow module instance.\n    \"\"\"\n    import mlflow\n\n    self.mlflow = mlflow\n    tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"\")\n    experiment_name = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", str(uuid4()))\n    run_name = os.getenv(\"MLFLOW_RUN_NAME\", str(uuid4()))\n\n    if self.mlflow:\n        self.mlflow.set_tracking_uri(tracking_uri)\n\n        # Create or get the experiment\n        exp_filter_string = f\"name = '{experiment_name}'\"\n        experiments = self.mlflow.search_experiments(filter_string=exp_filter_string)\n        if not experiments:\n            self.mlflow.create_experiment(name=experiment_name)\n\n        self.mlflow.set_experiment(experiment_name)\n        self.run = self.mlflow.start_run(run_name=run_name, nested=False)\n\n    return self.mlflow\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.plot","title":"<code>plot(model, iteration, plotting_functions)</code>","text":"<p>Logs plots of the model using provided plotting functions.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to plot.</p> <p> TYPE: <code>Module</code> </p> <code>iteration</code> <p>The current iteration number.</p> <p> TYPE: <code>int</code> </p> <code>plotting_functions</code> <p>Functions used to generate plots.</p> <p> TYPE: <code>tuple[PlottingFunction, ...]</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def plot(\n    self,\n    model: Module,\n    iteration: int,\n    plotting_functions: tuple[PlottingFunction, ...],\n) -&gt; None:\n    \"\"\"\n    Logs plots of the model using provided plotting functions.\n\n    Args:\n        model (Module): The model to plot.\n        iteration (int): The current iteration number.\n        plotting_functions (tuple[PlottingFunction, ...]): Functions used\n            to generate plots.\n    \"\"\"\n    if self.mlflow:\n        for pf in plotting_functions:\n            descr, fig = pf(model, iteration)\n            self.mlflow.log_figure(fig, descr)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.MLFlowWriter.write","title":"<code>write(iteration, metrics)</code>","text":"<p>Logs the results of the current iteration to MLflow.</p> PARAMETER DESCRIPTION <code>iteration</code> <p>The current training iteration.</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>A dictionary of metrics to log, where keys are metric names             and values are the corresponding metric values.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def write(self, iteration: int, metrics: dict) -&gt; None:\n    \"\"\"\n    Logs the results of the current iteration to MLflow.\n\n    Args:\n        iteration (int): The current training iteration.\n        metrics (dict): A dictionary of metrics to log, where keys are metric names\n                        and values are the corresponding metric values.\n    \"\"\"\n    if self.mlflow:\n        self.mlflow.log_metrics(metrics, step=iteration)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing.\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter","title":"<code>TensorBoardWriter()</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for logging to TensorBoard.</p> ATTRIBUTE DESCRIPTION <code>writer</code> <p>The TensorBoard SummaryWriter instance.</p> <p> TYPE: <code>SummaryWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def __init__(self) -&gt; None:\n    self.writer = None\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.close","title":"<code>close()</code>","text":"<p>Closes the TensorBoard writer.</p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Closes the TensorBoard writer.\"\"\"\n    if self.writer:\n        self.writer.close()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.log_hyperparams","title":"<code>log_hyperparams(hyperparams)</code>","text":"<p>Logs hyperparameters to TensorBoard.</p> PARAMETER DESCRIPTION <code>hyperparams</code> <p>A dictionary of hyperparameters to log.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_hyperparams(self, hyperparams: dict) -&gt; None:\n    \"\"\"\n    Logs hyperparameters to TensorBoard.\n\n    Args:\n        hyperparams (dict): A dictionary of hyperparameters to log.\n    \"\"\"\n    if self.writer:\n        self.writer.add_hparams(hyperparams, {})\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.log_model","title":"<code>log_model(model, train_dataloader=None, val_dataloader=None, test_dataloader=None)</code>","text":"<p>Logs the model.</p> <p>Currently not supported by TensorBoard.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to log.</p> <p> TYPE: <code>Module</code> </p> <code>train_dataloader</code> <p>DataLoader for training data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>val_dataloader</code> <p>DataLoader for validation data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> <code>test_dataloader</code> <p>DataLoader for testing data.</p> <p> TYPE: <code>DataLoader | DictDataLoader | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def log_model(\n    self,\n    model: Module,\n    train_dataloader: DataLoader | DictDataLoader | None = None,\n    val_dataloader: DataLoader | DictDataLoader | None = None,\n    test_dataloader: DataLoader | DictDataLoader | None = None,\n) -&gt; None:\n    \"\"\"\n    Logs the model.\n\n    Currently not supported by TensorBoard.\n\n    Args:\n        model (Module): The model to log.\n        train_dataloader (DataLoader | DictDataLoader |  None): DataLoader for training data.\n        val_dataloader (DataLoader | DictDataLoader |  None): DataLoader for validation data.\n        test_dataloader (DataLoader | DictDataLoader |  None): DataLoader for testing data.\n    \"\"\"\n    logger.warning(\"Model logging is not supported by tensorboard. No model will be logged.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.open","title":"<code>open(config, iteration=None)</code>","text":"<p>Opens the TensorBoard writer.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration object containing settings for logging.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>iteration</code> <p>The iteration step to start logging from. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SummaryWriter</code> <p>The initialized TensorBoard writer.</p> <p> TYPE: <code>SummaryWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def open(self, config: TrainConfig, iteration: int | None = None) -&gt; SummaryWriter:\n    \"\"\"\n    Opens the TensorBoard writer.\n\n    Args:\n        config: Configuration object containing settings for logging.\n        iteration (int, optional): The iteration step to start logging from.\n            Defaults to None.\n\n    Returns:\n        SummaryWriter: The initialized TensorBoard writer.\n    \"\"\"\n    log_dir = str(config.log_folder)\n    purge_step = iteration if isinstance(iteration, int) else None\n    self.writer = SummaryWriter(log_dir=log_dir, purge_step=purge_step)\n    return self.writer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.plot","title":"<code>plot(model, iteration, plotting_functions)</code>","text":"<p>Logs plots of the model using provided plotting functions.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to plot.</p> <p> TYPE: <code>Module</code> </p> <code>iteration</code> <p>The current iteration number.</p> <p> TYPE: <code>int</code> </p> <code>plotting_functions</code> <p>Functions used to generate plots.</p> <p> TYPE: <code>tuple[PlottingFunction, ...]</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def plot(\n    self,\n    model: Module,\n    iteration: int,\n    plotting_functions: tuple[PlottingFunction, ...],\n) -&gt; None:\n    \"\"\"\n    Logs plots of the model using provided plotting functions.\n\n    Args:\n        model (Module): The model to plot.\n        iteration (int): The current iteration number.\n        plotting_functions (tuple[PlottingFunction, ...]): Functions used\n            to generate plots.\n    \"\"\"\n    if self.writer:\n        for pf in plotting_functions:\n            descr, fig = pf(model, iteration)\n            self.writer.add_figure(descr, fig, global_step=iteration)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.TensorBoardWriter.write","title":"<code>write(iteration, metrics)</code>","text":"<p>Logs the results of the current iteration to TensorBoard.</p> PARAMETER DESCRIPTION <code>iteration</code> <p>The current training iteration.</p> <p> TYPE: <code>int</code> </p> <code>metrics</code> <p>A dictionary of metrics to log, where keys are metric names             and values are the corresponding metric values.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def write(self, iteration: int, metrics: dict) -&gt; None:\n    \"\"\"\n    Logs the results of the current iteration to TensorBoard.\n\n    Args:\n        iteration (int): The current training iteration.\n        metrics (dict): A dictionary of metrics to log, where keys are metric names\n                        and values are the corresponding metric values.\n    \"\"\"\n    if self.writer:\n        for key, value in metrics.items():\n            self.writer.add_scalar(key, value, iteration)\n    else:\n        raise RuntimeError(\n            \"The writer is not initialized.\"\n            \"Please call the 'writer.open()' method before writing.\"\n        )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.callbacks.writer_registry.get_writer","title":"<code>get_writer(tracking_tool)</code>","text":"<p>Factory method to get the appropriate writer based on the tracking tool.</p> PARAMETER DESCRIPTION <code>tracking_tool</code> <p>The experiment tracking tool to use.</p> <p> TYPE: <code>ExperimentTrackingTool</code> </p> RETURNS DESCRIPTION <code>BaseWriter</code> <p>An instance of the appropriate writer.</p> <p> TYPE: <code>BaseWriter</code> </p> Source code in <code>qadence/ml_tools/callbacks/writer_registry.py</code> <pre><code>def get_writer(tracking_tool: ExperimentTrackingTool) -&gt; BaseWriter:\n    \"\"\"Factory method to get the appropriate writer based on the tracking tool.\n\n    Args:\n        tracking_tool (ExperimentTrackingTool): The experiment tracking tool to use.\n\n    Returns:\n        BaseWriter: An instance of the appropriate writer.\n    \"\"\"\n    writer_class = WRITER_REGISTRY.get(tracking_tool)\n    if writer_class:\n        return writer_class()\n    else:\n        raise ValueError(f\"Unsupported tracking tool: {tracking_tool}\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent","title":"<code>InformationContent(model, loss_fn, xs, epsilons, variation_multiple=20)</code>","text":"<p>Information Landscape class.</p> <p>This class handles the study of loss landscape from information theoretic perspective and provides methods to get bounds on the norm of the gradient from the Information Content of the loss landscape.</p> PARAMETER DESCRIPTION <code>model</code> <p>The quantum or classical model to analyze.</p> <p> TYPE: <code>Module</code> </p> <code>loss_fn</code> <p>Loss function that takes model output and calculates loss</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>Input data to evaluate the model on</p> <p> TYPE: <code>Any</code> </p> <code>epsilons</code> <p>The thresholds to use for discretization of the finite derivatives</p> <p> TYPE: <code>Tensor</code> </p> <code>variation_multiple</code> <p>The number of sets of variational parameters to generate per each variational parameter. The number of variational parameters required for the statistical analysis scales linearly with the amount of them present in the model. This is that linear factor.</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> Notes <p>This class provides flexibility in terms of what the model, the loss function, and the xs are. The only requirement is that the loss_fn takes the model and xs as arguments and returns the loss, and another dictionary of other metrics.</p> <p>Thus, assumed structure:     loss_fn(model, xs) -&gt; (loss, metrics, ...)</p> <p>Example: A Classifier     <pre><code>model = nn.Linear(10, 1)\n\ndef loss_fn(\n    model: nn.Module,\n    xs: tuple[torch.Tensor, torch.Tensor]\n) -&gt; tuple[torch.Tensor, dict[str, float]:\n    criterion = nn.MSELoss()\n    inputs, labels = xs\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    metrics = {\"loss\": loss.item()}\n    return loss, metrics\n\nxs = (torch.randn(10, 10), torch.randn(10, 1))\n\ninfo_landscape = InfoLandscape(model, loss_fn, xs)\n</code></pre>     In this example, the model is a linear classifier, and the <code>xs</code> include both the     inputs and the target labels. The logic for calculation of the loss from this lies     entirely within the <code>loss_fn</code> function. This can then further be used to obtain the     bounds on the average norm of the gradient of the loss function.</p> <p>Example: A Physics Informed Neural Network     <pre><code>class PhysicsInformedNN(nn.Module):\n    // &lt;Initialization Logic&gt;\n\n    def forward(self, xs: dict[str, torch.Tensor]):\n        return {\n            \"pde_residual\": pde_residual(xs[\"pde\"]),\n            \"boundary_condition\": bc_term(xs[\"bc\"]),\n        }\n\ndef loss_fn(\n    model: PhysicsInformedNN,\n    xs: dict[str, torch.Tensor]\n) -&gt; tuple[torch.Tensor, dict[str, float]:\n    pde_residual, bc_term = model(xs)\n    loss = torch.mean(torch.sum(pde_residual**2, dim=1), dim=0)\n        + torch.mean(torch.sum(bc_term**2, dim=1), dim=0)\n\n    return loss, {\"pde_residual\": pde_residual, \"bc_term\": bc_term}\n\nxs = {\n    \"pde\": torch.linspace(0, 1, 10),\n    \"bc\": torch.tensor([0.0]),\n}\n\ninfo_landscape = InfoLandscape(model, loss_fn, xs)\n</code></pre></p> <pre><code>In this example, the model is a Physics Informed Neural Network, and the `xs`\nare the inputs to the different residual components of the model. The logic\nfor calculation of the residuals lies within the PhysicsInformedNN class, and\nthe loss function is defined to calculate the loss that is to be optimized\nfrom these residuals. This can then further be used to obtain the\nbounds on the average norm of the gradient of the loss function.\n</code></pre> <p>The first value that the <code>loss_fn</code> returns is the loss value that is being optimized. The function is also expected to return other value(s), often the metrics that are used to calculate the loss. These values are ignored for the purpose of this class.</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def __init__(\n    self,\n    model: nn.Module,\n    loss_fn: Callable,\n    xs: Any,\n    epsilons: torch.Tensor,\n    variation_multiple: int = 20,\n) -&gt; None:\n    \"\"\"Information Landscape class.\n\n    This class handles the study of loss landscape from information theoretic\n    perspective and provides methods to get bounds on the norm of the\n    gradient from the Information Content of the loss landscape.\n\n    Args:\n        model: The quantum or classical model to analyze.\n        loss_fn: Loss function that takes model output and calculates loss\n        xs: Input data to evaluate the model on\n        epsilons: The thresholds to use for discretization of the finite derivatives\n        variation_multiple: The number of sets of variational parameters to generate per each\n            variational parameter. The number of variational parameters required for the\n            statistical analysis scales linearly with the amount of them present in the\n            model. This is that linear factor.\n\n    Notes:\n        This class provides flexibility in terms of what the model, the loss function,\n        and the xs are. The only requirement is that the loss_fn takes the model and xs as\n        arguments and returns the loss, and another dictionary of other metrics.\n\n        Thus, assumed structure:\n            loss_fn(model, xs) -&gt; (loss, metrics, ...)\n\n        Example: A Classifier\n            ```python\n            model = nn.Linear(10, 1)\n\n            def loss_fn(\n                model: nn.Module,\n                xs: tuple[torch.Tensor, torch.Tensor]\n            ) -&gt; tuple[torch.Tensor, dict[str, float]:\n                criterion = nn.MSELoss()\n                inputs, labels = xs\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                metrics = {\"loss\": loss.item()}\n                return loss, metrics\n\n            xs = (torch.randn(10, 10), torch.randn(10, 1))\n\n            info_landscape = InfoLandscape(model, loss_fn, xs)\n            ```\n            In this example, the model is a linear classifier, and the `xs` include both the\n            inputs and the target labels. The logic for calculation of the loss from this lies\n            entirely within the `loss_fn` function. This can then further be used to obtain the\n            bounds on the average norm of the gradient of the loss function.\n\n        Example: A Physics Informed Neural Network\n            ```python\n            class PhysicsInformedNN(nn.Module):\n                // &lt;Initialization Logic&gt;\n\n                def forward(self, xs: dict[str, torch.Tensor]):\n                    return {\n                        \"pde_residual\": pde_residual(xs[\"pde\"]),\n                        \"boundary_condition\": bc_term(xs[\"bc\"]),\n                    }\n\n            def loss_fn(\n                model: PhysicsInformedNN,\n                xs: dict[str, torch.Tensor]\n            ) -&gt; tuple[torch.Tensor, dict[str, float]:\n                pde_residual, bc_term = model(xs)\n                loss = torch.mean(torch.sum(pde_residual**2, dim=1), dim=0)\n                    + torch.mean(torch.sum(bc_term**2, dim=1), dim=0)\n\n                return loss, {\"pde_residual\": pde_residual, \"bc_term\": bc_term}\n\n            xs = {\n                \"pde\": torch.linspace(0, 1, 10),\n                \"bc\": torch.tensor([0.0]),\n            }\n\n            info_landscape = InfoLandscape(model, loss_fn, xs)\n            ```\n\n            In this example, the model is a Physics Informed Neural Network, and the `xs`\n            are the inputs to the different residual components of the model. The logic\n            for calculation of the residuals lies within the PhysicsInformedNN class, and\n            the loss function is defined to calculate the loss that is to be optimized\n            from these residuals. This can then further be used to obtain the\n            bounds on the average norm of the gradient of the loss function.\n\n        The first value that the `loss_fn` returns is the loss value that is being optimized.\n        The function is also expected to return other value(s), often the metrics that are\n        used to calculate the loss. These values are ignored for the purpose of this class.\n    \"\"\"\n    self.model = model\n    self.loss_fn = loss_fn\n    self.xs = xs\n    self.epsilons = epsilons\n    self.device = next(model.parameters()).device\n\n    self.param_shapes = {}\n    self.total_params = 0\n\n    for name, param in model.named_parameters():\n        self.param_shapes[name] = param.shape\n        self.total_params += param.numel()\n    self.n_variations = variation_multiple * self.total_params\n    self.all_variations = torch.empty(\n        (self.n_variations, self.total_params), device=self.device\n    ).uniform_(0, 2 * torch.pi)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.calculate_IC","title":"<code>calculate_IC</code>  <code>cached</code> <code>property</code>","text":"<p>Calculate Information Content for multiple epsilon values.</p> <p>Returns: Tensor of IC values for each epsilon [n_epsilons]</p>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.batched_loss","title":"<code>batched_loss()</code>","text":"<p>Calculate loss for all parameter variations in a batched manner.</p> <p>Returns: Tensor of loss values for each parameter variation</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def batched_loss(self) -&gt; torch.Tensor:\n    \"\"\"Calculate loss for all parameter variations in a batched manner.\n\n    Returns: Tensor of loss values for each parameter variation\n    \"\"\"\n    param_variations = self.reshape_param_variations()\n    losses = torch.zeros(self.n_variations, device=self.device)\n\n    for i in range(self.n_variations):\n        params = {name: param[i] for name, param in param_variations.items()}\n        current_model = lambda x: functional_call(self.model, params, (x,))\n        losses[i] = self.loss_fn(current_model, self.xs)[0]\n\n    return losses\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.calculate_transition_probabilities_batch","title":"<code>calculate_transition_probabilities_batch()</code>","text":"<p>Calculate transition probabilities for multiple epsilon values.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor of shape [n_epsilons, 6] containing probabilities for each transition type</p> <code>Tensor</code> <p>Columns order: [+1to0, +1to-1, 0to+1, 0to-1, -1to0, -1to+1]</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def calculate_transition_probabilities_batch(self) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate transition probabilities for multiple epsilon values.\n\n    Returns:\n        Tensor of shape [n_epsilons, 6] containing probabilities for each transition type\n        Columns order: [+1to0, +1to-1, 0to+1, 0to-1, -1to0, -1to+1]\n    \"\"\"\n    discretized = self.discretize_derivatives()\n\n    current = discretized[:, :-1]\n    next_val = discretized[:, 1:]\n\n    transitions = torch.stack(\n        [\n            ((current == 1) &amp; (next_val == 0)).sum(dim=1),\n            ((current == 1) &amp; (next_val == -1)).sum(dim=1),\n            ((current == 0) &amp; (next_val == 1)).sum(dim=1),\n            ((current == 0) &amp; (next_val == -1)).sum(dim=1),\n            ((current == -1) &amp; (next_val == 0)).sum(dim=1),\n            ((current == -1) &amp; (next_val == 1)).sum(dim=1),\n        ],\n        dim=1,\n    ).float()\n\n    total_transitions = current.size(1)\n    probabilities = transitions / total_transitions\n\n    return probabilities\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.discretize_derivatives","title":"<code>discretize_derivatives()</code>","text":"<p>Convert finite derivatives into discrete values.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor containing discretized derivatives with shape [n_epsilons, n_variations-2]</p> <code>Tensor</code> <p>Each row contains {-1, 0, 1} values for that epsilon</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def discretize_derivatives(self) -&gt; torch.Tensor:\n    \"\"\"\n    Convert finite derivatives into discrete values.\n\n    Returns:\n        Tensor containing discretized derivatives with shape [n_epsilons, n_variations-2]\n        Each row contains {-1, 0, 1} values for that epsilon\n    \"\"\"\n    derivatives = self.randomized_finite_der()\n\n    derivatives = derivatives.unsqueeze(0)\n    epsilons = self.epsilons.unsqueeze(1)\n\n    discretized = torch.zeros((len(epsilons), len(derivatives[0])), device=self.device)\n    discretized[derivatives &gt; epsilons] = 1\n    discretized[derivatives &lt; -epsilons] = -1\n\n    return discretized\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.get_grad_norm_bounds_max_IC","title":"<code>get_grad_norm_bounds_max_IC()</code>","text":"<p>Compute the bounds on the average norm of the gradient.</p> RETURNS DESCRIPTION <code>tuple[float, float]</code> <p>tuple[Tensor, Tensor]: The lower and upper bounds.</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def get_grad_norm_bounds_max_IC(self) -&gt; tuple[float, float]:\n    \"\"\"\n    Compute the bounds on the average norm of the gradient.\n\n    Returns:\n        tuple[Tensor, Tensor]: The lower and upper bounds.\n    \"\"\"\n    max_IC, epsilon_m = self.max_IC()\n    lower_bound = (\n        epsilon_m\n        * sqrt(self.total_params)\n        / (NormalDist().inv_cdf(1 - 2 * self.q_value(max_IC)))\n    )\n    upper_bound = (\n        epsilon_m\n        * sqrt(self.total_params)\n        / (NormalDist().inv_cdf(0.5 * (1 + 2 * self.q_value(max_IC))))\n    )\n\n    if max_IC &lt; log(2, 6):\n        logger.warning(\n            \"Warning: The maximum IC is less than the required value. The bounds may be\"\n            + \" inaccurate.\"\n        )\n\n    return lower_bound, upper_bound\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.get_grad_norm_bounds_sensitivity_IC","title":"<code>get_grad_norm_bounds_sensitivity_IC(eta)</code>","text":"<p>Compute the bounds on the average norm of the gradient.</p> PARAMETER DESCRIPTION <code>eta</code> <p>The sensitivity IC.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The lower bound.</p> <p> TYPE: <code>float</code> </p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def get_grad_norm_bounds_sensitivity_IC(self, eta: float) -&gt; float:\n    \"\"\"\n    Compute the bounds on the average norm of the gradient.\n\n    Args:\n        eta (float): The sensitivity IC.\n\n    Returns:\n        Tensor: The lower bound.\n    \"\"\"\n    epsilon_sensitivity = self.sensitivity_IC(eta)\n    upper_bound = (\n        epsilon_sensitivity * sqrt(self.total_params) / (NormalDist().inv_cdf(1 - 3 * eta / 2))\n    )\n    return upper_bound\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.max_IC","title":"<code>max_IC()</code>","text":"<p>Get the maximum Information Content and its corresponding epsilon.</p> <p>Returns: Tuple of (maximum IC value, optimal epsilon)</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def max_IC(self) -&gt; tuple[float, float]:\n    \"\"\"\n    Get the maximum Information Content and its corresponding epsilon.\n\n    Returns: Tuple of (maximum IC value, optimal epsilon)\n    \"\"\"\n    max_ic, max_idx = torch.max(self.calculate_IC, dim=0)\n    max_epsilon = self.epsilons[max_idx]\n    return max_ic.item(), max_epsilon.item()\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.q_value","title":"<code>q_value(H_value)</code>  <code>cached</code> <code>staticmethod</code>","text":"<p>Compute the q value.</p> <p>q is the solution to the equation: H(x) = 4h(x) + 2h(1/2 - 2x)</p> <p>It is the value of the probability of 4 of the 6 transitions such that the IC is the same as the IC of our system.</p> <p>This quantity is useful in calculating the bounds on the norms of the gradients.</p> PARAMETER DESCRIPTION <code>H_value</code> <p>The information content.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>float</code> <p>The q value</p> <p> TYPE: <code>float</code> </p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>@staticmethod\n@functools.lru_cache\ndef q_value(H_value: float) -&gt; float:\n    \"\"\"\n    Compute the q value.\n\n    q is the solution to the equation:\n    H(x) = 4h(x) + 2h(1/2 - 2x)\n\n    It is the value of the probability of 4 of the 6 transitions such that\n    the IC is the same as the IC of our system.\n\n    This quantity is useful in calculating the bounds on the norms of the gradients.\n\n    Args:\n        H_value (float): The information content.\n\n    Returns:\n        float: The q value\n    \"\"\"\n\n    x = torch.linspace(0.001, 0.16667, 10000)\n\n    H = -4 * x * torch.log(x) / torch.log(torch.tensor(6)) - 2 * (0.5 - 2 * x) * torch.log(\n        0.5 - 2 * x\n    ) / torch.log(torch.tensor(6))\n    err = torch.abs(H - H_value)\n    idx = torch.argmin(err)\n    return float(x[idx].item())\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.randomized_finite_der","title":"<code>randomized_finite_der()</code>","text":"<p>Calculate normalized finite difference of loss on doing random walk in the parameter space.</p> <p>This serves as a proxy for the derivative of the loss with respect to parameters.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>Tensor containing normalized finite differences (approximate directional derivatives)</p> <code>Tensor</code> <p>between consecutive points in the random walk. Shape: [n_variations - 1]</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def randomized_finite_der(self) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate normalized finite difference of loss on doing random walk in the parameter space.\n\n    This serves as a proxy for the derivative of the loss with respect to parameters.\n\n    Returns:\n        Tensor containing normalized finite differences (approximate directional derivatives)\n        between consecutive points in the random walk. Shape: [n_variations - 1]\n    \"\"\"\n    losses = self.batched_loss()\n\n    return (losses[1:] - losses[:-1]) / (\n        torch.norm(self.all_variations[1:] - self.all_variations[:-1], dim=1) + 1e-8\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.reshape_param_variations","title":"<code>reshape_param_variations()</code>","text":"<p>Reshape variations of the model's variational parameters.</p> RETURNS DESCRIPTION <code>dict[str, Tensor]</code> <p>Dictionary of parameter tensors, each with shape [n_variations, *param_shape]</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def reshape_param_variations(self) -&gt; dict[str, torch.Tensor]:\n    \"\"\"Reshape variations of the model's variational parameters.\n\n    Returns:\n        Dictionary of parameter tensors, each with shape [n_variations, *param_shape]\n    \"\"\"\n    param_variations = {}\n    start_idx = 0\n\n    for name, shape in self.param_shapes.items():\n        param_size = torch.prod(torch.tensor(shape)).item()\n        param_variations[name] = self.all_variations[\n            :, start_idx : start_idx + param_size\n        ].view(self.n_variations, *shape)\n        start_idx += param_size\n\n    return param_variations\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.information.information_content.InformationContent.sensitivity_IC","title":"<code>sensitivity_IC(eta)</code>","text":"<p>Find the minimum value of epsilon such that the information content is less than eta.</p> PARAMETER DESCRIPTION <code>eta</code> <p>Threshold value, the sensitivity IC.</p> <p> TYPE: <code>float</code> </p> <p>Returns: The epsilon value that gives IC that is less than the sensitivity IC.</p> Source code in <code>qadence/ml_tools/information/information_content.py</code> <pre><code>def sensitivity_IC(self, eta: float) -&gt; float:\n    \"\"\"\n    Find the minimum value of epsilon such that the information content is less than eta.\n\n    Args:\n        eta: Threshold value, the sensitivity IC.\n\n    Returns: The epsilon value that gives IC that is less than the sensitivity IC.\n    \"\"\"\n    ic_values = self.calculate_IC\n    mask = ic_values &lt; eta\n    epsilons = self.epsilons[mask]\n    return float(epsilons.min().item())\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator","title":"<code>Accelerator(nprocs=1, compute_setup='auto', log_setup='cpu', backend='gloo', dtype=None)</code>","text":"<p>               Bases: <code>Distributor</code></p> <p>A class for handling distributed training.</p> <p>This class extends <code>Distributor</code> to manage distributed training using PyTorch's <code>torch.distributed</code> API. It supports spawning multiple processes and wrapping models with <code>DistributedDataParallel</code> (DDP) when required.</p> <p>This class is provides head level method - distribute() - which wraps a function at a head process level, before launching <code>nprocs</code> processes as required. Furthermore, it provides processes level methods, such as prepare(), and prepare_batch() which can be run inside each process for correct movement and preparation of model, optimizers and datasets.</p> Inherited Attributes <p>nprocs (int): Number of processes to launch for distributed training. execution (BaseExecution): Detected execution instance for process launch (e.g., \"torchrun\",\"default\"). execution_type (ExecutionType): Type of execution used. rank (int): Global rank of the process (to be set during environment setup). world_size (int): Total number of processes (to be set during environment setup). local_rank (int | None): Local rank on the node (to be set during environment setup). master_addr (str): Master node address (to be set during environment setup). master_port (str): Master node port (to be set during environment setup). node_rank (int): Rank of the node on the cluster setup.</p> There are three different indicators for number of processes executed. <ul> <li> <ol> <li>self._config_nprocs: Number of processes specified by the user. Provided in the initilization of the Accelerator. (acc = Accelerator(nprocs = 2))</li> </ol> </li> <li> <ol> <li>self.nprocs: Number of processes defined at the head level.</li> <li>When accelerator is used to spawn processes (e.g., In case default, python execution), nprocs = _config_nprocs.</li> <li>When an external elastic method is used to spawn processes (e.g., In case of torchrun), nprocs = 1. This is because the external launcher already spawns multiple processes, and the accelerator init is called from each process.</li> </ol> </li> <li> <ol> <li>self.world_size: Number of processes actually executed.</li> </ol> </li> </ul> <p>Initializes the Accelerator class.</p> PARAMETER DESCRIPTION <code>nprocs</code> <p>Number of processes to launch. Default is 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>compute_setup</code> <p>Compute device setup; options are \"auto\" (default), \"gpu\", or \"cpu\". - \"auto\": Uses GPU if available, otherwise CPU. - \"gpu\": Forces GPU usage, raising an error if no CUDA device is available. - \"cpu\": Forces CPU usage.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'auto'</code> </p> <code>log_setup</code> <p>Logging device setup; options are \"auto\", \"cpu\" (default). - \"auto\": Uses same device to log as used for computation. - \"cpu\": Forces CPU logging.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <code>backend</code> <p>The backend for distributed communication. Default is \"gloo\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'gloo'</code> </p> <code>dtype</code> <p>Data type for controlling numerical precision. Default is None.</p> <p> TYPE: <code>dtype | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def __init__(\n    self,\n    nprocs: int = 1,\n    compute_setup: str = \"auto\",\n    log_setup: str = \"cpu\",\n    backend: str = \"gloo\",\n    dtype: torch_dtype | None = None,\n) -&gt; None:\n    \"\"\"\n    Initializes the Accelerator class.\n\n    Args:\n        nprocs (int): Number of processes to launch. Default is 1.\n        compute_setup (str): Compute device setup; options are \"auto\" (default), \"gpu\", or \"cpu\".\n            - \"auto\": Uses GPU if available, otherwise CPU.\n            - \"gpu\": Forces GPU usage, raising an error if no CUDA device is available.\n            - \"cpu\": Forces CPU usage.\n        log_setup (str): Logging device setup; options are \"auto\", \"cpu\" (default).\n            - \"auto\": Uses same device to log as used for computation.\n            - \"cpu\": Forces CPU logging.\n        backend (str): The backend for distributed communication. Default is \"gloo\".\n        dtype (torch.dtype | None): Data type for controlling numerical precision. Default is None.\n    \"\"\"\n    super().__init__(nprocs, compute_setup, log_setup, backend, dtype)\n\n    # Default values\n    self.rank = 0\n    self.local_rank = 0\n    self.world_size = self.execution.get_world_size(0, self.nprocs)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.all_reduce_dict","title":"<code>all_reduce_dict(d, op='mean')</code>","text":"<p>Performs an all-reduce operation on a dictionary of tensors, averaging values across all processes.</p> PARAMETER DESCRIPTION <code>d</code> <p>A dictionary where values are tensors to be reduced across processes.</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> <code>op</code> <p>Operation method to all_reduce with. Available options include <code>sum</code>, <code>avg</code>, and <code>max</code>.             Defaults to <code>avg</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>dict[str, Tensor]</code> <p>dict[str, torch.Tensor]: A dictionary with the reduced tensors, averaged over the world size.</p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def all_reduce_dict(\n    self, d: dict[str, torch.Tensor], op: str = \"mean\"\n) -&gt; dict[str, torch.Tensor]:\n    \"\"\"\n    Performs an all-reduce operation on a dictionary of tensors, averaging values across all processes.\n\n    Args:\n        d (dict[str, torch.Tensor]): A dictionary where values are tensors to be reduced across processes.\n        op (str): Operation method to all_reduce with. Available options include `sum`, `avg`, and `max`.\n                        Defaults to `avg`\n\n    Returns:\n        dict[str, torch.Tensor]: A dictionary with the reduced tensors, averaged over the world size.\n    \"\"\"\n    if dist.is_initialized():\n        world_size = dist.get_world_size()\n        reduced: dict[str, torch.Tensor] = {}\n        for key, tensor in d.items():\n            if not isinstance(tensor, torch.Tensor):\n                tensor = torch.tensor(\n                    tensor, device=self.execution.device, dtype=self.execution.data_dtype\n                )\n            tensor = tensor.detach().clone()\n            if op == \"max\":\n                dist.all_reduce(tensor, op=dist.ReduceOp.MAX)\n            elif op == \"sum\":\n                dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n            else:\n                dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n                tensor /= world_size\n            reduced[key] = tensor\n        return reduced\n    else:\n        return d\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.broadcast","title":"<code>broadcast(obj, src)</code>","text":"<p>Broadcasts an object from the source process to all processes.</p> <p>On non-source processes, this value is ignored.</p> PARAMETER DESCRIPTION <code>obj</code> <p>The object to broadcast on the source process.</p> <p> TYPE: <code>Any</code> </p> <code>src</code> <p>The source process rank.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The broadcasted object from the source process.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def broadcast(self, obj: Any, src: int) -&gt; Any:\n    \"\"\"\n    Broadcasts an object from the source process to all processes.\n\n    On non-source processes, this value is ignored.\n\n    Args:\n        obj (Any): The object to broadcast on the source process.\n        src (int): The source process rank.\n\n    Returns:\n        Any : The broadcasted object from the source process.\n    \"\"\"\n    if dist.is_initialized():\n        obj_list = [obj] if self.rank == src else [None]\n        dist.broadcast_object_list(obj_list, src=src)\n        return obj_list[0]\n    else:\n        return obj\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.distribute","title":"<code>distribute(fun)</code>","text":"<p>Decorator to distribute the fit function across multiple processes.</p> <p>This function is generic and can work with other methods as well. Weather it is bound or unbound.</p> <p>When applied to a function (typically a fit function), this decorator will execute the function in a distributed fashion using torch.multiprocessing. The number of processes used is determined by <code>self.nprocs</code>, and if multiple nodes are involved (<code>self.num_nodes &gt; 1</code>), the process count is adjusted accordingly. In single process mode (<code>self.nporcs</code> is 1), the function is executed directly in the current process.</p> <p>After execution, the decorator returns the model stored in <code>instance.model</code>.</p> PARAMETER DESCRIPTION <code>fun</code> <p>The function to be decorated. This function usually implements             a model fitting or training routine.</p> <p> TYPE: <code>callable</code> </p> RETURNS DESCRIPTION <code>callable</code> <p>The wrapped function. When called, it will execute in distributed mode       (if configured) and return the value of <code>instance.model</code>.</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def distribute(self, fun: Callable) -&gt; Callable:\n    \"\"\"\n    Decorator to distribute the fit function across multiple processes.\n\n    This function is generic and can work with other methods as well.\n    Weather it is bound or unbound.\n\n    When applied to a function (typically a fit function), this decorator\n    will execute the function in a distributed fashion using torch.multiprocessing.\n    The number of processes used is determined by `self.nprocs`,\n    and if multiple nodes are involved (`self.num_nodes &gt; 1`), the process count is\n    adjusted accordingly. In single process mode (`self.nporcs` is 1), the function\n    is executed directly in the current process.\n\n    After execution, the decorator returns the model stored in `instance.model`.\n\n    Parameters:\n        fun (callable): The function to be decorated. This function usually implements\n                        a model fitting or training routine.\n\n    Returns:\n        callable: The wrapped function. When called, it will execute in distributed mode\n                  (if configured) and return the value of `instance.model`.\n    \"\"\"\n\n    @functools.wraps(fun)\n    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n\n        # Get the original picklable function\n        # for the case of bound class method\n        # as well as a function\n        if self.is_class_method(fun, args):\n            instance = args[0]\n            method_name = fun.__name__\n            method = getattr(instance, method_name)\n            args = args[1:]\n            self._spawn_method(instance, method, args, kwargs)\n        else:\n            instance = None\n            # method_name = fun.__name__\n            # module = inspect.getmodule(fun)\n            # method = getattr(module, method_name) if module else fun\n            self._spawn_method(instance, fun, args, kwargs)\n\n        if instance and hasattr(instance, \"accelerator\"):\n            instance.accelerator.finalize()\n        else:\n            self.finalize()\n\n        # TODO: Return the original returns from fun\n        # Currently it only returns the model and optimizer\n        # similar to the fit method.\n        try:\n            return instance.model, instance.optimizer\n        except Exception:\n            return\n\n    return wrapper\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.is_class_method","title":"<code>is_class_method(fun, args)</code>","text":"<p>Determines if <code>fun</code> is a class method or a standalone function.</p> <p>Frist argument of the args should be: - An object and has dict: making it a class - Has a method named fun: making it a class that has this method.</p> PARAMETER DESCRIPTION <code>fun</code> <p>The function being checked.</p> <p> TYPE: <code>Callable</code> </p> <code>args</code> <p>The arguments passed to the function.</p> <p> TYPE: <code>tuple</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True if <code>fun</code> is a class method, False otherwise.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def is_class_method(self, fun: Callable, args: Any) -&gt; bool:\n    \"\"\"\n    Determines if `fun` is a class method or a standalone function.\n\n    Frist argument of the args should be:\n    - An object and has __dict__: making it a class\n    - Has a method named fun: making it a class that has this method.\n\n    Args:\n        fun (Callable): The function being checked.\n        args (tuple): The arguments passed to the function.\n\n    Returns:\n        bool: True if `fun` is a class method, False otherwise.\n    \"\"\"\n    return (\n        bool(args)\n        and isinstance(args[0], object)\n        and hasattr(args[0], \"__dict__\")\n        and hasattr(args[0], fun.__name__)\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.prepare","title":"<code>prepare(*args)</code>","text":"<p>Prepares models, optimizers, and dataloaders for distributed training.</p> <p>This method iterates over the provided objects and: - Moves models to the specified device (e.g., GPU or CPU) and casts them to the     desired precision (specified by <code>self.dtype</code>). It then wraps models in     DistributedDataParallel (DDP) if more than one device is used. - Passes through optimizers unchanged. - For dataloaders, it adjusts them to use a distributed sampler (if applicable)     by calling a helper method. Note that only the sampler is prepared; moving the     actual batch data to the device is handled separately during training.     Please use the <code>prepare_batch</code> method to move the batch to correct device/dtype.</p> PARAMETER DESCRIPTION <code>*args</code> <p>A variable number of objects to be prepared. These can include: - PyTorch models (<code>nn.Module</code>) - Optimizers (<code>optim.Optimizer</code>) - DataLoaders (or a dictionary-like <code>DictDataLoader</code> of dataloaders)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>tuple[Any, ...]</code> <p>tuple[Any, ...]: A tuple containing the prepared objects, where each object has been             modified as needed to support distributed training.</p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def prepare(self, *args: Any) -&gt; tuple[Any, ...]:\n    \"\"\"\n    Prepares models, optimizers, and dataloaders for distributed training.\n\n    This method iterates over the provided objects and:\n    - Moves models to the specified device (e.g., GPU or CPU) and casts them to the\n        desired precision (specified by `self.dtype`). It then wraps models in\n        DistributedDataParallel (DDP) if more than one device is used.\n    - Passes through optimizers unchanged.\n    - For dataloaders, it adjusts them to use a distributed sampler (if applicable)\n        by calling a helper method. Note that only the sampler is prepared; moving the\n        actual batch data to the device is handled separately during training.\n        Please use the `prepare_batch` method to move the batch to correct device/dtype.\n\n    Args:\n        *args (Any): A variable number of objects to be prepared. These can include:\n            - PyTorch models (`nn.Module`)\n            - Optimizers (`optim.Optimizer`)\n            - DataLoaders (or a dictionary-like `DictDataLoader` of dataloaders)\n\n    Returns:\n        tuple[Any, ...]: A tuple containing the prepared objects, where each object has been\n                        modified as needed to support distributed training.\n    \"\"\"\n    prepared: list = []\n    for obj in args:\n        if obj is None:\n            prepared.append(None)\n        elif isinstance(obj, nn.Module):\n            prepared.append(self._prepare_model(obj))\n        elif isinstance(obj, optim.Optimizer):\n            prepared.append(self._prepare_optimizer(obj))\n        elif isinstance(obj, (DataLoader, DictDataLoader)):\n            prepared.append(self._prepare_data(obj))\n        else:\n            prepared.append(obj)\n    return tuple(prepared)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.prepare_batch","title":"<code>prepare_batch(batch)</code>","text":"<p>Moves a batch of data to the target device and casts it to the desired data dtype.</p> <p>This method is typically called within the optimization step of your training loop. It supports various batch formats:     - If the batch is a dictionary, each value is moved individually.     - If the batch is a tuple or list, each element is processed and returned as a tuple.     - Otherwise, the batch is processed directly.</p> PARAMETER DESCRIPTION <code>batch</code> <p>The batch of data to move to the device. This can be a dict, tuple, list,          or any type compatible with <code>data_to_device</code>.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The batch with all elements moved to <code>self.device</code> and cast to <code>self.data_dtype</code>.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def prepare_batch(self, batch: dict | list | tuple | torch.Tensor | None) -&gt; Any:\n    \"\"\"\n    Moves a batch of data to the target device and casts it to the desired data dtype.\n\n    This method is typically called within the optimization step of your training loop.\n    It supports various batch formats:\n        - If the batch is a dictionary, each value is moved individually.\n        - If the batch is a tuple or list, each element is processed and returned as a tuple.\n        - Otherwise, the batch is processed directly.\n\n    Args:\n        batch (Any): The batch of data to move to the device. This can be a dict, tuple, list,\n                     or any type compatible with `data_to_device`.\n\n    Returns:\n        Any: The batch with all elements moved to `self.device` and cast to `self.data_dtype`.\n    \"\"\"\n    if batch is None:\n        return None\n\n    if isinstance(batch, dict):\n        return {\n            key: data_to_device(\n                value, device=self.execution.device, dtype=self.execution.data_dtype\n            )\n            for key, value in batch.items()\n        }\n    elif isinstance(batch, (tuple, list)):\n        return tuple(\n            data_to_device(x, device=self.execution.device, dtype=self.execution.data_dtype)\n            for x in batch\n        )\n    elif isinstance(batch, torch.Tensor):\n        return data_to_device(\n            batch, device=self.execution.device, dtype=self.execution.data_dtype\n        )\n    return\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_utils.accelerator.Accelerator.worker","title":"<code>worker(rank, instance, fun, args, kwargs)</code>","text":"<p>Worker function to be executed in each spawned process.</p> <p>This function is called in every subprocess created by torch.multiprocessing (via mp.spawn). It performs the following tasks:   1. Sets up the accelerator for the given process rank. This typically involves configuring      the GPU or other hardware resources for distributed training.   2. If the retrieved method has been decorated (i.e. it has a 'wrapped' attribute),      the original, unwrapped function is invoked with the given arguments. Otherwise,      the method is called directly.</p> PARAMETER DESCRIPTION <code>rank</code> <p>The rank (or identifier) of the spawned process.</p> <p> TYPE: <code>int</code> </p> <code>instance</code> <p>The object (Trainer) that contains the method to execute.                This object is expected to have an <code>accelerator</code> attribute with a <code>setup_process(rank)</code> method.                This argument is optional, in case it is None, the fun will be called independently.</p> <p> TYPE: <code>object</code> </p> <code>fun</code> <p>The function of the method on the instance to be executed.</p> <p> TYPE: <code>Callable</code> </p> <code>args</code> <p>Positional arguments to pass to the target method.</p> <p> TYPE: <code>tuple</code> </p> <code>kwargs</code> <p>Keyword arguments to pass to the target method.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>qadence/ml_tools/train_utils/accelerator.py</code> <pre><code>def worker(self, rank: int, instance: Any, fun: Callable, args: tuple, kwargs: dict) -&gt; None:\n    \"\"\"\n    Worker function to be executed in each spawned process.\n\n    This function is called in every subprocess created by torch.multiprocessing (via mp.spawn).\n    It performs the following tasks:\n      1. Sets up the accelerator for the given process rank. This typically involves configuring\n         the GPU or other hardware resources for distributed training.\n      2. If the retrieved method has been decorated (i.e. it has a '__wrapped__' attribute),\n         the original, unwrapped function is invoked with the given arguments. Otherwise,\n         the method is called directly.\n\n    Args:\n        rank (int): The rank (or identifier) of the spawned process.\n        instance (object): The object (Trainer) that contains the method to execute.\n                           This object is expected to have an `accelerator` attribute with a `setup_process(rank)` method.\n                           This argument is optional, in case it is None, the fun will be called independently.\n        fun (Callable): The function of the method on the instance to be executed.\n        args (tuple): Positional arguments to pass to the target method.\n        kwargs (dict): Keyword arguments to pass to the target method.\n    \"\"\"\n    # Setup the accelerator for the given process rank (e.g., configuring GPU)\n    if instance and instance.accelerator:\n        instance.accelerator.setup_process(rank)\n    else:\n        self.setup_process(rank)\n\n    if hasattr(fun, \"__wrapped__\"):\n        # Explicitly get the original (unbound) method, passing in the instance.\n        # We need to call the original method in case so that MP spawn does not\n        # create multiple processes. (To Avoid infinite loop)\n        fun = fun.__wrapped__  # Unwrap if decorated\n        fun(instance, *args, **kwargs) if instance else fun(*args, **kwargs)\n    else:\n        fun(*args, **kwargs)\n</code></pre>"},{"location":"api/models/","title":"Quantum models","text":""},{"location":"api/models/#qadence.model.QuantumModel","title":"<code>QuantumModel(circuit, observable=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, mitigation=None, configuration=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>The central class of qadence that executes <code>QuantumCircuit</code>s and make them differentiable.</p> <p>This class should be used as base class for any new quantum model supported in the qadence framework for information on the implementation of custom models see here.</p> <p>Example: <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit, RX, RY, Z, PI, chain, kron\nfrom qadence import FeatureParameter, VariationalParameter\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, theta), RY(1, theta)),\n    kron(RX(0, phi), RY(1, phi)),\n)\n\ncircuit = QuantumCircuit(2, block)\n\nobservable = Z(0) + Z(1)\n\nmodel = QuantumModel(circuit, observable)\nvalues = {\"phi\": torch.tensor([PI, PI/2]), \"theta\": torch.tensor([PI, PI/2])}\n\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\nprint(wf)\nprint(xs)\nprint(ex)\n</code></pre> <pre><code>tensor([[ 1.0000e+00+0.0000e+00j, -1.2246e-16+0.0000e+00j,\n          0.0000e+00+1.2246e-16j,  0.0000e+00-1.4998e-32j],\n        [ 4.9304e-32+0.0000e+00j,  2.2204e-16+0.0000e+00j,\n          0.0000e+00-2.2204e-16j,  0.0000e+00-1.0000e+00j]])\n[OrderedCounter({'00': 100}), OrderedCounter({'11': 100})]\ntensor([[ 2.],\n        [-2.]], requires_grad=True)\n</code></pre>  ```</p> <p>Initialize a generic QuantumModel instance.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>Optional observable(s) that are used only in the <code>expectation</code> method. You can also provide observables on the fly to the expectation call directly.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>A backend for circuit execution.</p> <p> TYPE: <code>BackendName | str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>A differentiability mode. Parameter shift based modes work on all backends. AD based modes only on PyTorch based backends.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Configuration for the backend.</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if the <code>diff_mode</code> argument is set to None</p> Source code in <code>qadence/model.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock | None = None,\n    backend: BackendName | str = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n):\n    \"\"\"Initialize a generic QuantumModel instance.\n\n    Arguments:\n        circuit: The circuit that is executed.\n        observable: Optional observable(s) that are used only in the `expectation` method. You\n            can also provide observables on the fly to the expectation call directly.\n        backend: A backend for circuit execution.\n        diff_mode: A differentiability mode. Parameter shift based modes work on all backends.\n            AD based modes only on PyTorch based backends.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        configuration: Configuration for the backend.\n        noise: A noise model to use.\n\n    Raises:\n        ValueError: if the `diff_mode` argument is set to None\n    \"\"\"\n    super().__init__()\n\n    if not isinstance(circuit, QuantumCircuit):\n        TypeError(\n            f\"The circuit should be of type '&lt;class QuantumCircuit&gt;'. Got {type(circuit)}.\"\n        )\n\n    if diff_mode is None:\n        raise ValueError(\"`diff_mode` cannot be `None` in a `QuantumModel`.\")\n\n    self.backend = backend_factory(\n        backend=backend, diff_mode=diff_mode, configuration=configuration\n    )\n\n    if isinstance(observable, list) or observable is None:\n        observable = observable\n    else:\n        observable = [observable]\n\n    def _is_feature_param(p: Parameter) -&gt; bool:\n        return not p.trainable and not p.is_number\n\n    if observable is None:\n        self.inputs = list(filter(_is_feature_param, circuit.unique_parameters))\n    else:\n        uparams = unique_parameters(chain(circuit.block, *observable))\n        self.inputs = list(filter(_is_feature_param, uparams))\n\n    conv = self.backend.convert(circuit, observable)\n    self.embedding_fn = conv.embedding_fn\n    self._circuit = conv.circuit\n    self._observable = conv.observable\n    self._backend_name = backend\n    self._diff_mode = diff_mode\n    self._measurement = measurement\n    self._noise = noise\n    self._mitigation = mitigation\n    if check_param_dict_values(conv.params):\n        self._params = nn.ParameterDict(\n            {\n                str(key): nn.Parameter(val, requires_grad=val.requires_grad)  # type: ignore[union-attr]\n                for key, val in conv.params.items()\n            }\n        )\n    else:\n        self._params = nn.ParameterDict(\n            {\n                str(key): nn.Parameter(val, requires_grad=val.requires_grad)  # type: ignore[union-attr]\n                for key, val in merge_separate_params(conv.params).items()\n            }\n        )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.device","title":"<code>device</code>  <code>property</code>","text":"<p>Get device.</p> RETURNS DESCRIPTION <code>device</code> <p>torch.device</p>"},{"location":"api/models/#qadence.model.QuantumModel.in_features","title":"<code>in_features</code>  <code>property</code>","text":"<p>Number of inputs.</p>"},{"location":"api/models/#qadence.model.QuantumModel.num_vparams","title":"<code>num_vparams</code>  <code>property</code>","text":"<p>The number of variational parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.out_features","title":"<code>out_features</code>  <code>property</code>","text":"<p>Number of outputs.</p>"},{"location":"api/models/#qadence.model.QuantumModel.params","title":"<code>params</code>  <code>property</code>","text":"<p>All parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.show_config","title":"<code>show_config</code>  <code>property</code>","text":"<p>Attain current quantum model configurations.</p>"},{"location":"api/models/#qadence.model.QuantumModel.vals_vparams","title":"<code>vals_vparams</code>  <code>property</code>","text":"<p>Dictionary with parameters which are actually updated during optimization.</p>"},{"location":"api/models/#qadence.model.QuantumModel.vparams","title":"<code>vparams</code>  <code>property</code>","text":"<p>Variational parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.assign_parameters","title":"<code>assign_parameters(values)</code>","text":"<p>Return the final, assigned circuit that is used in e.g. <code>backend.run</code>.</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Final, assigned circuit that is used in e.g. <code>backend.run</code></p> Source code in <code>qadence/model.py</code> <pre><code>def assign_parameters(self, values: dict[str, Tensor]) -&gt; Any:\n    \"\"\"Return the final, assigned circuit that is used in e.g. `backend.run`.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n\n    Returns:\n        Final, assigned circuit that is used in e.g. `backend.run`\n    \"\"\"\n    params = self.embedding_fn(self._params, values)\n    return self.backend.assign_parameters(self._circuit, params)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.change_config","title":"<code>change_config(new_config)</code>","text":"<p>Change configuration with the input.</p> Source code in <code>qadence/model.py</code> <pre><code>def change_config(self, new_config: dict) -&gt; None:\n    \"\"\"Change configuration with the input.\"\"\"\n    if isinstance(self.backend, DifferentiableBackend):\n        current_config = self.backend.backend.config\n    BackendConfiguration.change_config(current_config, new_config)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.circuit","title":"<code>circuit(circuit)</code>","text":"<p>Get backend-converted circuit.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>QuantumCircuit instance.</p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>Backend circuit.</p> Source code in <code>qadence/model.py</code> <pre><code>def circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Get backend-converted circuit.\n\n    Args:\n        circuit: QuantumCircuit instance.\n\n    Returns:\n        Backend circuit.\n    \"\"\"\n    return self.backend.circuit(circuit)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.expectation","title":"<code>expectation(values={}, observable=None, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute expectation using the given backend.</p> <p>Given an input state \\(|\\psi_0 \\rangle\\), a set of variational parameters \\(\\vec{\\theta}\\) and the unitary representation of the model \\(U(\\vec{\\theta})\\) we return \\(\\langle \\psi_0 | U(\\vec{\\theta}) | \\psi_0 \\rangle\\).</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>observable</code> <p>Observable part of the expectation.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable | None</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional input state.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>A mitigation protocol to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>when no observable is set.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor of shape n_batches x n_obs</p> Source code in <code>qadence/model.py</code> <pre><code>def expectation(\n    self,\n    values: dict[str, Tensor] = {},\n    observable: list[ConvertedObservable] | ConvertedObservable | None = None,\n    state: Optional[Tensor] = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    r\"\"\"Compute expectation using the given backend.\n\n\n\n    Given an input state $|\\psi_0 \\rangle$,\n    a set of variational parameters $\\vec{\\theta}$\n    and the unitary representation of the model $U(\\vec{\\theta})$\n    we return $\\langle \\psi_0 | U(\\vec{\\theta}) | \\psi_0 \\rangle$.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        observable: Observable part of the expectation.\n        state: Optional input state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: A mitigation protocol to use.\n        endianness: Storage convention for binary information.\n\n    Raises:\n        ValueError: when no observable is set.\n\n    Returns:\n        A torch.Tensor of shape n_batches x n_obs\n    \"\"\"\n    if observable is None:\n        if self._observable is None:\n            raise ValueError(\n                \"Provide an AbstractBlock as the observable to compute expectation.\"\n                \"Either pass a 'native_observable' directly to 'QuantumModel.expectation'\"\n                \"or pass a (non-native) '&lt;class AbstractBlock&gt;' to the 'QuantumModel.__init__'.\"\n            )\n        observable = self._observable\n\n    params = self.embedding_fn(self._params, values)\n    if measurement is None:\n        measurement = self._measurement\n    if noise is None:\n        noise = self._noise\n    else:\n        self._noise = noise\n    if mitigation is None:\n        mitigation = self._mitigation\n    return self.backend.expectation(\n        circuit=self._circuit,\n        observable=observable,\n        param_values=params,\n        state=state,\n        measurement=measurement,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Calls run method with arguments.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor representing output.</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def forward(self, *args: Any, **kwargs: Any) -&gt; Tensor:\n    \"\"\"Calls run method with arguments.\n\n    Returns:\n        Tensor: A torch.Tensor representing output.\n    \"\"\"\n    return self.run(*args, **kwargs)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.load","title":"<code>load(file_path, as_torch=False, map_location='cpu')</code>  <code>classmethod</code>","text":"<p>Load QuantumModel.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>File path to load model from.</p> <p> TYPE: <code>str | Path</code> </p> <code>as_torch</code> <p>Load parameters as torch tensor. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>map_location</code> <p>Location for loading. Defaults to \"cpu\".</p> <p> TYPE: <code>str | device</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>QuantumModel</code> <p>QuantumModel from file_path.</p> Source code in <code>qadence/model.py</code> <pre><code>@classmethod\ndef load(\n    cls, file_path: str | Path, as_torch: bool = False, map_location: str | torch.device = \"cpu\"\n) -&gt; QuantumModel:\n    \"\"\"Load QuantumModel.\n\n    Arguments:\n        file_path: File path to load model from.\n        as_torch: Load parameters as torch tensor. Defaults to False.\n        map_location (str | torch.device, optional): Location for loading. Defaults to \"cpu\".\n\n    Returns:\n        QuantumModel from file_path.\n    \"\"\"\n    qm_pt = {}\n    if isinstance(file_path, str):\n        file_path = Path(file_path)\n    if os.path.isdir(file_path):\n        from qadence.ml_tools.callbacks.saveload import get_latest_checkpoint_name\n\n        file_path = file_path / get_latest_checkpoint_name(file_path, \"model\")\n\n    try:\n        qm_pt = torch.load(file_path, map_location=map_location, weights_only=False)\n    except Exception as e:\n        logger.error(f\"Unable to load QuantumModel due to {e}\")\n    return cls._from_dict(qm_pt, as_torch)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.load_params_from_dict","title":"<code>load_params_from_dict(d, strict=True)</code>","text":"<p>Copy parameters from dictionary into this QuantumModel.</p> <p>Unlike :meth:<code>~qadence.QuantumModel.from_dict</code>, this method does not create a new QuantumModel instance, but rather loads the parameters into the same QuantumModel. The behaviour of this method is similar to :meth:<code>~torch.nn.Module.load_state_dict</code>.</p> <p>The dictionary is assumed to have the format as saved via :meth:<code>~qadence.QuantumModel.to_dict</code></p> PARAMETER DESCRIPTION <code>d</code> <p>The dictionary</p> <p> TYPE: <code>dict</code> </p> <code>strict</code> <p>Whether to strictly enforce that the parameter keys in the dictionary and in the model match exactly. Default: <code>True</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def load_params_from_dict(self, d: dict, strict: bool = True) -&gt; None:\n    \"\"\"Copy parameters from dictionary into this QuantumModel.\n\n    Unlike :meth:`~qadence.QuantumModel.from_dict`, this method does not create a new\n    QuantumModel instance, but rather loads the parameters into the same QuantumModel.\n    The behaviour of this method is similar to :meth:`~torch.nn.Module.load_state_dict`.\n\n    The dictionary is assumed to have the format as saved via\n    :meth:`~qadence.QuantumModel.to_dict`\n\n    Args:\n        d (dict): The dictionary\n        strict (bool, optional):\n            Whether to strictly enforce that the parameter keys in the dictionary and\n            in the model match exactly. Default: ``True``.\n    \"\"\"\n    param_dict = d[\"param_dict\"]\n    missing_keys = set(self._params.keys()) - set(param_dict.keys())\n    unexpected_keys = set(param_dict.keys()) - set(self._params.keys())\n\n    if strict:\n        error_msgs = []\n        if len(unexpected_keys) &gt; 0:\n            error_msgs.append(f\"Unexpected key(s) in dictionary: {unexpected_keys}\")\n        if len(missing_keys) &gt; 0:\n            error_msgs.append(f\"Missing key(s) in dictionary: {missing_keys}\")\n        if len(error_msgs) &gt; 0:\n            errors_string = \"\\n\\t\".join(error_msgs)\n            raise RuntimeError(\n                f\"Error(s) loading the parameter dictionary due to: \\n\\t{errors_string}\\n\"\n                \"This error was thrown because the `strict` argument is set `True`.\"\n                \"If you don't need the parameter keys of the dictionary to exactly match \"\n                \"the model parameters, set `strict=False`.\"\n            )\n\n    for n, param in param_dict.items():\n        try:\n            with torch.no_grad():\n                self._params[n].copy_(\n                    torch.nn.Parameter(param, requires_grad=param.requires_grad)\n                )\n        except Exception as e:\n            logger.warning(f\"Unable to load parameter {n} from dictionary due to {e}.\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.observable","title":"<code>observable(observable, n_qubits)</code>","text":"<p>Get backend observable.</p> PARAMETER DESCRIPTION <code>observable</code> <p>Observable block.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Backend observable.</p> Source code in <code>qadence/model.py</code> <pre><code>def observable(self, observable: AbstractBlock, n_qubits: int) -&gt; Any:\n    \"\"\"Get backend observable.\n\n    Args:\n        observable: Observable block.\n        n_qubits: Number of qubits\n\n    Returns:\n        Backend observable.\n    \"\"\"\n    return self.backend.observable(observable, n_qubits)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.observables_to_expression","title":"<code>observables_to_expression()</code>","text":"<pre><code>Convert the observable to a dictionary representation of Pauli terms.\n</code></pre> <p>If no observable is set, returns an empty dictionary. Each observable is represented by its tag (if available) as the key and its mathematical expression as the value.</p> RETURNS DESCRIPTION <code>dict[str, str] | str</code> <p>dict[str, str]: A dictionary where the keys are observable tags (or \"Obs.\" if not provided)             and the values are the corresponding mathematical expressions.</p> Source code in <code>qadence/model.py</code> <pre><code>def observables_to_expression(self) -&gt; dict[str, str] | str:\n    \"\"\"\n        Convert the observable to a dictionary representation of Pauli terms.\n\n    If no observable is set, returns an empty dictionary. Each observable is\n    represented by its tag (if available) as the key and its mathematical expression\n    as the value.\n\n    Returns:\n        dict[str, str]: A dictionary where the keys are observable tags (or \"Obs.\" if not provided)\n                        and the values are the corresponding mathematical expressions.\n    \"\"\"\n    if self._observable is None:\n        return \"No observable set.\"\n    else:\n        return {\n            obs.original.tag if obs.original.tag else \"Obs.\": block_to_mathematical_expression(\n                obs.original\n            )\n            for obs in self._observable\n        }\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.overlap","title":"<code>overlap()</code>","text":"<p>Overlap of model.</p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>The overlap method is not implemented for this model.</p> Source code in <code>qadence/model.py</code> <pre><code>def overlap(self) -&gt; Tensor:\n    \"\"\"Overlap of model.\n\n    Raises:\n        NotImplementedError: The overlap method is not implemented for this model.\n    \"\"\"\n    raise NotImplementedError(\"The overlap method is not implemented for this model.\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.reset_vparams","title":"<code>reset_vparams(values)</code>","text":"<p>Reset all the variational parameters with a given list of values.</p> Source code in <code>qadence/model.py</code> <pre><code>def reset_vparams(self, values: Sequence) -&gt; None:\n    \"\"\"Reset all the variational parameters with a given list of values.\"\"\"\n    current_vparams = OrderedDict({k: v for k, v in self._params.items() if v.requires_grad})\n\n    assert (\n        len(values) == self.num_vparams\n    ), \"Pass an iterable with the values of all variational parameters\"\n    for i, k in enumerate(current_vparams.keys()):\n        current_vparams[k].data = torch.tensor([values[i]])\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.run","title":"<code>run(values=None, state=None, endianness=Endianness.BIG)</code>","text":"<p>Run model.</p> <p>Given an input state \\(| \\psi_0 \\rangle\\), a set of variational parameters \\(\\vec{\\theta}\\) and the unitary representation of the model \\(U(\\vec{\\theta})\\) we return \\(U(\\vec{\\theta}) | \\psi_0 \\rangle\\).</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional input state to apply model on.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor representing output.</p> Source code in <code>qadence/model.py</code> <pre><code>def run(\n    self,\n    values: dict[str, Tensor] = None,\n    state: Tensor | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    r\"\"\"Run model.\n\n    Given an input state $| \\psi_0 \\rangle$,\n    a set of variational parameters $\\vec{\\theta}$\n    and the unitary representation of the model $U(\\vec{\\theta})$\n    we return $U(\\vec{\\theta}) | \\psi_0 \\rangle$.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        state: Optional input state to apply model on.\n        endianness: Storage convention for binary information.\n\n    Returns:\n        A torch.Tensor representing output.\n    \"\"\"\n    if values is None:\n        values = {}\n\n    params = self.embedding_fn(self._params, values)\n\n    return self.backend.run(self._circuit, params, state=state, endianness=endianness)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.sample","title":"<code>sample(values={}, n_shots=1000, state=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Obtain samples from model.</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Observable part of the expectation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Optional input state to apply model on.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>A mitigation protocol to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results.</p> Source code in <code>qadence/model.py</code> <pre><code>def sample(\n    self,\n    values: dict[str, torch.Tensor] = {},\n    n_shots: int = 1000,\n    state: torch.Tensor | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n    \"\"\"Obtain samples from model.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        n_shots: Observable part of the expectation.\n        state: Optional input state to apply model on.\n        noise: A noise model to use.\n        mitigation: A mitigation protocol to use.\n        endianness: Storage convention for binary information.\n\n    Returns:\n        A list of Counter instances with the sample results.\n    \"\"\"\n    params = self.embedding_fn(self._params, values)\n    if noise is None:\n        noise = self._noise\n    if mitigation is None:\n        mitigation = self._mitigation\n    return self.backend.sample(\n        self._circuit,\n        params,\n        n_shots=n_shots,\n        state=state,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.save","title":"<code>save(folder, file_name='quantum_model.pt', save_params=True)</code>","text":"<p>Save model.</p> PARAMETER DESCRIPTION <code>folder</code> <p>Folder where model is saved.</p> <p> TYPE: <code>str | Path</code> </p> <code>file_name</code> <p>File name for saving model. Defaults to \"quantum_model.pt\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'quantum_model.pt'</code> </p> <code>save_params</code> <p>Save parameters if True. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If folder is not a directory.</p> Source code in <code>qadence/model.py</code> <pre><code>def save(\n    self, folder: str | Path, file_name: str = \"quantum_model.pt\", save_params: bool = True\n) -&gt; None:\n    \"\"\"Save model.\n\n    Arguments:\n        folder: Folder where model is saved.\n        file_name: File name for saving model. Defaults to \"quantum_model.pt\".\n        save_params: Save parameters if True. Defaults to True.\n\n    Raises:\n        FileNotFoundError: If folder is not a directory.\n    \"\"\"\n    if not os.path.isdir(folder):\n        raise FileNotFoundError\n    try:\n        torch.save(self._to_dict(save_params), folder / Path(file_name))\n    except Exception as e:\n        logger.error(f\"Unable to write QuantumModel to disk due to {e}\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.set_as_fixed","title":"<code>set_as_fixed(params=list())</code>","text":"<p>Set as fixed the list of names in <code>params</code>.</p> PARAMETER DESCRIPTION <code>params</code> <p>List of parameters to fix. Defaults to list().</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>list()</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def set_as_fixed(self, params: list[str] = list()) -&gt; None:\n    \"\"\"Set as fixed the list of names in `params`.\n\n    Args:\n        params (list[str], optional): List of parameters to fix. Defaults to list().\n    \"\"\"\n    circuit: QuantumCircuit = self._circuit.original\n    if self._observable is not None:\n        if isinstance(self._observable, list):\n            for obs in self._observable:\n                set_as_fixed(obs.original, params)\n            observable = [obs.original for obs in self._observable]\n        else:\n            set_as_fixed(self._observable.original, params)\n            observable = [self._observable.original]\n    else:\n        observable = self._observable  # type: ignore[assignment]\n    set_as_fixed(circuit.block, params)\n    conv = self.backend.convert(circuit, observable)\n    self.embedding_fn = conv.embedding_fn\n    self._circuit = conv.circuit\n    self._observable = conv.observable\n    if check_param_dict_values(conv.params):\n        self._params = nn.ParameterDict(\n            {\n                str(key): nn.Parameter(val, requires_grad=val.requires_grad)  # type: ignore[union-attr]\n                for key, val in conv.params.items()\n            }\n        )\n    else:\n        self._params = nn.ParameterDict(\n            {\n                str(key): nn.Parameter(val, requires_grad=val.requires_grad)  # type: ignore[union-attr]\n                for key, val in merge_separate_params(conv.params).items()\n            }\n        )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.set_as_variational","title":"<code>set_as_variational(params=list())</code>","text":"<p>Set as variational the list of names in <code>params</code>.</p> PARAMETER DESCRIPTION <code>params</code> <p>List of parameters to fix. Defaults to list().</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>list()</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def set_as_variational(self, params: list[str] = list()) -&gt; None:\n    \"\"\"Set as variational the list of names in `params`.\n\n    Args:\n        params (list[str], optional): List of parameters to fix. Defaults to list().\n    \"\"\"\n    circuit: QuantumCircuit = self._circuit.original\n    if self._observable is not None:\n        if isinstance(self._observable, list):\n            for obs in self._observable:\n                set_as_variational(obs.original, params)\n            observable = [obs.original for obs in self._observable]\n        else:\n            set_as_variational(self._observable.original, params)\n            observable = [self._observable.original]\n    else:\n        observable = self._observable  # type: ignore[assignment]\n    set_as_variational(circuit.block, params)\n    conv = self.backend.convert(circuit, observable)\n    self.embedding_fn = conv.embedding_fn\n    self._circuit = conv.circuit\n    self._observable = conv.observable\n    if check_param_dict_values(conv.params):\n        self._params = nn.ParameterDict(\n            {\n                str(key): nn.Parameter(val, requires_grad=val.requires_grad)  # type: ignore[union-attr]\n                for key, val in conv.params.items()\n            }\n        )\n    else:\n        self._params = nn.ParameterDict(\n            {\n                str(key): nn.Parameter(val, requires_grad=val.requires_grad)  # type: ignore[union-attr]\n                for key, val in merge_separate_params(conv.params).items()\n            }\n        )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.to","title":"<code>to(*args, **kwargs)</code>","text":"<p>Conversion method for device or types.</p> RETURNS DESCRIPTION <code>QuantumModel</code> <p>QuantumModel with conversions.</p> Source code in <code>qadence/model.py</code> <pre><code>def to(self, *args: Any, **kwargs: Any) -&gt; QuantumModel:\n    \"\"\"Conversion method for device or types.\n\n    Returns:\n        QuantumModel with conversions.\n    \"\"\"\n    from pyqtorch import QuantumCircuit as PyQCircuit\n\n    try:\n        if isinstance(self._circuit.native, PyQCircuit):\n            self._circuit.native = self._circuit.native.to(*args, **kwargs)\n            if self._observable is not None:\n                if isinstance(self._observable, ConvertedObservable):\n                    self._observable.native = self._observable.native.to(*args, **kwargs)\n                elif isinstance(self._observable, list):\n                    for obs in self._observable:\n                        obs.native = obs.native.to(*args, **kwargs)\n            self._params = self._params.to(\n                device=self._circuit.native.device,\n                dtype=(\n                    torch.float64\n                    if self._circuit.native.dtype == torch.cdouble\n                    else torch.float32\n                ),\n            )\n            logger.debug(f\"Moved {self} to {args}, {kwargs}.\")\n        else:\n            logger.debug(\"QuantumModel.to only supports pyqtorch.QuantumCircuits.\")\n    except Exception as e:\n        logger.warning(f\"Unable to move {self} to {args}, {kwargs} due to {e}.\")\n    return self\n</code></pre>"},{"location":"api/noise/","title":"Noise","text":""},{"location":"api/noise/#noise-for-simulations","title":"Noise for simulations","text":""},{"location":"api/noise/#qadence.noise.protocols.NoiseHandler","title":"<code>NoiseHandler(protocol, options=dict())</code>","text":"<p>A container for multiple sources of noise.</p> <p>Note <code>NoiseProtocol.ANALOG</code> and <code>NoiseProtocol.DIGITAL</code> sources cannot be both present. Also <code>NoiseProtocol.READOUT</code> can only be present once as the last noise sources, and only exclusively with <code>NoiseProtocol.DIGITAL</code> sources.</p> PARAMETER DESCRIPTION <code>protocol</code> <p>The protocol(s) applied. To be defined from <code>NoiseProtocol</code>.</p> <p> TYPE: <code>NoiseEnum | list[NoiseEnum]</code> </p> <code>options</code> <p>A list of options defining the protocol. For <code>NoiseProtocol.ANALOG</code>, options should contain a field <code>noise_probs</code>. For <code>NoiseProtocol.DIGITAL</code>, options should contain a field <code>error_probability</code>.</p> <p> TYPE: <code>dict | list[dict]</code> DEFAULT: <code>dict()</code> </p> <p>Examples:</p> <pre><code>    from qadence import NoiseProtocol, NoiseHandler\n\n    analog_options = {\"noise_probs\": 0.1}\n    digital_options = {\"error_probability\": 0.1}\n    readout_options = {\"error_probability\": 0.1, \"seed\": 0}\n\n    # single noise sources\n    analog_noise = NoiseHandler(NoiseProtocol.ANALOG.DEPOLARIZING, analog_options)\n    digital_depo_noise = NoiseHandler(NoiseProtocol.DIGITAL.DEPOLARIZING, digital_options)\n    readout_noise = NoiseHandler(NoiseProtocol.READOUT, readout_options)\n\n    # init from multiple sources\n    protocols: list = [NoiseProtocol.DIGITAL.DEPOLARIZING, NoiseProtocol.READOUT]\n    options: list = [digital_options, readout_noise]\n    noise_combination = NoiseHandler(protocols, options)\n\n    # Appending noise sources\n    noise_combination = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, digital_options)\n    noise_combination.append([digital_depo_noise, readout_noise])\n</code></pre> Source code in <code>qadence/noise/protocols.py</code> <pre><code>def __init__(\n    self,\n    protocol: NoiseEnum | list[NoiseEnum],\n    options: dict | list[dict] = dict(),\n) -&gt; None:\n    self.protocol = protocol if isinstance(protocol, list) else [protocol]\n    self.options = options if isinstance(options, list) else [options] * len(self.protocol)\n    self.verify_all_protocols()\n</code></pre>"},{"location":"api/noise/#qadence.noise.protocols.NoiseHandler.append","title":"<code>append(other)</code>","text":"<p>Append noises.</p> PARAMETER DESCRIPTION <code>other</code> <p>The noises to add.</p> <p> TYPE: <code>NoiseHandler | list[NoiseHandler]</code> </p> Source code in <code>qadence/noise/protocols.py</code> <pre><code>def append(self, other: NoiseHandler | list[NoiseHandler]) -&gt; None:\n    \"\"\"Append noises.\n\n    Args:\n        other (NoiseHandler | list[NoiseHandler]): The noises to add.\n    \"\"\"\n    # To avoid overwriting the noise_sources list if an error is raised, make a copy\n    other_list = other if isinstance(other, list) else [other]\n    protocols = self.protocol[:]\n    options = self.options[:]\n\n    for noise in other_list:\n        protocols += noise.protocol\n        options += noise.options\n\n    # init may raise an error\n    temp_handler = NoiseHandler(protocols, options)\n    # if verify passes, replace protocols and options\n    self.protocol = temp_handler.protocol\n    self.options = temp_handler.options\n</code></pre>"},{"location":"api/noise/#qadence.noise.protocols.NoiseHandler.verify_all_protocols","title":"<code>verify_all_protocols()</code>","text":"<p>Make sure all protocols are correct in terms and their combination too.</p> Source code in <code>qadence/noise/protocols.py</code> <pre><code>def verify_all_protocols(self) -&gt; None:\n    \"\"\"Make sure all protocols are correct in terms and their combination too.\"\"\"\n\n    if len(self.protocol) == 0:\n        raise ValueError(\"NoiseHandler should be specified with one valid configuration.\")\n\n    if len(self.protocol) != len(self.options):\n        raise ValueError(\"Specify lists of same length when defining noises.\")\n\n    for protocol, option in zip(self.protocol, self.options):\n        self._verify_single_protocol(protocol, option)\n\n    types = [type(p) for p in self.protocol]\n    unique_types = set(types)\n    if NoiseProtocol.DIGITAL in unique_types and NoiseProtocol.ANALOG in unique_types:\n        raise ValueError(\"Cannot define a config with both Digital and Analog noises.\")\n\n    if NoiseProtocol.ANALOG in unique_types:\n        if NoiseProtocol.READOUT in unique_types:\n            raise ValueError(\"Cannot define a config with both READOUT and Analog noises.\")\n        if types.count(NoiseProtocol.ANALOG) &gt; 1:\n            raise ValueError(\"Multiple Analog Noises are not supported yet.\")\n\n    if NoiseProtocol.READOUT in unique_types:\n        if (\n            not isinstance(self.protocol[-1], NoiseProtocol.READOUT)\n            or types.count(NoiseProtocol.READOUT) &gt; 1\n        ):\n            raise ValueError(\"Only define a NoiseHandler with one READOUT as the last Noise.\")\n</code></pre>"},{"location":"api/operations/","title":"Operations","text":"<p>Operations are common <code>PrimitiveBlocks</code>, these are often called gates elsewhere.</p>"},{"location":"api/operations/#constant-blocks","title":"Constant blocks","text":"<p>CY gate not implemented</p>"},{"location":"api/operations/#qadence.operations.X","title":"<code>X(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The X gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.Y","title":"<code>Y(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Y gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.Z","title":"<code>Z(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Z gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.I","title":"<code>I(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The identity gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.H","title":"<code>H(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hadamard or H gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = (1 / np.sqrt(2)) * (X(target) + Z(target) - np.sqrt(2) * I(target))\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.S","title":"<code>S(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The S / Phase gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.SDagger","title":"<code>SDagger(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the S / Phase gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.SWAP","title":"<code>SWAP(control, target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The SWAP gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    a11 = 0.5 * (Z(control) - I(control))\n    a22 = -0.5 * (Z(target) + I(target))\n    a12 = 0.5 * (chain(X(control), Z(control)) + X(control))\n    a21 = 0.5 * (chain(Z(target), X(target)) + X(target))\n    self.generator = (\n        kron(-1.0 * a22, a11) + kron(-1.0 * a11, a22) + kron(a12, a21) + kron(a21, a12)\n    )\n    super().__init__((control, target), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.T","title":"<code>T(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The T gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.TDagger","title":"<code>TDagger(target, noise=None)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the T gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CNOT","title":"<code>CNOT(control, target, noise=None)</code>","text":"<p>               Bases: <code>ControlBlock</code></p> <p>The CNot, or CX, gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(self, control: int, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    self.generator = kron(N(control), X(target) - I(target))\n    super().__init__((control,), X(target), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CZ","title":"<code>CZ(control, target, noise=None)</code>","text":"<p>               Bases: <code>MCZ</code></p> <p>The CZ gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(self, control: int, target: int, noise: NoiseHandler | None = None) -&gt; None:\n    super().__init__((control,), target, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CPHASE","title":"<code>CPHASE(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCPHASE</code></p> <p>The CPHASE gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#parametrized-blocks","title":"Parametrized blocks","text":""},{"location":"api/operations/#qadence.operations.RX","title":"<code>RX(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Rx gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TParameter | ParamMap,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    # TODO: should we give them more meaningful names? like 'angle'?\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = X(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.RY","title":"<code>RY(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Ry gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TParameter | ParamMap,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = Y(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.RZ","title":"<code>RZ(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Rz gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TParameter | ParamMap,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRX","title":"<code>CRX(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCRX</code></p> <p>The CRX gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRY","title":"<code>CRY(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCRY</code></p> <p>The CRY gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self, control: int, target: int, parameter: TParameter, noise: NoiseHandler | None = None\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRZ","title":"<code>CRZ(control, target, parameter, noise=None)</code>","text":"<p>               Bases: <code>MCRZ</code></p> <p>The CRZ gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n):\n    super().__init__((control,), target, parameter, noise=noise)\n</code></pre>"},{"location":"api/operations/#qadence.operations.PHASE","title":"<code>PHASE(target, parameter, noise=None)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Parametric Phase / S gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(\n    self,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n    noise: NoiseHandler | None = None,\n) -&gt; None:\n    self.parameters = ParamMap(parameter=parameter)\n    self.generator = I(target) - Z(target)\n    super().__init__((target,), noise=noise)\n</code></pre>"},{"location":"api/operations/#hamiltonian-evolution","title":"Hamiltonian Evolution","text":"<p>AnalogSWAP should be turned into a proper analog block</p>"},{"location":"api/operations/#qadence.operations.HamEvo","title":"<code>HamEvo(generator, parameter, qubit_support=None, duration=None, noise_operators=list())</code>","text":"<p>               Bases: <code>TimeEvolutionBlock</code></p> <p>The Hamiltonian evolution operator U(t).</p> <p>For time-independent Hamiltonians the solution is exact:</p> <pre><code>U(t) = exp(-iGt)\n</code></pre> <p>where G represents an Hermitian generator, or Hamiltonian and t represents the time parameter. For time-dependent Hamiltonians, the solution is obtained by numerical integration of the Schrodinger equation.</p> PARAMETER DESCRIPTION <code>generator</code> <p>Hamiltonian generator, either symbolic as an AbstractBlock, or as a torch.Tensor or numpy.ndarray.</p> <p> TYPE: <code>Union[TGenerator, AbstractBlock]</code> </p> <code>parameter</code> <p>The time parameter for evolution operator. For the time-independent case, it represents the actual value for which the evolution will be evaluated. For the time-dependent case, it should be an instance of TimeParameter to signal the solver the variable that will be integrated over.</p> <p> TYPE: <code>TParameter</code> </p> <code>qubit_support</code> <p>The qubits on which the evolution will be performed on. Only required for generators that are not a composition of blocks.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>duration</code> <p>(optional) duration of the evolution in case of time-dependent generator. By default, a FeatureParameter with tag \"duration\" will be initialized, and the value will then be required in the values dict.</p> <p> TYPE: <code>TParameter | None</code> DEFAULT: <code>None</code> </p> <code>noise_operators</code> <p>(optional) the list of jump operators to use when using a shrodinger solver, allowing to perform noisy simulations.</p> <p> TYPE: <code>list[AbstractBlock]</code> DEFAULT: <code>list()</code> </p> <p>Examples:</p> <pre><code>from qadence import X, HamEvo, PI, add, run\nfrom qadence import FeatureParameter, TimeParameter\nimport torch\n\nn_qubits = 3\n\n# Hamiltonian as a block composition\nhamiltonian = add(X(i) for i in range(n_qubits))\nhevo = HamEvo(hamiltonian, parameter=torch.rand(2))\nstate = run(hevo)\n\n# Hamiltonian as a random matrix\nhamiltonian = torch.rand(2, 2, dtype=torch.complex128)\nhevo = HamEvo(hamiltonian, parameter=torch.rand(2), qubit_support=(0,))\nstate = run(hevo)\n\n# Time-dependent Hamiltonian\nt = TimeParameter(\"t\")\nhamiltonian = t * add(X(i) for i in range(n_qubits))\nhevo = HamEvo(hamiltonian, parameter=t)\nstate = run(hevo, values = {\"duration\": torch.tensor(1.0)})\n\n# Adding noise operators\nnoise_ops = [X(0)]\nhevo = HamEvo(hamiltonian, parameter=t, noise_operators=noise_ops)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/operations/ham_evo.py</code> <pre><code>def __init__(\n    self,\n    generator: Union[TGenerator, AbstractBlock],\n    parameter: TParameter,\n    qubit_support: tuple[int, ...] = None,\n    duration: TParameter | None = None,\n    noise_operators: list[AbstractBlock] = list(),\n):\n    params = {}\n    if qubit_support is None and not isinstance(generator, AbstractBlock):\n        raise ValueError(\"You have to supply a qubit support for non-block generators.\")\n    super().__init__(qubit_support if qubit_support else generator.qubit_support)\n    if isinstance(generator, AbstractBlock):\n        qubit_support = generator.qubit_support\n        if generator.is_parametric:\n            params = {str(e): e for e in expressions(generator)}\n        if generator.is_time_dependent:\n            if isinstance(duration, str):\n                duration = Parameter(duration, trainable=False)\n            elif duration is None:\n                duration = Parameter(\"duration\", trainable=False)\n        if not generator.is_time_dependent and duration is not None:\n            raise TypeError(\n                \"Duration argument is only supported for time-dependent generators.\"\n            )\n    elif isinstance(generator, torch.Tensor):\n        if duration is not None:\n            raise TypeError(\n                \"Duration argument is only supported for time-dependent generators.\"\n            )\n        msg = \"Please provide a square generator.\"\n        if len(generator.shape) == 2:\n            assert generator.shape[0] == generator.shape[1], msg\n        elif len(generator.shape) == 3:\n            assert generator.shape[1] == generator.shape[2], msg\n            assert generator.shape[0] == 1, \"Qadence doesnt support batched generators.\"\n        else:\n            raise TypeError(\n                \"Only 2D or 3D generators are supported.\\\n                            In case of a 3D generator, the batch dim\\\n                            is expected to be at dim 0.\"\n            )\n        params = {str(generator.__hash__()): generator}\n    elif isinstance(generator, (sympy.Basic, sympy.Array)):\n        if duration is not None:\n            raise TypeError(\n                \"Duration argument is only supported for time-dependent generators.\"\n            )\n        params = {str(generator): generator}\n    else:\n        raise TypeError(\n            f\"Generator of type {type(generator)} not supported.\\\n                        If you're using a numpy.ndarray, please cast it to a torch tensor.\"\n        )\n    if duration is not None:\n        params = {\"duration\": Parameter(duration), **params}\n    params = {\"parameter\": Parameter(parameter), **params}\n    self.parameters = ParamMap(**params)\n    self.time_param = parameter\n    self.generator = generator\n    self.duration = duration\n\n    if len(noise_operators) &gt; 0:\n        if not all(\n            [\n                len(set(op.qubit_support + self.qubit_support) - set(self.qubit_support)) == 0\n                for op in noise_operators\n            ]\n        ):\n            raise ValueError(\n                \"Noise operators should be defined\"\n                \" over the same or a subset of the qubit support\"\n            )\n        if True in [op.is_parametric for op in noise_operators]:\n            raise ValueError(\"Parametric operators are not supported\")\n    self.noise_operators = noise_operators\n</code></pre>"},{"location":"api/operations/#qadence.operations.HamEvo.digital_decomposition","title":"<code>digital_decomposition(approximation=LTSOrder.ST4)</code>","text":"<p>Decompose the Hamiltonian evolution into digital gates.</p> PARAMETER DESCRIPTION <code>approximation</code> <p>Choose the type of decomposition. Defaults to \"st4\". Available types are: * 'basic' = apply first-order Trotter formula and decompose each term of     the exponential into digital gates. It is exact only if applied to an     operator whose terms are mutually commuting. * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting     Hamiltonians. * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting     Hamiltonians.</p> <p> TYPE: <code>str</code> DEFAULT: <code>ST4</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>a block with the digital decomposition</p> <p> TYPE: <code>AbstractBlock</code> </p> Source code in <code>qadence/operations/ham_evo.py</code> <pre><code>def digital_decomposition(self, approximation: LTSOrder = LTSOrder.ST4) -&gt; AbstractBlock:\n    \"\"\"Decompose the Hamiltonian evolution into digital gates.\n\n    Args:\n        approximation (str, optional): Choose the type of decomposition. Defaults to \"st4\".\n            Available types are:\n            * 'basic' = apply first-order Trotter formula and decompose each term of\n                the exponential into digital gates. It is exact only if applied to an\n                operator whose terms are mutually commuting.\n            * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting\n                Hamiltonians.\n            * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting\n                Hamiltonians.\n\n    Returns:\n        AbstractBlock: a block with the digital decomposition\n    \"\"\"\n\n    # psi(t) = exp(-i * H * t * psi0)\n    # psi(t) = exp(-i * lambda * t * psi0)\n    # H = sum(Paulin) + sum(Pauli1*Pauli2)\n    logger.info(\"Quantum simulation of the time-independent Schr\u00f6dinger equation.\")\n\n    blocks = []\n\n    # how to change the type/dict to enum effectively\n\n    # when there is a term including non-commuting matrices use st2 or st4\n\n    # 1) should check that the given generator respects the constraints\n    # single-qubit gates\n\n    assert isinstance(\n        self.generator, AbstractBlock\n    ), \"Only a generator represented as a block can be decomposed\"\n\n    if block_is_qubit_hamiltonian(self.generator):\n        try:\n            block_is_commuting_hamiltonian(self.generator)\n            approximation = LTSOrder.BASIC  # use the simpler approach if the H is commuting\n        except TypeError:\n            logger.warning(\n                \"\"\"Non-commuting terms in the Pauli operator.\n                The Suzuki-Trotter approximation is applied.\"\"\"\n            )\n\n        blocks.extend(\n            lie_trotter_suzuki(\n                block=self.generator,\n                parameter=self.parameters.parameter,\n                order=LTSOrder[approximation],\n            )\n        )\n\n        # 2) return an AbstractBlock instance with the set of gates\n        # resulting from the decomposition\n\n        return chain(*blocks)\n    else:\n        raise NotImplementedError(\n            \"The current digital decomposition can be applied only to Pauli Hamiltonians.\"\n        )\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogSWAP","title":"<code>AnalogSWAP(control, target, parameter=3 * PI / 4)</code>","text":"<p>               Bases: <code>HamEvo</code></p> <p>Single time-independent Hamiltonian evolution over a Rydberg Ising.</p> <p>hamiltonian yielding a SWAP (up to global phase).</p> <p>Derived from Bapat et al. where it is applied to XX-type Hamiltonian</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def __init__(self, control: int, target: int, parameter: TParameter = 3 * PI / 4):\n    rydberg_ising_hamiltonian_generator = (\n        4.0 * kron((I(control) - Z(control)) / 2.0, (I(target) - Z(target)) / 2.0)\n        + (2.0 / 3.0) * np.sqrt(2.0) * X(control)\n        + (2.0 / 3.0) * np.sqrt(2.0) * X(target)\n        + (1.0 + np.sqrt(5.0) / 3) * Z(control)\n        + (1.0 + np.sqrt(5.0) / 3) * Z(target)\n    )\n    super().__init__(rydberg_ising_hamiltonian_generator, parameter, (control, target))\n</code></pre>"},{"location":"api/operations/#analog-blocks","title":"Analog blocks","text":""},{"location":"api/operations/#qadence.operations.AnalogRX","title":"<code>AnalogRX(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog X rotation.</p> <p>Shorthand for <code>AnalogRot</code>:</p> <pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9)\n</code></pre> PARAMETER DESCRIPTION <code>angle</code> <p>Rotation angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRX(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog X rotation.\n\n    Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9)\n    ```\n\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n    return _analog_rot(angle, qubit_support, phase=0, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRY","title":"<code>AnalogRY(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog Y rotation.</p> <p>Shorthand for <code>AnalogRot</code>:</p> <p><pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n</code></pre> Arguments:     angle: Rotation angle [rad]     qubit_support: Defines the (local/global) qubit support</p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRY(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog Y rotation.\n\n    Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n    return _analog_rot(angle, qubit_support, phase=-PI / 2, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRZ","title":"<code>AnalogRZ(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog Z rotation. Shorthand for <code>AnalogRot</code>: <pre><code>\u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\nAnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n</code></pre></p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRZ(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog Z rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```\n    \u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\n    AnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n    ```\n    \"\"\"\n    q = _cast(QubitSupport, qubit_support)\n    alpha = _cast(Parameter, angle)\n    delta = PI\n    omega = 0\n    duration = alpha / delta * 1000\n    h_norm = sympy.sqrt(omega**2 + delta**2)\n    ps = ParamMap(\n        alpha=alpha, duration=duration, omega=omega, delta=delta, phase=0.0, h_norm=h_norm\n    )\n    return ConstantAnalogRotation(qubit_support=q, parameters=ps, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRot","title":"<code>AnalogRot(duration, omega=0, delta=0, phase=0, qubit_support='global', add_pattern=True)</code>","text":"<p>General analog rotation operation.</p> PARAMETER DESCRIPTION <code>duration</code> <p>Duration of the rotation [ns].</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>omega</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>delta</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>phase</code> <p>Phase angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> <code>add_pattern</code> <p>False disables the semi-local addressing pattern for the execution of this specific block.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRot(\n    duration: float | str | Parameter,\n    omega: float | str | Parameter = 0,\n    delta: float | str | Parameter = 0,\n    phase: float | str | Parameter = 0,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"General analog rotation operation.\n\n    Arguments:\n        duration: Duration of the rotation [ns].\n        omega: Rotation frequency [rad/\u03bcs]\n        delta: Rotation frequency [rad/\u03bcs]\n        phase: Phase angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n        add_pattern: False disables the semi-local addressing pattern\n            for the execution of this specific block.\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n\n    if omega == 0 and delta == 0:\n        raise ValueError(\"Parameters omega and delta cannot both be 0.\")\n\n    q = _cast(QubitSupport, qubit_support)\n    duration = Parameter(duration)\n    omega = Parameter(omega)\n    delta = Parameter(delta)\n    phase = Parameter(phase)\n    h_norm = sympy.sqrt(omega**2 + delta**2)\n    alpha = duration * h_norm / 1000\n    ps = ParamMap(\n        alpha=alpha, duration=duration, omega=omega, delta=delta, phase=phase, h_norm=h_norm\n    )\n    return ConstantAnalogRotation(parameters=ps, qubit_support=q, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogInteraction","title":"<code>AnalogInteraction(duration, qubit_support='global', add_pattern=True)</code>","text":"<p>Evolution of the interaction term for a register of qubits.</p> <p>Constructs a <code>InteractionBlock</code>.</p> PARAMETER DESCRIPTION <code>duration</code> <p>Time to evolve the interaction for in nanoseconds.</p> <p> TYPE: <code>TNumber | Basic</code> </p> <code>qubit_support</code> <p>Qubits the <code>InteractionBlock</code> is applied to. Can be either <code>\"global\"</code> to evolve the interaction block to all qubits or a tuple of integers.</p> <p> TYPE: <code>str | QubitSupport | tuple</code> DEFAULT: <code>'global'</code> </p> <code>add_pattern</code> <p>False disables the semi-local addressing pattern for the execution of this specific block.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>InteractionBlock</code> <p>a <code>InteractionBlock</code></p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogInteraction(\n    duration: TNumber | sympy.Basic,\n    qubit_support: str | QubitSupport | tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; InteractionBlock:\n    \"\"\"Evolution of the interaction term for a register of qubits.\n\n    Constructs a [`InteractionBlock`][qadence.blocks.analog.InteractionBlock].\n\n    Arguments:\n        duration: Time to evolve the interaction for in nanoseconds.\n        qubit_support: Qubits the `InteractionBlock` is applied to. Can be either\n            `\"global\"` to evolve the interaction block to all qubits or a tuple of integers.\n        add_pattern: False disables the semi-local addressing pattern\n            for the execution of this specific block.\n\n    Returns:\n        a `InteractionBlock`\n    \"\"\"\n    q = _cast(QubitSupport, qubit_support)\n    ps = ParamMap(duration=duration)\n    return InteractionBlock(parameters=ps, qubit_support=q, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/parameters/","title":"Parameters","text":""},{"location":"api/parameters/#parameters","title":"Parameters","text":""},{"location":"api/parameters/#qadence.parameters.ParamMap","title":"<code>ParamMap(**kwargs)</code>","text":"<p>Connects UUIDs of parameters to their expressions and names.</p> <p>This class is not user-facing and only needed for more complex block definitions. It provides convenient access to expressions/UUIDs/names needed in different backends.</p> PARAMETER DESCRIPTION <code>kwargs</code> <p>Parameters.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>import sympy\nfrom qadence.parameters import ParamMap\n\n(x,y) = sympy.symbols(\"x y\")\nps = ParamMap(omega=2.0, duration=x+y)\n\nprint(f\"{ps.names() = }\")\nprint(f\"{ps.expressions() = }\")\nprint(f\"{ps.uuids() = }\")\n</code></pre> <pre><code>ps.names() = dict_keys(['omega', 'duration'])\nps.expressions() = dict_values([2.00000000000000, x + y])\nps.uuids() = dict_keys(['151539b6-5db6-4730-8639-70e0e77bc8e9', 'e65bf32e-795e-4963-8e0c-61bc76f40f76'])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __init__(self, **kwargs: str | TNumber | Tensor | Basic | Parameter):\n    self._name_dict: dict[str, tuple[str, Basic]] = {}\n    self._uuid_dict: dict[str, str] = {}\n    for name, v in kwargs.items():\n        param = v if isinstance(v, sympy.Basic) else Parameter(v)\n        uuid = str(uuid4())\n        self._name_dict[name] = (uuid, param)\n        self._uuid_dict[uuid] = param\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.Parameter","title":"<code>Parameter</code>","text":"<p>               Bases: <code>Symbol</code></p> <p>A wrapper on top of <code>sympy.Symbol</code>.</p> <p>Includes two additional keywords: <code>trainable</code> and <code>value</code>. This class is to define both feature parameter and variational parameters.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.trainable","title":"<code>trainable</code>  <code>instance-attribute</code>","text":"<p>Trainable parameters are variational parameters.</p> <p>Non-trainable parameters are feature parameters.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.value","title":"<code>value</code>  <code>instance-attribute</code>","text":"<p>(Initial) value of the parameter.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.__new__","title":"<code>__new__(name, **assumptions)</code>","text":"<p>Arguments:</p> <pre><code>name: When given a string only, the class\n    constructs a trainable Parameter with a a randomly initialized value.\n**assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n    kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n</code></pre> <p>Example: <pre><code>from qadence.parameters import Parameter, VariationalParameter\n\ntheta = Parameter(\"theta\")\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\nassert not theta.is_number\n\n# you can specify both trainable/value in the constructor\ntheta = Parameter(\"theta\", trainable=True, value=2.0)\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n\n# VariationalParameter/FeatureParameter are constructing\n# trainable/untrainable Parameters\ntheta = VariationalParameter(\"theta\", value=2.0)\nassert theta == Parameter(\"theta\", trainable=True, value=2.0)\n\n# When provided with a numeric type, Parameter constructs a sympy numeric type\":\nconstant_zero = Parameter(0)\nassert constant_zero.is_number\n\n# When passed a Parameter or a sympy expression, it just returns it.\nexpr = Parameter(\"x\") * Parameter(\"y\")\nprint(f\"{expr=} : {expr.free_symbols}\")\n</code></pre> <pre><code>theta: trainable=True value=0.5466825457076002\ntheta: trainable=True value=2.0\nexpr=x*y : {y, x}\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __new__(\n    cls, name: str | TNumber | Tensor | Basic | Parameter, **assumptions: Any\n) -&gt; Parameter | Basic | Expr | Array:\n    \"\"\"\n    Arguments:\n\n        name: When given a string only, the class\n            constructs a trainable Parameter with a a randomly initialized value.\n        **assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n            kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, VariationalParameter\n\n    theta = Parameter(\"theta\")\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    assert not theta.is_number\n\n    # you can specify both trainable/value in the constructor\n    theta = Parameter(\"theta\", trainable=True, value=2.0)\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n\n    # VariationalParameter/FeatureParameter are constructing\n    # trainable/untrainable Parameters\n    theta = VariationalParameter(\"theta\", value=2.0)\n    assert theta == Parameter(\"theta\", trainable=True, value=2.0)\n\n    # When provided with a numeric type, Parameter constructs a sympy numeric type\":\n    constant_zero = Parameter(0)\n    assert constant_zero.is_number\n\n    # When passed a Parameter or a sympy expression, it just returns it.\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    print(f\"{expr=} : {expr.free_symbols}\")\n    ```\n    \"\"\"\n    p: Parameter\n    if isinstance(name, get_args(TNumber)):\n        return sympify(name)\n    elif isinstance(name, Tensor):\n        if name.numel() == 1:\n            return sympify(name)\n        else:\n            return Array(name.detach().numpy())\n    elif isinstance(name, Parameter):\n        p = super().__new__(cls, name.name, **assumptions)\n        p.name = name.name\n        p.trainable = name.trainable\n        p.value = name.value\n        p.is_time = name.is_time\n        return p\n    elif isinstance(name, (Basic, Expr)):\n        if name.is_number:\n            return sympify(evaluate(name))\n        return name\n    elif isinstance(name, str):\n        p = super().__new__(cls, name, **assumptions)\n        p.trainable = assumptions.get(\"trainable\", True)\n        p.value = assumptions.get(\"value\", None)\n        p.is_time = assumptions.get(\"is_time\", False)\n        if p.value is None:\n            p.value = rand(1).item()\n        return p\n    else:\n        raise TypeError(f\"Parameter does not support type {type(name)}\")\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.FeatureParameter","title":"<code>FeatureParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def FeatureParameter(name: str, **kwargs: Any) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=False)`.\"\"\"\n    return Parameter(name, trainable=False, **kwargs)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.TimeParameter","title":"<code>TimeParameter(name)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False, is_time=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def TimeParameter(name: str) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=False, is_time=True)`.\"\"\"\n    return Parameter(name, trainable=False, is_time=True)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.VariationalParameter","title":"<code>VariationalParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def VariationalParameter(name: str, **kwargs: Any) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=True)`.\"\"\"\n    return Parameter(name, trainable=True, **kwargs)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.evaluate","title":"<code>evaluate(expr, values=None, as_torch=False)</code>","text":"<p>Arguments:</p> <pre><code>expr: An expression consisting of Parameters.\nvalues: values dict which contains values for the Parameters,\n    if empty, Parameter.value will be used.\nas_torch: Whether to retrieve a torch-differentiable expression result.\n</code></pre> <p>Example: <pre><code>from qadence.parameters import Parameter, evaluate\n\nexpr = Parameter(\"x\") * Parameter(\"y\")\n\n# Unless specified, Parameter initialized random values\n# Lets evaluate this expression and see what the result is\nres = evaluate(expr)\nprint(res)\n\n# We can also evaluate the expr using a custom dict\nd = {\"x\": 1, \"y\":2}\nres = evaluate(expr, d)\nprint(res)\n\n# Lastly, if we want a differentiable result, lets put the as_torch flag\nres = evaluate(expr, d, as_torch=True)\nprint(res)\n</code></pre> <pre><code>0.001909049133431892\n2\ntensor([2])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def evaluate(expr: Expr, values: dict | None = None, as_torch: bool = False) -&gt; TNumber | Tensor:\n    \"\"\"\n    Arguments:\n\n        expr: An expression consisting of Parameters.\n        values: values dict which contains values for the Parameters,\n            if empty, Parameter.value will be used.\n        as_torch: Whether to retrieve a torch-differentiable expression result.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, evaluate\n\n    expr = Parameter(\"x\") * Parameter(\"y\")\n\n    # Unless specified, Parameter initialized random values\n    # Lets evaluate this expression and see what the result is\n    res = evaluate(expr)\n    print(res)\n\n    # We can also evaluate the expr using a custom dict\n    d = {\"x\": 1, \"y\":2}\n    res = evaluate(expr, d)\n    print(res)\n\n    # Lastly, if we want a differentiable result, lets put the as_torch flag\n    res = evaluate(expr, d, as_torch=True)\n    print(res)\n    ```\n    \"\"\"\n    res: Basic\n    res_value: TNumber | Tensor\n    query: dict[Parameter, TNumber | Tensor] = dict()\n    values = values or dict()\n    if isinstance(expr, Array):\n        return Tensor(expr.tolist())\n    else:\n        if not expr.is_number:\n            for s in expr.free_symbols:\n                if s.name in values.keys():\n                    query[s] = values[s.name]\n                elif hasattr(s, \"value\"):\n                    query[s] = s.value\n                else:\n                    raise ValueError(f\"No value provided for symbol {s.name}\")\n        if as_torch:\n            res_value = make_differentiable(expr)(**{s.name: tensor(v) for s, v in query.items()})\n        else:\n            res = expr.subs(query)\n            res_value = sympy_to_numeric(res)\n        return res_value\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.extract_original_param_entry","title":"<code>extract_original_param_entry(param)</code>","text":"<p>Given an Expression, what was the original \"param\" given by the user? It is either.</p> <p>going to be a numeric value, or a sympy Expression (in case a string was given, it was converted via Parameter(\"string\").</p> Source code in <code>qadence/parameters.py</code> <pre><code>def extract_original_param_entry(\n    param: Expr,\n) -&gt; TNumber | Tensor | Expr:\n    \"\"\"\n    Given an Expression, what was the original \"param\" given by the user? It is either.\n\n    going to be a numeric value, or a sympy Expression (in case a string was given,\n    it was converted via Parameter(\"string\").\n    \"\"\"\n    return param if not param.is_number else evaluate(param)\n</code></pre>"},{"location":"api/parameters/#parameter-embedding","title":"Parameter embedding","text":""},{"location":"api/parameters/#qadence.blocks.embedding.embedding","title":"<code>embedding(block, to_gate_params=False, engine=Engine.TORCH)</code>","text":"<p>Construct embedding function which maps user-facing parameters to either expression-level.</p> <p>parameters or gate-level parameters. The constructed embedding function has the signature:</p> <pre><code> embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n</code></pre> <p>which means that it maps the variational parameter dict <code>params</code> and the feature parameter dict <code>inputs</code> to one new parameter dict <code>embedded_dict</code> which holds all parameters that are needed to execute a circuit on a given backend. There are two different modes for this mapping:</p> <ul> <li>Expression-level parameters: For AD-based optimization. For every unique expression we end   up with one entry in the embedded dict:   <code>len(embedded_dict) == len(unique_parameter_expressions)</code>.</li> <li>Gate-level parameters: For PSR-based optimization or real devices. One parameter for each   gate parameter, regardless if they are based on the same expression. <code>len(embedded_dict) ==   len(parametric_gates)</code>. This is needed because PSR requires to shift the angles of every   gate where the same parameter appears.</li> </ul> PARAMETER DESCRIPTION <code>block</code> <p>parametrized block into which we want to embed parameters.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>to_gate_params</code> <p>A boolean flag whether to generate gate-level parameters or expression-level parameters.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>tuple[ParamDictType, Callable[[ParamDictType, ParamDictType], ParamDictType]]</code> <p>A tuple with variational parameter dict and the embedding function.</p> Source code in <code>qadence/blocks/embedding.py</code> <pre><code>def embedding(\n    block: AbstractBlock, to_gate_params: bool = False, engine: Engine = Engine.TORCH\n) -&gt; tuple[\n    ParamDictType,\n    Callable[[ParamDictType, ParamDictType], ParamDictType],\n]:\n    \"\"\"Construct embedding function which maps user-facing parameters to either *expression-level*.\n\n    parameters or *gate-level* parameters. The constructed embedding function has the signature:\n\n         embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n\n    which means that it maps the *variational* parameter dict `params` and the *feature* parameter\n    dict `inputs` to one new parameter dict `embedded_dict` which holds all parameters that are\n    needed to execute a circuit on a given backend. There are two different *modes* for this\n    mapping:\n\n    - *Expression-level* parameters: For AD-based optimization. For every unique expression we end\n      up with one entry in the embedded dict:\n      `len(embedded_dict) == len(unique_parameter_expressions)`.\n    - *Gate-level* parameters: For PSR-based optimization or real devices. One parameter for each\n      gate parameter, regardless if they are based on the same expression. `len(embedded_dict) ==\n      len(parametric_gates)`. This is needed because PSR requires to shift the angles of **every**\n      gate where the same parameter appears.\n\n    Arguments:\n        block: parametrized block into which we want to embed parameters.\n        to_gate_params: A boolean flag whether to generate gate-level parameters or\n            expression-level parameters.\n\n    Returns:\n        A tuple with variational parameter dict and the embedding function.\n    \"\"\"\n    concretize_parameter = _concretize_parameter(engine)\n    if engine == Engine.TORCH:\n        cast_dtype = tensor\n    else:\n        from jax.numpy import array\n\n        cast_dtype = array\n\n    unique_expressions = unique(expressions(block))\n    unique_symbols = [p for p in unique(parameters(block)) if not isinstance(p, sympy.Array)]\n    unique_const_matrices = [e for e in unique_expressions if isinstance(e, sympy.Array)]\n    unique_expressions = [e for e in unique_expressions if not isinstance(e, sympy.Array)]\n\n    # NOTE\n    # there are 3 kinds of parameters in qadence\n    # - non-trainable which are considered as inputs for classical data\n    # - trainable which are the variational parameters to be optimized\n    # - fixed: which are non-trainable parameters with fixed value (e.g. pi/2)\n    #\n    # both non-trainable and trainable parameters can have the same element applied\n    # to different operations in the quantum circuit, e.g. assigning the same parameter\n    # to multiple gates.\n    non_numeric_symbols = [p for p in unique_symbols if not p.is_number]\n    trainable_symbols = [p for p in non_numeric_symbols if p.trainable]\n    constant_expressions = [expr for expr in unique_expressions if expr.is_number]\n    # we dont need to care about constant symbols if they are contained in an symbolic expression\n    # we only care about gate params which are ONLY a constant\n\n    embeddings: dict[sympy.Expr, DifferentiableExpression] = {\n        expr: make_differentiable(expr=expr, engine=engine)\n        for expr in unique_expressions\n        if not expr.is_number\n    }\n\n    uuid_to_expr = uuid_to_expression(block)\n\n    def embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n        embedded_params: dict[sympy.Expr, ArrayLike] = {}\n        if \"circuit\" in inputs or \"observables\" in inputs:\n            inputs = merge_separate_params(inputs)\n        for expr, fn in embeddings.items():\n            angle: ArrayLike\n            values = {}\n            for symbol in expr.free_symbols:\n                if symbol.name in inputs:\n                    value = inputs[symbol.name]\n                elif symbol.name in params:\n                    value = params[symbol.name]\n                else:\n                    if symbol.is_time:\n                        value = tensor(1.0)\n                    else:\n                        msg_trainable = \"Trainable\" if symbol.trainable else \"Non-trainable\"\n                        raise KeyError(\n                            f\"{msg_trainable} parameter '{symbol.name}' not found in the \"\n                            f\"inputs list: {list(inputs.keys())} nor the \"\n                            f\"params list: {list(params.keys())}.\"\n                        )\n                values[symbol.name] = value\n            angle = fn(**values)\n            # do not reshape parameters which are multi-dimensional\n            # tensors, such as for example generator matrices\n            if not len(angle.squeeze().shape) &gt; 1:\n                angle = angle.reshape(-1)\n            embedded_params[expr] = angle\n\n        for e in constant_expressions + unique_const_matrices:\n            embedded_params[e] = params[stringify(e)]\n\n        if to_gate_params:\n            gate_lvl_params: ParamDictType = {}\n            for uuid, e in uuid_to_expr.items():\n                gate_lvl_params[uuid] = embedded_params[e]\n            return gate_lvl_params\n        else:\n            embedded_params.update(inputs)\n            for k, v in params.items():\n                if k not in embedded_params:\n                    embedded_params[k] = v\n            out = {\n                stringify(k) if not isinstance(k, str) else k: (\n                    as_tensor(v)[None] if as_tensor(v).ndim == 0 else v\n                )\n                for k, v in embedded_params.items()\n            }\n            return out\n\n    params: ParamDictType\n    params = {\n        p.name: concretize_parameter(value=p.value, trainable=True) for p in trainable_symbols\n    }\n    params.update(\n        {\n            stringify(expr): concretize_parameter(value=evaluate(expr), trainable=False)\n            for expr in constant_expressions\n        }\n    )\n    params.update(\n        {\n            stringify(expr): cast_dtype(nparray(expr.tolist(), dtype=npcdouble))\n            for expr in unique_const_matrices\n        }\n    )\n    return params, embedding_fn\n</code></pre>"},{"location":"api/pasqal_cloud_connection/","title":"Pasqal Cloud Connection","text":""},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.WorkloadNotDoneError","title":"<code>WorkloadNotDoneError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Is raised if a workload is not yet finished running on remote.</p>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.WorkloadSpec","title":"<code>WorkloadSpec(circuit, backend, result_types, parameter_values=None, observable=None)</code>  <code>dataclass</code>","text":"<p>Specification of a workload to be executed on Pasqal Cloud.</p> <p>This data class defines a single workload specification that is to be executed on Pasqal's cloud platform.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The quantum circuit to be executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>backend</code> <p>The backend to execute the workload on. Not all backends are available on the cloud platform. Currently the supported backend is <code>BackendName.PYQTORCH</code>.</p> <p> TYPE: <code>BackendName | str</code> </p> <code>result_types</code> <p>The types of result to compute for this workload. The circuit will be run for all result types specified here one by one.</p> <p> TYPE: <code>list[ResultType]</code> </p> <code>parameter_values</code> <p>If the quantum circuit has feature parameters, values for those need to be provided. In the case there are only variational parameters, this field is optional. In the case there are no parameters, this field needs to be <code>None</code>. The parameter values can be either a tensor of dimension 0 or 1, which can differ per parameter. For parameters that are an array, i.e. dimension 1, all array lengths should be equal.</p> <p> TYPE: <code>dict[str, Tensor] | None</code> DEFAULT: <code>None</code> </p> <code>observable</code> <p>Observable that is used when <code>result_types</code> contains <code>ResultType.EXPECTATION</code>. The observable field is mandatory in this case. If not, the value of this field will be ignored. Only a single observable can be passed for cloud submission; providing a list of observables is not supported.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.WorkloadStoppedError","title":"<code>WorkloadStoppedError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Is raised when a workload has stopped running on remote for some reason.</p>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.check_status","title":"<code>check_status(connection, workload_id)</code>","text":"<p>Checks if the workload is successfully finished on remote connection.</p> PARAMETER DESCRIPTION <code>connection</code> <p>A <code>pasqal_cloud.SDK</code> instance which is used to connect to the cloud.</p> <p> TYPE: <code>SDK</code> </p> <code>workload_id</code> <p>the id <code>str</code> that is associated with the workload.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>WorkloadNotDoneError</code> <p>Is raised when the workload status is \"PENDING\", \"RUNNING\" or \"PAUSED\".</p> <code>WorkloadStoppedError</code> <p>Is raise when the workload status is \"CANCELED\", \"TIMED_OUT\" or \"ERROR\".</p> <code>ValueError</code> <p>Is raised when the workload status has an unsupported value.</p> RETURNS DESCRIPTION <code>Workload</code> <p>The workload result if its status is \"DONE\" as a <code>pasqal_cloud.Workload</code> object.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def check_status(connection: SDK, workload_id: str) -&gt; WorkloadResult:\n    \"\"\"Checks if the workload is successfully finished on remote connection.\n\n    Args:\n        connection: A `pasqal_cloud.SDK` instance which is used to connect to the cloud.\n        workload_id: the id `str` that is associated with the workload.\n\n    Raises:\n        WorkloadNotDoneError: Is raised when the workload status is \"PENDING\", \"RUNNING\" or\n            \"PAUSED\".\n        WorkloadStoppedError: Is raise when the workload status is \"CANCELED\", \"TIMED_OUT\" or\n            \"ERROR\".\n        ValueError: Is raised when the workload status has an unsupported value.\n\n    Returns:\n        The workload result if its status is \"DONE\" as a `pasqal_cloud.Workload` object.\n    \"\"\"\n    # TODO Make the function return a \"nice\" result object\n    result = connection.get_workload(workload_id)\n    if result.status == \"DONE\":\n        return result\n    if result.status in (\"PENDING\", \"RUNNING\", \"PAUSED\"):\n        raise WorkloadNotDoneError(\n            f\"Workload with id {workload_id} is not yet finished, the status is {result.status}\"\n        )\n    if result.status in (\"CANCELED\", \"TIMED_OUT\", \"ERROR\"):\n        message = f\"Workload with id {workload_id} couldn't finish, the status is {result.status}.\"\n        if result.status == \"ERROR\":\n            message += f\"The following error(s) occurred {result.errors}\"\n        raise WorkloadStoppedError(message)\n    raise ValueError(\n        f\"Undefined workload status ({result.status}) was returned for workload ({result.id})\"\n    )\n</code></pre>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.get_result","title":"<code>get_result(connection, workload_id, timeout=60.0, refresh_time=1.0)</code>","text":"<p>Repeatedly checks if a workload has finished and returns the result.</p> PARAMETER DESCRIPTION <code>connection</code> <p>A <code>pasqal_cloud.SDK</code> instance which is used to connect to the cloud.</p> <p> TYPE: <code>SDK</code> </p> <code>workload_id</code> <p>the id <code>str</code> that is associated with the workload.</p> <p> TYPE: <code>str</code> </p> <code>timeout</code> <p>Time in seconds after which the function times out. Defaults to 60.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>60.0</code> </p> <code>refresh_time</code> <p>Time in seconds after which the remote is requested to update the status again, when the workload is not finished yet. Defaults to 1.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> RAISES DESCRIPTION <code>TimeoutError</code> <p>description</p> RETURNS DESCRIPTION <code>Workload</code> <p>The workload result if its status is \"DONE\" as a <code>pasqal_cloud.Workload</code> object.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def get_result(\n    connection: SDK, workload_id: str, timeout: float = 60.0, refresh_time: float = 1.0\n) -&gt; WorkloadResult:\n    \"\"\"Repeatedly checks if a workload has finished and returns the result.\n\n    Args:\n        connection: A `pasqal_cloud.SDK` instance which is used to connect to the cloud.\n        workload_id: the id `str` that is associated with the workload.\n        timeout: Time in seconds after which the function times out. Defaults to 60.0.\n        refresh_time: Time in seconds after which the remote is requested to update the status\n            again, when the workload is not finished yet. Defaults to 1.0.\n\n    Raises:\n        TimeoutError: _description_\n\n    Returns:\n        The workload result if its status is \"DONE\" as a `pasqal_cloud.Workload` object.\n    \"\"\"\n    max_refresh_count = int(timeout // refresh_time)\n    for _ in range(max_refresh_count):\n        try:\n            result = check_status(connection, workload_id)\n        except WorkloadNotDoneError:\n            time.sleep(refresh_time)\n            continue\n        return result\n    raise TimeoutError(\"Request timed out because it wasn't finished in the specified time. \")\n</code></pre>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.get_workload_spec","title":"<code>get_workload_spec(model, result_types, parameter_values=None, observable=None)</code>","text":"<p>Creates a <code>WorkloadSpec</code> from a quantum model.</p> <p>This function creates a <code>WorkloadSpec</code> from a <code>QuantumModel</code> and the other arguments provided. The circuit, that is extracted from the model, is the original circuit that was used to initialize the model, not the backend converted circuit in <code>model.circuit</code>. The backend set in the model will be used in the workload specification.</p> <p>It is important to note that in case there is an observable defined in the model, it is ignored in the workload specification. To provide an observable to the workload specification, it is only possible to set it in the observable argument of this function.</p> PARAMETER DESCRIPTION <code>model</code> <p>The quantum model that defines the circuit and backend for the workload spec.</p> <p> TYPE: <code>QuantumModel</code> </p> <code>result_types</code> <p>A list of result types that is requested in this workload.</p> <p> TYPE: <code>list[ResultType]</code> </p> <code>parameter_values</code> <p>The parameter values that should be used during execution of the workload.</p> <p> TYPE: <code>dict[str, Tensor] | None</code> DEFAULT: <code>None</code> </p> <code>observable</code> <p>Observable that is used when <code>result_types</code> contains <code>ResultType.EXPECTATION</code>. The observable field is mandatory in this case. If not, the value of this field will be ignored. Only a single observable can be passed for cloud submission; providing a list of observables is not supported.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>WorkloadSpec</code> <p>A <code>WorkloadSpec</code> instance based on the quantum model passed to this function.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def get_workload_spec(\n    model: QuantumModel,\n    result_types: list[ResultType],\n    parameter_values: dict[str, Tensor] | None = None,\n    observable: AbstractBlock | None = None,\n) -&gt; WorkloadSpec:\n    \"\"\"Creates a `WorkloadSpec` from a quantum model.\n\n    This function creates a `WorkloadSpec` from a `QuantumModel` and the other arguments provided.\n    The circuit, that is extracted from the model, is the original circuit that was used to\n    initialize the model, not the backend converted circuit in `model.circuit`. The backend set in\n    the model will be used in the workload specification.\n\n    It is important to note that in case there is an observable defined in the model, it is ignored\n    in the workload specification. To provide an observable to the workload specification, it is\n    only possible to set it in the observable argument of this function.\n\n    Args:\n        model: The quantum model that defines the circuit and backend for the workload spec.\n        result_types: A list of result types that is requested in this workload.\n        parameter_values: The parameter values that should be used during execution of the\n            workload.\n        observable: Observable that is used when `result_types` contains `ResultType.EXPECTATION`.\n            The observable field is mandatory in this case. If not, the value of this field will\n            be ignored. Only a single observable can be passed for cloud submission; providing a\n            list of observables is not supported.\n\n    Returns:\n        A `WorkloadSpec` instance based on the quantum model passed to this function.\n    \"\"\"\n    circuit = model._circuit.original\n    backend = model._backend_name\n    return WorkloadSpec(circuit, backend, result_types, parameter_values, observable)\n</code></pre>"},{"location":"api/pasqal_cloud_connection/#qadence.pasqal_cloud_connection.submit_workload","title":"<code>submit_workload(connection, workload)</code>","text":"<p>Uploads a workload to Pasqal's Cloud and returns the created workload ID.</p> PARAMETER DESCRIPTION <code>connection</code> <p>A <code>pasqal_cloud.SDK</code> instance which is used to connect to the cloud.</p> <p> TYPE: <code>SDK</code> </p> <code>workload</code> <p>A <code>WorkloadSpec</code> object, defining the specification of the workload that needs to be uploaded.</p> <p> TYPE: <code>WorkloadSpec</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A workload id as a <code>str</code>.</p> Source code in <code>qadence/pasqal_cloud_connection.py</code> <pre><code>def submit_workload(connection: SDK, workload: WorkloadSpec) -&gt; str:\n    \"\"\"Uploads a workload to Pasqal's Cloud and returns the created workload ID.\n\n    Args:\n        connection: A `pasqal_cloud.SDK` instance which is used to connect to the cloud.\n        workload: A `WorkloadSpec` object, defining the specification of the workload that needs to\n            be uploaded.\n\n    Returns:\n        A workload id as a `str`.\n    \"\"\"\n    workload_json = _workload_spec_to_json(workload)\n    remote_workload = connection.create_workload(\n        workload_json.workload_type, workload_json.backend_type, workload_json.config\n    )\n    workload_id: str = remote_workload.id\n    return workload_id\n</code></pre>"},{"location":"api/quantumcircuit/","title":"QuantumCircuit","text":""},{"location":"api/quantumcircuit/#quantumcircuit","title":"QuantumCircuit","text":"<p>The abstract <code>QuantumCircuit</code> is the key object in Qadence, as it is what can be executed.</p>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit","title":"<code>QuantumCircuit(support, *blocks)</code>  <code>dataclass</code>","text":"<p>Am abstract QuantumCircuit instance.</p> <p>It needs to be passed to a quantum backend for execution.</p> <p>Arguments:</p> <pre><code>support: `Register` or number of qubits. If an integer is provided, a register is\n    constructed with `Register.all_to_all(x)`\n*blocks: (Possibly multiple) blocks to construct the circuit from.\n</code></pre> Source code in <code>qadence/circuit.py</code> <pre><code>def __init__(self, support: int | Register, *blocks: AbstractBlock):\n    \"\"\"\n    Arguments:\n\n        support: `Register` or number of qubits. If an integer is provided, a register is\n            constructed with `Register.all_to_all(x)`\n        *blocks: (Possibly multiple) blocks to construct the circuit from.\n    \"\"\"\n    self.block = chain(*blocks) if len(blocks) != 1 else blocks[0]\n    self.register = Register(support) if isinstance(support, int) else support\n\n    global_block = isinstance(self.block, AnalogBlock) and self.block.qubit_support.is_global\n    if not global_block and len(self.block) and self.block.n_qubits &gt; self.register.n_qubits:\n        raise ValueError(\n            f\"Register with {self.register.n_qubits} qubits is too small for the \"\n            f\"given block with {self.block.n_qubits} qubits\"\n        )\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.unique_parameters","title":"<code>unique_parameters</code>  <code>property</code>","text":"<p>Return the unique parameters in the circuit.</p> <p>These parameters are the actual user-facing parameters which can be assigned by the user. Multiple gates can contain the same unique parameter</p> RETURNS DESCRIPTION <code>list[Parameter]</code> <p>list[Parameter]: List of unique parameters in the circuit</p>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.dagger","title":"<code>dagger()</code>","text":"<p>Reverse the QuantumCircuit by calling dagger on the block.</p> Source code in <code>qadence/circuit.py</code> <pre><code>def dagger(self) -&gt; QuantumCircuit:\n    \"\"\"Reverse the QuantumCircuit by calling dagger on the block.\"\"\"\n    return QuantumCircuit(self.n_qubits, self.block.dagger())\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.get_blocks_by_tag","title":"<code>get_blocks_by_tag(tag)</code>","text":"<p>Extract one or more blocks using the human-readable tag.</p> <p>This function recursively explores all composite blocks to find all the occurrences of a certain tag in the blocks.</p> PARAMETER DESCRIPTION <code>tag</code> <p>the tag to look for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>list[AbstractBlock]: The block(s) corresponding to the given tag</p> Source code in <code>qadence/circuit.py</code> <pre><code>def get_blocks_by_tag(self, tag: str) -&gt; list[AbstractBlock]:\n    \"\"\"Extract one or more blocks using the human-readable tag.\n\n    This function recursively explores all composite blocks to find\n    all the occurrences of a certain tag in the blocks.\n\n    Args:\n        tag (str): the tag to look for\n\n    Returns:\n        list[AbstractBlock]: The block(s) corresponding to the given tag\n    \"\"\"\n\n    def _get_block(block: AbstractBlock) -&gt; list[AbstractBlock]:\n        blocks = []\n        if block.tag == tag:\n            blocks += [block]\n        if isinstance(block, CompositeBlock):\n            blocks += flatten(*[_get_block(b) for b in block.blocks])\n        return blocks\n\n    return _get_block(self.block)\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.parameters","title":"<code>parameters()</code>","text":"<p>Extract all parameters for primitive blocks in the circuit.</p> <p>Notice that this function returns all the unique Parameters used in the quantum circuit. These can correspond to constants too.</p> RETURNS DESCRIPTION <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>List[tuple[Parameter]]: A list of tuples containing the Parameter</p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>instance of each of the primitive blocks in the circuit or, if the <code>flatten</code></p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>flag is set to True, a flattened list of all circuit parameters</p> Source code in <code>qadence/circuit.py</code> <pre><code>def parameters(self) -&gt; list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]:\n    \"\"\"Extract all parameters for primitive blocks in the circuit.\n\n    Notice that this function returns all the unique Parameters used\n    in the quantum circuit. These can correspond to constants too.\n\n    Returns:\n        List[tuple[Parameter]]: A list of tuples containing the Parameter\n        instance of each of the primitive blocks in the circuit or, if the `flatten`\n        flag is set to True, a flattened list of all circuit parameters\n    \"\"\"\n    return parameters(self.block)\n</code></pre>"},{"location":"api/register/","title":"Register","text":""},{"location":"api/register/#quantum-registers","title":"Quantum Registers","text":""},{"location":"api/register/#qadence.register.Register","title":"<code>Register(support, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>","text":"<p>A register of qubits including 2D coordinates.</p> <p>Instantiating the Register class directly is only recommended for building custom registers. For most uses where a predefined lattice is desired it is recommended to use the various class methods available, e.g. <code>Register.triangular_lattice</code>.</p> PARAMETER DESCRIPTION <code>support</code> <p>A NetworkX graph or number of qubits. Nodes can include a <code>\"pos\"</code> attribute such that e.g.: <code>graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}</code> which will be used in backends that need qubit coordinates. Passing a number of qubits calls <code>Register.all_to_all(n_qubits)</code>.</p> <p> TYPE: <code>Graph | int</code> </p> <code>spacing</code> <p>Value set as the distance between the two closest qubits. The spacing argument is also available for all the class method constructors.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>1.0</code> </p> <p>Examples: <pre><code>from qadence import Register\n\nreg_all = Register.all_to_all(n_qubits = 4)\nreg_line = Register.line(n_qubits = 4)\nreg_circle = Register.circle(n_qubits = 4)\nreg_squre = Register.square(qubits_side = 2)\nreg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\nreg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\nreg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n</code></pre> </p> Source code in <code>qadence/register.py</code> <pre><code>def __init__(\n    self,\n    support: nx.Graph | int,\n    spacing: float | None = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n):\n    \"\"\"\n    A register of qubits including 2D coordinates.\n\n    Instantiating the Register class directly is only recommended for building custom registers.\n    For most uses where a predefined lattice is desired it is recommended to use the various\n    class methods available, e.g. `Register.triangular_lattice`.\n\n    Arguments:\n        support: A NetworkX graph or number of qubits. Nodes can include a `\"pos\"` attribute\n            such that e.g.: `graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}` which\n            will be used in backends that need qubit coordinates. Passing a number of qubits\n            calls `Register.all_to_all(n_qubits)`.\n        spacing: Value set as the distance between the two closest qubits. The spacing\n            argument is also available for all the class method constructors.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import Register\n\n    reg_all = Register.all_to_all(n_qubits = 4)\n    reg_line = Register.line(n_qubits = 4)\n    reg_circle = Register.circle(n_qubits = 4)\n    reg_squre = Register.square(qubits_side = 2)\n    reg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\n    reg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\n    reg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n    ```\n    \"\"\"\n    if device_specs is not None and not isinstance(device_specs, RydbergDevice):\n        raise ValueError(\"Device specs are not valid. Please pass a `RydbergDevice` instance.\")\n\n    self.device_specs = device_specs\n\n    self.graph = support if isinstance(support, nx.Graph) else alltoall_graph(support)\n\n    if spacing is not None and self.min_distance != 0.0:\n        _scale_node_positions(self.graph, self.min_distance, spacing)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.all_node_pairs","title":"<code>all_node_pairs</code>  <code>property</code>","text":"<p>Return a list of all possible qubit pairs in the register.</p>"},{"location":"api/register/#qadence.register.Register.coords","title":"<code>coords</code>  <code>property</code>","text":"<p>Return the dictionary of qubit coordinates.</p>"},{"location":"api/register/#qadence.register.Register.distances","title":"<code>distances</code>  <code>property</code>","text":"<p>Return a dictionary of distances for all qubit pairs in the register.</p>"},{"location":"api/register/#qadence.register.Register.edge_distances","title":"<code>edge_distances</code>  <code>property</code>","text":"<p>Return a dictionary of distances for the qubit pairs that are.</p> <p>connected by an edge in the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return the EdgeView of the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.min_distance","title":"<code>min_distance</code>  <code>property</code>","text":"<p>Return the minimum distance between two qubts in the register.</p>"},{"location":"api/register/#qadence.register.Register.n_qubits","title":"<code>n_qubits</code>  <code>property</code>","text":"<p>Total number of qubits in the register.</p>"},{"location":"api/register/#qadence.register.Register.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return the NodeView of the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.support","title":"<code>support</code>  <code>property</code>","text":"<p>Return the set of qubits in the register.</p>"},{"location":"api/register/#qadence.register.Register.all_to_all","title":"<code>all_to_all(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a register with an all-to-all connectivity graph.</p> <p>The graph is projected onto a 2D space and the qubit coordinates are set using a spring layout algorithm.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef all_to_all(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a register with an all-to-all connectivity graph.\n\n    The graph is projected\n    onto a 2D space and the qubit coordinates are set using a spring layout algorithm.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    return cls(alltoall_graph(n_qubits), spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.circle","title":"<code>circle(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a circle register.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef circle(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a circle register.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    graph = nx.grid_2d_graph(n_qubits, 1, periodic=True)\n    graph = nx.relabel_nodes(graph, {(i, 0): i for i in range(n_qubits)})\n    coords = nx.circular_layout(graph)\n    values = {i: {\"pos\": pos} for i, pos in coords.items()}\n    nx.set_node_attributes(graph, values)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.draw","title":"<code>draw(show=True)</code>","text":"<p>Draw the underlying NetworkX graph representing the register.</p> Source code in <code>qadence/register.py</code> <pre><code>def draw(self, show: bool = True) -&gt; None:\n    \"\"\"Draw the underlying NetworkX graph representing the register.\"\"\"\n    coords = {i: n[\"pos\"] for i, n in self.graph.nodes.items()}\n    nx.draw(self.graph, with_labels=True, pos=coords)\n    if show:\n        plt.gcf().show()\n</code></pre>"},{"location":"api/register/#qadence.register.Register.from_coordinates","title":"<code>from_coordinates(coords, lattice=LatticeTopology.ARBITRARY, spacing=None, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a register from a list of qubit coordinates.</p> <p>Each node is added to the underlying graph with the respective coordinates, but the edges are left empty.</p> PARAMETER DESCRIPTION <code>coords</code> <p>List of qubit coordinate tuples.</p> <p> TYPE: <code>list[tuple]</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef from_coordinates(\n    cls,\n    coords: list[tuple],\n    lattice: LatticeTopology | str = LatticeTopology.ARBITRARY,\n    spacing: float | None = None,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a register from a list of qubit coordinates.\n\n    Each node is added to the underlying\n    graph with the respective coordinates, but the edges are left empty.\n\n    Arguments:\n        coords: List of qubit coordinate tuples.\n    \"\"\"\n    graph = nx.Graph()\n    for i, pos in enumerate(coords):\n        graph.add_node(i, pos=pos)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.honeycomb_lattice","title":"<code>honeycomb_lattice(n_cells_row, n_cells_col, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a honeycomb lattice register.</p> <p>Each cell is an hexagon made up of six qubits.</p> PARAMETER DESCRIPTION <code>n_cells_row</code> <p>Number of cells in each row.</p> <p> TYPE: <code>int</code> </p> <code>n_cells_col</code> <p>Number of cells in each column.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef honeycomb_lattice(\n    cls,\n    n_cells_row: int,\n    n_cells_col: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a honeycomb lattice register.\n\n    Each cell is an hexagon made up of six qubits.\n\n    Arguments:\n        n_cells_row: Number of cells in each row.\n        n_cells_col: Number of cells in each column.\n    \"\"\"\n    graph = nx.hexagonal_lattice_graph(n_cells_row, n_cells_col)\n    graph = nx.relabel_nodes(graph, {(i, j): k for k, (i, j) in enumerate(graph.nodes)})\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.line","title":"<code>line(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a line register.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef line(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a line register.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    return cls(line_graph(n_qubits), spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.rescale_coords","title":"<code>rescale_coords(scaling)</code>","text":"<p>Rescale the coordinates of all qubits in the register.</p> PARAMETER DESCRIPTION <code>scaling</code> <p>Scaling value.</p> <p> TYPE: <code>float</code> </p> Source code in <code>qadence/register.py</code> <pre><code>def rescale_coords(self, scaling: float) -&gt; Register:\n    \"\"\"\n    Rescale the coordinates of all qubits in the register.\n\n    Arguments:\n        scaling: Scaling value.\n    \"\"\"\n    g = deepcopy(self.graph)\n    _scale_node_positions(g, min_distance=1.0, spacing=scaling)\n    return Register(g, spacing=None, device_specs=self.device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.square","title":"<code>square(qubits_side, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a square register.</p> PARAMETER DESCRIPTION <code>qubits_side</code> <p>Number of qubits on one side of the square.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef square(\n    cls,\n    qubits_side: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a square register.\n\n    Arguments:\n        qubits_side: Number of qubits on one side of the square.\n    \"\"\"\n    n_points = 4 * (qubits_side - 1)\n\n    def gen_points() -&gt; np.ndarray:\n        rotate_left = np.array([[0.0, -1.0], [1.0, 0.0]])\n        increment = np.array([0.0, 1.0])\n\n        points = [np.array([0.0, 0.0])]\n        counter = 1\n        while len(points) &lt; n_points:\n            points.append(points[-1] + increment)\n\n            counter = (counter + 1) % qubits_side\n            if counter == 0:\n                increment = rotate_left.dot(increment)\n                counter = 1\n        points = np.array(points)  # type: ignore[assignment]\n        points -= np.mean(points, axis=0)\n\n        return points  # type: ignore[return-value]\n\n    graph = nx.grid_2d_graph(n_points, 1, periodic=True)\n    graph = nx.relabel_nodes(graph, {(i, 0): i for i in range(n_points)})\n    values = {i: {\"pos\": point} for i, point in zip(graph.nodes, gen_points())}\n    nx.set_node_attributes(graph, values)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.triangular_lattice","title":"<code>triangular_lattice(n_cells_row, n_cells_col, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a triangular lattice register.</p> <p>Each cell is a triangle made up of three qubits.</p> PARAMETER DESCRIPTION <code>n_cells_row</code> <p>Number of cells in each row.</p> <p> TYPE: <code>int</code> </p> <code>n_cells_col</code> <p>Number of cells in each column.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef triangular_lattice(\n    cls,\n    n_cells_row: int,\n    n_cells_col: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a triangular lattice register.\n\n    Each cell is a triangle made up of three qubits.\n\n    Arguments:\n        n_cells_row: Number of cells in each row.\n        n_cells_col: Number of cells in each column.\n    \"\"\"\n    return cls(triangular_lattice_graph(n_cells_row, n_cells_col), spacing, device_specs)\n</code></pre>"},{"location":"api/serialization/","title":"Serialization","text":""},{"location":"api/serialization/#serialization","title":"Serialization","text":""},{"location":"api/serialization/#qadence.serialization.SerializationModel","title":"<code>SerializationModel(d=dict())</code>  <code>dataclass</code>","text":"<p>A serialization model class to serialize data from <code>QuantumModel</code>s,.</p> <p><code>torch.nn.Module</code> and similar structures. The data included in the serialization logic includes: the <code>AbstractBlock</code> and its children classes, <code>QuantumCircuit</code>, <code>Register</code>, and <code>sympy</code> expressions (including <code>Parameter</code> class from <code>qadence.parameters</code>).</p> <p>A children class must define the <code>value</code> attribute type and how to handle it, since it is the main property for the class to be used by the serialization process. For instance:</p> <pre><code>@dataclass\nclass QuantumCircuitSerialization(SerializationModel):\n    value: QuantumCircuit = dataclass_field(init=False)\n\n    def __post_init__(self) -&gt; None:\n        self.value = (\n            QuantumCircuit._from_dict(self.d)\n            if isinstance(self.d, dict)\n            else self.d\n        )\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.deserialize","title":"<code>deserialize(d, as_torch=False)</code>","text":"<p>Supported Types:</p> <p>AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module Deserializes a dict to one of the supported types.</p> PARAMETER DESCRIPTION <code>d</code> <p>A dict containing a serialized object.</p> <p> TYPE: <code>dict</code> </p> <code>as_torch</code> <p>Whether to transform to torch for the deserialized object.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Returns:     AbstractBlock, QuantumCircuit, QuantumModel, Register, torch.nn.Module.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n\n## Lets use myblock in a QuantumCircuit and serialize it.\n\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('d997d740-ec17-4898-a829-0a2f6112b85c', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.903918129919439'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('9d96143b-f5e4-48a9-9237-26e1453b89ec', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.8292579286822497'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('a23589e5-c0c0-433f-8557-10e9818725b6', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.443373344920984'}}})}}, 'noise': None}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('01be1c2c-d407-4a47-a531-08c393c0ac4a', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.6946851989636091'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('91a02313-9d17-47bd-8542-e870fc98fc7a', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.519782552266572'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('a6699859-c511-494f-9fe5-1ea54703cf90', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.30345589825999975'}}})}}, 'noise': None}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None, 'noise': None}], 'noise': None}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def deserialize(d: dict, as_torch: bool = False) -&gt; SUPPORTED_TYPES:\n    \"\"\"\n    Supported Types:\n\n    AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module\n    Deserializes a dict to one of the supported types.\n\n    Arguments:\n        d (dict): A dict containing a serialized object.\n        as_torch (bool): Whether to transform to torch for the deserialized object.\n    Returns:\n        AbstractBlock, QuantumCircuit, QuantumModel, Register, torch.nn.Module.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\n    obj: SerializationModel\n    if d.get(\"expression\"):\n        obj = ExpressionSerialization(d)\n    elif d.get(\"block\") and d.get(\"register\"):\n        obj = QuantumCircuitSerialization(d)\n    elif d.get(\"graph\"):\n        obj = RegisterSerialization(d)\n    elif d.get(\"type\"):\n        obj = BlockTypeSerialization(d)\n    else:\n        obj = ModelSerialization(d, as_torch=as_torch)\n    return obj.value\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.load","title":"<code>load(file_path, map_location='cpu')</code>","text":"<p>Same as serialize/deserialize but for storing/loading files.</p> <p>Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register Loads a .json or .pt file to one of the supported types.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> </p> <code>map_location</code> <p>In case of a .pt file, on which device to load the object (cpu,cuda).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <p>Returns:     A object of type AbstractBlock, QuantumCircuit, QuantumModel, Register.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\n\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def load(file_path: str | Path, map_location: str = \"cpu\") -&gt; SUPPORTED_TYPES:\n    \"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n\n    Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register\n    Loads a .json or .pt file to one of the supported types.\n\n    Arguments:\n        file_path (str): The name of the file.\n        map_location (str): In case of a .pt file, on which device to load the object (cpu,cuda).\n    Returns:\n        A object of type AbstractBlock, QuantumCircuit, QuantumModel, Register.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\n    d = {}\n    if isinstance(file_path, str):\n        file_path = Path(file_path)\n    if not os.path.exists(file_path):\n        logger.error(f\"File {file_path} not found.\")\n        raise FileNotFoundError\n    FORMAT = file_extension(file_path)\n    _, _, load_fn, _ = FORMAT_DICT[FORMAT]  # type: ignore[index]\n    try:\n        d = load_fn(file_path, map_location)\n        logger.debug(f\"Successfully loaded {d} from {file_path}.\")\n    except Exception as e:\n        logger.error(f\"Unable to load Object from {file_path} due to {e}\")\n    return deserialize(d)\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.parse_expr_fn","title":"<code>parse_expr_fn(code)</code>","text":"<p>A parsing expressions function that checks whether a given code is valid on.</p> <p>the parsing grammar. The grammar is defined to be compatible with <code>sympy</code> expressions, such as <code>Float('-0.33261030434342942', precision=53)</code>, while avoiding code injection such as <code>2*3</code> or <code>__import__('os').system('ls -la')</code>.</p> PARAMETER DESCRIPTION <code>code</code> <p>code to be parsed and checked.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Boolean indicating whether the code matches the defined grammar or not.</p> Source code in <code>qadence/serialization.py</code> <pre><code>def parse_expr_fn(code: str) -&gt; bool:\n    \"\"\"\n    A parsing expressions function that checks whether a given code is valid on.\n\n    the parsing grammar. The grammar is defined to be compatible with `sympy`\n    expressions, such as `Float('-0.33261030434342942', precision=53)`, while\n    avoiding code injection such as `2*3` or `__import__('os').system('ls -la')`.\n\n    Args:\n        code (str): code to be parsed and checked.\n\n    Returns:\n        Boolean indicating whether the code matches the defined grammar or not.\n    \"\"\"\n\n    parser = _parsing_serialize_expr\n    try:\n        parser.parse(code)\n    except NoMatch:\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.save","title":"<code>save(obj, folder, file_name='', format=SerializationFormat.JSON)</code>","text":"<p>Same as serialize/deserialize but for storing/loading files.</p> <p>Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module Saves a qadence object to a json/.pt.</p> PARAMETER DESCRIPTION <code>obj</code> <pre><code>Either AbstractBlock, QuantumCircuit, QuantumModel, Register.\n</code></pre> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register</code> </p> <code>file_name</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>format</code> <p>The type of file to save.</p> <p> TYPE: <code>str</code> DEFAULT: <code>JSON</code> </p> <p>Returns:     None.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\n\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def save(\n    obj: SUPPORTED_TYPES,\n    folder: str | Path,\n    file_name: str = \"\",\n    format: SerializationFormat = SerializationFormat.JSON,\n) -&gt; None:\n    \"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n\n    Supported types:\n    AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module\n    Saves a qadence object to a json/.pt.\n\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register):\n                Either AbstractBlock, QuantumCircuit, QuantumModel, Register.\n        file_name (str): The name of the file.\n        format (str): The type of file to save.\n    Returns:\n        None.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\n    if not isinstance(obj, get_args(SUPPORTED_TYPES)):\n        logger.error(f\"Serialization of object type {type(obj)} not supported.\")\n    folder = Path(folder)\n    if not folder.is_dir():\n        logger.error(NotADirectoryError)\n    if file_name == \"\":\n        file_name = type(obj).__name__\n    try:\n        suffix, save_fn, _, save_params = FORMAT_DICT[format]\n        d = serialize(obj, save_params)\n        file_path = folder / Path(file_name + suffix)\n        save_fn(d, file_path)\n        logger.debug(f\"Successfully saved {obj} from to {folder}.\")\n    except Exception as e:\n        logger.error(f\"Unable to write {type(obj)} to disk due to {e}\")\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.serialize","title":"<code>serialize(obj, save_params=False)</code>","text":"<p>Supported Types:</p> <p>AbstractBlock | QuantumCircuit | QuantumModel | torch.nn.Module | Register | Module Serializes a qadence object to a dictionary.</p> PARAMETER DESCRIPTION <code>obj</code> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register | Module</code> </p> <p>Returns:     A dict.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n\n## Lets use myblock in a QuantumCircuit and serialize it.\n\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('ec65f7fa-ab32-49f3-bebb-8f4a689ea07b', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.5308828318298372'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('971bce47-a559-45fb-8d17-939d678c8d26', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.5200833080012761'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('60e58ff4-7344-43d7-8f7d-ad0bf07a9561', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.9106922858766201'}}})}}, 'noise': None}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('454fcfda-745c-4b5d-9fdf-b9a48e964c5f', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.06211720774564189'}}})}}, 'noise': None}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('ed71b3df-3c5f-45ca-8918-9deeafc50980', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.2475845964398562'}}})}}, 'noise': None}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('f16d5318-9701-4fa5-92c9-35558467dc15', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.004416638079044688'}}})}}, 'noise': None}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None, 'noise': None}], 'noise': None}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def serialize(obj: SUPPORTED_TYPES, save_params: bool = False) -&gt; dict:\n    \"\"\"\n    Supported Types:\n\n    AbstractBlock | QuantumCircuit | QuantumModel | torch.nn.Module | Register | Module\n    Serializes a qadence object to a dictionary.\n\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module):\n    Returns:\n        A dict.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\n    if not isinstance(obj, get_args(SUPPORTED_TYPES)):\n        logger.error(TypeError(f\"Serialization of object type {type(obj)} not supported.\"))\n\n    d: dict = dict()\n    try:\n        if isinstance(obj, core.Expr):\n            symb_dict = dict()\n            expr_dict = {\"name\": str(obj), \"expression\": srepr(obj)}\n            symbs: set[Parameter | core.Basic] = obj.free_symbols\n            if symbs:\n                symb_dict = {\"symbols\": {str(s): s._to_dict() for s in symbs}}\n            d = {**expr_dict, **symb_dict}\n        else:\n            if hasattr(obj, \"_to_dict\"):\n                model_to_dict: Callable = obj._to_dict\n                d = (\n                    model_to_dict(save_params)\n                    if isinstance(obj, torch.nn.Module)\n                    else model_to_dict()\n                )\n            elif hasattr(obj, \"state_dict\"):\n                d = {type(obj).__name__: obj.state_dict()}\n            else:\n                raise ValueError(f\"Cannot serialize object {obj}.\")\n    except Exception as e:\n        logger.error(f\"Serialization of object {obj} failed due to {e}\")\n    return d\n</code></pre>"},{"location":"api/states/","title":"State preparation","text":""},{"location":"api/states/#state-preparation-routines","title":"State Preparation Routines","text":""},{"location":"api/states/#qadence.states.density_mat","title":"<code>density_mat(state)</code>","text":"<p>Computes the density matrix from a pure state vector.</p> PARAMETER DESCRIPTION <code>state</code> <p>The pure state vector :math:<code>|\\psi\\rangle</code>.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>The density matrix :math:<code>\\rho = |\\psi \\rangle \\langle\\psi|</code>.</p> <p> TYPE: <code>DensityMatrix</code> </p> Source code in <code>qadence/states.py</code> <pre><code>def density_mat(state: Tensor) -&gt; DensityMatrix:\n    \"\"\"\n    Computes the density matrix from a pure state vector.\n\n    Arguments:\n        state: The pure state vector :math:`|\\\\psi\\\\rangle`.\n\n    Returns:\n        Tensor: The density matrix :math:`\\\\rho = |\\psi \\\\rangle \\\\langle\\\\psi|`.\n    \"\"\"\n    if isinstance(state, DensityMatrix):\n        return state\n    return DensityMatrix(torch.einsum(\"bi,bj-&gt;bij\", (state, state.conj())))\n</code></pre>"},{"location":"api/states/#qadence.states.ghz_block","title":"<code>ghz_block(n_qubits)</code>","text":"<p>Generates the abstract ghz state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A ChainBlock representing the GHZ state.</p> <p>Examples: <pre><code>from qadence.states import ghz_block\n\nblock = ghz_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 CNOT(0, 1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_block(n_qubits: int) -&gt; ChainBlock:\n    \"\"\"\n    Generates the abstract ghz state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A ChainBlock representing the GHZ state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_block\n\n    block = ghz_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    cnots = chain(CNOT(i - 1, i) for i in range(1, n_qubits))\n    return chain(H(0), cnots)\n</code></pre>"},{"location":"api/states/#qadence.states.ghz_state","title":"<code>ghz_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a GHZ state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import ghz_state\n\nprint(ghz_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j],\n        [0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Creates a GHZ state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_state\n\n    print(ghz_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\n    norm = 1 / torch.sqrt(torch.tensor(2))\n    return norm * (zero_state(n_qubits, batch_size) + one_state(n_qubits, batch_size))\n</code></pre>"},{"location":"api/states/#qadence.states.is_normalized","title":"<code>is_normalized(wf, atol=NORMALIZATION_ATOL)</code>","text":"<p>Checks if a wave function is normalized.</p> PARAMETER DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>atol</code> <p>The tolerance.</p> <p> TYPE: <code>float) </code> DEFAULT: <code>NORMALIZATION_ATOL</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A bool.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, is_normalized\n\nprint(is_normalized(uniform_state(2)))\n</code></pre> <pre><code>True\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def is_normalized(wf: Tensor, atol: float = NORMALIZATION_ATOL) -&gt; bool:\n    \"\"\"\n    Checks if a wave function is normalized.\n\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n        atol (float) : The tolerance.\n\n    Returns:\n        A bool.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, is_normalized\n\n    print(is_normalized(uniform_state(2)))\n    ```\n    \"\"\"\n    if wf.dim() == 1:\n        wf = wf.unsqueeze(0)\n    sum_probs: Tensor = (wf.abs() ** 2).sum(dim=1)\n    ones = torch.ones_like(sum_probs)\n    return torch.allclose(sum_probs, ones, rtol=0.0, atol=atol)  # type: ignore[no-any-return]\n</code></pre>"},{"location":"api/states/#qadence.states.normalize","title":"<code>normalize(wf)</code>","text":"<p>Normalizes a wavefunction or batch of wave functions.</p> PARAMETER DESCRIPTION <code>wf</code> <p>Normalized wavefunctions.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, normalize\n\nprint(normalize(uniform_state(2, 2)))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j],\n        [0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def normalize(wf: Tensor) -&gt; Tensor:\n    \"\"\"\n    Normalizes a wavefunction or batch of wave functions.\n\n    Arguments:\n        wf (torch.Tensor): Normalized wavefunctions.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, normalize\n\n    print(normalize(uniform_state(2, 2)))\n    ```\n    \"\"\"\n    if wf.dim() == 1:\n        return wf / torch.sqrt((wf.abs() ** 2).sum())\n    else:\n        return wf / torch.sqrt((wf.abs() ** 2).sum(1)).unsqueeze(1)\n</code></pre>"},{"location":"api/states/#qadence.states.one_block","title":"<code>one_block(n_qubits)</code>","text":"<p>Generates the abstract one state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the one state.</p> <p>Examples: <pre><code>from qadence.states import one_block\n\nblock = one_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract one state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the one state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_block\n\n    block = one_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(X, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.one_state","title":"<code>one_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the one state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import one_state\n\nstate = one_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the one state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_state\n\n    state = one_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    bitstring = \"1\" * n_qubits\n    return _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"api/states/#qadence.states.overlap","title":"<code>overlap(s0, s1)</code>","text":"<p>Computes the exact overlap between two statevectors.</p> PARAMETER DESCRIPTION <code>s0</code> <p>A statevector or batch of statevectors.</p> <p> TYPE: <code>Tensor</code> </p> <code>s1</code> <p>A statevector or batch of statevectors.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor with the result.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\n\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>00010100\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def overlap(s0: torch.Tensor, s1: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the exact overlap between two statevectors.\n\n    Arguments:\n        s0 (torch.Tensor): A statevector or batch of statevectors.\n        s1 (torch.Tensor): A statevector or batch of statevectors.\n\n    Returns:\n        A torch.Tensor with the result.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\n    from qadence.overlap import overlap_exact\n\n    return overlap_exact(s0, s1)\n</code></pre>"},{"location":"api/states/#qadence.states.pmf","title":"<code>pmf(wf)</code>","text":"<p>Converts a wave function into a torch Distribution.</p> PARAMETER DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Distribution</code> <p>A torch.distributions.Distribution.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, pmf\n\nprint(pmf(uniform_state(2)).probs)\n</code></pre> <pre><code>tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def pmf(wf: Tensor) -&gt; Distribution:\n    \"\"\"\n    Converts a wave function into a torch Distribution.\n\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n\n    Returns:\n        A torch.distributions.Distribution.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, pmf\n\n    print(pmf(uniform_state(2)).probs)\n    ```\n    \"\"\"\n    return Categorical(torch.abs(torch.pow(wf, 2)))\n</code></pre>"},{"location":"api/states/#qadence.states.product_block","title":"<code>product_block(bitstring)</code>","text":"<p>Creates an abstract product state from a bitstring.</p> PARAMETER DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import product_block\n\nprint(product_block(\"1100\"))\n</code></pre> <pre><code>KronBlock(0,1,2,3)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u251c\u2500\u2500 I(2)\n\u2514\u2500\u2500 I(3)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def product_block(bitstring: str) -&gt; KronBlock:\n    \"\"\"\n    Creates an abstract product state from a bitstring.\n\n    Arguments:\n        bitstring (str): A bitstring.\n\n    Returns:\n        A KronBlock representing the product state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_block\n\n    print(product_block(\"1100\"))\n    ```\n    \"\"\"\n    return _block_from_bitstring(bitstring)\n</code></pre>"},{"location":"api/states/#qadence.states.product_state","title":"<code>product_state(bitstring, batch_size=1, endianness=Endianness.BIG, backend=BackendName.PYQTORCH)</code>","text":"<p>Creates a product state from a bitstring.</p> PARAMETER DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size.</p> <p> TYPE: <code>int) </code> DEFAULT: <code>1</code> </p> <code>backend</code> <p>The backend to use. Default is \"pyqtorch\".</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> RETURNS DESCRIPTION <code>ArrayLike</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import product_state\n\nprint(product_state(\"1100\", backend=\"pyqtorch\"))\nprint(product_state(\"1100\", backend=\"horqrux\"))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n         1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n 0.+0.j 0.+0.j 1.+0.j 0.+0.j 0.+0.j 0.+0.j]\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>@singledispatch\ndef product_state(\n    bitstring: str,\n    batch_size: int = 1,\n    endianness: Endianness = Endianness.BIG,\n    backend: BackendName = BackendName.PYQTORCH,\n) -&gt; ArrayLike:\n    \"\"\"\n    Creates a product state from a bitstring.\n\n    Arguments:\n        bitstring (str): A bitstring.\n        batch_size (int) : Batch size.\n        backend (BackendName): The backend to use. Default is \"pyqtorch\".\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_state\n\n    print(product_state(\"1100\", backend=\"pyqtorch\"))\n    print(product_state(\"1100\", backend=\"horqrux\"))\n    ```\n    \"\"\"\n    if batch_size:\n        logger.debug(\n            \"The input `batch_size` is going to be deprecated. \"\n            \"For now, default batch_size is set to 1.\"\n        )\n    return run(product_block(bitstring), backend=backend, endianness=endianness)\n</code></pre>"},{"location":"api/states/#qadence.states.rand_bitstring","title":"<code>rand_bitstring(N)</code>","text":"<p>Creates a random bistring.</p> PARAMETER DESCRIPTION <code>N</code> <p>The length of the bitstring.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\n\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>11111100\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_bitstring(N: int) -&gt; str:\n    \"\"\"\n    Creates a random bistring.\n\n    Arguments:\n        N (int): The length of the bitstring.\n\n    Returns:\n        A string.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\n    return \"\".join(str(random.randint(0, 1)) for _ in range(N))\n</code></pre>"},{"location":"api/states/#qadence.states.rand_product_block","title":"<code>rand_product_block(n_qubits)</code>","text":"<p>Creates a block representing a random abstract product state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import rand_product_block\n\nprint(rand_product_block(n_qubits=2))\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Creates a block representing a random abstract product state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the product state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_block\n\n    print(rand_product_block(n_qubits=2))\n    ```\n    \"\"\"\n    return product_block(rand_bitstring(n_qubits))\n</code></pre>"},{"location":"api/states/#qadence.states.rand_product_state","title":"<code>rand_product_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a random product state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import rand_product_state\n\nprint(rand_product_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Creates a random product state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_state\n\n    print(rand_product_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\n    wf_batch = torch.zeros(batch_size, 2**n_qubits, dtype=DTYPE)\n    rand_pos = torch.randint(0, 2**n_qubits, (batch_size,))\n    wf_batch[torch.arange(batch_size), rand_pos] = torch.tensor(1.0 + 0j, dtype=DTYPE)\n    return wf_batch\n</code></pre>"},{"location":"api/states/#qadence.states.random_state","title":"<code>random_state(n_qubits, batch_size=1, backend=BackendName.PYQTORCH, type=StateGeneratorType.HAAR_MEASURE_FAST)</code>","text":"<p>Generates a random state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>backend</code> <p>The backend to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>type</code> <p>StateGeneratorType.</p> <p> DEFAULT: <code>HAAR_MEASURE_FAST</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import random_state, StateGeneratorType\nfrom qadence.states import random_state, is_normalized, pmf\nfrom qadence.types import BackendName\nfrom torch.distributions import Distribution\n\n### We have the following options:\nprint([g.value for g in StateGeneratorType])\n\nn_qubits = 2\n# The default is StateGeneratorType.HAAR_MEASURE_FAST\nstate = random_state(n_qubits=n_qubits)\nprint(state)\n\n### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\nrandom = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\nprint(random)\n</code></pre> <pre><code>['RandomRotations', 'HaarMeasureFast', 'HaarMeasureSlow']\ntensor([[-0.3825+0.1844j, -0.1523-0.0281j, -0.6161+0.6149j, -0.1737-0.0889j]])\ntensor([[ 0.8348-0.4412j, -0.2912+0.1539j,  0.0000+0.0000j,  0.0000+0.0000j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def random_state(\n    n_qubits: int,\n    batch_size: int = 1,\n    backend: str = BackendName.PYQTORCH,\n    type: StateGeneratorType = StateGeneratorType.HAAR_MEASURE_FAST,\n) -&gt; Tensor:\n    \"\"\"\n    Generates a random state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        backend (str): The backend to use.\n        batch_size (int): The batch size.\n        type : StateGeneratorType.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import random_state, StateGeneratorType\n    from qadence.states import random_state, is_normalized, pmf\n    from qadence.types import BackendName\n    from torch.distributions import Distribution\n\n    ### We have the following options:\n    print([g.value for g in StateGeneratorType])\n\n    n_qubits = 2\n    # The default is StateGeneratorType.HAAR_MEASURE_FAST\n    state = random_state(n_qubits=n_qubits)\n    print(state)\n\n    ### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\n    random = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\n    print(random)\n    ```\n    \"\"\"\n\n    if type == StateGeneratorType.HAAR_MEASURE_FAST:\n        state = concat(tuple(_rand_haar_fast(n_qubits) for _ in range(batch_size)), dim=0)\n    elif type == StateGeneratorType.HAAR_MEASURE_SLOW:\n        state = concat(tuple(_rand_haar_slow(n_qubits) for _ in range(batch_size)), dim=0)\n    elif type == StateGeneratorType.RANDOM_ROTATIONS:\n        state = run(_abstract_random_state(n_qubits, batch_size))  # type: ignore\n    assert all(list(map(is_normalized, state)))\n    return state\n</code></pre>"},{"location":"api/states/#qadence.states.uniform_block","title":"<code>uniform_block(n_qubits)</code>","text":"<p>Generates the abstract uniform state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the uniform state.</p> <p>Examples: <pre><code>from qadence.states import uniform_block\n\nblock = uniform_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract uniform state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the uniform state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_block\n\n    block = uniform_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(H, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.uniform_state","title":"<code>uniform_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the uniform state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state\n\nstate = uniform_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the uniform state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state\n\n    state = uniform_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    norm = 1 / torch.sqrt(torch.tensor(2**n_qubits))\n    return norm * torch.ones(batch_size, 2**n_qubits, dtype=DTYPE)\n</code></pre>"},{"location":"api/states/#qadence.states.zero_block","title":"<code>zero_block(n_qubits)</code>","text":"<p>Generates the abstract zero state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the zero state.</p> <p>Examples: <pre><code>from qadence.states import zero_block\n\nblock = zero_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract zero state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the zero state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_block\n\n    block = zero_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(I, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.zero_state","title":"<code>zero_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the zero state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits for which the zero state is to be generated.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size for the zero state.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import zero_state\n\nstate = zero_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the zero state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits for which the zero state is to be generated.\n        batch_size (int): The batch size for the zero state.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_state\n\n    state = zero_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    bitstring = \"0\" * n_qubits\n    return _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"api/transpile/","title":"Transpilation","text":"<p>Contains functions that operate on blocks and circuits to <code>transpile</code> them to new blocks/circuits.</p>"},{"location":"api/transpile/#qadence.transpile.transpile.transpile","title":"<code>transpile(*fs)</code>","text":"<pre><code>transpile(*fs: Callable[[AbstractBlock], AbstractBlock]) -&gt; Callable[[AbstractBlock], AbstractBlock]\n</code></pre><pre><code>transpile(*fs: Callable[[QuantumCircuit], QuantumCircuit]) -&gt; Callable[[QuantumCircuit], QuantumCircuit]\n</code></pre> <p><code>AbstractBlock</code> or <code>QuantumCircuit</code> transpilation.</p> <p>Compose functions that accept a circuit/block and returns a circuit/block.</p> PARAMETER DESCRIPTION <code>*fs</code> <p>composable functions that either map blocks to blocks (<code>Callable[[AbstractBlock], AbstractBlock]</code>) or circuits to circuits (<code>Callable[[QuantumCircuit], QuantumCircuit]</code>).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Composed function.</p> <p>Examples:</p> <p>Flatten a block of nested chains and krons: <pre><code>from qadence import *\nfrom qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n\nb = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\nprint(b)\n\n# both flatten and scale_primitive_blocks_only are functions that accept and\n# return a block\nt = transpile(flatten, scale_primitive_blocks_only)(b)\nprint(t)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 ChainBlock(0)\n\u2502           \u251c\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u251c\u2500\u2500 X(0)\n        \u2514\u2500\u2500 X(1)\n\nChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 X(1)\n</code></pre> </p> <p>We also proved a decorator to easily turn a function <code>Callable[[AbstractBlock], AbstractBlock]</code> into a <code>Callable[[QuantumCircuit], QuantumCircuit]</code> to be used in circuit transpilation. <pre><code>from qadence import *\nfrom qadence.transpile import transpile, blockfn_to_circfn, flatten\n\n# We want to pass this circuit to `transpile` instead of a block,\n# so we need functions that map from a circuit to a circuit.\ncirc = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n\n@blockfn_to_circfn\ndef fn(block):\n    # un-decorated function accepts a block and returns a block\n    return block * block\n\ntransp = transpile(\n    # the decorated function accepts a circuit and returns a circuit\n    fn,\n    # already existing functions can also be decorated\n    blockfn_to_circfn(flatten)\n)\nprint(transp(circ))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/transpile/transpile.py</code> <pre><code>def transpile(*fs: Callable) -&gt; Callable:\n    \"\"\"`AbstractBlock` or `QuantumCircuit` transpilation.\n\n    Compose functions that\n    accept a circuit/block and returns a circuit/block.\n\n    Arguments:\n        *fs: composable functions that either map blocks to blocks\n            (`Callable[[AbstractBlock], AbstractBlock]`)\n            or circuits to circuits (`Callable[[QuantumCircuit], QuantumCircuit]`).\n\n    Returns:\n        Composed function.\n\n    Examples:\n\n    Flatten a block of nested chains and krons:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n\n    b = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\n    print(b)\n    print() # markdown-exec: hide\n\n    # both flatten and scale_primitive_blocks_only are functions that accept and\n    # return a block\n    t = transpile(flatten, scale_primitive_blocks_only)(b)\n    print(t)\n    ```\n\n    We also proved a decorator to easily turn a function `Callable[[AbstractBlock], AbstractBlock]`\n    into a `Callable[[QuantumCircuit], QuantumCircuit]` to be used in circuit transpilation.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, blockfn_to_circfn, flatten\n\n    # We want to pass this circuit to `transpile` instead of a block,\n    # so we need functions that map from a circuit to a circuit.\n    circ = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n\n    @blockfn_to_circfn\n    def fn(block):\n        # un-decorated function accepts a block and returns a block\n        return block * block\n\n    transp = transpile(\n        # the decorated function accepts a circuit and returns a circuit\n        fn,\n        # already existing functions can also be decorated\n        blockfn_to_circfn(flatten)\n    )\n    print(transp(circ))\n    ```\n    \"\"\"\n    return lambda x: reduce(lambda acc, f: f(acc), reversed(fs), x)\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.chain_single_qubit_ops","title":"<code>chain_single_qubit_ops(block)</code>","text":"<p>Transpile a chain of krons into a kron of chains of single qubit operations.</p> <p>Examples: <pre><code>from qadence import hea\nfrom qadence.transpile.block import chain_single_qubit_ops\n\n# Consider a single HEA layer\nblock = hea(2,1)\nprint(block)\n\n# After applying chain_single_qubit_ops, we get:\nprint(chain_single_qubit_ops(block))\n</code></pre> <pre><code>ChainBlock(0,1) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u2514\u2500\u2500 CNOT(0, 1)\nChainBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502   \u2514\u2500\u2500 ChainBlock(1)\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502       \u251c\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u2514\u2500\u2500 CNOT(0, 1)\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def chain_single_qubit_ops(block: AbstractBlock) -&gt; AbstractBlock:\n    \"\"\"Transpile a chain of krons into a kron of chains of single qubit operations.\n\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import hea\n    from qadence.transpile.block import chain_single_qubit_ops\n\n    # Consider a single HEA layer\n    block = hea(2,1)\n    print(block)\n\n    # After applying chain_single_qubit_ops, we get:\n    print(chain_single_qubit_ops(block))\n    ```\n    \"\"\"\n    if is_chain_of_primitivekrons(block):\n        try:\n            return kron(*map(lambda bs: chain(*bs), zip(*block)))  # type: ignore[misc]\n        except Exception as e:\n            logger.debug(\n                f\"Unable to transpile {block} using chain_single_qubit_ops\\\n                         due to {e}. Returning original circuit.\"\n            )\n            return block\n\n    elif isinstance(block, CompositeBlock):\n        return _construct(type(block), tuple(chain_single_qubit_ops(b) for b in block.blocks))\n    else:\n        return block\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.scale_primitive_blocks_only","title":"<code>scale_primitive_blocks_only(block, scale=None)</code>","text":"<p>Push the scale all the way down into the leaves of the block tree.</p> <p>When given a scaled CompositeBlock consisting of several PrimitiveBlocks.</p> PARAMETER DESCRIPTION <code>block</code> <p>The block to be transpiled.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>scale</code> <p>An optional scale parameter. Only to be used for recursive calls internally.</p> <p> TYPE: <code>Basic</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>A block of the same type where the scales have been moved into the subblocks.</p> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples:</p> <p>There are two different cases: <code>ChainBlock</code>s/<code>KronBlock</code>s: Only the first subblock needs to be scaled because chains/krons represent multiplications. <pre><code>from qadence import chain, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * chain(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 ChainBlock(0)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\nChainBlock(0)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> <p><code>AddBlock</code>s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")). <pre><code>from qadence import add, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * add(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 AddBlock(0)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\nAddBlock(0)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 [mul: 2] \n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>@singledispatch\ndef scale_primitive_blocks_only(block: AbstractBlock, scale: sympy.Basic = None) -&gt; AbstractBlock:\n    \"\"\"Push the scale all the way down into the leaves of the block tree.\n\n    When given a scaled CompositeBlock consisting of several PrimitiveBlocks.\n\n    Arguments:\n        block: The block to be transpiled.\n        scale: An optional scale parameter. Only to be used for recursive calls internally.\n\n    Returns:\n        AbstractBlock: A block of the same type where the scales have been moved into the subblocks.\n\n    Examples:\n\n    There are two different cases:\n    `ChainBlock`s/`KronBlock`s: Only the first subblock needs to be scaled because chains/krons\n    represent multiplications.\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import chain, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * chain(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n\n    `AddBlock`s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all\n    subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")).\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import add, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * add(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    \"\"\"\n    raise NotImplementedError(f\"scale_primitive_blocks_only is not implemented for {type(block)}\")\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.set_as_fixed","title":"<code>set_as_fixed(blocks, restricted_names=list(), inplace=True)</code>","text":"<p>Set parameters in blocks as fixed (non-trainable parameters).</p> PARAMETER DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>restricted_names</code> <p>Restricted list of parameters names to set the value.</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>list()</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to False</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_as_fixed(\n    blocks: AbstractBlock | list[AbstractBlock],\n    restricted_names: list[str] = list(),\n    inplace: bool = True,\n) -&gt; AbstractBlock | list[AbstractBlock]:\n    \"\"\"Set parameters in blocks as fixed (non-trainable parameters).\n\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        restricted_names (list[str]): Restricted list of parameters names to set the value.\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to False\n    \"\"\"\n    return set_trainable(blocks, restricted_names=restricted_names, value=False, inplace=inplace)\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.set_as_variational","title":"<code>set_as_variational(blocks, restricted_names=list(), inplace=True)</code>","text":"<p>Set parameters in blocks as variational (trainable parameters).</p> PARAMETER DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>restricted_names</code> <p>Restricted list of parameters names to set the value.</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>list()</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to True</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_as_variational(\n    blocks: AbstractBlock | list[AbstractBlock],\n    restricted_names: list[str] = list(),\n    inplace: bool = True,\n) -&gt; AbstractBlock | list[AbstractBlock]:\n    \"\"\"Set parameters in blocks as variational (trainable parameters).\n\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        restricted_names (list[str]): Restricted list of parameters names to set the value.\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to True\n    \"\"\"\n    return set_trainable(blocks, restricted_names=restricted_names, inplace=inplace)\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.set_trainable","title":"<code>set_trainable(blocks, restricted_names=list(), value=True, inplace=True)</code>","text":"<p>Set the trainability of all parameters in a block to a given value.</p> PARAMETER DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>restricted_names</code> <p>Restricted list of parameters names to set the value.</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>list()</code> </p> <code>value</code> <p>The value of the trainable attribute to assign to the input blocks</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to the given value</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_trainable(\n    blocks: AbstractBlock | list[AbstractBlock],\n    restricted_names: list[str] = list(),\n    value: bool = True,\n    inplace: bool = True,\n) -&gt; AbstractBlock | list[AbstractBlock]:\n    \"\"\"Set the trainability of all parameters in a block to a given value.\n\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        restricted_names (list[str]): Restricted list of parameters names to set the value.\n        value (bool, optional): The value of the trainable attribute to assign to the input blocks\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to the given value\n    \"\"\"\n\n    if isinstance(blocks, AbstractBlock):\n        blocks = [blocks]\n\n    if inplace:\n        for block in blocks:\n            params: list[sympy.Basic] = list(filter(lambda p: not p.is_number, parameters(block)))\n            if bool(restricted_names):\n                params = list(filter(lambda p: p.name in restricted_names, params))\n            for p in params:\n                p.trainable = value\n    else:\n        raise NotImplementedError(\"Not inplace set_trainable is not yet available\")\n\n    return blocks if len(blocks) &gt; 1 else blocks[0]\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.validate","title":"<code>validate(block)</code>","text":"<p>Moves a block from global to local qubit numbers by adding PutBlocks.</p> <p>Reassigns qubit locations appropriately.</p>"},{"location":"api/transpile/#qadence.transpile.block.validate--example","title":"Example","text":"<pre><code>from qadence.blocks import chain\nfrom qadence.operations import X\nfrom qadence.transpile import validate\n\nx = chain(chain(X(0)), chain(X(1)))\nprint(x)\nprint(validate(x))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 ChainBlock(1)\n    \u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 put on (0)\n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 put on (0)\n\u2502           \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 put on (1)\n    \u2514\u2500\u2500 ChainBlock(0)\n        \u2514\u2500\u2500 put on (0)\n            \u2514\u2500\u2500 X(0)\n</code></pre> Source code in <code>qadence/transpile/block.py</code> <pre><code>def validate(block: AbstractBlock) -&gt; AbstractBlock:\n    \"\"\"Moves a block from global to local qubit numbers by adding PutBlocks.\n\n    Reassigns qubit locations appropriately.\n\n    # Example\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence.blocks import chain\n    from qadence.operations import X\n    from qadence.transpile import validate\n\n    x = chain(chain(X(0)), chain(X(1)))\n    print(x)\n    print(validate(x))\n    ```\n    \"\"\"\n    vblock: AbstractBlock\n    from qadence.transpile import reassign\n\n    if isinstance(block, ControlBlock):\n        vblock = deepcopy(block)\n        b: AbstractBlock\n        (b,) = block.blocks\n        b = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\n        b = validate(b)\n        vblock.blocks = (b,)  # type: ignore[assignment]\n\n    elif isinstance(block, CompositeBlock):\n        blocks = []\n        for b in block.blocks:\n            mi, ma = min(b.qubit_support), max(b.qubit_support)\n            nb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\n            nb = validate(nb)\n            nb = PutBlock(nb, tuple(range(mi, ma + 1)))\n            blocks.append(nb)\n        try:\n            vblock = _construct(type(block), tuple(blocks))\n        except AssertionError as e:\n            if str(e) == \"Make sure blocks act on distinct qubits!\":\n                vblock = chain(*blocks)\n            else:\n                raise e\n\n    elif isinstance(block, PrimitiveBlock):\n        vblock = deepcopy(block)\n\n    else:\n        raise NotImplementedError\n\n    vblock.tag = block.tag\n    return vblock\n</code></pre>"},{"location":"api/types/","title":"Types","text":""},{"location":"api/types/#qadence-types","title":"Qadence Types","text":""},{"location":"api/types/#qadence.types.TArray","title":"<code>TArray = Union[Iterable, Tensor, np.ndarray]</code>  <code>module-attribute</code>","text":"<p>Union of common array types.</p>"},{"location":"api/types/#qadence.types.TGenerator","title":"<code>TGenerator = Union[Tensor, sympy.Array, sympy.Basic]</code>  <code>module-attribute</code>","text":"<p>Union of torch tensors and numpy arrays.</p>"},{"location":"api/types/#qadence.types.TNumber","title":"<code>TNumber = Union[int, float, complex, np.int64, np.float64]</code>  <code>module-attribute</code>","text":"<p>Union of python and numpy numeric types.</p>"},{"location":"api/types/#qadence.types.TParameter","title":"<code>TParameter = Union[TNumber, Tensor, sympy.Basic, str]</code>  <code>module-attribute</code>","text":"<p>Union of numbers, tensors, and parameter types.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo","title":"<code>AlgoHEvo</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Hamiltonian Evolution algorithms that can be used by the backend.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.EIG","title":"<code>EIG = 'EIG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using Hamiltonian diagonalization.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.EXP","title":"<code>EXP = 'EXP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using torch.matrix_exp on the generator matrix.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.RK4","title":"<code>RK4 = 'RK4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>4th order Runge-Kutta approximation.</p>"},{"location":"api/types/#qadence.types.AnalogNoise","title":"<code>AnalogNoise</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Type of noise protocol.</p>"},{"location":"api/types/#qadence.types.AnsatzType","title":"<code>AnsatzType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Ansatz types for variational circuits.</p>"},{"location":"api/types/#qadence.types.AnsatzType.ALA","title":"<code>ALA = 'ala'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Alternating Layer Ansatz.</p>"},{"location":"api/types/#qadence.types.AnsatzType.HEA","title":"<code>HEA = 'hea'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hardware-efficient ansatz.</p>"},{"location":"api/types/#qadence.types.AnsatzType.IIA","title":"<code>IIA = 'iia'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Identity-Initialised Ansatz.</p>"},{"location":"api/types/#qadence.types.BasisSet","title":"<code>BasisSet</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Basis set for feature maps.</p>"},{"location":"api/types/#qadence.types.BasisSet.CHEBYSHEV","title":"<code>CHEBYSHEV = 'Chebyshev'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Chebyshev polynomials of the first kind.</p>"},{"location":"api/types/#qadence.types.BasisSet.FOURIER","title":"<code>FOURIER = 'Fourier'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fourier basis set.</p>"},{"location":"api/types/#qadence.types.DeviceType","title":"<code>DeviceType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Supported types of devices for Pulser backend.</p>"},{"location":"api/types/#qadence.types.DeviceType.IDEALIZED","title":"<code>IDEALIZED = 'IdealDevice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Idealized device, least realistic.</p>"},{"location":"api/types/#qadence.types.DeviceType.REALISTIC","title":"<code>REALISTIC = 'RealisticDevice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Device with realistic specs.</p>"},{"location":"api/types/#qadence.types.DiffMode","title":"<code>DiffMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Differentiation modes to choose from.</p>"},{"location":"api/types/#qadence.types.DiffMode.AD","title":"<code>AD = 'ad'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Automatic Differentiation.</p>"},{"location":"api/types/#qadence.types.DiffMode.ADJOINT","title":"<code>ADJOINT = 'adjoint'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Adjoint Differentiation.</p>"},{"location":"api/types/#qadence.types.DiffMode.GPSR","title":"<code>GPSR = 'gpsr'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic generalized parameter shift rule.</p>"},{"location":"api/types/#qadence.types.Endianness","title":"<code>Endianness</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The endianness convention to use.</p>"},{"location":"api/types/#qadence.types.Endianness.BIG","title":"<code>BIG = 'Big'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use Big endianness.</p>"},{"location":"api/types/#qadence.types.Endianness.LITTLE","title":"<code>LITTLE = 'Little'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use little endianness.</p>"},{"location":"api/types/#qadence.types.ExecutionType","title":"<code>ExecutionType</code>","text":"<p>               Bases: <code>StrEnum</code></p>"},{"location":"api/types/#qadence.types.ExecutionType.DEFAULT","title":"<code>DEFAULT = 'default'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default distribution execution.</p>"},{"location":"api/types/#qadence.types.ExecutionType.TORCHRUN","title":"<code>TORCHRUN = 'torchrun'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torchrun based distribution execution.</p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool","title":"<code>ExperimentTrackingTool</code>","text":"<p>               Bases: <code>StrEnum</code></p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool.MLFLOW","title":"<code>MLFLOW = 'mlflow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the ml-flow experiment tracker.</p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool.TENSORBOARD","title":"<code>TENSORBOARD = 'tensorboard'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the tensorboard experiment tracker.</p>"},{"location":"api/types/#qadence.types.FigFormat","title":"<code>FigFormat</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available output formats for exporting visualized circuits to a file.</p>"},{"location":"api/types/#qadence.types.FigFormat.PDF","title":"<code>PDF = 'PDF'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PDF format.</p>"},{"location":"api/types/#qadence.types.FigFormat.PNG","title":"<code>PNG = 'PNG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PNG format.</p>"},{"location":"api/types/#qadence.types.FigFormat.SVG","title":"<code>SVG = 'SVG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>SVG format.</p>"},{"location":"api/types/#qadence.types.GenDAQC","title":"<code>GenDAQC</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The type of interaction for the DAQC transform.</p>"},{"location":"api/types/#qadence.types.GenDAQC.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN</p>"},{"location":"api/types/#qadence.types.GenDAQC.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ</p>"},{"location":"api/types/#qadence.types.InputDiffMode","title":"<code>InputDiffMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Derivative modes w.r.t inputs of UFAs.</p>"},{"location":"api/types/#qadence.types.InputDiffMode.AD","title":"<code>AD = 'ad'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Reverse automatic differentiation.</p>"},{"location":"api/types/#qadence.types.InputDiffMode.FD","title":"<code>FD = 'fd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Central finite differencing.</p>"},{"location":"api/types/#qadence.types.Interaction","title":"<code>Interaction</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Interaction types used in.</p> <ul> <li><code>RydbergDevice</code>.</li> <li><code>hamiltonian_factory</code>.</li> </ul>"},{"location":"api/types/#qadence.types.Interaction.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN-Ising Interaction, N=(I-Z)/2.</p>"},{"location":"api/types/#qadence.types.Interaction.XY","title":"<code>XY = 'XY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XY Interaction.</p>"},{"location":"api/types/#qadence.types.Interaction.XYZ","title":"<code>XYZ = 'XYZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XYZ Interaction.</p>"},{"location":"api/types/#qadence.types.Interaction.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ-Ising Interaction.</p>"},{"location":"api/types/#qadence.types.LTSOrder","title":"<code>LTSOrder</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Lie-Trotter-Suzuki approximation order.</p>"},{"location":"api/types/#qadence.types.LTSOrder.BASIC","title":"<code>BASIC = 'BASIC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic.</p>"},{"location":"api/types/#qadence.types.LTSOrder.ST2","title":"<code>ST2 = 'ST2'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST2.</p>"},{"location":"api/types/#qadence.types.LTSOrder.ST4","title":"<code>ST4 = 'ST4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST4.</p>"},{"location":"api/types/#qadence.types.LatticeTopology","title":"<code>LatticeTopology</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Lattice topologies to choose from for the register.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.ALL_TO_ALL","title":"<code>ALL_TO_ALL = 'all_to_all'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>All to all- connected lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.ARBITRARY","title":"<code>ARBITRARY = 'arbitrary'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Arbitrarily-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.CIRCLE","title":"<code>CIRCLE = 'circle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Circular lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.HONEYCOMB_LATTICE","title":"<code>HONEYCOMB_LATTICE = 'honeycomb_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Honeycomb-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.LINE","title":"<code>LINE = 'line'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Line-format lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.RECTANGULAR_LATTICE","title":"<code>RECTANGULAR_LATTICE = 'rectangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rectangular-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.SQUARE","title":"<code>SQUARE = 'square'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Square lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.TRIANGULAR_LATTICE","title":"<code>TRIANGULAR_LATTICE = 'triangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Triangular-shaped shape.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy","title":"<code>MultivariateStrategy</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Multivariate strategy for feature maps.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy.PARALLEL","title":"<code>PARALLEL = 'Parallel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Parallel strategy.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy.SERIES","title":"<code>SERIES = 'Series'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Serial strategy.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol","title":"<code>NoiseProtocol()</code>  <code>dataclass</code>","text":"<p>Type of noise protocol.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol.ANALOG","title":"<code>ANALOG = AnalogNoise</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Noise applied in analog blocks.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol.DIGITAL","title":"<code>DIGITAL = DigitalNoise</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Noise applied to digital blocks.</p>"},{"location":"api/types/#qadence.types.NoiseProtocol.READOUT","title":"<code>READOUT = ReadoutNoise</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Noise applied on outputs of quantum programs.</p>"},{"location":"api/types/#qadence.types.OpName","title":"<code>OpName</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>A list of all available of digital-analog operations.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGENTANG","title":"<code>ANALOGENTANG = 'AnalogEntanglement'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog entanglement operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGINTERACTION","title":"<code>ANALOGINTERACTION = 'AnalogInteraction'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog interaction operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRX","title":"<code>ANALOGRX = 'AnalogRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RX operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRY","title":"<code>ANALOGRY = 'AnalogRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RY operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRZ","title":"<code>ANALOGRZ = 'AnalogRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RZ operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGSWAP","title":"<code>ANALOGSWAP = 'AnalogSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog SWAP operation.</p>"},{"location":"api/types/#qadence.types.OpName.CNOT","title":"<code>CNOT = 'CNOT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CNOT gate.</p>"},{"location":"api/types/#qadence.types.OpName.CPHASE","title":"<code>CPHASE = 'CPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The controlled PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRX","title":"<code>CRX = 'CRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRY","title":"<code>CRY = 'CRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Controlled RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRZ","title":"<code>CRZ = 'CRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.CSWAP","title":"<code>CSWAP = 'CSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control SWAP gate.</p>"},{"location":"api/types/#qadence.types.OpName.CZ","title":"<code>CZ = 'CZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.ENTANGLE","title":"<code>ENTANGLE = 'entangle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The entanglement operation.</p>"},{"location":"api/types/#qadence.types.OpName.H","title":"<code>H = 'H'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hadamard gate.</p>"},{"location":"api/types/#qadence.types.OpName.HAMEVO","title":"<code>HAMEVO = 'HamEvo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hamiltonian Evolution operation.</p>"},{"location":"api/types/#qadence.types.OpName.I","title":"<code>I = 'I'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Identity gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCPHASE","title":"<code>MCPHASE = 'MCPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRX","title":"<code>MCRX = 'MCRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRY","title":"<code>MCRY = 'MCRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRZ","title":"<code>MCRZ = 'MCRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCZ","title":"<code>MCZ = 'MCZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol CZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.N","title":"<code>N = 'N'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The N = (1/2)(I-Z) operator.</p>"},{"location":"api/types/#qadence.types.OpName.PHASE","title":"<code>PHASE = 'PHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.PROJ","title":"<code>PROJ = 'Projector'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The projector operation.</p>"},{"location":"api/types/#qadence.types.OpName.RX","title":"<code>RX = 'RX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.RY","title":"<code>RY = 'RY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.RZ","title":"<code>RZ = 'RZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.S","title":"<code>S = 'S'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S gate.</p>"},{"location":"api/types/#qadence.types.OpName.SDAGGER","title":"<code>SDAGGER = 'SDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S dagger gate.</p>"},{"location":"api/types/#qadence.types.OpName.SWAP","title":"<code>SWAP = 'SWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The SWAP gate.</p>"},{"location":"api/types/#qadence.types.OpName.T","title":"<code>T = 'T'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T gate.</p>"},{"location":"api/types/#qadence.types.OpName.TDAGGER","title":"<code>TDAGGER = 'TDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T dagger gate.</p>"},{"location":"api/types/#qadence.types.OpName.TOFFOLI","title":"<code>TOFFOLI = 'Toffoli'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Toffoli gate.</p>"},{"location":"api/types/#qadence.types.OpName.U","title":"<code>U = 'U'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The U gate.</p>"},{"location":"api/types/#qadence.types.OpName.X","title":"<code>X = 'X'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The X gate.</p>"},{"location":"api/types/#qadence.types.OpName.Y","title":"<code>Y = 'Y'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Y gate.</p>"},{"location":"api/types/#qadence.types.OpName.Z","title":"<code>Z = 'Z'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Z gate.</p>"},{"location":"api/types/#qadence.types.OpName.ZERO","title":"<code>ZERO = 'Zero'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The zero gate.</p>"},{"location":"api/types/#qadence.types.OverlapMethod","title":"<code>OverlapMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Overlap Methods to choose from.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.COMPUTE_UNCOMPUTE","title":"<code>COMPUTE_UNCOMPUTE = 'compute_uncompute'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute-uncompute.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.EXACT","title":"<code>EXACT = 'exact'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exact.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.HADAMARD_TEST","title":"<code>HADAMARD_TEST = 'hadamard_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hadamard-test.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.JENSEN_SHANNON","title":"<code>JENSEN_SHANNON = 'jensen_shannon'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Jensen-shannon.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.SWAP_TEST","title":"<code>SWAP_TEST = 'swap_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Swap-test.</p>"},{"location":"api/types/#qadence.types.ParameterType","title":"<code>ParameterType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Parameter types available in qadence.</p>"},{"location":"api/types/#qadence.types.ParameterType.FEATURE","title":"<code>FEATURE = 'Feature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>FeatureParameters act as input and are not trainable.</p>"},{"location":"api/types/#qadence.types.ParameterType.FIXED","title":"<code>FIXED = 'Fixed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fixed/ constant parameters are neither trainable nor act as input.</p>"},{"location":"api/types/#qadence.types.ParameterType.VARIATIONAL","title":"<code>VARIATIONAL = 'Variational'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>VariationalParameters are trainable.</p>"},{"location":"api/types/#qadence.types.QubitSupportType","title":"<code>QubitSupportType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Qubit support types.</p>"},{"location":"api/types/#qadence.types.QubitSupportType.GLOBAL","title":"<code>GLOBAL = 'global'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use global qubit support.</p>"},{"location":"api/types/#qadence.types.ReadoutNoise","title":"<code>ReadoutNoise</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Type of readout protocol.</p>"},{"location":"api/types/#qadence.types.ReadoutNoise.CORRELATED","title":"<code>CORRELATED = 'Correlated Readout'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using a confusion matrix (2n, 2n) for corrupting bitstrings values.</p>"},{"location":"api/types/#qadence.types.ReadoutNoise.INDEPENDENT","title":"<code>INDEPENDENT = 'Independent Readout'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Simple readout protocols where each qubit is corrupted independently.</p>"},{"location":"api/types/#qadence.types.ResultType","title":"<code>ResultType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available data types for generating certain results.</p>"},{"location":"api/types/#qadence.types.ResultType.NUMPY","title":"<code>NUMPY = 'Numpy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Numpy Array Type.</p>"},{"location":"api/types/#qadence.types.ResultType.STRING","title":"<code>STRING = 'String'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String Type.</p>"},{"location":"api/types/#qadence.types.ResultType.TORCH","title":"<code>TORCH = 'Torch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torch Tensor Type.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling","title":"<code>ReuploadScaling</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Scaling for data reuploads in feature maps.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.CONSTANT","title":"<code>CONSTANT = 'Constant'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Constant scaling.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.EXP","title":"<code>EXP = 'Exponential'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exponentially increasing scaling.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.TOWER","title":"<code>TOWER = 'Tower'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Linearly increasing scaling.</p>"},{"location":"api/types/#qadence.types.SerializationFormat","title":"<code>SerializationFormat</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available serialization formats for circuits.</p>"},{"location":"api/types/#qadence.types.SerializationFormat.JSON","title":"<code>JSON = 'JSON'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Json format.</p>"},{"location":"api/types/#qadence.types.SerializationFormat.PT","title":"<code>PT = 'PT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PT format used by Torch.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType","title":"<code>StateGeneratorType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Methods to generate random states.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_FAST","title":"<code>HAAR_MEASURE_FAST = 'HaarMeasureFast'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_SLOW","title":"<code>HAAR_MEASURE_SLOW = 'HaarMeasureSlow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure non-optimized version.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.RANDOM_ROTATIONS","title":"<code>RANDOM_ROTATIONS = 'RandomRotations'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Random Rotations.</p>"},{"location":"api/types/#qadence.types.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"api/types/#qadence.types.StrEnum.__str__","title":"<code>__str__()</code>","text":"<p>Used when dumping enum fields in a schema.</p> Source code in <code>qadence/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Used when dumping enum fields in a schema.\"\"\"\n    ret: str = self.value\n    return ret\n</code></pre>"},{"location":"api/types/#qadence.types.Strategy","title":"<code>Strategy</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Computing paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.ANALOG","title":"<code>ANALOG = 'Analog'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the analog paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.BDAQC","title":"<code>BDAQC = 'bDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the banged digital-analog QC paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.DIGITAL","title":"<code>DIGITAL = 'Digital'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the digital paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.RYDBERG","title":"<code>RYDBERG = 'Rydberg'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the Rydberg QC paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.SDAQC","title":"<code>SDAQC = 'sDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the step-wise digital-analog QC paradigm.</p>"},{"location":"api/types/#qadence.types.TensorType","title":"<code>TensorType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Tensor Types for converting blocks to tensors.</p>"},{"location":"api/types/#qadence.types.TensorType.DENSE","title":"<code>DENSE = 'Dense'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a block to a dense tensor.</p>"},{"location":"api/types/#qadence.types.TensorType.SPARSE","title":"<code>SPARSE = 'Sparse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a observable block to a sparse tensor.</p>"},{"location":"api/types/#qadence.types.TensorType.SPARSEDIAGONAL","title":"<code>SPARSEDIAGONAL = 'SparseDiagonal'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a diagonal observable block to a sparse diagonal if possible.</p>"},{"location":"api/backends/backend/","title":"Abstract backend","text":""},{"location":"api/backends/backend/#qadence.backend.Backend","title":"<code>Backend(name, supports_ad, support_bp, supports_adjoint, is_remote, with_measurements, native_endianness, engine, with_noise, config)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The abstract class that defines the interface for the backends.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>backend unique string identifier</p> <p> TYPE: <code>BackendName</code> </p> <code>supports_ad</code> <p>whether or not the backend has a native autograd</p> <p> TYPE: <code>bool</code> </p> <code>supports_bp</code> <p>whether or not the backend has a native backprop</p> <p> TYPE: <code>bool</code> </p> <code>supports_adjoint</code> <p>Does the backend support native adjoint differentation.</p> <p> TYPE: <code>bool</code> </p> <code>is_remote</code> <p>whether computations are executed locally or remotely on this backend, useful when using cloud platforms where credentials are needed for example.</p> <p> TYPE: <code>bool</code> </p> <code>with_measurements</code> <p>whether it supports counts or not</p> <p> TYPE: <code>bool</code> </p> <code>with_noise</code> <p>whether to add realistic noise or not</p> <p> TYPE: <code>bool</code> </p> <code>native_endianness</code> <p>The native endianness of the backend</p> <p> TYPE: <code>Endianness</code> </p> <code>engine</code> <p>The underlying (native) automatic differentiation engine of the backend.</p> <p> TYPE: <code>Engine</code> </p>"},{"location":"api/backends/backend/#qadence.backend.Backend.circuit","title":"<code>circuit(circuit)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract <code>QuantumCircuit</code> to the native backend representation.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A circuit, for example: <code>QuantumCircuit(2, X(0))</code></p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>A converted circuit <code>c</code>. You can access the original, arbstract circuit via <code>c.abstract</code></p> <code>ConvertedCircuit</code> <p>and the converted (or backend native) circuit via <code>c.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Converts an abstract `QuantumCircuit` to the native backend representation.\n\n    Arguments:\n        circuit: A circuit, for example: `QuantumCircuit(2, X(0))`\n\n    Returns:\n        A converted circuit `c`. You can access the original, arbstract circuit via `c.abstract`\n        and the converted (or backend *native*) circuit via `c.native`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit and an optional observable to their native representation.</p> <p>Additionally, this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\n    self, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n    \"\"\"Convert an abstract circuit and an optional observable to their native representation.\n\n    Additionally, this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\n\n    def check_observable(obs_obj: Any) -&gt; AbstractBlock:\n        if isinstance(obs_obj, QubitOperator):\n            from qadence.blocks.manipulate import from_openfermion\n\n            assert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\n\n            return from_openfermion(obs_obj)\n\n        elif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\n            from qadence.blocks.utils import block_is_qubit_hamiltonian\n\n            assert block_is_qubit_hamiltonian(\n                obs_obj\n            ), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\n            return obs_obj\n        raise TypeError(\n            \"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n        )\n\n    conv_circ = self.circuit(circuit)\n    circ_params, circ_embedding_fn = embedding(\n        conv_circ.abstract.block, self.config._use_gate_params, self.engine\n    )\n    params = circ_params\n    if observable is not None:\n        observable = observable if isinstance(observable, list) else [observable]\n        conv_obs = []\n        obs_embedding_fns = []\n\n        for obs in observable:\n            obs = check_observable(obs)\n            c_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\n            obs_params, obs_embedding_fn = embedding(\n                c_obs.abstract, self.config._use_gate_params, self.engine\n            )\n            params.update(obs_params)\n            obs_embedding_fns.append(obs_embedding_fn)\n            conv_obs.append(c_obs)\n\n        def embedding_fn_dict(a: dict, b: dict) -&gt; dict:\n            if \"circuit\" in b or \"observables\" in b:\n                embedding_dict = {\"circuit\": circ_embedding_fn(a, b), \"observables\": dict()}\n                for obs_embedding_fn in obs_embedding_fns:\n                    embedding_dict[\"observables\"].update(obs_embedding_fn(a, b))\n            else:\n                embedding_dict = circ_embedding_fn(a, b)\n                for obs_embedding_fn in obs_embedding_fns:\n                    embedding_dict.update(obs_embedding_fn(a, b))\n            return embedding_dict\n\n        return Converted(conv_circ, conv_obs, embedding_fn_dict, params)\n\n    def embedding_fn(a: dict, b: dict) -&gt; dict:\n        return circ_embedding_fn(a, b)\n\n    return Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.observable","title":"<code>observable(observable, n_qubits)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract observable (which is just an <code>AbstractBlock</code>) to the native backend.</p> <p>representation.</p> PARAMETER DESCRIPTION <code>observable</code> <p>An observable.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits the observable covers. This is typically <code>circuit.n_qubits</code>.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ConvertedObservable</code> <p>A converted observable <code>o</code>. You can access the original, arbstract observable via</p> <code>ConvertedObservable</code> <p><code>o.abstract</code> and the converted (or backend native) observable via <code>o.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef observable(self, observable: AbstractBlock, n_qubits: int) -&gt; ConvertedObservable:\n    \"\"\"Converts an abstract observable (which is just an `AbstractBlock`) to the native backend.\n\n    representation.\n\n    Arguments:\n        observable: An observable.\n        n_qubits: Number of qubits the observable covers. This is typically `circuit.n_qubits`.\n\n    Returns:\n        A converted observable `o`. You can access the original, arbstract observable via\n        `o.abstract` and the converted (or backend *native*) observable via `o.native`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG, *args, **kwargs)</code>","text":"<p>Run a circuit and return the resulting wave function.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, ArrayLike]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting wavefunction.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>ArrayLike</code> <p>A list of Counter objects where each key represents a bitstring</p> <code>ArrayLike</code> <p>and its value the number of times it has been sampled from the given wave function.</p> Source code in <code>qadence/backend.py</code> <pre><code>def run(\n    self,\n    circuit: ConvertedCircuit,\n    param_values: dict[str, ArrayLike] = {},\n    state: Tensor | None = None,\n    endianness: Endianness = Endianness.BIG,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Run a circuit and return the resulting wave function.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting wavefunction.\n\n    Returns:\n        A list of Counter objects where each key represents a bitstring\n        and its value the number of times it has been sampled from the given wave function.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1000, state=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Sample bit strings.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Number of shots to sample.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>An error mitigation protocol to apply.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef sample(\n    self,\n    circuit: ConvertedCircuit,\n    param_values: dict[str, Tensor] = {},\n    n_shots: int = 1000,\n    state: ArrayLike | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n    \"\"\"Sample bit strings.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        n_shots: Number of shots to sample.\n        state: Initial state.\n        noise: A noise model to use.\n        mitigation: An error mitigation protocol to apply.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration","title":"<code>BackendConfiguration(_use_gate_params=True, use_sparse_observable=False, use_gradient_checkpointing=False, use_single_qubit_composition=False, transpilation_passes=None)</code>  <code>dataclass</code>","text":""},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.available_options","title":"<code>available_options()</code>","text":"<p>Return as a string the available fields with types of the configuration.</p> RETURNS DESCRIPTION <code>str</code> <p>a string with all the available fields, one per line</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>def available_options(self) -&gt; str:\n    \"\"\"Return as a string the available fields with types of the configuration.\n\n    Returns:\n        str: a string with all the available fields, one per line\n    \"\"\"\n    conf_msg = \"\"\n    for _field in fields(self):\n        if not _field.name.startswith(\"_\"):\n            conf_msg += f\"Name: {_field.name} - Type: {_field.type} - Current value: {getattr(self, _field.name)} - Default value: {_field.default}\\n\"\n    return conf_msg\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.change_config","title":"<code>change_config(new_config)</code>","text":"<p>Change configuration with the input.</p> Source code in <code>qadence/backend.py</code> <pre><code>def change_config(self, new_config: dict) -&gt; None:\n    \"\"\"Change configuration with the input.\"\"\"\n\n    for key, value in new_config.items():\n        if hasattr(self, key):\n            setattr(self, key, value)\n        else:\n            raise ValueError(f\"Warning: '{key}' is not a valid configuration attribute.\")\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.get_param_name","title":"<code>get_param_name(blk)</code>","text":"<p>Return parameter names for the current backend.</p> <p>Depending on which backend is in use this function returns either UUIDs or expressions of parameters.</p> Source code in <code>qadence/backend.py</code> <pre><code>def get_param_name(self, blk: AbstractBlock) -&gt; Tuple[str, ...]:\n    \"\"\"Return parameter names for the current backend.\n\n    Depending on which backend is in use this\n    function returns either UUIDs or expressions of parameters.\n    \"\"\"\n    param_ids: Tuple\n    # FIXME: better type hiearchy?\n    types = (TimeEvolutionBlock, ParametricBlock, ConstantAnalogRotation, InteractionBlock)\n    if not isinstance(blk, types):\n        raise TypeError(f\"Can not infer param name from {type(blk)}\")\n    else:\n        if self._use_gate_params:\n            param_ids = tuple(blk.parameters.uuids())\n        else:\n            param_ids = tuple(map(stringify, blk.parameters.expressions()))\n    return param_ids\n</code></pre>"},{"location":"api/backends/differentiable/","title":"DifferentiableBackend","text":""},{"location":"api/backends/differentiable/#qadence.engines.torch.differentiable_backend.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>               Bases: <code>DifferentiableBackend</code></p> <p>A class which wraps a QuantumBackend with the automatic differentation engine TORCH.</p> PARAMETER DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/engines/torch/differentiable_backend.py</code> <pre><code>def __init__(\n    self,\n    backend: QuantumBackend,\n    diff_mode: DiffMode = DiffMode.AD,\n    **psr_args: int | float | None,\n) -&gt; None:\n    super().__init__(backend=backend, engine=Engine.TORCH, diff_mode=diff_mode)\n    self.psr_args = psr_args\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.torch.differentiable_backend.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A converted observable as returned by <code>backend.observable</code>.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>The error mitigation to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/engines/torch/differentiable_backend.py</code> <pre><code>def expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        observable: A converted observable as returned by `backend.observable`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: The error mitigation to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    observable = observable if isinstance(observable, list) else [observable]\n    differentiable_expectation = DifferentiableExpectation(\n        backend=self.backend,\n        circuit=circuit,\n        observable=observable,\n        param_values=param_values,\n        state=state,\n        measurement=measurement,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n\n    if self.diff_mode == DiffMode.AD:\n        expectation = differentiable_expectation.ad\n    elif self.diff_mode == DiffMode.ADJOINT:\n        expectation = differentiable_expectation.adjoint\n    elif self.diff_mode == DiffMode.GPSR:\n        expectation = partial(\n            differentiable_expectation.psr, psr_fn=general_psr, **self.psr_args\n        )\n    return expectation()\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.jax.differentiable_backend.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>               Bases: <code>DifferentiableBackend</code></p> <p>A class which wraps a QuantumBackend with the automatic differentation engine JAX.</p> PARAMETER DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/engines/jax/differentiable_backend.py</code> <pre><code>def __init__(\n    self,\n    backend: Backend,\n    diff_mode: DiffMode = DiffMode.AD,\n    **psr_args: int | float | None,\n) -&gt; None:\n    super().__init__(backend=backend, engine=Engine.JAX, diff_mode=diff_mode)\n    self.psr_args = psr_args\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.jax.differentiable_backend.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A converted observable as returned by <code>backend.observable</code>.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>The error mitigation to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/engines/jax/differentiable_backend.py</code> <pre><code>def expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        observable: A converted observable as returned by `backend.observable`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: The error mitigation to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    observable = observable if isinstance(observable, list) else [observable]\n\n    if self.diff_mode == DiffMode.AD:\n        expectation = self.backend.expectation(circuit, observable, param_values, state)\n    else:\n        expectation = DifferentiableExpectation(\n            backend=self.backend,\n            circuit=circuit,\n            observable=observable,\n            param_values=param_values,\n            state=state,\n            measurement=measurement,\n            noise=noise,\n            mitigation=mitigation,\n            endianness=endianness,\n        ).psr()\n    return expectation\n</code></pre>"},{"location":"api/backends/pulser/","title":"Pulser","text":"<p>The Pulser backend features a basic integration with the pulse-level programming interface Pulser. This backend offers for now few simple operations which are translated into a valid, non time-dependent pulse sequence. In particular, one has access to:</p> <ul> <li>analog rotations: <code>AnalogRx</code> and <code>AnalogRy</code> blocks</li> <li>free evolution blocks (basically no pulse, just interaction): <code>AnalogWait</code> block</li> <li>a block for creating entangled states: <code>AnalogEntanglement</code></li> <li>digital rotation <code>Rx</code> and <code>Ry</code></li> </ul>"},{"location":"api/backends/pulser/#qadence.backends.pulser.backend.Backend","title":"<code>Backend(name=BackendName.PULSER, supports_ad=False, support_bp=False, supports_adjoint=False, is_remote=False, with_measurements=True, native_endianness=Endianness.BIG, engine=Engine.TORCH, with_noise=False, config=Configuration())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Backend</code></p> <p>The Pulser backend.</p>"},{"location":"api/backends/pulser/#qadence.backends.pulser.backend.create_register","title":"<code>create_register(register)</code>","text":"<p>Convert Qadence Register to Pulser Register.</p> Source code in <code>qadence/backends/pulser/backend.py</code> <pre><code>def create_register(register: Register) -&gt; PulserRegister:\n    \"\"\"Convert Qadence Register to Pulser Register.\"\"\"\n    coords = np.array(list(register.coords.values()))\n    return PulserRegister.from_coordinates(coords)\n</code></pre>"},{"location":"api/backends/pyqtorch/","title":"PyQTorch","text":"<p>Fast differentiable statevector emulator based on PyTorch. The code is open source, hosted on Github and maintained by Pasqal.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend","title":"<code>Backend(name=BackendName.PYQTORCH, supports_ad=True, support_bp=True, supports_adjoint=True, is_remote=False, with_measurements=True, native_endianness=Endianness.BIG, engine=Engine.TORCH, with_noise=False, config=Configuration())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Backend</code></p> <p>PyQTorch backend.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.circuit","title":"<code>circuit(circuit)</code>","text":"<p>Return the converted circuit.</p> <p>Note that to get a representation with noise, noise should be passed within the config.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Original circuit</p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>ConvertedCircuit instance for backend.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Return the converted circuit.\n\n    Note that to get a representation with noise, noise\n    should be passed within the config.\n\n    Args:\n        circuit (QuantumCircuit): Original circuit\n\n    Returns:\n        ConvertedCircuit: ConvertedCircuit instance for backend.\n    \"\"\"\n    passes = self.config.transpilation_passes\n    if passes is None:\n        passes = default_passes(self.config)\n\n    original_circ = circuit\n    if len(passes) &gt; 0:\n        circuit = transpile(*passes)(circuit)\n    # Setting noise in the circuit.\n    if self.config.noise:\n        set_noise(circuit, self.config.noise)\n\n    ops = convert_block(circuit.block, n_qubits=circuit.n_qubits, config=self.config)\n    readout_noise = (\n        convert_readout_noise(circuit.n_qubits, self.config.noise)\n        if self.config.noise\n        else None\n    )\n    if self.config.dropout_probability == 0:\n        native = pyq.QuantumCircuit(\n            circuit.n_qubits,\n            ops,\n            readout_noise,\n        )\n    else:\n        native = pyq.DropoutQuantumCircuit(\n            circuit.n_qubits,\n            ops,\n            readout_noise,\n            dropout_prob=self.config.dropout_probability,\n            dropout_mode=self.config.dropout_mode,\n        )\n    return ConvertedCircuit(native=native, abstract=circuit, original=original_circ)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit and an optional observable to their native representation.</p> <p>Additionally, this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\n    self, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n    \"\"\"Convert an abstract circuit and an optional observable to their native representation.\n\n    Additionally, this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\n\n    def check_observable(obs_obj: Any) -&gt; AbstractBlock:\n        if isinstance(obs_obj, QubitOperator):\n            from qadence.blocks.manipulate import from_openfermion\n\n            assert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\n\n            return from_openfermion(obs_obj)\n\n        elif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\n            from qadence.blocks.utils import block_is_qubit_hamiltonian\n\n            assert block_is_qubit_hamiltonian(\n                obs_obj\n            ), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\n            return obs_obj\n        raise TypeError(\n            \"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n        )\n\n    conv_circ = self.circuit(circuit)\n    circ_params, circ_embedding_fn = embedding(\n        conv_circ.abstract.block, self.config._use_gate_params, self.engine\n    )\n    params = circ_params\n    if observable is not None:\n        observable = observable if isinstance(observable, list) else [observable]\n        conv_obs = []\n        obs_embedding_fns = []\n\n        for obs in observable:\n            obs = check_observable(obs)\n            c_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\n            obs_params, obs_embedding_fn = embedding(\n                c_obs.abstract, self.config._use_gate_params, self.engine\n            )\n            params.update(obs_params)\n            obs_embedding_fns.append(obs_embedding_fn)\n            conv_obs.append(c_obs)\n\n        def embedding_fn_dict(a: dict, b: dict) -&gt; dict:\n            if \"circuit\" in b or \"observables\" in b:\n                embedding_dict = {\"circuit\": circ_embedding_fn(a, b), \"observables\": dict()}\n                for obs_embedding_fn in obs_embedding_fns:\n                    embedding_dict[\"observables\"].update(obs_embedding_fn(a, b))\n            else:\n                embedding_dict = circ_embedding_fn(a, b)\n                for obs_embedding_fn in obs_embedding_fns:\n                    embedding_dict.update(obs_embedding_fn(a, b))\n            return embedding_dict\n\n        return Converted(conv_circ, conv_obs, embedding_fn_dict, params)\n\n    def embedding_fn(a: dict, b: dict) -&gt; dict:\n        return circ_embedding_fn(a, b)\n\n    return Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.set_block_and_readout_noises","title":"<code>set_block_and_readout_noises(circuit, noise, config)</code>","text":"<p>Add noise on blocks and readout on circuit.</p> <p>We first start by adding noise to the abstract blocks. Then we do a conversion to their native representation. Finally, we add readout.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Input circuit.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>noise</code> <p>Noise to add.</p> <p> TYPE: <code>NoiseHandler | None</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def set_block_and_readout_noises(\n    circuit: ConvertedCircuit, noise: NoiseHandler | None, config: Configuration\n) -&gt; None:\n    \"\"\"Add noise on blocks and readout on circuit.\n\n    We first start by adding noise to the abstract blocks. Then we do a conversion to their\n    native representation. Finally, we add readout.\n\n    Args:\n        circuit (ConvertedCircuit): Input circuit.\n        noise (NoiseHandler | None): Noise to add.\n    \"\"\"\n    if noise:\n        set_noise(circuit, noise)\n        set_noise_abstract_to_native(circuit, config)\n        set_readout_noise(circuit, noise)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.set_noise_abstract_to_native","title":"<code>set_noise_abstract_to_native(circuit, config)</code>","text":"<p>Set noise in native blocks from the abstract ones with noise.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Input converted circuit.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def set_noise_abstract_to_native(circuit: ConvertedCircuit, config: Configuration) -&gt; None:\n    \"\"\"Set noise in native blocks from the abstract ones with noise.\n\n    Args:\n        circuit (ConvertedCircuit): Input converted circuit.\n    \"\"\"\n    ops = convert_block(circuit.abstract.block, n_qubits=circuit.native.n_qubits, config=config)\n    circuit.native = pyq.QuantumCircuit(circuit.native.n_qubits, ops, circuit.native.readout_noise)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.set_readout_noise","title":"<code>set_readout_noise(circuit, noise)</code>","text":"<p>Set readout noise in place in native.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>Input converted circuit.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>noise</code> <p>Noise.</p> <p> TYPE: <code>NoiseHandler | None</code> </p> Source code in <code>qadence/backends/pyqtorch/backend.py</code> <pre><code>def set_readout_noise(circuit: ConvertedCircuit, noise: NoiseHandler) -&gt; None:\n    \"\"\"Set readout noise in place in native.\n\n    Args:\n        circuit (ConvertedCircuit):  Input converted circuit.\n        noise (NoiseHandler | None): Noise.\n    \"\"\"\n    readout = convert_readout_noise(circuit.abstract.n_qubits, noise)\n    if readout:\n        circuit.native.readout_noise = readout\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration","title":"<code>Configuration(_use_gate_params=True, use_sparse_observable=False, use_gradient_checkpointing=False, use_single_qubit_composition=False, transpilation_passes=None, algo_hevo=AlgoHEvo.EXP, ode_solver=SolverType.DP5_SE, n_steps_hevo=100, loop_expectation=False, noise=None, dropout_probability=0.0, dropout_mode=DropoutMode.ROTATIONAL, n_eqs=None, shift_prefac=0.5, gap_step=1.0, lb=None, ub=None)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BackendConfiguration</code></p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.algo_hevo","title":"<code>algo_hevo = AlgoHEvo.EXP</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Determine which kind of Hamiltonian evolution algorithm to use.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.dropout_mode","title":"<code>dropout_mode = DropoutMode.ROTATIONAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of quantum dropout to perform.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.dropout_probability","title":"<code>dropout_probability = 0.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Quantum dropout probability (0 means no dropout).</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.gap_step","title":"<code>gap_step = 1.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Step between generated pseudo-gaps when using aGPSR algorithm.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.lb","title":"<code>lb = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Lower bound of optimal shift value search interval.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.loop_expectation","title":"<code>loop_expectation = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>When computing batches of expectation values, only allocate one wavefunction.</p> <p>Loop over the batch of parameters to only allocate a single wavefunction at any given time.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.n_eqs","title":"<code>n_eqs = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of equations to use in aGPSR calculations.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.n_steps_hevo","title":"<code>n_steps_hevo = 100</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default number of steps for the Hamiltonian evolution.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.noise","title":"<code>noise = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NoiseHandler containing readout noise applied in backend.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.ode_solver","title":"<code>ode_solver = SolverType.DP5_SE</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Determine which ODE solver to use for time-dependent blocks.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.shift_prefac","title":"<code>shift_prefac = 0.5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Prefactor governing the magnitude of parameter shift values.</p> <p>Select smaller value if spectral gaps are large.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.ub","title":"<code>ub = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Upper bound of optimal shift value search interval.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_gradient_checkpointing","title":"<code>use_gradient_checkpointing = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use gradient checkpointing.</p> <p>Recommended for higher-order optimization tasks.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_single_qubit_composition","title":"<code>use_single_qubit_composition = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Composes chains of single qubit gates into a single matmul if possible.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.supported_gates","title":"<code>supported_gates = list(set(OpName.list()) - set([OpName.TDAGGER]))</code>  <code>module-attribute</code>","text":"<p>The set of supported gates.</p> <p>Tdagger is currently not supported.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.convert_block","title":"<code>convert_block(block, n_qubits=None, config=None)</code>","text":"<p>Convert block to native Pyqtorch representation.</p> PARAMETER DESCRIPTION <code>block</code> <p>Block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits. Defaults to None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Backend configuration instance. Defaults to None.</p> <p> TYPE: <code>Configuration</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>For non supported blocks.</p> RETURNS DESCRIPTION <code>Sequence[Module | Tensor | str | Expr]</code> <p>Sequence[Module | Tensor | str | sympy.Expr]: List of native operations.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def convert_block(\n    block: AbstractBlock,\n    n_qubits: int = None,\n    config: Configuration = None,\n) -&gt; Sequence[Module | Tensor | str | sympy.Expr]:\n    \"\"\"Convert block to native Pyqtorch representation.\n\n    Args:\n        block (AbstractBlock): Block to convert.\n        n_qubits (int, optional): Number of qubits. Defaults to None.\n        config (Configuration, optional): Backend configuration instance. Defaults to None.\n\n    Raises:\n        NotImplementedError: For non supported blocks.\n\n    Returns:\n        Sequence[Module | Tensor | str | sympy.Expr]: List of native operations.\n    \"\"\"\n    if isinstance(block, (Tensor, str, sympy.Expr)):  # case for hamevo generators\n        if isinstance(block, Tensor):\n            block = block.permute(1, 2, 0)  # put batch size in the back\n        return [block]\n    qubit_support = block.qubit_support\n    if n_qubits is None:\n        n_qubits = max(qubit_support) + 1\n\n    if config is None:\n        config = Configuration()\n\n    noise: NoiseHandler | None = None\n    if hasattr(block, \"noise\") and block.noise:\n        noise = convert_digital_noise(block.noise)\n\n    if isinstance(block, ScaleBlock):\n        scaled_ops = convert_block(block.block, n_qubits, config)\n        scale = extract_parameter(block, config=config)\n\n        # replace underscore by dot when underscore is between two numbers in string\n        if isinstance(scale, str):\n            scale = replace_underscore_floats(scale)\n\n        if isinstance(scale, str) and not config._use_gate_params:\n            param = sympy_to_pyq(sympy.parse_expr(scale))\n        else:\n            param = scale\n\n        return [pyq.Scale(pyq.Sequence(scaled_ops), param)]\n\n    elif isinstance(block, TimeEvolutionBlock):\n        duration = block.duration  # type: ignore [attr-defined]\n        if getattr(block.generator, \"is_time_dependent\", False):\n            config._use_gate_params = False\n            duration = config.get_param_name(block)[1]\n            generator = convert_block(block.generator, config=config)[0]  # type: ignore [arg-type]\n        elif isinstance(block.generator, sympy.Basic):\n            generator = config.get_param_name(block)[1]\n\n        elif isinstance(block.generator, Tensor):\n            m = block.generator.to(dtype=cdouble)\n            generator = convert_block(\n                MatrixBlock(\n                    m,\n                    qubit_support=qubit_support,\n                    check_unitary=False,\n                    check_hermitian=True,\n                )\n            )[0]\n        else:\n            generator = convert_block(block.generator, n_qubits, config)[0]  # type: ignore[arg-type]\n        time_param = config.get_param_name(block)[0]\n\n        # convert noise operators here\n        noise_operators: list = [\n            convert_block(noise_block, config=config)[0] for noise_block in block.noise_operators\n        ]\n        if len(noise_operators) &gt; 0:\n            # squeeze batch size for noise operators\n            noise_operators = [\n                pyq_op.tensor(full_support=qubit_support).squeeze(-1) for pyq_op in noise_operators\n            ]\n\n        return [\n            pyq.HamiltonianEvolution(\n                qubit_support=qubit_support,\n                generator=generator,\n                time=time_param,\n                cache_length=0,\n                duration=duration,\n                solver=config.ode_solver,\n                steps=config.n_steps_hevo,\n                noise=noise_operators if len(noise_operators) &gt; 0 else None,\n            )\n        ]\n\n    elif isinstance(block, MatrixBlock):\n        return [pyq.primitives.Primitive(block.matrix, block.qubit_support, noise=noise)]\n    elif isinstance(block, CompositeBlock):\n        ops = list(flatten(*(convert_block(b, n_qubits, config) for b in block.blocks)))\n        if isinstance(block, AddBlock):\n            return [pyq.Add(ops)]  # add\n        elif is_single_qubit_chain(block) and config.use_single_qubit_composition:\n            return [pyq.Merge(ops)]  # for chains of single qubit ops on the same qubit\n        else:\n            return [pyq.Sequence(ops)]  # for kron and chain\n    elif isinstance(block, tuple(non_unitary_gateset)):\n        if isinstance(block, ProjectorBlock):\n            projector = getattr(pyq, block.name)\n            if block.name == OpName.N:\n                return [projector(target=qubit_support, noise=noise)]\n            else:\n                return [\n                    projector(\n                        qubit_support=qubit_support,\n                        ket=block.ket,\n                        bra=block.bra,\n                        noise=noise,\n                    )\n                ]\n        else:\n            return [getattr(pyq, block.name)(qubit_support[0])]\n    elif isinstance(block, tuple(single_qubit_gateset)):\n        pyq_cls = getattr(pyq, block.name)\n        if isinstance(block, ParametricBlock):\n            if isinstance(block, U):\n                op = pyq_cls(\n                    qubit_support[0],\n                    *config.get_param_name(block),\n                    noise=noise,\n                )\n            else:\n                param = extract_parameter(block, config)\n                op = pyq_cls(qubit_support[0], param, noise=noise)\n        else:\n            op = pyq_cls(qubit_support[0], noise=noise)  # type: ignore [attr-defined]\n        return [op]\n    elif isinstance(block, tuple(two_qubit_gateset)):\n        pyq_cls = getattr(pyq, block.name)\n        if isinstance(block, ParametricBlock):\n            op = pyq_cls(\n                qubit_support[0],\n                qubit_support[1],\n                extract_parameter(block, config),\n                noise=noise,\n            )\n        else:\n            op = pyq_cls(\n                qubit_support[0], qubit_support[1], noise=noise  # type: ignore [attr-defined]\n            )\n        return [op]\n    elif isinstance(block, tuple(three_qubit_gateset) + tuple(multi_qubit_gateset)):\n        block_name = block.name[1:] if block.name.startswith(\"M\") else block.name\n        pyq_cls = getattr(pyq, block_name)\n        if isinstance(block, ParametricBlock):\n            op = pyq_cls(\n                qubit_support[:-1],\n                qubit_support[-1],\n                extract_parameter(block, config),\n                noise=noise,\n            )\n        else:\n            if \"CSWAP\" in block_name:\n                op = pyq_cls(\n                    qubit_support[:-2], qubit_support[-2:], noise=noise  # type: ignore [attr-defined]\n                )\n            else:\n                op = pyq_cls(\n                    qubit_support[:-1], qubit_support[-1], noise=noise  # type: ignore [attr-defined]\n                )\n        return [op]\n    else:\n        raise NotImplementedError(\n            f\"Non supported operation of type {type(block)}. \"\n            \"In case you are trying to run an `AnalogBlock`, make sure you \"\n            \"specify the `device_specs` in your `Register` first.\"\n        )\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.convert_digital_noise","title":"<code>convert_digital_noise(noise)</code>","text":"<p>Convert the digital noise into pyqtorch NoiseProtocol.</p> PARAMETER DESCRIPTION <code>noise</code> <p>Noise to convert.</p> <p> TYPE: <code>NoiseHandler</code> </p> RETURNS DESCRIPTION <code>DigitalNoiseProtocol | None</code> <p>pyq.noise.DigitalNoiseProtocol | None: Pyqtorch native noise protocol if there are any digital noise protocols.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def convert_digital_noise(noise: NoiseHandler) -&gt; pyq.noise.DigitalNoiseProtocol | None:\n    \"\"\"Convert the digital noise into pyqtorch NoiseProtocol.\n\n    Args:\n        noise (NoiseHandler): Noise to convert.\n\n    Returns:\n        pyq.noise.DigitalNoiseProtocol | None: Pyqtorch native noise protocol\n            if there are any digital noise protocols.\n    \"\"\"\n    digital_part = noise.filter(NoiseProtocol.DIGITAL)\n    if digital_part is None:\n        return None\n    return pyq.noise.DigitalNoiseProtocol(\n        [\n            pyq.noise.DigitalNoiseProtocol(proto, option.get(\"error_probability\"))\n            for proto, option in zip(digital_part.protocol, digital_part.options)\n        ]\n    )\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.convert_readout_noise","title":"<code>convert_readout_noise(n_qubits, noise)</code>","text":"<p>Convert the readout noise into pyqtorch ReadoutNoise.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Number of qubits</p> <p> TYPE: <code>int</code> </p> <code>noise</code> <p>Noise to convert.</p> <p> TYPE: <code>NoiseHandler</code> </p> RETURNS DESCRIPTION <code>ReadoutNoise | None</code> <p>pyq.noise.ReadoutNoise | None: Pyqtorch native ReadoutNoise instance if readout is is noise.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def convert_readout_noise(n_qubits: int, noise: NoiseHandler) -&gt; pyq.noise.ReadoutNoise | None:\n    \"\"\"Convert the readout noise into pyqtorch ReadoutNoise.\n\n    Args:\n        n_qubits (int): Number of qubits\n        noise (NoiseHandler):  Noise to convert.\n\n    Returns:\n        pyq.noise.ReadoutNoise | None: Pyqtorch native ReadoutNoise instance\n            if readout is is noise.\n    \"\"\"\n    readout_part = noise.filter(NoiseProtocol.READOUT)\n    if readout_part is None:\n        return None\n\n    if readout_part.protocol[0] == NoiseProtocol.READOUT.INDEPENDENT:\n        return pyq.noise.ReadoutNoise(n_qubits, **readout_part.options[0])\n    else:\n        return pyq.noise.CorrelatedReadoutNoise(**readout_part.options[0])\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.extract_parameter","title":"<code>extract_parameter(block, config)</code>","text":"<p>Extract the parameter as string or its tensor value.</p> PARAMETER DESCRIPTION <code>block</code> <p>Block to extract parameter from.</p> <p> TYPE: <code>ScaleBlock | ParametricBlock</code> </p> <code>config</code> <p>Configuration instance.</p> <p> TYPE: <code>Configuration</code> </p> RETURNS DESCRIPTION <code>str | Tensor</code> <p>str | Tensor: Parameter value or symbol.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def extract_parameter(block: ScaleBlock | ParametricBlock, config: Configuration) -&gt; str | Tensor:\n    \"\"\"Extract the parameter as string or its tensor value.\n\n    Args:\n        block (ScaleBlock | ParametricBlock): Block to extract parameter from.\n        config (Configuration): Configuration instance.\n\n    Returns:\n        str | Tensor: Parameter value or symbol.\n    \"\"\"\n    if not block.is_parametric:\n        tensor_val = tensor([block.parameters.parameter], dtype=complex64)\n        return (\n            tensor([block.parameters.parameter], dtype=float64)\n            if torch.all(tensor_val.imag == 0)\n            else tensor_val\n        )\n\n    return config.get_param_name(block)[0]\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.replace_underscore_floats","title":"<code>replace_underscore_floats(s)</code>","text":"<p>Replace underscores with periods for all floats in given string.</p> <p>Needed for correct parsing of string by sympy parser.</p> PARAMETER DESCRIPTION <code>s</code> <p>string expression</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>transformed string expression</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def replace_underscore_floats(s: str) -&gt; str:\n    \"\"\"Replace underscores with periods for all floats in given string.\n\n    Needed for correct parsing of string by sympy parser.\n\n    Args:\n        s (str): string expression\n\n    Returns:\n        str: transformed string expression\n    \"\"\"\n\n    # Regular expression to match floats written with underscores instead of dots\n    float_with_underscore_pattern = r\"\"\"\n        (?&lt;!\\w)            # Negative lookbehind to ensure not part of a word\n        -?                 # Optional negative sign\n        \\d+                # One or more digits (before underscore)\n        _                  # The underscore acting as decimal separator\n        \\d+                # One or more digits (after underscore)\n        ([eE][-+]?\\d+)?    # Optional exponent part for scientific notation\n        (?!\\w)             # Negative lookahead to ensure not part of a word\n    \"\"\"\n\n    # Function to replace the underscore with a dot\n    def underscore_to_dot(match: re.Match) -&gt; Any:\n        return match.group(0).replace(\"_\", \".\")\n\n    # Compile the regular expression\n    pattern = re.compile(float_with_underscore_pattern, re.VERBOSE)\n\n    return pattern.sub(underscore_to_dot, s)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.sympy_to_pyq","title":"<code>sympy_to_pyq(expr)</code>","text":"<p>Convert sympy expression to pyqtorch ConcretizedCallable object.</p> PARAMETER DESCRIPTION <code>expr</code> <p>sympy expression</p> <p> TYPE: <code>Expr</code> </p> RETURNS DESCRIPTION <code>ConcretizedCallable</code> <p>expression encoded as ConcretizedCallable</p> <p> TYPE: <code>ConcretizedCallable | Tensor</code> </p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def sympy_to_pyq(expr: sympy.Expr) -&gt; ConcretizedCallable | Tensor:\n    \"\"\"Convert sympy expression to pyqtorch ConcretizedCallable object.\n\n    Args:\n        expr (sympy.Expr): sympy expression\n\n    Returns:\n        ConcretizedCallable: expression encoded as ConcretizedCallable\n    \"\"\"\n\n    # base case - independent argument\n    if len(expr.args) == 0:\n        try:\n            res = torch.as_tensor(float(expr))\n        except Exception as e:\n            res = str(expr)\n\n            if \"/\" in res:  # Found a rational\n                res = torch.as_tensor(float(sympy.Rational(res).evalf()))\n        return res\n\n    # Recursively iterate through current function arguments\n    all_results = []\n    for arg in expr.args:\n        res = sympy_to_pyq(arg)\n        all_results.append(res)\n\n    # deal with multi-argument (&gt;2) sympy functions: converting to nested\n    # ConcretizedCallable objects\n    if len(all_results) &gt; 2:\n\n        def fn(x: str | ConcretizedCallable, y: str | ConcretizedCallable) -&gt; Callable:\n            return partial(ConcretizedCallable, call_name=SYMPY_TO_PYQ_MAPPING[expr.func])(  # type: ignore [no-any-return]\n                abstract_args=[x, y]\n            )\n\n        concretized_callable = reduce(fn, all_results)\n    else:\n        concretized_callable = ConcretizedCallable(SYMPY_TO_PYQ_MAPPING[expr.func], all_results)\n    return concretized_callable\n</code></pre>"},{"location":"content/backends/","title":"Backends","text":"<p>Backends allow execution of Qadence abstract quantum circuits. They could be chosen from a variety of simulators, emulators and hardware and can enable circuit differentiability. The primary way to interact and configure a backend is via the high-level API <code>QuantumModel</code>.</p> <p>Not all backends are equivalent</p> <p>Not all backends support the same set of operations, especially while executing analog blocks. Qadence will throw descriptive errors in such cases.</p>"},{"location":"content/backends/#execution-backends","title":"Execution backends","text":"<p>PyQTorch: An efficient, large-scale simulator designed for quantum machine learning, seamlessly integrated with the popular PyTorch deep learning framework for automatic differentiability. It also offers analog computing for time-(in)dependent pulses. See <code>PyQTorchBackend</code>.</p> <p>Pulser: A Python library for pulse-level/analog control of neutral atom devices. Execution via QuTiP. See <code>PulserBackend</code>.</p> <p>More: Proprietary Qadence extensions provide more high-performance backends based on tensor networks or differentiation engines. For more enquiries, please contact: <code>info@pasqal.com</code>.</p>"},{"location":"content/backends/#differentiation-backend","title":"Differentiation backend","text":"<p>The <code>DifferentiableBackend</code> class enables different differentiation modes for the given backend. This can be chosen from two types:</p> <ul> <li>Automatic differentiation (AD): available for PyTorch based backends (PyQTorch).</li> <li>Parameter Shift Rules (PSR): available for all backends. See this section for more information on differentiability and PSR.</li> </ul> <p>In practice, only a <code>diff_mode</code> should be provided in the <code>QuantumModel</code>. Please note that <code>diff_mode</code> defaults to <code>None</code>:</p> <pre><code>import sympy\nimport torch\nfrom qadence import Parameter, RX, RZ, Z, CNOT, QuantumCircuit, QuantumModel, chain, BackendName, DiffMode\n\nx = Parameter(\"x\", trainable=False)\ny = Parameter(\"y\", trainable=False)\nfm = chain(\n    RX(0, 3 * x),\n    RX(0, x),\n    RZ(1, sympy.exp(y)),\n    RX(0, 3.14),\n    RZ(1, \"theta\")\n)\n\nansatz = CNOT(0, 1)\nblock = chain(fm, ansatz)\n\ncircuit = QuantumCircuit(2, block)\n\nobservable = Z(0)\n\n# DiffMode.GPSR is available for any backend.\n# DiffMode.AD is only available for natively differentiable backends.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.GPSR)\n\n# Get some values for the feature parameters.\nvalues = {\"x\": (x := torch.tensor([0.5], requires_grad=True)), \"y\": torch.tensor([0.1])}\n\n# Compute expectation.\nexp = model.expectation(values)\n\n# Differentiate the expectation wrt x.\ndexp_dx = torch.autograd.grad(exp, x, torch.ones_like(exp))\n</code></pre> <pre><code>dexp_dx = (tensor([3.6398]),)\n</code></pre>"},{"location":"content/backends/#low-level-backend_factory-interface","title":"Low-level <code>backend_factory</code> interface","text":"<p>Every backend in Qadence inherits from the abstract <code>Backend</code> class: <code>Backend</code> and implement the following methods:</p> <ul> <li><code>run</code>: propagate the initial state according to the quantum circuit and return the final wavefunction object.</li> <li><code>sample</code>: sample from a circuit.</li> <li><code>expectation</code>: computes the expectation of a circuit given an observable.</li> <li><code>convert</code>: convert the abstract <code>QuantumCircuit</code> object to its backend-native representation including a backend specific parameter embedding function.</li> </ul> <p>Backends are purely functional objects which take as input the values for the circuit parameters and return the desired output from a call to a method. In order to use a backend directly, embedded parameters must be supplied as they are returned by the backend specific embedding function.</p> <p>Here is a simple demonstration of the use of the PyQTorch backend to execute a circuit in non-differentiable mode:</p> <pre><code>from qadence import QuantumCircuit, FeatureParameter, RX, RZ, CNOT, hea, chain\n\n# Construct a feature map.\nx = FeatureParameter(\"x\")\nz = FeatureParameter(\"y\")\nfm = chain(RX(0, 3 * x), RZ(1, z), CNOT(0, 1))\n\n# Construct a circuit with an hardware-efficient ansatz.\ncircuit = QuantumCircuit(3, fm, hea(3,1))\n</code></pre> <p>The abstract <code>QuantumCircuit</code> can now be converted to its native representation via the PyQTorch backend.</p> <pre><code>from qadence import backend_factory\n\n# Use only PyQtorch in non-differentiable mode:\nbackend = backend_factory(\"pyqtorch\")\n\n# The `Converted` object\n# (contains a `ConvertedCircuit` with the original and native representation)\nconv = backend.convert(circuit)\n</code></pre> <pre><code>conv.circuit.original = ChainBlock(0,1,2)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 RX(0) [params: ['3*x']]\n\u2502   \u251c\u2500\u2500 RZ(1) [params: ['y']]\n\u2502   \u2514\u2500\u2500 CNOT(0, 1)\n\u2514\u2500\u2500 ChainBlock(0,1,2) [tag: HEA]\n    \u251c\u2500\u2500 ChainBlock(0,1,2)\n    \u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n    \u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n    \u2502   \u2502   \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n    \u2502   \u2502   \u2514\u2500\u2500 RX(2) [params: ['theta_2']]\n    \u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n    \u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_3']]\n    \u2502   \u2502   \u251c\u2500\u2500 RY(1) [params: ['theta_4']]\n    \u2502   \u2502   \u2514\u2500\u2500 RY(2) [params: ['theta_5']]\n    \u2502   \u2514\u2500\u2500 KronBlock(0,1,2)\n    \u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_6']]\n    \u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_7']]\n    \u2502       \u2514\u2500\u2500 RX(2) [params: ['theta_8']]\n    \u2514\u2500\u2500 ChainBlock(0,1,2)\n        \u251c\u2500\u2500 KronBlock(0,1)\n        \u2502   \u2514\u2500\u2500 CNOT(0, 1)\n        \u2514\u2500\u2500 KronBlock(1,2)\n            \u2514\u2500\u2500 CNOT(1, 2)\nconv.circuit.native = QuantumCircuit(\n  (operations): ModuleList(\n    (0): Sequence(\n      (operations): ModuleList(\n        (0): Sequence(\n          (operations): ModuleList(\n            (0): RX(target: (0,), param: 35ff3017-8dd8-43d1-a07f-637174ddbd54)\n            (1): RZ(target: (1,), param: 9a9ac60a-c985-48a8-88e3-3401b8265a6f)\n            (2): CNOT(control: (0,), target: (1,))\n          )\n        )\n        (1): Sequence(\n          (operations): ModuleList(\n            (0): Sequence(\n              (operations): ModuleList(\n                (0): Merge(\n                  (operations): ModuleList(\n                    (0): RX(target: (0,), param: d8e8d64d-b83b-424f-914c-11477b0b2a98)\n                    (1): RY(target: (0,), param: a9da3743-e6ca-49ed-938e-85dcc3ba3512)\n                    (2): RX(target: (0,), param: 94d5e65f-0f1d-4051-9768-3f35166a7037)\n                  )\n                )\n                (1): Merge(\n                  (operations): ModuleList(\n                    (0): RX(target: (1,), param: dcff6863-44f9-48d6-b6f4-46dd8b926064)\n                    (1): RY(target: (1,), param: 89144979-e143-4586-89f4-fe7d446f484c)\n                    (2): RX(target: (1,), param: 623553a3-6dbd-409e-b077-d3adf4a8e945)\n                  )\n                )\n                (2): Merge(\n                  (operations): ModuleList(\n                    (0): RX(target: (2,), param: dfafa560-3774-44d6-b6a9-4bf075456ffc)\n                    (1): RY(target: (2,), param: 5800415b-193d-4a55-b051-85c274135731)\n                    (2): RX(target: (2,), param: 24a2f9cd-5db8-4e57-bab5-84cfb71d01b9)\n                  )\n                )\n              )\n            )\n            (1): Sequence(\n              (operations): ModuleList(\n                (0): Sequence(\n                  (operations): ModuleList(\n                    (0): CNOT(control: (0,), target: (1,))\n                  )\n                )\n                (1): Sequence(\n                  (operations): ModuleList(\n                    (0): CNOT(control: (1,), target: (2,))\n                  )\n                )\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n)\n</code></pre> <p>Additionally, <code>Converted</code> contains all fixed and variational parameters, as well as an embedding function which accepts feature parameters to construct a dictionary of circuit native parameters. These are needed as each backend uses a different representation of the circuit parameters:</p> <pre><code>import torch\n\n# Contains fixed parameters and variational (from the HEA)\nconv.params\n\ninputs = {\"x\": torch.tensor([1., 1.]), \"y\":torch.tensor([2., 2.])}\n\n# get all circuit parameters (including feature params)\nembedded = conv.embedding_fn(conv.params, inputs)\n</code></pre> <pre><code>conv.params = {\n  theta_4: tensor([0.9814], requires_grad=True)\n  theta_2: tensor([0.1933], requires_grad=True)\n  theta_8: tensor([0.6324], requires_grad=True)\n  theta_6: tensor([0.7180], requires_grad=True)\n  theta_5: tensor([0.0821], requires_grad=True)\n  theta_1: tensor([0.9822], requires_grad=True)\n  theta_3: tensor([0.1060], requires_grad=True)\n  theta_7: tensor([0.9369], requires_grad=True)\n  theta_0: tensor([0.6262], requires_grad=True)\n}\nembedded = {\n  35ff3017-8dd8-43d1-a07f-637174ddbd54: tensor([3., 3.], grad_fn=&lt;ViewBackward0&gt;)\n  9a9ac60a-c985-48a8-88e3-3401b8265a6f: tensor([2., 2.])\n  d8e8d64d-b83b-424f-914c-11477b0b2a98: tensor([0.6262], grad_fn=&lt;ViewBackward0&gt;)\n  a9da3743-e6ca-49ed-938e-85dcc3ba3512: tensor([0.1060], grad_fn=&lt;ViewBackward0&gt;)\n  94d5e65f-0f1d-4051-9768-3f35166a7037: tensor([0.7180], grad_fn=&lt;ViewBackward0&gt;)\n  dcff6863-44f9-48d6-b6f4-46dd8b926064: tensor([0.9822], grad_fn=&lt;ViewBackward0&gt;)\n  89144979-e143-4586-89f4-fe7d446f484c: tensor([0.9814], grad_fn=&lt;ViewBackward0&gt;)\n  623553a3-6dbd-409e-b077-d3adf4a8e945: tensor([0.9369], grad_fn=&lt;ViewBackward0&gt;)\n  dfafa560-3774-44d6-b6a9-4bf075456ffc: tensor([0.1933], grad_fn=&lt;ViewBackward0&gt;)\n  5800415b-193d-4a55-b051-85c274135731: tensor([0.0821], grad_fn=&lt;ViewBackward0&gt;)\n  24a2f9cd-5db8-4e57-bab5-84cfb71d01b9: tensor([0.6324], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>With the embedded parameters, <code>QuantumModel</code> methods are accessible:</p> <pre><code>output = backend.run(conv.circuit, embedded)\nprint(f\"{output = }\")\n</code></pre> <pre><code>output = tensor([[ 0.5028-0.0714j, -0.0071-0.2234j,  0.0891+0.0741j, -0.1452+0.2195j,\n         -0.3420-0.1748j, -0.0929+0.1412j,  0.2633+0.0322j, -0.0076+0.6025j],\n        [ 0.5028-0.0714j, -0.0071-0.2234j,  0.0891+0.0741j, -0.1452+0.2195j,\n         -0.3420-0.1748j, -0.0929+0.1412j,  0.2633+0.0322j, -0.0076+0.6025j]],\n       grad_fn=&lt;TBackward0&gt;)\n</code></pre>"},{"location":"content/backends/#lower-level-the-backend-representation","title":"Lower-level: the <code>Backend</code> representation","text":"<p>If there is a requirement to work with a specific backend, it is possible to access directly the native circuit. For example, should one wish to use PyQtorch noise features directly instead of using the <code>NoiseHandler</code> interface from Qadence:</p> <pre><code>from pyqtorch.noise import Depolarizing\n\ninputs = {\"x\": torch.rand(1), \"y\":torch.rand(1)}\nembedded = conv.embedding_fn(conv.params, inputs)\n\n# Define a noise channel on qubit 0\nnoise = Depolarizing(0, error_probability=0.1)\n\n# Add noise to circuit\nconv.circuit.native.operations.append(noise)\n</code></pre> <p>When running With noise, one can see that the output is a density matrix:</p> <pre><code>density_result = backend.run(conv.circuit, embedded)\nprint(density_result.shape)\n</code></pre> <pre><code>torch.Size([1, 8, 8])\n</code></pre>"},{"location":"content/block_system/","title":"Block system","text":"<p>Quantum programs in Qadence are constructed using a block-system, with an emphasis on composability of primitive blocks to obtain larger, composite blocks. This functional approach is different from other frameworks which follow a more object-oriented way to construct circuits and express programs.</p>"},{"location":"content/block_system/#primitive-blocks","title":"Primitive blocks","text":"<p>A <code>PrimitiveBlock</code> represents a digital or an analog time-evolution quantum operation applied to a qubit support. Programs can always be decomposed down into a sequence of <code>PrimitiveBlock</code> elements.</p> <p>Two canonical examples of digital primitive blocks are the parametrized <code>RX</code> and the <code>CNOT</code> gates:</p> <pre><code>from qadence import chain, RX, CNOT\n\nrx = RX(0, 0.5)\ncnot = CNOT(0, 1)\n\nblock = chain(rx, cnot)\n</code></pre> %3 24c00e8859944b519dc3cd83afa64c8a 0 f7fddb1a3ed64e20be138aab6cd3f5d3 RX(0.5) 24c00e8859944b519dc3cd83afa64c8a--f7fddb1a3ed64e20be138aab6cd3f5d3 a108098f56394259b131ed81bef13b9b 1 a578b59f60294113a2322b883544e704 f7fddb1a3ed64e20be138aab6cd3f5d3--a578b59f60294113a2322b883544e704 562213396c6946a5b091412893577fac a578b59f60294113a2322b883544e704--562213396c6946a5b091412893577fac 990a91a094484b8081036de4192a3d2e 6767a861eb2d49bcb5d0dfadf79c127b a108098f56394259b131ed81bef13b9b--6767a861eb2d49bcb5d0dfadf79c127b 73872184f07b4e208689abdd0fb49464 X 6767a861eb2d49bcb5d0dfadf79c127b--73872184f07b4e208689abdd0fb49464 73872184f07b4e208689abdd0fb49464--a578b59f60294113a2322b883544e704 73872184f07b4e208689abdd0fb49464--990a91a094484b8081036de4192a3d2e <p>A list of all available primitive operations can be found here.</p> How to visualize blocks <p>There are two ways to display blocks in a Python interpreter: either as a tree in ASCII format using <code>print</code>:</p> <pre><code>from qadence import X, Y, kron\n\nkron_block = kron(X(0), Y(1))\nprint(kron_block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> <p>Or using the visualization package:</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nkron_block = kron(X(0), Y(1))\n# display(kron_block)\n</code></pre> %3 34e19453ea544f32a687e8fd7ca6e72d 0 edd497c355e141e8b335b20aed53ec9d X 34e19453ea544f32a687e8fd7ca6e72d--edd497c355e141e8b335b20aed53ec9d 45f03e2362c940e1b81f8ec0322983b6 1 5c2678ae2a2d4dde868c07ef52d15d8e edd497c355e141e8b335b20aed53ec9d--5c2678ae2a2d4dde868c07ef52d15d8e 9527567064644e899e394139e1e18573 757ad4bfb2f24b75be1e7ad4896ec557 Y 45f03e2362c940e1b81f8ec0322983b6--757ad4bfb2f24b75be1e7ad4896ec557 757ad4bfb2f24b75be1e7ad4896ec557--9527567064644e899e394139e1e18573"},{"location":"content/block_system/#composite-blocks","title":"Composite Blocks","text":"<p>Programs can be expressed by composing blocks to result in a larger <code>CompositeBlock</code> using three fundamental operations: chain, kron, and add.</p> <ul> <li>chain applies a set of blocks in sequence, which can have overlapping qubit supports, and results in a <code>ChainBlock</code> type. It is akin to applying a matrix product of the sub-blocks, and can also be used with the <code>*</code> operator.</li> <li>kron applies a set of blocks in parallel, requiring disjoint qubit support, and results in a <code>KronBlock</code> type. This is akin to applying a tensor product of the sub-blocks, and can also be used with the <code>@</code> operator.</li> <li>add performs a direct sum of the operators, and results in an <code>AddBlock</code> type. Blocks constructed this way are typically non-unitary, as is the case for Hamiltonians which can be constructed through sums of Pauli strings. Addition can also be performed directly with the <code>+</code> operator.</li> </ul> <pre><code>from qadence import X, Y, chain, kron\n\nchain_0 = chain(X(0), Y(0))\nchain_1 = chain(X(1), Y(1))\n\nkron_block = kron(chain_0, chain_1)\n</code></pre> %3 657e7b2e70de470cba9821457e12779d 0 5cfac8ff89eb47f7bfa408a669007062 X 657e7b2e70de470cba9821457e12779d--5cfac8ff89eb47f7bfa408a669007062 8c3d346b7b2047578d806effc63ae296 1 08aeec478048482899736643d5e2ecc1 Y 5cfac8ff89eb47f7bfa408a669007062--08aeec478048482899736643d5e2ecc1 39b65d1ad0db404cae6cf3d5447e5ae9 08aeec478048482899736643d5e2ecc1--39b65d1ad0db404cae6cf3d5447e5ae9 fb28761de74f479788de53aac7e52089 72cce998aabc40f998d80356889cbf54 X 8c3d346b7b2047578d806effc63ae296--72cce998aabc40f998d80356889cbf54 a9e2b47ae043419f803e2e2899d91f53 Y 72cce998aabc40f998d80356889cbf54--a9e2b47ae043419f803e2e2899d91f53 a9e2b47ae043419f803e2e2899d91f53--fb28761de74f479788de53aac7e52089 <p>All composition functions support list comprehension syntax. Below we exemplify the creation of an XY Hamiltonian for qubits laid out on a line.</p> <pre><code>from qadence import X, Y, add\n\ndef xy_int(i: int, j: int):\n    return (1/2) * (X(i)@X(j) + Y(i)@Y(j))\n\nn_qubits = 3\n\nxy_ham = add(xy_int(i, i+1) for i in range(n_qubits-1))\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u251c\u2500\u2500 KronBlock(0,1)\n\u2502       \u2502   \u251c\u2500\u2500 X(0)\n\u2502       \u2502   \u2514\u2500\u2500 X(1)\n\u2502       \u2514\u2500\u2500 KronBlock(0,1)\n\u2502           \u251c\u2500\u2500 Y(0)\n\u2502           \u2514\u2500\u2500 Y(1)\n\u2514\u2500\u2500 [mul: 0.500] \n    \u2514\u2500\u2500 AddBlock(1,2)\n        \u251c\u2500\u2500 KronBlock(1,2)\n        \u2502   \u251c\u2500\u2500 X(1)\n        \u2502   \u2514\u2500\u2500 X(2)\n        \u2514\u2500\u2500 KronBlock(1,2)\n            \u251c\u2500\u2500 Y(1)\n            \u2514\u2500\u2500 Y(2)\n</code></pre> <p>Qadence blocks can be directly translated to matrix form by calling <code>block.tensor()</code>. Note that first dimension is the batch dimension, following PyTorch conventions. This becomes relevant if the block are parameterized and batched input values are passed, as we will see later.</p> <pre><code>from qadence import X, Y\n\nxy = (1/2) * (X(0)@X(1) + Y(0)@Y(1))\n\nprint(xy.tensor().real)\n</code></pre> <pre><code>tensor([[[0., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [0., 1., 0., 0.],\n         [0., 0., 0., 0.]]])\n</code></pre> <p>For a final example of the flexibility of functional block composition, below is an implementation of the Quantum Fourier Transform on an arbitrary qubit support.</p> <pre><code>from qadence import H, CPHASE, PI, chain, kron\n\ndef qft_layer(qs: tuple, l: int):\n    cphases = chain(CPHASE(qs[j], qs[l], PI/2**(j-l)) for j in range(l+1, len(qs)))\n    return H(qs[l]) * cphases\n\ndef qft(qs: tuple):\n    return chain(qft_layer(qs, l) for l in range(len(qs)))\n</code></pre> %3 4e6b7cb03acb4186bd308f020b16535a 0 58eae21fc2fe40cd96509028f253765a H 4e6b7cb03acb4186bd308f020b16535a--58eae21fc2fe40cd96509028f253765a dc3d933c171f4c53bb07461892b4aa18 1 61fb294805274a268bd3150ac1e9f5d4 PHASE(1.571) 58eae21fc2fe40cd96509028f253765a--61fb294805274a268bd3150ac1e9f5d4 a994f1a2ec464a138a2efd2e3ad12b7b PHASE(0.785) 61fb294805274a268bd3150ac1e9f5d4--a994f1a2ec464a138a2efd2e3ad12b7b a4a11439b0d34cf38945c02c984bf8fa 61fb294805274a268bd3150ac1e9f5d4--a4a11439b0d34cf38945c02c984bf8fa 3ae2b0bde1bb43f7ab3768d9fd0bf022 a994f1a2ec464a138a2efd2e3ad12b7b--3ae2b0bde1bb43f7ab3768d9fd0bf022 c51d19b1db8f4d7d9f61105a12ab7768 a994f1a2ec464a138a2efd2e3ad12b7b--c51d19b1db8f4d7d9f61105a12ab7768 758d81c38a2843a4a024698b998b9ae1 3ae2b0bde1bb43f7ab3768d9fd0bf022--758d81c38a2843a4a024698b998b9ae1 576065bb384f47a8ad62217cff636006 758d81c38a2843a4a024698b998b9ae1--576065bb384f47a8ad62217cff636006 94c41669618d47fe86c21df03787ed4c 576065bb384f47a8ad62217cff636006--94c41669618d47fe86c21df03787ed4c 507f533cf2bd440b9324de3cfbfa69a7 8c505921e7114d7c9a0fbbeda116de75 dc3d933c171f4c53bb07461892b4aa18--8c505921e7114d7c9a0fbbeda116de75 30923189ba544318bd8edf8055da31a6 2 8c505921e7114d7c9a0fbbeda116de75--a4a11439b0d34cf38945c02c984bf8fa 11bd70c3ee784ae68bf78437531eef1e a4a11439b0d34cf38945c02c984bf8fa--11bd70c3ee784ae68bf78437531eef1e 826c1234bfa7436483e8eeaceaf8c18c H 11bd70c3ee784ae68bf78437531eef1e--826c1234bfa7436483e8eeaceaf8c18c 7cb01d8008824aa7b55dfe1e41008c13 PHASE(1.571) 826c1234bfa7436483e8eeaceaf8c18c--7cb01d8008824aa7b55dfe1e41008c13 4334f86c65414dd88d49ea100987886f 7cb01d8008824aa7b55dfe1e41008c13--4334f86c65414dd88d49ea100987886f fa8e8cc698334e2f9d6367595e6d9c18 7cb01d8008824aa7b55dfe1e41008c13--fa8e8cc698334e2f9d6367595e6d9c18 4334f86c65414dd88d49ea100987886f--507f533cf2bd440b9324de3cfbfa69a7 7d2de6e1f4e24be29eeabce64420227d 83850d17bafd472cb243e3434d528093 30923189ba544318bd8edf8055da31a6--83850d17bafd472cb243e3434d528093 124e1832ac8144de9ca1297ba1348b0b 83850d17bafd472cb243e3434d528093--124e1832ac8144de9ca1297ba1348b0b 124e1832ac8144de9ca1297ba1348b0b--c51d19b1db8f4d7d9f61105a12ab7768 e3005a0f1a8f4743b199d70d50168dcf c51d19b1db8f4d7d9f61105a12ab7768--e3005a0f1a8f4743b199d70d50168dcf e3005a0f1a8f4743b199d70d50168dcf--fa8e8cc698334e2f9d6367595e6d9c18 a77bdc8295af4b4282e8fdfbd82c1d1d H fa8e8cc698334e2f9d6367595e6d9c18--a77bdc8295af4b4282e8fdfbd82c1d1d a77bdc8295af4b4282e8fdfbd82c1d1d--7d2de6e1f4e24be29eeabce64420227d <p>Other functionalities are directly built in the block system. For example, the inverse operation can be created with the <code>dagger()</code> method.</p> <pre><code>qft_inv = qft((0, 1, 2)).dagger()\n</code></pre> %3 20eb5cd345cb4e6db99042c162fe6cbf 0 4b58507f3c6d4709a28e60a083ae73e8 20eb5cd345cb4e6db99042c162fe6cbf--4b58507f3c6d4709a28e60a083ae73e8 08ad963562f4426598eb883cd1c618e4 1 9a65a8bd963d4a38a9f88ee0ecc37728 4b58507f3c6d4709a28e60a083ae73e8--9a65a8bd963d4a38a9f88ee0ecc37728 37bf2547f92b442da08f353867773640 9a65a8bd963d4a38a9f88ee0ecc37728--37bf2547f92b442da08f353867773640 afa253d8701e4c04a86686e17fe9fb63 PHASE(-0.785) 37bf2547f92b442da08f353867773640--afa253d8701e4c04a86686e17fe9fb63 c473e880e4814bee8f9e9611d0f8ece2 PHASE(-1.571) afa253d8701e4c04a86686e17fe9fb63--c473e880e4814bee8f9e9611d0f8ece2 a9ad184986cb45b18972fe6d65294fe1 afa253d8701e4c04a86686e17fe9fb63--a9ad184986cb45b18972fe6d65294fe1 67891b40638044db9651f1a0e3be8c0b H c473e880e4814bee8f9e9611d0f8ece2--67891b40638044db9651f1a0e3be8c0b 7a40e19726394cb78116e70f94647d8f c473e880e4814bee8f9e9611d0f8ece2--7a40e19726394cb78116e70f94647d8f bcc1564c2c2c4d3a9514e9d94682a159 67891b40638044db9651f1a0e3be8c0b--bcc1564c2c2c4d3a9514e9d94682a159 7c54e5cf7893448f80ded82bf12634e8 948e891dfd9448d79dc7e31eec34810c 08ad963562f4426598eb883cd1c618e4--948e891dfd9448d79dc7e31eec34810c cb884d5d714d432d93c6916b699c8db1 2 5bb4d2731ab24c1295739a3371e2ae48 PHASE(-1.571) 948e891dfd9448d79dc7e31eec34810c--5bb4d2731ab24c1295739a3371e2ae48 4afac28346fa46eea8cc167896c8d720 H 5bb4d2731ab24c1295739a3371e2ae48--4afac28346fa46eea8cc167896c8d720 5141fec7a1e4452897b8fe160cca9a7c 5bb4d2731ab24c1295739a3371e2ae48--5141fec7a1e4452897b8fe160cca9a7c d57e4f90470545ecb7f604a150b1dcf5 4afac28346fa46eea8cc167896c8d720--d57e4f90470545ecb7f604a150b1dcf5 d57e4f90470545ecb7f604a150b1dcf5--7a40e19726394cb78116e70f94647d8f 39acb45e15054419b36940fb1e587f8e 7a40e19726394cb78116e70f94647d8f--39acb45e15054419b36940fb1e587f8e 39acb45e15054419b36940fb1e587f8e--7c54e5cf7893448f80ded82bf12634e8 2968430e107143179fd34c4586b195e3 3d0d275941224c21807333b3ea1cd2d2 H cb884d5d714d432d93c6916b699c8db1--3d0d275941224c21807333b3ea1cd2d2 3d0d275941224c21807333b3ea1cd2d2--5141fec7a1e4452897b8fe160cca9a7c 7dfa1d133ffc499fac8306242fe7b10c 5141fec7a1e4452897b8fe160cca9a7c--7dfa1d133ffc499fac8306242fe7b10c 7dfa1d133ffc499fac8306242fe7b10c--a9ad184986cb45b18972fe6d65294fe1 39c36748ed394f9e9e881b3231a1287e a9ad184986cb45b18972fe6d65294fe1--39c36748ed394f9e9e881b3231a1287e eebaab360b094dc49fcc06f358b2d968 39c36748ed394f9e9e881b3231a1287e--eebaab360b094dc49fcc06f358b2d968 eebaab360b094dc49fcc06f358b2d968--2968430e107143179fd34c4586b195e3"},{"location":"content/block_system/#digital-analog-composition","title":"Digital-analog composition","text":"<p>In Qadence, analog operations are first-class citizens. An analog operation is one whose unitary is best described by the evolution of some hermitian generator, or Hamiltonian, acting on an arbitrary number of qubits. Qadence provides the <code>HamEvo</code> class to initialize analog operations. For a time-independent generator \\(\\mathcal{H}\\) and some time variable \\(t\\), <code>HamEvo(H, t)</code> represents the evolution operator \\(\\exp(-i\\mathcal{H}t)\\).</p> <p>Analog operations constitute a generalization of digital operations, and all digital operations can also be represented as the evolution of some hermitian generator. For example, the <code>RX</code> gate is the evolution of <code>X</code>.</p> <pre><code>from qadence import X, RX, HamEvo, PI\nfrom torch import allclose\n\nangle = PI/2\n\nblock_digital = RX(0, angle)\n\nblock_analog = HamEvo(0.5*X(0), angle)\n\nprint(allclose(block_digital.tensor(), block_analog.tensor()))\n</code></pre> <pre><code>True\n</code></pre> <p>As seen in the previous section, arbitrary Hamiltonians can be constructed using Pauli operators. Their evolution can be combined with other arbitrary digital operations and incorporated into any quantum program.</p> <pre><code>from qadence import X, Y, RX, HamEvo\nfrom qadence import add, kron, PI\n\ndef xy_int(i: int, j: int):\n    return (1/2) * (X(i)@X(j) + Y(i)@Y(j))\n\nn_qubits = 3\n\nxy_ham = add(xy_int(i, i+1) for i in range(n_qubits-1))\n\nanalog_evo = HamEvo(xy_ham, 1.0)\n\ndigital_block = kron(RX(i, i*PI/2) for i in range(n_qubits))\n\nprogram = digital_block * analog_evo * digital_block\n</code></pre> %3 cluster_bfab9528a13c489da726e5453fe556c5 aedd2aa954d341e3a41c3099ba9f080c 0 929d7f09aa5e4729b70208c22ff390af RX(0.0) aedd2aa954d341e3a41c3099ba9f080c--929d7f09aa5e4729b70208c22ff390af 4fb15f3651ca430ab0c921a3a3ebb3d3 1 e662b58627b549f98f83a9fce88c349f HamEvo 929d7f09aa5e4729b70208c22ff390af--e662b58627b549f98f83a9fce88c349f 9977c1fa5c02442ab05c9953ea512852 RX(0.0) e662b58627b549f98f83a9fce88c349f--9977c1fa5c02442ab05c9953ea512852 d7508994eb02497fb07fac77a6301343 9977c1fa5c02442ab05c9953ea512852--d7508994eb02497fb07fac77a6301343 c0ca5e015ba8415eaf1a019e9c8f8a1e 747e79898a1f4d80815217c522f06ac2 RX(1.571) 4fb15f3651ca430ab0c921a3a3ebb3d3--747e79898a1f4d80815217c522f06ac2 d4f4f09b739d438f8332b2cd390eeb57 2 322282e8377046edbdbd5ad28608220f t = 1.000 747e79898a1f4d80815217c522f06ac2--322282e8377046edbdbd5ad28608220f 25dac6a6280245a5a311098880e858b5 RX(1.571) 322282e8377046edbdbd5ad28608220f--25dac6a6280245a5a311098880e858b5 25dac6a6280245a5a311098880e858b5--c0ca5e015ba8415eaf1a019e9c8f8a1e 07f1daeadd6d4be1ba51a5558df331ed d4eac60ee09541bbb9f0141d84cfdf74 RX(3.142) d4f4f09b739d438f8332b2cd390eeb57--d4eac60ee09541bbb9f0141d84cfdf74 9ecce9980d1341c9bb83b4257263acc7 d4eac60ee09541bbb9f0141d84cfdf74--9ecce9980d1341c9bb83b4257263acc7 73ba10cc822f4ad4aa971e160d5954d2 RX(3.142) 9ecce9980d1341c9bb83b4257263acc7--73ba10cc822f4ad4aa971e160d5954d2 73ba10cc822f4ad4aa971e160d5954d2--07f1daeadd6d4be1ba51a5558df331ed"},{"location":"content/block_system/#block-execution","title":"Block execution","text":"<p>To quickly run block operations and access wavefunctions, samples or expectation values of observables, one can use the convenience functions <code>run</code>, <code>sample</code> and <code>expectation</code>.</p> <pre><code>from qadence import kron, add, H, Z, run, sample, expectation\n\nn_qubits = 2\n\n# Prepares a uniform state\nh_block = kron(H(i) for i in range(n_qubits))\n\nwf = run(h_block)\n\nxs = sample(h_block, n_shots=1000)\n\nobs = add(Z(i) for i in range(n_qubits))\nex = expectation(h_block, obs)\n</code></pre> <pre><code>wf = tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\nxs = [OrderedCounter({'10': 266, '00': 254, '01': 241, '11': 239})]\nex = tensor([[0.]])\n</code></pre>"},{"location":"content/block_system/#execution-via-quantumcircuit-and-quantummodel","title":"Execution via <code>QuantumCircuit</code> and <code>QuantumModel</code>","text":"<p>More fine-grained control and better performance is provided via the high-level <code>QuantumModel</code> abstraction. Quantum programs in Qadence are constructed in two steps:</p> <ol> <li>Build a <code>QuantumCircuit</code> which ties together a composite block and a register.</li> <li>Define a <code>QuantumModel</code> which differentiates, compiles and executes the circuit.</li> </ol> <p>Execution of more complex Qadence programs will be explored in the next tutorials.</p>"},{"location":"content/block_system/#adding-noise-to-gates","title":"Adding noise to gates","text":"<p>It is possible to add noise to gates. Please refer to the noise tutorial here.</p>"},{"location":"content/hamiltonians/","title":"Constructing arbitrary Hamiltonians","text":"<p>At the heart of digital-analog quantum computing is the description and execution of analog blocks, which represent a set of interacting qubits under some interaction Hamiltonian. For this purpose, Qadence relies on the <code>hamiltonian_factory</code> function to create arbitrary Hamiltonian blocks to be used as generators of <code>HamEvo</code> or as observables to be measured.</p>"},{"location":"content/hamiltonians/#arbitrary-all-to-all-hamiltonians","title":"Arbitrary all-to-all Hamiltonians","text":"<p>Arbitrary all-to-all interaction Hamiltonians can be easily created by passing the number of qubits in the first argument. The type of <code>interaction</code> can be chosen from the available ones in the <code>Interaction</code> enum type.</p> <pre><code>from qadence import hamiltonian_factory\nfrom qadence import N, X, Y, Z\nfrom qadence import Interaction\n\nn_qubits = 3\n\nhamilt = hamiltonian_factory(n_qubits, interaction=Interaction.ZZ)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 Z(1)\n        \u2514\u2500\u2500 Z(2)\n</code></pre> <p>Alternatively, a custom interaction function can also be defined. The input should be two integer indices \\(i\\) and \\(j\\) and it should return a composition of pauli terms representing the interaction between qubits \\(i\\) and \\(j\\):</p> <pre><code>def custom_int(i: int, j: int):\n    return X(i) @ X(j) + Y(i) @ Y(j)\n\nn_qubits = 2\n\nhamilt = hamiltonian_factory(n_qubits, interaction=custom_int)\n</code></pre> <pre><code>AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 AddBlock(0,1)\n        \u251c\u2500\u2500 KronBlock(0,1)\n        \u2502   \u251c\u2500\u2500 X(0)\n        \u2502   \u2514\u2500\u2500 X(1)\n        \u2514\u2500\u2500 KronBlock(0,1)\n            \u251c\u2500\u2500 Y(0)\n            \u2514\u2500\u2500 Y(1)\n</code></pre> <p>Single-qubit terms can also be added by passing the respective operator directly to the <code>detuning</code> argument. For example, the total magnetization is commonly used as an observable to be measured:</p> <pre><code>total_mag = hamiltonian_factory(n_qubits, detuning = Z)\n</code></pre> <pre><code>AddBlock(0,1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 Z(0)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 Z(1)\n</code></pre> <p>For further customization, arbitrary coefficients can be passed as arrays to the <code>interaction_strength</code> and <code>detuning_strength</code> arguments for the two-qubits and single-qubit terms respectively.</p> <pre><code>n_qubits = 3\n\nhamilt = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.ZZ,\n    detuning=Z,\n    interaction_strength=[0.5, 0.2, 0.1],\n    detuning_strength=[0.1, 0.5, -0.3]\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.100] \n\u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: -0.30] \n\u2502   \u2514\u2500\u2500 Z(2)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 0.200] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 0.100] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 Z(1)\n        \u2514\u2500\u2500 Z(2)\n</code></pre> <p>Ordering interaction strengths matters</p> <p>When passing interaction strengths as an array, the ordering must be identical to the one obtained from the <code>edges</code> property of a Qadence <code>Register</code>:</p> <pre><code>from qadence import Register\n\nprint(Register(n_qubits).edges)\n</code></pre> <pre><code>[(0, 1), (0, 2), (1, 2)]\n</code></pre> <p>For one more example, let's create a transverse-field Ising model,</p> <pre><code>n_qubits = 4\nn_edges = int(0.5 * n_qubits * (n_qubits - 1))\n\nz_terms = [1.0] * n_qubits\nzz_terms = [2.0] * n_edges\n\nzz_ham = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.ZZ,\n    detuning=Z,\n    interaction_strength=zz_terms,\n    detuning_strength=z_terms\n)\n\nx_terms = [-1.0] * n_qubits\nx_ham = hamiltonian_factory(n_qubits, detuning = X, detuning_strength = x_terms)\n\ntransverse_ising = zz_ham + x_ham\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 AddBlock(0,1,2,3)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(0)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u2514\u2500\u2500 [mul: 2.000] \n\u2502       \u2514\u2500\u2500 KronBlock(2,3)\n\u2502           \u251c\u2500\u2500 Z(2)\n\u2502           \u2514\u2500\u2500 Z(3)\n\u2514\u2500\u2500 AddBlock(0,1,2,3)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(0)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(1)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(2)\n    \u2514\u2500\u2500 [mul: -1.00] \n        \u2514\u2500\u2500 X(3)\n</code></pre> <p>Random interaction coefficients</p> <p>Random interaction coefficients can be chosen between -1 and 1 by simply passing <code>random_strength = True</code> instead of <code>detuning_strength</code> and <code>interaction_strength</code>.</p>"},{"location":"content/hamiltonians/#arbitrary-hamiltonian-topologies","title":"Arbitrary Hamiltonian topologies","text":"<p>Arbitrary interaction topologies can be created using the Qadence <code>Register</code>. Simply pass the register with the desired topology as the first argument to the <code>hamiltonian_factory</code>:</p> <pre><code>from qadence import Register\n\nreg = Register.square(qubits_side=2)\n\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(2,3)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(3)\n</code></pre>"},{"location":"content/hamiltonians/#adding-variational-parameters","title":"Adding variational parameters","text":"<p>Finally, fully parameterized Hamiltonians can be created by passing a string to the strength arguments, and used to prefix the name of the variational parameters.</p> <pre><code>n_qubits = 3\n\nnn_ham = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.NN,\n    detuning=N,\n    interaction_strength=\"c\",\n    detuning_strength=\"d\"\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: d_0] \n\u2502   \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: d_1] \n\u2502   \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: d_2] \n\u2502   \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: c_01] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: c_02] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: c_12] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 N(1)\n        \u2514\u2500\u2500 N(2)\n</code></pre> <p>Alternatively, fully customizable sympy functions can be passed in an array using the Qadence parameters. Furthermore, the <code>use_all_node_pairs = True</code> option can be passed so that interactions are created for every single node pair in the register, irrespectively of the topology of the edges. This is useful for creating Hamiltonians that depend on qubit distance.</p> <pre><code>from qadence import VariationalParameter, Register\n\n# Square register of 4 qubits with a dimensionless distance of 8.0\nreg = Register.square(2, spacing = 8.0)\n\n# Get the distances between all pairs of qubits\ndistance_dict = reg.distances\n\n# Create interaction strength with variational parameter and 1/r term\nstrength_list = []\nfor node_pair in reg.all_node_pairs:\n    param = VariationalParameter(\"x\" + f\"_{node_pair[0]}{node_pair[1]}\")\n    dist_factor = reg.distances[node_pair]\n    strength_list.append(param / dist_factor)\n\nnn_ham = hamiltonian_factory(\n    reg,\n    interaction=Interaction.NN,\n    interaction_strength=strength_list,\n    use_all_node_pairs=True,\n)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 0.125*x_01] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 0.088*x_02] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: 0.125*x_03] \n\u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 0.125*x_12] \n\u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: 0.088*x_13] \n\u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(3)\n\u2514\u2500\u2500 [mul: 0.125*x_23] \n    \u2514\u2500\u2500 KronBlock(2,3)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(3)\n</code></pre>"},{"location":"content/noisy_simulation/","title":"Noisy Simulation","text":"<p>Running programs on NISQ devices often leads to imperfect results due to the presence of noise. In order to perform realistic simulations, a number of noise models (for digital operations, analog operations and simulated readout errors) are supported in <code>Qadence</code>.</p> <p>Noisy simulations shift the quantum paradigm from a close-system (noiseless case) to an open-system (noisy case) where a quantum system is represented by a probabilistic combination \\(p_i\\) of possible pure states \\(|\\psi_i \\rangle\\). Thus, the system is described by a density matrix \\(\\rho\\) (and computation modify the density matrix) defined as follows:</p> \\[ \\rho = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i| \\] <p>The noise protocols applicable in <code>Qadence</code> are classified into three types: digital (for digital operations), analog (for analog operations), and readout error (for measurements).</p>"},{"location":"content/noisy_simulation/#specifying-a-noise-protocol","title":"Specifying a noise protocol","text":"<p>Each noise protocol can be specified using <code>NoiseProtocol</code> and requires specific <code>options</code> parameter passed as a dictionary. We show below for each type of noise how this can be done.</p>"},{"location":"content/noisy_simulation/#digital-noise-protocol","title":"Digital noise protocol","text":"<p>Digital noise refer to unintended changes occurring with reference to the application of a noiseless digital gate operation. The following are the protocols of supported digital noise, along with brief descriptions. For digital noise, the <code>error_probability</code> is necessary for the noise initialization at the <code>options</code> parameter.</p> <p>When dealing with programs involving digital operations, <code>Qadence</code> has interface to noise models implemented in <code>PyQTorch</code>. Detailed equations for these protocols are available from PyQTorch.</p> <ul> <li>BITFLIP: flips between |0\u27e9 and |1\u27e9 with <code>error_probability</code></li> <li>PHASEFLIP: flips the phase of a qubit by applying a Z gate with <code>error_probability</code></li> <li>DEPOLARIZING: randomizes the state of a qubit by applying I, X, Y, or Z gates with equal <code>error_probability</code></li> <li>PAULI_CHANNEL: applies the Pauli operators (X, Y, Z) to a qubit with specified <code>error_probabilities</code></li> <li>AMPLITUDE_DAMPING: models the asymmetric process through which the qubit state |1\u27e9 irreversibly decays into the state |0\u27e9 with <code>error_probability</code></li> <li>PHASE_DAMPING: similar to AMPLITUDE_DAMPING but concerning the phase</li> <li>GENERALIZED_AMPLITUDE_DAMPING: extends amplitude damping; the first float is <code>error_probability</code> of amplitude damping, and second float is the <code>damping_rate</code></li> </ul> <p>For digital noise simulation, you need to state <code>NoiseProtocol</code> with <code>DIGITAL</code> and then specify the noise protocol. Also, you put the value of <code>error_probability</code> as in next example.</p> <pre><code>from qadence import NoiseProtocol\n\nprotocol = NoiseProtocol.DIGITAL.DEPOLARIZING\noptions = {\"error_probability\": 0.1}\n</code></pre>"},{"location":"content/noisy_simulation/#analog-noise-protocol","title":"Analog noise protocol","text":"<p>Analog noise can be set for analog operations. At the moment, we only enabled simulations via the <code>Pulser</code> backend. For <code>Pulser</code> noise implementation, you can refer to Pulser. <code>Qadence</code> is in the process of fully supporting all the noise protocols in the backends (especially <code>Pulser</code>). However, we are in transition, and currently, only DEPOLARIZING and DEPHAZING are available as protocols. The <code>options</code> dictionary requires to specify the field <code>noise_probs</code>.</p> <ul> <li>Depolarizing: evolves to the maximally mixed state with <code>noise_probs</code></li> <li>Dephasing: induces the loss of phase coherence without affecting the population of computational basis states</li> </ul> <pre><code>from qadence import NoiseProtocol\n\nprotocol = NoiseProtocol.ANALOG.DEPOLARIZING\noptions = {\"noise_probs\": 0.1}\n</code></pre>"},{"location":"content/noisy_simulation/#readout-error-protocol","title":"Readout error protocol","text":"<p>Readout errors are linked to the incorrect measurement outcomes from the system. In this protocol, we have <code>error_probability</code>, <code>confusion_matrix</code>, and <code>seed</code> option parameters. For the <code>error_probability</code> parameter, if float, the same probability error is applied to every bit. A different probability can be set for each qubit if a 1D tensor has an element number equal to the number of qubits. For <code>confusion_matrix</code> parameter, the square matrix for each possible bitstring of length <code>n</code> qubits. We have a <code>seed</code> parameter for reproducible purposes.</p> <p>Currently, two readout protocols are available via PyQTorch.</p> <ul> <li>Independent: all bits are corrupted independently with each other.</li> <li>Correlated: apply a <code>confusion_matrix</code> of corruption between each possible bitstrings</li> </ul> <pre><code>from qadence import NoiseProtocol\n\nprotocol=NoiseProtocol.READOUT.INDEPENDENT\noptions = {\"error_probability\": 0.01, \"seed\": 0}\n</code></pre>"},{"location":"content/noisy_simulation/#preparing-noise-protocols-for-usage","title":"Preparing noise protocols for usage","text":"<p>In order to apply the noise to <code>Qadence</code> objects, we need a wrapper called the <code>NoiseHandler</code> type. It is a container of several noise instances that require a specific <code>protocol</code> and a dictionary of <code>options</code> (or lists). The <code>protocol</code> field is to be instantiated from <code>NoiseProtocol</code> and <code>options</code> includes error-related information such as <code>error_probability</code>, <code>noise_probs</code>, and <code>seed</code>.</p> <pre><code>from qadence import NoiseHandler, NoiseProtocol\n\ndigital_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.AMPLITUDE_DAMPING, options={\"error_probability\": 0.1})\nanalog_noise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options={\"noise_probs\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\n</code></pre> <p><code>NoiseHandler</code> can be used in a more compact way to represent noise in batches.</p> <ul> <li>A <code>NoiseHandler</code> can be initiated with a list of protocols and a list of options (careful with the order)</li> <li>A <code>NoiseHandler</code> can be appended to other <code>NoiseHandler</code> instances</li> </ul> <pre><code>from qadence import NoiseHandler, NoiseProtocol\n\n# initiating with list of protocols and options\nprotocols = [NoiseProtocol.DIGITAL.DEPOLARIZING, NoiseProtocol.READOUT]\noptions = [{\"error_probability\": 0.1}, {\"error_probability\": 0.1, \"seed\": 0}]\n\nnoise_handler_list = NoiseHandler(protocols, options)\n\n# NoiseHandler appending\ndepo_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.DEPOLARIZING, options={\"error_probability\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\nnoise_combination = NoiseHandler(protocol=NoiseProtocol.DIGITAL.BITFLIP, options={\"error_probability\": 0.1})\n\n# prints noise_combination\nnoise_combination.append([depo_noise, readout_noise])\n</code></pre> <pre><code>Noise(BitFlip, {'error_probability': 0.1})\nNoise(Depolarizing, {'error_probability': 0.1})\nNoise(Independent Readout, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>NoiseHandler scope</p> <p>Note it is not possible to define <code>NoiseHandler</code> instances with both digital and analog noises, both readout and analog noises, several analog noises, several readout noises, or a readout noise that is not the last defined protocol within <code>NoiseHandler</code>.</p>"},{"location":"content/noisy_simulation/#executing-noisy-simulation","title":"Executing Noisy Simulation","text":"<p>Noisy simulation can be set by applying a <code>NoiseHandler</code> to the desired <code>gate</code>, <code>block</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <pre><code>from qadence import NoiseProtocol, RX, run, NoiseHandler\nimport torch\n\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.2})\ncircuit = RX(0, torch.pi, noise = noise)\n\n# prints density matrix\nrun(circuit)\n</code></pre> <pre><code>Noisy density matrix = DensityMatrix([[[0.2000+0.0000e+00j, 0.0000+3.6739e-17j],\n                [0.0000-3.6739e-17j, 0.8000+0.0000e+00j]]])\n</code></pre> <p>We can also apply noise with the <code>set_noise</code> function that apply a given noise configuration to the whole object.</p> <pre><code>from qadence import DiffMode, NoiseHandler, QuantumModel\nfrom qadence.blocks import chain, kron\nfrom qadence.circuit import QuantumCircuit\nfrom qadence.operations import AnalogRX, AnalogRZ, Z\nfrom qadence.types import PI, BackendName, NoiseProtocol\nfrom qadence import set_noise\n\nanalog_block = chain(AnalogRX(PI / 2.0), AnalogRZ(PI))\nobservable = Z(0) + Z(1)\ncircuit = QuantumCircuit(2, analog_block)\n\nnoise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options={\"noise_probs\": 0.2})\nmodel = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR,\n)\n\nnoiseless_expectation = model.expectation()\n\nnoisy_model = set_noise(model, noise)\nnoisy_expectation = noisy_model.expectation()\n</code></pre> <pre><code>Noiseless expectation = tensor([[0.3961]])\nNoisy expectation = tensor([[0.3254]])\n</code></pre> <p>Let's say we want to apply noise only to specific type of gates, a <code>target_class</code> argument can be passed with the corresponding block in <code>set_noise</code>.</p> <pre><code>from qadence import X, chain, set_noise, NoiseHandler, NoiseProtocol\n\nblock = chain(RX(0, \"theta\"), X(0))\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.AMPLITUDE_DAMPING, {\"error_probability\": 0.1})\n\n# prints noise configuration for each gate\nset_noise(block, noise, target_class=X)\n</code></pre> <pre><code>Noise type for gate RX(0) [params: ['theta']] is None.\nNoise type for gate X(0) is Noise(AmplitudeDamping, {'error_probability': 0.1}).\n</code></pre> <p>One can set different noise models for each individual gates within the same circuit as follows:</p> <pre><code>from qadence import QuantumCircuit, X, sample, kron, NoiseHandler, NoiseProtocol\nimport matplotlib.pyplot as plt\n\nn_qubits = 2\nnoise_bitflip = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.1})\nnoise_amplitude_damping = NoiseHandler(NoiseProtocol.DIGITAL.AMPLITUDE_DAMPING, {\"error_probability\": 0.3})\nblock = kron(X(0, noise=noise_bitflip), X(1, noise=noise_amplitude_damping))\ncircuit = QuantumCircuit(n_qubits, block)\n\nn_shots=1000\nxs = sample(circuit, n_shots=n_shots)\n\nitems = list(xs[0].keys())\nvalues = [v/n_shots for v in xs[0].values()]\n\nplt.figure()\nplt.bar(range(len(values)), values, color='blue', alpha=0.7)\nplt.xticks(range(len(items)), items)\nplt.title(\"Probability of state occurrence\")\nplt.xlabel('Possible States')\nplt.ylabel('Probability')\n</code></pre> 2025-05-12T10:16:57.701803 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>The result of this figure would be a 100% <code>11</code> state without noise. However, with <code>X(0)</code> bitflip noise, the state <code>01</code> has some possibility, and with <code>X(1)</code> amplitude damping noise, more gap appears between state pairs of (<code>00</code>, <code>01</code>) and (<code>10</code>, <code>11</code>), as shown in the figure.</p> <p>The readout error is computed with the density matrix of the state through <code>sample</code> execution.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use.\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1})\n\n# Run noiseless and noisy simulations.\nnoiseless_samples = model.sample(n_shots=100)\nnoisy_samples = model.sample(noise=noise, n_shots=100)\n</code></pre> <pre><code>noiseless = [OrderedCounter({'10': 53, '00': 47})]\nnoisy = [OrderedCounter({'00': 53, '10': 42, '11': 3, '01': 2})]\n</code></pre>"},{"location":"content/overlap/","title":"Wavefunction overlaps","text":"<p>Qadence offers convenience functions for computing the overlap between the wavefunctions generated by two quantum circuits \\(U\\) and \\(W\\) as:</p> \\[ S = |\\langle \\psi_U | \\psi_W \\rangle|^2 \\quad \\textrm{where} \\quad \\psi_U = U|\\psi_0\\rangle \\] <p>Here is an example on how to compute the overlap between two very simple parametric circuits consisting of a single <code>RX</code> rotation on different qubits. The overlap is expected to be non-zero only when the rotation angle is different from \\(\\pi \\; \\textrm{mod}\\; 2\\pi\\) for both rotations:</p> <pre><code>import numpy as np\nfrom torch import tensor\nfrom qadence import Overlap, OverlapMethod, QuantumCircuit, H, RX, X, FeatureParameter, hea, PI\n\n\n# Create two quantum circuits\n# with a single qubit rotation on two random qubits\nn_qubits = 4\nqubits = np.random.choice(n_qubits, n_qubits, replace=False)\n\nphi = FeatureParameter(\"phi\")\ncircuit_bra = QuantumCircuit(n_qubits, RX(qubits[0], phi))\n\npsi = FeatureParameter(\"psi\")\ncircuit_ket = QuantumCircuit(n_qubits, RX(qubits[1], psi))\n\n# Values for the feature parameters\nvalues_bra = {\"phi\": tensor([PI / 2, PI])}\nvalues_ket = {\"psi\": tensor([PI / 2, PI])}\n\n# Calculate overlap by assigning values to the given bra and ket circuits\novrlp = Overlap(circuit_bra, circuit_ket)\novrlp = ovrlp(bra_param_values=values_bra, ket_param_values=values_ket)\n</code></pre> <pre><code>Overlap with exact method:\n tensor([[2.5000e-01, 1.8747e-33],\n        [1.8747e-33, 1.4058e-65]])\n</code></pre> <p>The <code>Overlap</code> class above inherits from <code>QuantumModel</code> and is executed through its inherited forward method for the given input parameter values. By default, the overlap is computed exactly by performing the dot product of the wavefunction propagated from bra and ket circuits.</p> <p>However, it is possible to choose a different method from the <code>OverlapMethod</code> enumeration to be passed via the <code>overlap_method</code> argument in the <code>Overlap</code> initializer. Currently, one can choose from:</p> <ul> <li><code>EXACT</code>: exact computation using the wavefunction matrix representation. Does not work with real devices since it assumes access to the complete qubit system wavefunction.</li> <li><code>COMPUTE_UNCOMPUTE</code>: exact or sampling-based computation using bra \\(U\\) and ket \\(W^{\\dagger}\\) unitaries.</li> <li><code>SWAP_TEST</code>: exact or sampling-based computation using the SWAP test method.</li> <li><code>HADAMARD_TEST</code>: exact or sampling-based computation using the Hadamard test method.</li> <li><code>JENSEN_SHANNON</code>: compute the overlap using the Jensen-Shannon divergence of the two probability distributions obtained by sampling the propagated circuits. This will yield a different result than the other methods.</li> </ul> <p>All methods (except for the <code>EXACT</code> method) take an optional <code>n_shots</code> argument which can be used to perform shot-based calculations.</p> <p>Warning</p> <p>If you select a finite number of shots, the overlap is not differentiable. Therefore, it cannot be used as output of a quantum model if gradients are required.</p> <pre><code># Calculate overlap with SWAP test\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket)\n\n# Calculate overlap with SWAP test\n# using a finite number of shots\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket, n_shots=10_000)\n</code></pre> <pre><code>Overlap with SWAP test:\n tensor([[ 2.5000e-01, -3.3307e-16],\n        [-3.3307e-16, -4.4409e-16]])\nOverlap with SWAP test with finite number of shots:\n tensor([[ 0.2634,  0.0018],\n        [ 0.0194, -0.0146]])\n</code></pre>"},{"location":"content/parameters/","title":"Parametric programs","text":"<p>Qadence provides a flexible parameter system built on top of Sympy. Parameters can be of different types:</p> <ul> <li>Fixed parameter: a constant with a fixed, non-trainable value (e.g. \\(\\dfrac{\\pi}{2}\\)).</li> <li>Variational parameter: a trainable parameter which will be automatically picked up by the optimizer.</li> <li>Feature parameter: a non-trainable parameter which can be used to pass input values.</li> </ul>"},{"location":"content/parameters/#fixed-parameters","title":"Fixed parameters","text":"<p>Passing fixed parameters to blocks can be done by simply passing a Python numeric type or a <code>torch.Tensor</code>.</p> <pre><code>import torch\nfrom qadence import RX, run, PI\n\nwf = run(RX(0, torch.tensor(PI)))\n\nwf = run(RX(0, PI))\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\nwf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\n</code></pre>"},{"location":"content/parameters/#variational-parameters","title":"Variational parameters","text":"<p>To parametrize a block a <code>VariationalParameter</code> instance is required. In most cases Qadence also accepts a Python string, which will be used to automatically initialize a <code>VariationalParameter</code>:</p> <pre><code>from qadence import RX, run, VariationalParameter\n\nblock = RX(0, VariationalParameter(\"theta\"))\nblock = RX(0, \"theta\")  # Equivalent\n\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[0.8808+0.0000j, 0.0000-0.4736j]])\n</code></pre> <p>By calling <code>run</code>, a random value for <code>\"theta\"</code> is initialized at execution. In a <code>QuantumModel</code>, variational parameters are stored in the underlying model parameter dictionary.</p>"},{"location":"content/parameters/#feature-parameters","title":"Feature parameters","text":"<p>A <code>FeatureParameter</code> type can also be used. It requires an input value or a batch of values. In most cases, Qadence accepts a <code>values</code> dictionary to set the input of feature parameters.</p> <pre><code>from torch import tensor\nfrom qadence import RX, PI, run, FeatureParameter\n\nblock = RX(0, FeatureParameter(\"phi\"))\n\nwf = run(block, values = {\"phi\": tensor([PI, PI/2])})\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.0000j, 0.0000e+00-1.0000j],\n        [7.0711e-01+0.0000j, 0.0000e+00-0.7071j]])\n</code></pre> <p>Since a batch of input values was passed, the <code>run</code> function returns a batch of output states. Note that <code>FeatureParameter(\"x\")</code> and <code>VariationalParameter(\"x\")</code> are simply aliases for <code>Parameter(\"x\", trainable = False)</code> and <code>Parameter(\"x\", trainable = True)</code>.</p>"},{"location":"content/parameters/#multiparameter-expressions-and-analog-integration","title":"Multiparameter expressions and analog integration","text":"<p>The integration with Sympy becomes useful when one wishes to write arbitrary parameter compositions. Parameters can also be used as scaling coefficients in the block system, which is essential when defining arbitrary analog operations.</p> <pre><code>from torch import tensor\nfrom qadence import RX, Z, HamEvo, PI\nfrom qadence import VariationalParameter, FeatureParameter, run\nfrom sympy import sin\n\ntheta, phi = VariationalParameter(\"theta\"), FeatureParameter(\"phi\")\n\n# Arbitrary parameter composition\nexpr = PI * sin(theta + phi)\n\n# Use as unitary gate arguments\ngate = RX(0, expr)\n\n# Or as scaling coefficients for Hermitian operators\nh_op = expr * (Z(0) @ Z(1))\n\nwf = run(gate * HamEvo(h_op, 1.0), values = {\"phi\": tensor(PI)})\n</code></pre> <pre><code>wf = tensor([[-0.2410+0.4566j,  0.0000+0.0000j,  0.7574-0.3998j,  0.0000+0.0000j]])\n</code></pre>"},{"location":"content/parameters/#parameter-redundancy","title":"Parameter redundancy","text":"<p>Parameters are uniquely defined by their name and redundancy is allowed in composite blocks to assign the same value to different blocks. This is useful, for example, when defining layers of rotation gates typically used as feature maps.</p> <pre><code>from torch import tensor\nfrom qadence import RY, PI, run, kron, FeatureParameter\n\nn_qubits = 3\n\nparam = FeatureParameter(\"phi\")\n\nblock = kron(RY(i, (i+1) * param) for i in range(n_qubits))\n\nwf = run(block, values = {\"phi\": tensor(PI)})\n</code></pre> <pre><code>wf = tensor([[ 1.1248e-32+0.j,  6.1232e-17+0.j, -1.3775e-48+0.j, -7.4988e-33+0.j,\n          1.8370e-16+0.j,  1.0000e+00+0.j, -2.2496e-32+0.j, -1.2246e-16+0.j]])\n</code></pre>"},{"location":"content/parameters/#parametrized-circuits","title":"Parametrized circuits","text":"<p>Let's look at a final example of an arbitrary composition of digital and analog parameterized blocks:</p> <pre><code>import sympy\nfrom qadence import RX, RY, RZ, CNOT, CPHASE, Z, HamEvo\nfrom qadence import run, chain, add, kron, FeatureParameter, VariationalParameter, PI\n\nn_qubits = 3\n\nphi = FeatureParameter(\"\u03a6\")\ntheta = VariationalParameter(\"\u03b8\")\n\nrotation_block = kron(\n    RX(0, phi/theta),\n    RY(1, theta*2),\n    RZ(2, sympy.cos(phi))\n)\ndigital_entangler = CNOT(0, 1) * CPHASE(1, 2, PI)\n\nhamiltonian = add(theta * (Z(i) @ Z(i+1)) for i in range(n_qubits-1))\n\nanalog_evo = HamEvo(hamiltonian, phi)\n\nprogram = chain(rotation_block, digital_entangler, analog_evo)\n</code></pre> %3 cluster_96869dee9d8e45c393a6306ffdbb0e36 7c10c237979f46988f9732d49f641c14 0 6ae306bbe875495492fff90990310152 RX(\u03a6/\u03b8) 7c10c237979f46988f9732d49f641c14--6ae306bbe875495492fff90990310152 0bf020c7b65f4e1c9f13ab564b9245de 1 bd1cb807cdcd48758a99dcf3b65367a7 6ae306bbe875495492fff90990310152--bd1cb807cdcd48758a99dcf3b65367a7 d212b1f575e3425c97e5ec38ea9092ff bd1cb807cdcd48758a99dcf3b65367a7--d212b1f575e3425c97e5ec38ea9092ff 9fb9b55e89fb401087f8f3d07d3a0ebd HamEvo d212b1f575e3425c97e5ec38ea9092ff--9fb9b55e89fb401087f8f3d07d3a0ebd c2fb6b9c803242e0ba6297bace4b9335 9fb9b55e89fb401087f8f3d07d3a0ebd--c2fb6b9c803242e0ba6297bace4b9335 d072f2f46a5e484f965c636c51f9b966 f690612ed21f4c99bcf984f3f6676007 RY(2*\u03b8) 0bf020c7b65f4e1c9f13ab564b9245de--f690612ed21f4c99bcf984f3f6676007 6a02ef2262b043bcb172eb8b8b5d468a 2 fafe0e7105584763acfbb8071e7f8319 X f690612ed21f4c99bcf984f3f6676007--fafe0e7105584763acfbb8071e7f8319 fafe0e7105584763acfbb8071e7f8319--bd1cb807cdcd48758a99dcf3b65367a7 aae693b819ca4c248b4ccc80699dd3e6 fafe0e7105584763acfbb8071e7f8319--aae693b819ca4c248b4ccc80699dd3e6 01c2d82845d847c9a712494f9527c288 t = \u03a6 aae693b819ca4c248b4ccc80699dd3e6--01c2d82845d847c9a712494f9527c288 01c2d82845d847c9a712494f9527c288--d072f2f46a5e484f965c636c51f9b966 98a5756cb1644d359aa9de5b690fee90 1a98dec744714cf9a48d0c1820a1e3e9 RZ(cos(\u03a6)) 6a02ef2262b043bcb172eb8b8b5d468a--1a98dec744714cf9a48d0c1820a1e3e9 e0b2e65375594e8c81b6cdbeb122680b 1a98dec744714cf9a48d0c1820a1e3e9--e0b2e65375594e8c81b6cdbeb122680b 8526d251c4c74194b8d692eae3798b69 PHASE(3.142) e0b2e65375594e8c81b6cdbeb122680b--8526d251c4c74194b8d692eae3798b69 8526d251c4c74194b8d692eae3798b69--aae693b819ca4c248b4ccc80699dd3e6 63deebc114ff4f5c9661167eed2dca22 8526d251c4c74194b8d692eae3798b69--63deebc114ff4f5c9661167eed2dca22 63deebc114ff4f5c9661167eed2dca22--98a5756cb1644d359aa9de5b690fee90 <p>Please note the different colors for the parametrization with different types. The default palette assigns blue for <code>VariationalParameter</code>, green for <code>FeatureParameter</code>, orange for numeric values, and shaded red for non-parametric gates.</p>"},{"location":"content/qml_constructors/","title":"Quantum machine learning constructors","text":"<p>Besides the arbitrary Hamiltonian constructors, Qadence also provides a complete set of program constructors useful for digital-analog quantum machine learning programs.</p>"},{"location":"content/qml_constructors/#feature-maps","title":"Feature maps","text":"<p>The <code>feature_map</code> function can easily create several types of data-encoding blocks. The two main types of feature maps use a Fourier basis or a Chebyshev basis.</p> <pre><code>from qadence import feature_map, BasisSet, chain\nfrom qadence.draw import display\n\nn_qubits = 3\n\nfourier_fm = feature_map(n_qubits, fm_type=BasisSet.FOURIER)\n\nchebyshev_fm = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV)\n\nblock = chain(fourier_fm, chebyshev_fm)\n</code></pre> %3 cluster_79398bf899124129a151cd3c455057d2 Constant Chebyshev FM cluster_3065aa526938479d8e9c910dbf8a93be Constant Fourier FM 416321d7d67b414c90a2b55840825f6e 0 09865386c5704693b1393ae7c248266c RX(phi) 416321d7d67b414c90a2b55840825f6e--09865386c5704693b1393ae7c248266c d75b036cc4544f7f8a0bd9bb855f66ae 1 a1b353ce7e6f4998a36dd94460c8d01a RX(acos(phi)) 09865386c5704693b1393ae7c248266c--a1b353ce7e6f4998a36dd94460c8d01a b8e901d40ce54e83b0a53997bafe1fbc a1b353ce7e6f4998a36dd94460c8d01a--b8e901d40ce54e83b0a53997bafe1fbc 35a914bdd3ee4d669ea960f47cbdbd15 5eeee7e437704648b277a6926bbcebd1 RX(phi) d75b036cc4544f7f8a0bd9bb855f66ae--5eeee7e437704648b277a6926bbcebd1 aec841de5885462fb20a9c94e5efc687 2 f48a2e0fe0714c188b35630e7f7a8b66 RX(acos(phi)) 5eeee7e437704648b277a6926bbcebd1--f48a2e0fe0714c188b35630e7f7a8b66 f48a2e0fe0714c188b35630e7f7a8b66--35a914bdd3ee4d669ea960f47cbdbd15 1a0e1e230f074d2880b6f43c055c2363 0ec0f4987ce54ae5bd9fc5e5567f75be RX(phi) aec841de5885462fb20a9c94e5efc687--0ec0f4987ce54ae5bd9fc5e5567f75be a249b12456094c6c9d6640edcc27b47b RX(acos(phi)) 0ec0f4987ce54ae5bd9fc5e5567f75be--a249b12456094c6c9d6640edcc27b47b a249b12456094c6c9d6640edcc27b47b--1a0e1e230f074d2880b6f43c055c2363 <p>A custom encoding function can also be passed with <code>sympy</code></p> <pre><code>from sympy import asin, Function\n\nn_qubits = 3\n\n# Using a pre-defined sympy Function\ncustom_fm_0 = feature_map(n_qubits, fm_type=asin)\n\n# Creating a custom function\ndef custom_fn(x):\n    return asin(x) + x**2\n\ncustom_fm_1 = feature_map(n_qubits, fm_type=custom_fn)\n\nblock = chain(custom_fm_0, custom_fm_1)\n</code></pre> %3 cluster_983dc0889f9344deacd940527d01c6f1 Constant &lt;function custom_fn at 0x7ff03df97910&gt; FM cluster_c73896c765134b1e8eeedb186b24fd27 Constant asin FM 2337badf32e04759b8300a09a15410e9 0 9803ebd184574244a3d7e0edadc1521d RX(asin(phi)) 2337badf32e04759b8300a09a15410e9--9803ebd184574244a3d7e0edadc1521d c7393f52e15f436b9b004fe52d095b3c 1 fc6d6aa333634f4b81b1c9f9f3a32eea RX(phi**2 + asin(phi)) 9803ebd184574244a3d7e0edadc1521d--fc6d6aa333634f4b81b1c9f9f3a32eea 0946a9db2e704e1ca0249ddccb3b8b1b fc6d6aa333634f4b81b1c9f9f3a32eea--0946a9db2e704e1ca0249ddccb3b8b1b fa55eb482db849b281359a42997eeb33 c30c61bae0bb43ee888c96af317b0493 RX(asin(phi)) c7393f52e15f436b9b004fe52d095b3c--c30c61bae0bb43ee888c96af317b0493 a8d73bb0b782444780897d684390ec4c 2 00f74f48b51e424d9d724f8497d40d28 RX(phi**2 + asin(phi)) c30c61bae0bb43ee888c96af317b0493--00f74f48b51e424d9d724f8497d40d28 00f74f48b51e424d9d724f8497d40d28--fa55eb482db849b281359a42997eeb33 4cfbe7374d024fb5b6fcba8a57fded55 ae669170896e42a69e609322a8741b5a RX(asin(phi)) a8d73bb0b782444780897d684390ec4c--ae669170896e42a69e609322a8741b5a f863fc07d3394056bac7b416c31e657b RX(phi**2 + asin(phi)) ae669170896e42a69e609322a8741b5a--f863fc07d3394056bac7b416c31e657b f863fc07d3394056bac7b416c31e657b--4cfbe7374d024fb5b6fcba8a57fded55 <p>Furthermore, the <code>reupload_scaling</code> argument can be used to change the scaling applied to each qubit in the support of the feature map. The default scalings can be chosen from the <code>ReuploadScaling</code> enumeration.</p> <pre><code>from qadence import ReuploadScaling\nfrom qadence.draw import display\n\nn_qubits = 5\n\n# Default constant value\nfm_constant = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT)\n\n# Linearly increasing scaling\nfm_tower = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.TOWER)\n\n# Exponentially increasing scaling\nfm_exp = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.EXP)\n\nblock = chain(fm_constant, fm_tower, fm_exp)\n</code></pre> %3 cluster_dfea6cb6ff264e26aa4c79468000a75b Exponential Fourier FM cluster_4a333aa7411c47aba862b520d5e01b67 Constant Fourier FM cluster_a01710f7804d406191620281d661f682 Tower Fourier FM a597fc5cf0704d31a60906ad768e09aa 0 df731f336922453099bc19b6a9566a02 RX(phi) a597fc5cf0704d31a60906ad768e09aa--df731f336922453099bc19b6a9566a02 1f18637d45a344ddb01c4c89ce5ec9e1 1 2cb3572bea1c4556a12de3a1dc833434 RX(1.0*phi) df731f336922453099bc19b6a9566a02--2cb3572bea1c4556a12de3a1dc833434 63a7731a981a40dcbe545818bf52ff17 RX(1.0*phi) 2cb3572bea1c4556a12de3a1dc833434--63a7731a981a40dcbe545818bf52ff17 2d4f89ddf6c547aa93127ceb44a14955 63a7731a981a40dcbe545818bf52ff17--2d4f89ddf6c547aa93127ceb44a14955 ccb718b9ec0f4245a56a557313432e76 8268661c19e2489f99e0d6f034f38945 RX(phi) 1f18637d45a344ddb01c4c89ce5ec9e1--8268661c19e2489f99e0d6f034f38945 fa5d556eaaa046c3995e383dbfab838a 2 657aae6054bb4d84b5dd7763250acbeb RX(2.0*phi) 8268661c19e2489f99e0d6f034f38945--657aae6054bb4d84b5dd7763250acbeb 507a7ba710964041996fb705c59232d1 RX(2.0*phi) 657aae6054bb4d84b5dd7763250acbeb--507a7ba710964041996fb705c59232d1 507a7ba710964041996fb705c59232d1--ccb718b9ec0f4245a56a557313432e76 4d594eba25234738aad33c4686f41c33 b10c91be71934aeb89f465182c886deb RX(phi) fa5d556eaaa046c3995e383dbfab838a--b10c91be71934aeb89f465182c886deb 82dac58be9fc4d2abb4d2a8aaab11b79 3 0d4575fa437a491ba4c374b5739d3dd3 RX(3.0*phi) b10c91be71934aeb89f465182c886deb--0d4575fa437a491ba4c374b5739d3dd3 b276971f1cf84d8b99def812dde48e30 RX(4.0*phi) 0d4575fa437a491ba4c374b5739d3dd3--b276971f1cf84d8b99def812dde48e30 b276971f1cf84d8b99def812dde48e30--4d594eba25234738aad33c4686f41c33 4d420105d63649ed8199832d5d069e8b b0af2504cf824b058d093fe5beaebe3c RX(phi) 82dac58be9fc4d2abb4d2a8aaab11b79--b0af2504cf824b058d093fe5beaebe3c 29a48a914610414f9bf2c86b6f33060c 4 e3d5f5e84d1f4a948a964b23e739b5b0 RX(4.0*phi) b0af2504cf824b058d093fe5beaebe3c--e3d5f5e84d1f4a948a964b23e739b5b0 788b0af2cad54212b8d5a9be0dbd818c RX(8.0*phi) e3d5f5e84d1f4a948a964b23e739b5b0--788b0af2cad54212b8d5a9be0dbd818c 788b0af2cad54212b8d5a9be0dbd818c--4d420105d63649ed8199832d5d069e8b 35a28beb3a1a4b3aa19aac4fb3f2a73c 4bac4833ecf3461b828ebb73c65a45f1 RX(phi) 29a48a914610414f9bf2c86b6f33060c--4bac4833ecf3461b828ebb73c65a45f1 073018acc6784cdcaf46b80d233c38ad RX(5.0*phi) 4bac4833ecf3461b828ebb73c65a45f1--073018acc6784cdcaf46b80d233c38ad cc27a6a62e9c42d6a527c9ee8105f50d RX(16.0*phi) 073018acc6784cdcaf46b80d233c38ad--cc27a6a62e9c42d6a527c9ee8105f50d cc27a6a62e9c42d6a527c9ee8105f50d--35a28beb3a1a4b3aa19aac4fb3f2a73c <p>A custom scaling can also be defined with a function with an <code>int</code> input and <code>int</code> or <code>float</code> output.</p> <pre><code>n_qubits = 5\n\ndef custom_scaling(i: int) -&gt; int | float:\n    \"\"\"Sqrt(i+1)\"\"\"\n    return (i+1) ** (0.5)\n\n# Custom scaling function\nfm_custom = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV, reupload_scaling=custom_scaling)\n</code></pre> %3 3eb982198161493687839c2f313765ab 0 7b2b3d7fd4514bacbfcd4b61b6815422 RX(1.0*acos(phi)) 3eb982198161493687839c2f313765ab--7b2b3d7fd4514bacbfcd4b61b6815422 4676db33d31348e498651a0b30d9823f 1 abec8899b70c4a40aaeaf2882c472e19 7b2b3d7fd4514bacbfcd4b61b6815422--abec8899b70c4a40aaeaf2882c472e19 2030ef1b5bd242a4a1201287c12b1193 2d2ba8437f554c0dbd74cabfa40fc867 RX(1.414*acos(phi)) 4676db33d31348e498651a0b30d9823f--2d2ba8437f554c0dbd74cabfa40fc867 bfd342aa6bbc4bbeb08d7e13215a4c05 2 2d2ba8437f554c0dbd74cabfa40fc867--2030ef1b5bd242a4a1201287c12b1193 aab800be98e14e9caf9da937e699d3a8 f280bf74232a48ed9a0c81eb83a0d730 RX(1.732*acos(phi)) bfd342aa6bbc4bbeb08d7e13215a4c05--f280bf74232a48ed9a0c81eb83a0d730 4a645341897f464ca0778d7d1607723d 3 f280bf74232a48ed9a0c81eb83a0d730--aab800be98e14e9caf9da937e699d3a8 d0ffeb86ae7d417084d482d15f6d0111 525a87326c2841cdb23f1d413f18c384 RX(2.0*acos(phi)) 4a645341897f464ca0778d7d1607723d--525a87326c2841cdb23f1d413f18c384 3b9b6b487dc74002b1d91e6de1f9c349 4 525a87326c2841cdb23f1d413f18c384--d0ffeb86ae7d417084d482d15f6d0111 cdf0f48b5f9e479db26cc8a43747efd4 009baedb131b45bb897992e0f7c75e4e RX(2.236*acos(phi)) 3b9b6b487dc74002b1d91e6de1f9c349--009baedb131b45bb897992e0f7c75e4e 009baedb131b45bb897992e0f7c75e4e--cdf0f48b5f9e479db26cc8a43747efd4 <p>To add a trainable parameter that multiplies the feature parameter inside the encoding function, simply pass a <code>param_prefix</code> string:</p> <pre><code>n_qubits = 5\n\nfm_trainable = feature_map(\n    n_qubits,\n    fm_type=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.EXP,\n    param_prefix = \"w\",\n)\n</code></pre> %3 c3abf4395bff4b83927c9d3aaf61d135 0 2bae966daf66423688e959e90142bde1 RX(1.0*phi*w\u2080) c3abf4395bff4b83927c9d3aaf61d135--2bae966daf66423688e959e90142bde1 d5dcfd84f85042f0b554b7585c26fdf9 1 6a7f6ce2041945f8b23b5e4503095559 2bae966daf66423688e959e90142bde1--6a7f6ce2041945f8b23b5e4503095559 41ec9659c341485fbef67c1b10e85527 d56f2588057a467e898ca0f67fd81418 RX(2.0*phi*w\u2081) d5dcfd84f85042f0b554b7585c26fdf9--d56f2588057a467e898ca0f67fd81418 d9aef5bc4d1d43328ff0b9333f30b3cb 2 d56f2588057a467e898ca0f67fd81418--41ec9659c341485fbef67c1b10e85527 80f8ff078e994ff6a3e288716d8b8654 6d9859ee53674af0ae8233b9d040c147 RX(4.0*phi*w\u2082) d9aef5bc4d1d43328ff0b9333f30b3cb--6d9859ee53674af0ae8233b9d040c147 df144f0811fe48099e4186e78b37e27e 3 6d9859ee53674af0ae8233b9d040c147--80f8ff078e994ff6a3e288716d8b8654 22fc92ffdbc24b54933d089b1ec3343d 1665276768714801afbebf0f2b74800a RX(8.0*phi*w\u2083) df144f0811fe48099e4186e78b37e27e--1665276768714801afbebf0f2b74800a 29193ba7e75b42b1b54fcd6d61737865 4 1665276768714801afbebf0f2b74800a--22fc92ffdbc24b54933d089b1ec3343d a653986b42464e9bbc63d659c462dbf0 de46812f08bf48a39412232392c01d67 RX(16.0*phi*w\u2084) 29193ba7e75b42b1b54fcd6d61737865--de46812f08bf48a39412232392c01d67 de46812f08bf48a39412232392c01d67--a653986b42464e9bbc63d659c462dbf0 <p>Note that for the Fourier feature map, the encoding function is simply \\(f(x)=x\\). For other cases, like the Chebyshev <code>acos()</code> encoding, the trainable parameter may cause the feature value to be outside the domain of the encoding function. This will eventually be fixed by adding range constraints to trainable parameters in Qadence.</p> <p>A full description of the remaining arguments can be found in the <code>feature_map</code> API reference. We provide an example below.</p> <pre><code>from qadence import RY\n\nn_qubits = 5\n\n# Custom scaling function\nfm_full = feature_map(\n    n_qubits = n_qubits,\n    support = tuple(reversed(range(n_qubits))), # Reverse the qubit support to run the scaling from bottom to top\n    param = \"x\", # Change the name of the parameter\n    op = RY, # Change the rotation gate between RX, RY, RZ or PHASE\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.EXP,\n    feature_range = (-1.0, 2.0), # Range from which the input data comes from\n    target_range = (1.0, 3.0), # Range the encoder assumes as the natural range\n    multiplier = 5.0, # Extra multiplier, which can also be a Parameter\n    param_prefix = \"w\", # Add trainable parameters\n)\n</code></pre> %3 3615109e76f645b0b6e2510c9d405229 0 7b6b73c7c7644b0b8414e548a6f9463f RY(80.0*acos(w\u2084*(0.667*x + 1.667))) 3615109e76f645b0b6e2510c9d405229--7b6b73c7c7644b0b8414e548a6f9463f e10b1dbfc1284659a0e4ea1f39d1d3b5 1 2ceca252652f4418b502483c0473b102 7b6b73c7c7644b0b8414e548a6f9463f--2ceca252652f4418b502483c0473b102 dd1a4a83a9a949878b5822a369213808 ac3013fc1020420f968a3a3e83d2a9e2 RY(40.0*acos(w\u2083*(0.667*x + 1.667))) e10b1dbfc1284659a0e4ea1f39d1d3b5--ac3013fc1020420f968a3a3e83d2a9e2 f3aabb9e7a9c4aceb6efd1ee7265543f 2 ac3013fc1020420f968a3a3e83d2a9e2--dd1a4a83a9a949878b5822a369213808 777f7103655848c68fa242984d3032ce 70c8ed8067294da6b0164595960fb4c0 RY(20.0*acos(w\u2082*(0.667*x + 1.667))) f3aabb9e7a9c4aceb6efd1ee7265543f--70c8ed8067294da6b0164595960fb4c0 d5a164995dc74aff9043190debe6cfeb 3 70c8ed8067294da6b0164595960fb4c0--777f7103655848c68fa242984d3032ce 703010dead7840ec9329404d2ba17cce 73abb5ef3baf4d8685955c5347c32204 RY(10.0*acos(w\u2081*(0.667*x + 1.667))) d5a164995dc74aff9043190debe6cfeb--73abb5ef3baf4d8685955c5347c32204 d72a33a75c6c4ada8620f70705d85184 4 73abb5ef3baf4d8685955c5347c32204--703010dead7840ec9329404d2ba17cce 096bcb34d53d491e851f0ada00c78d74 0a3b471ba70e4235b185134e012419c8 RY(5.0*acos(w\u2080*(0.667*x + 1.667))) d72a33a75c6c4ada8620f70705d85184--0a3b471ba70e4235b185134e012419c8 0a3b471ba70e4235b185134e012419c8--096bcb34d53d491e851f0ada00c78d74"},{"location":"content/qml_constructors/#hardware-efficient-ansatz","title":"Hardware-efficient ansatz","text":"<p>Ansatze blocks for quantum machine-learning are typically built following the Hardware-Efficient Ansatz formalism (HEA). Both fully digital and digital-analog HEAs can easily be built with the <code>hea</code> function. By default, the digital version is returned:</p> <pre><code>from qadence import hea\nfrom qadence.draw import display\n\nn_qubits = 3\ndepth = 2\n\nansatz = hea(n_qubits, depth)\n</code></pre> %3 d81338df5c7b4237985521e3ff23f2a8 0 22b7f4d4ba304063bee337e1bca1fd3b RX(theta\u2080) d81338df5c7b4237985521e3ff23f2a8--22b7f4d4ba304063bee337e1bca1fd3b 1f0d4629dd3a448aab9ff5e0c351c774 1 acf48d535f6e45279f83b393a9a38559 RY(theta\u2083) 22b7f4d4ba304063bee337e1bca1fd3b--acf48d535f6e45279f83b393a9a38559 d01f9be925b84e1e8aa1a5c549ab13ea RX(theta\u2086) acf48d535f6e45279f83b393a9a38559--d01f9be925b84e1e8aa1a5c549ab13ea 14f3cb34499042d586fb3035941fcca2 d01f9be925b84e1e8aa1a5c549ab13ea--14f3cb34499042d586fb3035941fcca2 bf19a4ad2f724419a26dc3ccf4c091f3 14f3cb34499042d586fb3035941fcca2--bf19a4ad2f724419a26dc3ccf4c091f3 f983886845594ee2bf4e4549d62bffd7 RX(theta\u2089) bf19a4ad2f724419a26dc3ccf4c091f3--f983886845594ee2bf4e4549d62bffd7 b0b973cc1d3e4434ba27d63ea70a64bf RY(theta\u2081\u2082) f983886845594ee2bf4e4549d62bffd7--b0b973cc1d3e4434ba27d63ea70a64bf 61d8635b7d0440a2a8908521fd5fa207 RX(theta\u2081\u2085) b0b973cc1d3e4434ba27d63ea70a64bf--61d8635b7d0440a2a8908521fd5fa207 0d59f081a2d34c5781d3e4c20c4a7ccf 61d8635b7d0440a2a8908521fd5fa207--0d59f081a2d34c5781d3e4c20c4a7ccf cad5407a03ce45958f38a40c0ac31ef2 0d59f081a2d34c5781d3e4c20c4a7ccf--cad5407a03ce45958f38a40c0ac31ef2 d1f5ee7849d34ebfb5a78eb21879304a cad5407a03ce45958f38a40c0ac31ef2--d1f5ee7849d34ebfb5a78eb21879304a 7c8c33fde5cf42adb0982fe5cf02dca1 edabb40a28124dd3a697d44b93571e1f RX(theta\u2081) 1f0d4629dd3a448aab9ff5e0c351c774--edabb40a28124dd3a697d44b93571e1f 424f987ee90b4e758cd2fdd96c4263e5 2 c1e86fdd76a94202a9eb6ad8dd9f2f90 RY(theta\u2084) edabb40a28124dd3a697d44b93571e1f--c1e86fdd76a94202a9eb6ad8dd9f2f90 30e7ce0da4ba403b9050ab4a3ed72f7f RX(theta\u2087) c1e86fdd76a94202a9eb6ad8dd9f2f90--30e7ce0da4ba403b9050ab4a3ed72f7f 5dadc108c9fb4c579a13e6441937d993 X 30e7ce0da4ba403b9050ab4a3ed72f7f--5dadc108c9fb4c579a13e6441937d993 5dadc108c9fb4c579a13e6441937d993--14f3cb34499042d586fb3035941fcca2 20db1fd9d8c1488d9675d99dbf47f044 5dadc108c9fb4c579a13e6441937d993--20db1fd9d8c1488d9675d99dbf47f044 6d110eff94514bafbc838e8063cb8c12 RX(theta\u2081\u2080) 20db1fd9d8c1488d9675d99dbf47f044--6d110eff94514bafbc838e8063cb8c12 b8381bc74a444ef6a21d7e7372a384ce RY(theta\u2081\u2083) 6d110eff94514bafbc838e8063cb8c12--b8381bc74a444ef6a21d7e7372a384ce 986c951809b74e0c8fcadf38c9e3ab0d RX(theta\u2081\u2086) b8381bc74a444ef6a21d7e7372a384ce--986c951809b74e0c8fcadf38c9e3ab0d 2d0877c18879432a8ae0b0e35bada556 X 986c951809b74e0c8fcadf38c9e3ab0d--2d0877c18879432a8ae0b0e35bada556 2d0877c18879432a8ae0b0e35bada556--0d59f081a2d34c5781d3e4c20c4a7ccf d8db7e4984d4436b9c07196d772ab004 2d0877c18879432a8ae0b0e35bada556--d8db7e4984d4436b9c07196d772ab004 d8db7e4984d4436b9c07196d772ab004--7c8c33fde5cf42adb0982fe5cf02dca1 c22e8141fd2b43328371dfa3a075e261 88b3f27c2d8747298424f078940ec1e3 RX(theta\u2082) 424f987ee90b4e758cd2fdd96c4263e5--88b3f27c2d8747298424f078940ec1e3 e170a6ac89d34fb2afe6803cb1fc83f5 RY(theta\u2085) 88b3f27c2d8747298424f078940ec1e3--e170a6ac89d34fb2afe6803cb1fc83f5 e4591c7b922c42319e75c90d34e83845 RX(theta\u2088) e170a6ac89d34fb2afe6803cb1fc83f5--e4591c7b922c42319e75c90d34e83845 16c3e665dffc4cf9933b8566ab8015a2 e4591c7b922c42319e75c90d34e83845--16c3e665dffc4cf9933b8566ab8015a2 c9daf6866065450b87dddd6132bce111 X 16c3e665dffc4cf9933b8566ab8015a2--c9daf6866065450b87dddd6132bce111 c9daf6866065450b87dddd6132bce111--20db1fd9d8c1488d9675d99dbf47f044 bad3893c2b7a4ba28e1a703c05ac844c RX(theta\u2081\u2081) c9daf6866065450b87dddd6132bce111--bad3893c2b7a4ba28e1a703c05ac844c aa2e92d546df40e1ad2f8625e6e60edf RY(theta\u2081\u2084) bad3893c2b7a4ba28e1a703c05ac844c--aa2e92d546df40e1ad2f8625e6e60edf 45613871eeeb44a99d817588366e6730 RX(theta\u2081\u2087) aa2e92d546df40e1ad2f8625e6e60edf--45613871eeeb44a99d817588366e6730 65abc450ed7545749f9b104a0f9a673b 45613871eeeb44a99d817588366e6730--65abc450ed7545749f9b104a0f9a673b 43c7f9514d8749f3aa5bd7221d31349a X 65abc450ed7545749f9b104a0f9a673b--43c7f9514d8749f3aa5bd7221d31349a 43c7f9514d8749f3aa5bd7221d31349a--d8db7e4984d4436b9c07196d772ab004 43c7f9514d8749f3aa5bd7221d31349a--c22e8141fd2b43328371dfa3a075e261 <p>As seen above, the rotation layers are automatically parameterized, and the prefix <code>\"theta\"</code> can be changed with the <code>param_prefix</code> argument.</p> <p>Furthermore, both the single-qubit rotations and the two-qubit entangler can be customized with the <code>operations</code> and <code>entangler</code> argument. The operations can be passed as a list of single-qubit rotations, while the entangler should be either <code>CNOT</code>, <code>CZ</code>, <code>CRX</code>, <code>CRY</code>, <code>CRZ</code> or <code>CPHASE</code>.</p> <pre><code>from qadence import RX, RY, CPHASE\n\nansatz = hea(\n    n_qubits=n_qubits,\n    depth=depth,\n    param_prefix=\"phi\",\n    operations=[RX, RY, RX],\n    entangler=CPHASE\n)\n</code></pre> %3 fb170b1d4e9b4bd8b9c34d93469cfd5a 0 966d1924c61f410dbc9fa4afd76dcdf1 RX(phi\u2080) fb170b1d4e9b4bd8b9c34d93469cfd5a--966d1924c61f410dbc9fa4afd76dcdf1 a345af49c8e243b99de5f0eaa5d10fee 1 d8011d1f7c2b4c6faeb8db7cee485355 RY(phi\u2083) 966d1924c61f410dbc9fa4afd76dcdf1--d8011d1f7c2b4c6faeb8db7cee485355 5c2c31326084446795a49064be547d8d RX(phi\u2086) d8011d1f7c2b4c6faeb8db7cee485355--5c2c31326084446795a49064be547d8d 48e29a45193941b4a83d7b033044a01d 5c2c31326084446795a49064be547d8d--48e29a45193941b4a83d7b033044a01d 41b6aee6deff4efaa8218024f156c0e4 48e29a45193941b4a83d7b033044a01d--41b6aee6deff4efaa8218024f156c0e4 991dd8f03b09464faa205bf0600f5386 RX(phi\u2089) 41b6aee6deff4efaa8218024f156c0e4--991dd8f03b09464faa205bf0600f5386 233625aed2fc4188951a65999c71aab9 RY(phi\u2081\u2082) 991dd8f03b09464faa205bf0600f5386--233625aed2fc4188951a65999c71aab9 d4cd2e3d25914402bc9566193a134016 RX(phi\u2081\u2085) 233625aed2fc4188951a65999c71aab9--d4cd2e3d25914402bc9566193a134016 d792c3a43135414cb4429259fc7e2c89 d4cd2e3d25914402bc9566193a134016--d792c3a43135414cb4429259fc7e2c89 b609bf357ac04ded824841f3dfe11b9e d792c3a43135414cb4429259fc7e2c89--b609bf357ac04ded824841f3dfe11b9e 00b86b47797c44f696958dbd586bb1c3 b609bf357ac04ded824841f3dfe11b9e--00b86b47797c44f696958dbd586bb1c3 70ad197ccc1f456ba1db7b0000d7e900 2bace85d1cf449709fd80256f9b52ccf RX(phi\u2081) a345af49c8e243b99de5f0eaa5d10fee--2bace85d1cf449709fd80256f9b52ccf 9cefb25aff21466fb7857448842d521f 2 10affda53bb4407081607522a06abe1c RY(phi\u2084) 2bace85d1cf449709fd80256f9b52ccf--10affda53bb4407081607522a06abe1c e26d8516d1f144cdb5e2b2fd09507d66 RX(phi\u2087) 10affda53bb4407081607522a06abe1c--e26d8516d1f144cdb5e2b2fd09507d66 007a2d94b6884f2086ae2aff14dd9cd4 PHASE(phi_ent\u2080) e26d8516d1f144cdb5e2b2fd09507d66--007a2d94b6884f2086ae2aff14dd9cd4 007a2d94b6884f2086ae2aff14dd9cd4--48e29a45193941b4a83d7b033044a01d 849e927e2d5849b1bb75b62aca9a70ea 007a2d94b6884f2086ae2aff14dd9cd4--849e927e2d5849b1bb75b62aca9a70ea ab8ec54e771a49398764f75be0bc2a24 RX(phi\u2081\u2080) 849e927e2d5849b1bb75b62aca9a70ea--ab8ec54e771a49398764f75be0bc2a24 aa1b97dca4eb44948fc0dbe0051e8d79 RY(phi\u2081\u2083) ab8ec54e771a49398764f75be0bc2a24--aa1b97dca4eb44948fc0dbe0051e8d79 91026893b0464df18a656ab67806a7dc RX(phi\u2081\u2086) aa1b97dca4eb44948fc0dbe0051e8d79--91026893b0464df18a656ab67806a7dc 4402cd695b9d40b59868c65c39edbbda PHASE(phi_ent\u2082) 91026893b0464df18a656ab67806a7dc--4402cd695b9d40b59868c65c39edbbda 4402cd695b9d40b59868c65c39edbbda--d792c3a43135414cb4429259fc7e2c89 e7690c27e7ce4f73972c4780ea627ac7 4402cd695b9d40b59868c65c39edbbda--e7690c27e7ce4f73972c4780ea627ac7 e7690c27e7ce4f73972c4780ea627ac7--70ad197ccc1f456ba1db7b0000d7e900 3dd0a62c1de44fb18f80464f5967882c dd5529cc54e54f4fb1dd9f1a99ef9442 RX(phi\u2082) 9cefb25aff21466fb7857448842d521f--dd5529cc54e54f4fb1dd9f1a99ef9442 fc75977eb227447d8d4f3830c8ed533e RY(phi\u2085) dd5529cc54e54f4fb1dd9f1a99ef9442--fc75977eb227447d8d4f3830c8ed533e bd227cc6c5654cb3806c808fc73a693c RX(phi\u2088) fc75977eb227447d8d4f3830c8ed533e--bd227cc6c5654cb3806c808fc73a693c cb0ba4f7df364ddd9bb6318f4f6ea825 bd227cc6c5654cb3806c808fc73a693c--cb0ba4f7df364ddd9bb6318f4f6ea825 062b6b02874e4c5381b093067b88ec6b PHASE(phi_ent\u2081) cb0ba4f7df364ddd9bb6318f4f6ea825--062b6b02874e4c5381b093067b88ec6b 062b6b02874e4c5381b093067b88ec6b--849e927e2d5849b1bb75b62aca9a70ea e244a527cad04a5c81e46a4261a9969f RX(phi\u2081\u2081) 062b6b02874e4c5381b093067b88ec6b--e244a527cad04a5c81e46a4261a9969f 627e7d290d2043299bb7bedda3484355 RY(phi\u2081\u2084) e244a527cad04a5c81e46a4261a9969f--627e7d290d2043299bb7bedda3484355 47687577a43442e782e4b0714caa08dd RX(phi\u2081\u2087) 627e7d290d2043299bb7bedda3484355--47687577a43442e782e4b0714caa08dd 009c9376592a4280922821b6f2a81c35 47687577a43442e782e4b0714caa08dd--009c9376592a4280922821b6f2a81c35 9d4ac1bbd35b4269b49671f321b48d01 PHASE(phi_ent\u2083) 009c9376592a4280922821b6f2a81c35--9d4ac1bbd35b4269b49671f321b48d01 9d4ac1bbd35b4269b49671f321b48d01--e7690c27e7ce4f73972c4780ea627ac7 9d4ac1bbd35b4269b49671f321b48d01--3dd0a62c1de44fb18f80464f5967882c <p>Having a truly hardware-efficient ansatz means that the entangling operation can be chosen according to each device's native interactions. Besides digital operations, in Qadence it is also possible to build digital-analog HEAs with the entanglement produced by the natural evolution of a set of interacting qubits, as natively implemented in neutral atom devices. As with other digital-analog functions, this can be controlled with the <code>strategy</code> argument which can be chosen from the <code>Strategy</code> enum type. Currently, only <code>Strategy.DIGITAL</code> and <code>Strategy.SDAQC</code> are available. By default, calling <code>strategy = Strategy.SDAQC</code> will use a global entangling Hamiltonian with Ising-like \\(NN\\) interactions and constant interaction strength,</p> <pre><code>from qadence import Strategy\n\nansatz = hea(\n    n_qubits,\n    depth=depth,\n    strategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_d83d17020d88431dab9d1fd07d737490 cluster_2d7600f903f64b4c8d6171183e498b4c f6f60c9f45d8428391983269f0f059e9 0 0442f9c096e7410e9584ba5e861c7b55 RX(theta\u2080) f6f60c9f45d8428391983269f0f059e9--0442f9c096e7410e9584ba5e861c7b55 ad45cbed5c6641279ebd32d6ce476f1b 1 edbd8f3fe0024ccd996db13e7d0ba490 RY(theta\u2083) 0442f9c096e7410e9584ba5e861c7b55--edbd8f3fe0024ccd996db13e7d0ba490 ac2f72b7e39c462bbf908a2da8892ebb RX(theta\u2086) edbd8f3fe0024ccd996db13e7d0ba490--ac2f72b7e39c462bbf908a2da8892ebb c4bd6af8b4174616b8ff2dccfe95c1c9 HamEvo ac2f72b7e39c462bbf908a2da8892ebb--c4bd6af8b4174616b8ff2dccfe95c1c9 f80b99c5438c43078d5ee4eda9161887 RX(theta\u2089) c4bd6af8b4174616b8ff2dccfe95c1c9--f80b99c5438c43078d5ee4eda9161887 741a15c4e0ca4c72b6160357282e7732 RY(theta\u2081\u2082) f80b99c5438c43078d5ee4eda9161887--741a15c4e0ca4c72b6160357282e7732 857de58e33b748cdb6e731ea14f5e0c6 RX(theta\u2081\u2085) 741a15c4e0ca4c72b6160357282e7732--857de58e33b748cdb6e731ea14f5e0c6 39311a50d5a940e896875e283899ff0b HamEvo 857de58e33b748cdb6e731ea14f5e0c6--39311a50d5a940e896875e283899ff0b 06582ed69c744597a107b4daaaaa3ac1 39311a50d5a940e896875e283899ff0b--06582ed69c744597a107b4daaaaa3ac1 004e1c457a264a548b43dd324e9ec04e da733b84ace9476898c2b857968c7d22 RX(theta\u2081) ad45cbed5c6641279ebd32d6ce476f1b--da733b84ace9476898c2b857968c7d22 f09a71ffd0864627ba79ef1d25869725 2 b7751870542a49d087ccb8eb05f73f14 RY(theta\u2084) da733b84ace9476898c2b857968c7d22--b7751870542a49d087ccb8eb05f73f14 cf54d96249fa4a4abe76830cce43ec27 RX(theta\u2087) b7751870542a49d087ccb8eb05f73f14--cf54d96249fa4a4abe76830cce43ec27 ee1e44dbaa074f69b8c19ad3faf304a4 t = theta_t\u2080 cf54d96249fa4a4abe76830cce43ec27--ee1e44dbaa074f69b8c19ad3faf304a4 fdd3bc2b973d456390cb9c15872b01af RX(theta\u2081\u2080) ee1e44dbaa074f69b8c19ad3faf304a4--fdd3bc2b973d456390cb9c15872b01af deb97473c03f4e39a8cd202ec97144a5 RY(theta\u2081\u2083) fdd3bc2b973d456390cb9c15872b01af--deb97473c03f4e39a8cd202ec97144a5 a2e0ecb23f034e34b23a5570ac92ab09 RX(theta\u2081\u2086) deb97473c03f4e39a8cd202ec97144a5--a2e0ecb23f034e34b23a5570ac92ab09 1bc75734625249f6b7cf1726c0fc9211 t = theta_t\u2081 a2e0ecb23f034e34b23a5570ac92ab09--1bc75734625249f6b7cf1726c0fc9211 1bc75734625249f6b7cf1726c0fc9211--004e1c457a264a548b43dd324e9ec04e 386fd1b6fca744ef96e513dd032d979f 1169990e79a14e2e954ac401fbe6cab4 RX(theta\u2082) f09a71ffd0864627ba79ef1d25869725--1169990e79a14e2e954ac401fbe6cab4 03089947560746f485b39bb192f1a9a9 RY(theta\u2085) 1169990e79a14e2e954ac401fbe6cab4--03089947560746f485b39bb192f1a9a9 d9aa5d311f174af08b431c7ebf39c99d RX(theta\u2088) 03089947560746f485b39bb192f1a9a9--d9aa5d311f174af08b431c7ebf39c99d e3a0175e880b49288ea11226858ef1aa d9aa5d311f174af08b431c7ebf39c99d--e3a0175e880b49288ea11226858ef1aa 3d3d8fbd23f441b1968e4388f7e38cf9 RX(theta\u2081\u2081) e3a0175e880b49288ea11226858ef1aa--3d3d8fbd23f441b1968e4388f7e38cf9 90ea48567f6242eaa9ce80a3e3d467dd RY(theta\u2081\u2084) 3d3d8fbd23f441b1968e4388f7e38cf9--90ea48567f6242eaa9ce80a3e3d467dd 227e54fb0c534858ab81c4738b5dda82 RX(theta\u2081\u2087) 90ea48567f6242eaa9ce80a3e3d467dd--227e54fb0c534858ab81c4738b5dda82 c8c3abe9adb7460d8d2a6b64dc4b708f 227e54fb0c534858ab81c4738b5dda82--c8c3abe9adb7460d8d2a6b64dc4b708f c8c3abe9adb7460d8d2a6b64dc4b708f--386fd1b6fca744ef96e513dd032d979f <p>Note that, by default, only the time-parameter is automatically parameterized when building a digital-analog HEA. However, as described in the Hamiltonians tutorial, arbitrary interaction Hamiltonians can be easily built with the <code>hamiltonian_factory</code> function, with both customized or fully parameterized interactions, and these can be directly passed as the <code>entangler</code> for a customizable digital-analog HEA.</p> <pre><code>from qadence import hamiltonian_factory, Interaction, N, Register, hea\n\n# Build a parameterized neutral-atom Hamiltonian following a honeycomb_lattice:\nregister = Register.honeycomb_lattice(1, 1)\n\nentangler = hamiltonian_factory(\n    register,\n    interaction=Interaction.NN,\n    detuning=N,\n    interaction_strength=\"e\",\n    detuning_strength=\"n\"\n)\n\n# Build a fully parameterized Digital-Analog HEA:\nn_qubits = register.n_qubits\ndepth = 2\n\nansatz = hea(\n    n_qubits=register.n_qubits,\n    depth=depth,\n    operations=[RX, RY, RX],\n    entangler=entangler,\n    strategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_87915b4bf15c4d68a739c02e7ba714bf cluster_4647ee04be084b0db96fb9b7139527b1 1cb46dcb60e547bfb0855ba5bb20a85f 0 cf5c84f4242b4ba98275235e5fec6ad0 RX(theta\u2080) 1cb46dcb60e547bfb0855ba5bb20a85f--cf5c84f4242b4ba98275235e5fec6ad0 57244bae1d2a48678a0e9ae9c5def047 1 81c998d57f714a34a06444d36feff183 RY(theta\u2086) cf5c84f4242b4ba98275235e5fec6ad0--81c998d57f714a34a06444d36feff183 c22972b53c974901b4198e741d2762f8 RX(theta\u2081\u2082) 81c998d57f714a34a06444d36feff183--c22972b53c974901b4198e741d2762f8 5b31111f24cb4221b23aefdf6d82bc6c c22972b53c974901b4198e741d2762f8--5b31111f24cb4221b23aefdf6d82bc6c dfcba9f8542440f1a336eaa812dd4f41 RX(theta\u2081\u2088) 5b31111f24cb4221b23aefdf6d82bc6c--dfcba9f8542440f1a336eaa812dd4f41 8f06bff96e5f4c1a85d479449d3a182c RY(theta\u2082\u2084) dfcba9f8542440f1a336eaa812dd4f41--8f06bff96e5f4c1a85d479449d3a182c 8106aea6138c441eb5e08b2eb0793127 RX(theta\u2083\u2080) 8f06bff96e5f4c1a85d479449d3a182c--8106aea6138c441eb5e08b2eb0793127 150ab4dbe0044b9791cba09f21a15a25 8106aea6138c441eb5e08b2eb0793127--150ab4dbe0044b9791cba09f21a15a25 95cca07a6a6b4a63a11fc5a5783a331d 150ab4dbe0044b9791cba09f21a15a25--95cca07a6a6b4a63a11fc5a5783a331d c52e69cf5e2d4918a23b975f8bb1fb5b 9524d5d862be4346a9ec1e63ed7f1bbc RX(theta\u2081) 57244bae1d2a48678a0e9ae9c5def047--9524d5d862be4346a9ec1e63ed7f1bbc 67a4ced3d82a4c7ba422ec4fe826fe6e 2 164d5bbe2bd142738a4fb8384e8e75ee RY(theta\u2087) 9524d5d862be4346a9ec1e63ed7f1bbc--164d5bbe2bd142738a4fb8384e8e75ee c99361560a8c4185b6053f95031d0793 RX(theta\u2081\u2083) 164d5bbe2bd142738a4fb8384e8e75ee--c99361560a8c4185b6053f95031d0793 8b86b68369f4444a9d92b3099b7f8033 c99361560a8c4185b6053f95031d0793--8b86b68369f4444a9d92b3099b7f8033 39c3d2d090d448168f132f301b74b266 RX(theta\u2081\u2089) 8b86b68369f4444a9d92b3099b7f8033--39c3d2d090d448168f132f301b74b266 8d8a912c4bf44219bacfa9af21508ba4 RY(theta\u2082\u2085) 39c3d2d090d448168f132f301b74b266--8d8a912c4bf44219bacfa9af21508ba4 42626198cbc945fca7651e2850c5c23a RX(theta\u2083\u2081) 8d8a912c4bf44219bacfa9af21508ba4--42626198cbc945fca7651e2850c5c23a 79fa8c28478c46c1af3d41966827a7d7 42626198cbc945fca7651e2850c5c23a--79fa8c28478c46c1af3d41966827a7d7 79fa8c28478c46c1af3d41966827a7d7--c52e69cf5e2d4918a23b975f8bb1fb5b 8e773a9d37d54ae6924cb78eca31def8 881e6264c25c4b00a957b94c482d5dcf RX(theta\u2082) 67a4ced3d82a4c7ba422ec4fe826fe6e--881e6264c25c4b00a957b94c482d5dcf 6b47175a025443c49d5f10b5dede801e 3 209d0bc273ca40efb484e28f1641b99b RY(theta\u2088) 881e6264c25c4b00a957b94c482d5dcf--209d0bc273ca40efb484e28f1641b99b 28508567b44349d3aff4360547bfe5c8 RX(theta\u2081\u2084) 209d0bc273ca40efb484e28f1641b99b--28508567b44349d3aff4360547bfe5c8 f3b6478637b74d848edc80542700bf18 HamEvo 28508567b44349d3aff4360547bfe5c8--f3b6478637b74d848edc80542700bf18 3771a76261e143de8682b16000ec51b1 RX(theta\u2082\u2080) f3b6478637b74d848edc80542700bf18--3771a76261e143de8682b16000ec51b1 d707ecee85ae49dcb1e1da3456e8b0c7 RY(theta\u2082\u2086) 3771a76261e143de8682b16000ec51b1--d707ecee85ae49dcb1e1da3456e8b0c7 d00fb94c1c3e46459ad7f22c1f0bf661 RX(theta\u2083\u2082) d707ecee85ae49dcb1e1da3456e8b0c7--d00fb94c1c3e46459ad7f22c1f0bf661 cf1c9e440a3248738e332da0983dc67c HamEvo d00fb94c1c3e46459ad7f22c1f0bf661--cf1c9e440a3248738e332da0983dc67c cf1c9e440a3248738e332da0983dc67c--8e773a9d37d54ae6924cb78eca31def8 8f156b26e4924178aefe64e58e599fe1 e517d3eeb3e14a4bbe5e1c4799107794 RX(theta\u2083) 6b47175a025443c49d5f10b5dede801e--e517d3eeb3e14a4bbe5e1c4799107794 4e11f45d739244f2bc2582f95008bc6b 4 cd6895b156594eef803dda5694475bb5 RY(theta\u2089) e517d3eeb3e14a4bbe5e1c4799107794--cd6895b156594eef803dda5694475bb5 155d03358b834cb7b0b6f0d8c298c3a2 RX(theta\u2081\u2085) cd6895b156594eef803dda5694475bb5--155d03358b834cb7b0b6f0d8c298c3a2 c1e9a2675ad74d04a2adb66eedf2da0f t = theta_t\u2080 155d03358b834cb7b0b6f0d8c298c3a2--c1e9a2675ad74d04a2adb66eedf2da0f 75730edf3adf4e86a4c1bac484ac7749 RX(theta\u2082\u2081) c1e9a2675ad74d04a2adb66eedf2da0f--75730edf3adf4e86a4c1bac484ac7749 eacd653cb57b48afb4cdada82605c09e RY(theta\u2082\u2087) 75730edf3adf4e86a4c1bac484ac7749--eacd653cb57b48afb4cdada82605c09e ce532d2a36f743a2b346619d9481c4ee RX(theta\u2083\u2083) eacd653cb57b48afb4cdada82605c09e--ce532d2a36f743a2b346619d9481c4ee c3c50ed6e430472392b9f152c165b0e2 t = theta_t\u2081 ce532d2a36f743a2b346619d9481c4ee--c3c50ed6e430472392b9f152c165b0e2 c3c50ed6e430472392b9f152c165b0e2--8f156b26e4924178aefe64e58e599fe1 14ea6f76874d44d7918b06c68689f3cb 2a46ff2fc62c4a259f4a288dbb39f477 RX(theta\u2084) 4e11f45d739244f2bc2582f95008bc6b--2a46ff2fc62c4a259f4a288dbb39f477 0434c28800c74a94b71491dadda9d499 5 fc31f57d2cd149c983956d00c0f5b773 RY(theta\u2081\u2080) 2a46ff2fc62c4a259f4a288dbb39f477--fc31f57d2cd149c983956d00c0f5b773 0fffdb83eb844cc8a55d8e3ee9c7e9c1 RX(theta\u2081\u2086) fc31f57d2cd149c983956d00c0f5b773--0fffdb83eb844cc8a55d8e3ee9c7e9c1 df94a66db46a4dafb9b8b9ebb5789023 0fffdb83eb844cc8a55d8e3ee9c7e9c1--df94a66db46a4dafb9b8b9ebb5789023 de2df7447abc42beb6895d6407e7a641 RX(theta\u2082\u2082) df94a66db46a4dafb9b8b9ebb5789023--de2df7447abc42beb6895d6407e7a641 9a65911af036450588cd85eec9c0febd RY(theta\u2082\u2088) de2df7447abc42beb6895d6407e7a641--9a65911af036450588cd85eec9c0febd 685a1158bdf845f9a82f2ef31c13da92 RX(theta\u2083\u2084) 9a65911af036450588cd85eec9c0febd--685a1158bdf845f9a82f2ef31c13da92 bf56f199e941438691e5e94120865153 685a1158bdf845f9a82f2ef31c13da92--bf56f199e941438691e5e94120865153 bf56f199e941438691e5e94120865153--14ea6f76874d44d7918b06c68689f3cb b7a01fd14c2a4946b530c2229e7d54f0 713cd581dc344747bbe7e34e906b91e5 RX(theta\u2085) 0434c28800c74a94b71491dadda9d499--713cd581dc344747bbe7e34e906b91e5 4c759d4c84d84dab87cacb9936893a45 RY(theta\u2081\u2081) 713cd581dc344747bbe7e34e906b91e5--4c759d4c84d84dab87cacb9936893a45 83358313fe114df1831640bf460a1649 RX(theta\u2081\u2087) 4c759d4c84d84dab87cacb9936893a45--83358313fe114df1831640bf460a1649 70c7d69ab8904dba8e9ca93c5e2ae1a4 83358313fe114df1831640bf460a1649--70c7d69ab8904dba8e9ca93c5e2ae1a4 ec5f7ca36bc54df6a921b41518e758ed RX(theta\u2082\u2083) 70c7d69ab8904dba8e9ca93c5e2ae1a4--ec5f7ca36bc54df6a921b41518e758ed 49f18e811d4b427a961a5dbb00c42a72 RY(theta\u2082\u2089) ec5f7ca36bc54df6a921b41518e758ed--49f18e811d4b427a961a5dbb00c42a72 f258c486de1049c3b5005d30b285eb64 RX(theta\u2083\u2085) 49f18e811d4b427a961a5dbb00c42a72--f258c486de1049c3b5005d30b285eb64 d0cbbe169c1b437a9a47a4ec24ef7aee f258c486de1049c3b5005d30b285eb64--d0cbbe169c1b437a9a47a4ec24ef7aee d0cbbe169c1b437a9a47a4ec24ef7aee--b7a01fd14c2a4946b530c2229e7d54f0"},{"location":"content/qml_constructors/#identity-initialized-ansatz","title":"Identity-initialized ansatz","text":"<p>It is widely known that parametrized quantum circuits are characterized by barren plateaus, where the gradient becomes exponentially small in the number of qubits. Here we include one of many techniques that have been proposed in recent years to mitigate this effect and facilitate <code>QNN</code>s training: Grant et al. showed that initializing the weights of a <code>QNN</code> so that each block of the circuit evaluates to identity reduces the effect of barren plateaus in the initial stage of training. In a similar fashion to <code>hea</code>, such circuit can be created via calling the associated function, <code>identity_initialized_ansatz</code>:</p> <pre><code>from qadence.constructors import identity_initialized_ansatz\nfrom qadence.draw import display\n\nn_qubits = 3\ndepth = 2\n\nansatz = identity_initialized_ansatz(n_qubits, depth)\n</code></pre> %3 cluster_2230b37ae654412fbd24118ba042e5dc BPMA-1 cluster_5979a327c7c2498bbfc1e90c69c9ab96 BPMA-0 1f237d0ceb03428bae4d2d9ea5ca758e 0 1d3916611f5847849d458a66012180c4 RX(iia_\u03b1\u2080\u2080) 1f237d0ceb03428bae4d2d9ea5ca758e--1d3916611f5847849d458a66012180c4 c887a45862244e189f27d486e32a97c6 1 247498cce4f543dc9062b08cff2e090f RY(iia_\u03b1\u2080\u2083) 1d3916611f5847849d458a66012180c4--247498cce4f543dc9062b08cff2e090f 4ca2878246f34c668c100b81104de29b 247498cce4f543dc9062b08cff2e090f--4ca2878246f34c668c100b81104de29b b4fe9d21906d4bb6badf664dc8f5b23e 4ca2878246f34c668c100b81104de29b--b4fe9d21906d4bb6badf664dc8f5b23e 9f48edd12b3e489c9a71b737864e52a4 RX(iia_\u03b3\u2080\u2080) b4fe9d21906d4bb6badf664dc8f5b23e--9f48edd12b3e489c9a71b737864e52a4 489fde47404a405996b1b96c0b376c86 9f48edd12b3e489c9a71b737864e52a4--489fde47404a405996b1b96c0b376c86 b3649dbc6207481f952c4fb1acc55523 489fde47404a405996b1b96c0b376c86--b3649dbc6207481f952c4fb1acc55523 550ae85b564344a796118e94a80e4ba0 RY(iia_\u03b2\u2080\u2083) b3649dbc6207481f952c4fb1acc55523--550ae85b564344a796118e94a80e4ba0 566a6db3fd654f71ac0d01e154f876d8 RX(iia_\u03b2\u2080\u2080) 550ae85b564344a796118e94a80e4ba0--566a6db3fd654f71ac0d01e154f876d8 eef295e7c1da49e29f173a11f638073e RX(iia_\u03b1\u2081\u2080) 566a6db3fd654f71ac0d01e154f876d8--eef295e7c1da49e29f173a11f638073e ae566b40bbb34bf7a724aee67b8da3c1 RY(iia_\u03b1\u2081\u2083) eef295e7c1da49e29f173a11f638073e--ae566b40bbb34bf7a724aee67b8da3c1 9fe4c28829064d10830b86ff47ba316f ae566b40bbb34bf7a724aee67b8da3c1--9fe4c28829064d10830b86ff47ba316f 891563fc11ca47f78453f0de97e803ea 9fe4c28829064d10830b86ff47ba316f--891563fc11ca47f78453f0de97e803ea 2db7890cc7d04bd0afb7133327a6c67e RX(iia_\u03b3\u2081\u2080) 891563fc11ca47f78453f0de97e803ea--2db7890cc7d04bd0afb7133327a6c67e b663ada7c812419984d4758310febd02 2db7890cc7d04bd0afb7133327a6c67e--b663ada7c812419984d4758310febd02 2a049c311ab542b3970f31b1687d22d8 b663ada7c812419984d4758310febd02--2a049c311ab542b3970f31b1687d22d8 1bd3581017a1470cac2772f8fed686ac RY(iia_\u03b2\u2081\u2083) 2a049c311ab542b3970f31b1687d22d8--1bd3581017a1470cac2772f8fed686ac 6330fc732e904c18ab0b5864f347168b RX(iia_\u03b2\u2081\u2080) 1bd3581017a1470cac2772f8fed686ac--6330fc732e904c18ab0b5864f347168b e2229a5d605744adb11d13bbe962e1f9 6330fc732e904c18ab0b5864f347168b--e2229a5d605744adb11d13bbe962e1f9 c94f60b79c6a40c9b3eef82534606ecb 72c4663dc5574e1eba03fc01a1abf549 RX(iia_\u03b1\u2080\u2081) c887a45862244e189f27d486e32a97c6--72c4663dc5574e1eba03fc01a1abf549 327b2bf18b0849358327ea10389bf590 2 e671181b5834496a953d568feaf514c8 RY(iia_\u03b1\u2080\u2084) 72c4663dc5574e1eba03fc01a1abf549--e671181b5834496a953d568feaf514c8 5de5e580fd614079ae65de55037650fb X e671181b5834496a953d568feaf514c8--5de5e580fd614079ae65de55037650fb 5de5e580fd614079ae65de55037650fb--4ca2878246f34c668c100b81104de29b 4490510c4f034b87bb54267a64887745 5de5e580fd614079ae65de55037650fb--4490510c4f034b87bb54267a64887745 9f7f88513330479993965de8a5afa338 RX(iia_\u03b3\u2080\u2081) 4490510c4f034b87bb54267a64887745--9f7f88513330479993965de8a5afa338 8dbd9d438a3a43ce8c0ce21ebfd92130 9f7f88513330479993965de8a5afa338--8dbd9d438a3a43ce8c0ce21ebfd92130 44d6b40d8f2241c3bb4849a5dca291c2 X 8dbd9d438a3a43ce8c0ce21ebfd92130--44d6b40d8f2241c3bb4849a5dca291c2 44d6b40d8f2241c3bb4849a5dca291c2--b3649dbc6207481f952c4fb1acc55523 4887e77a5cb544aab9530edfc100bafb RY(iia_\u03b2\u2080\u2084) 44d6b40d8f2241c3bb4849a5dca291c2--4887e77a5cb544aab9530edfc100bafb e721822c0c9c4796a1f6ba529dde79e9 RX(iia_\u03b2\u2080\u2081) 4887e77a5cb544aab9530edfc100bafb--e721822c0c9c4796a1f6ba529dde79e9 e641d9739f95499693460a09aafd4b1c RX(iia_\u03b1\u2081\u2081) e721822c0c9c4796a1f6ba529dde79e9--e641d9739f95499693460a09aafd4b1c 3bf69dba2f5848a18f1050dbec2a40e3 RY(iia_\u03b1\u2081\u2084) e641d9739f95499693460a09aafd4b1c--3bf69dba2f5848a18f1050dbec2a40e3 f76936a6998740778ea4eaed73105299 X 3bf69dba2f5848a18f1050dbec2a40e3--f76936a6998740778ea4eaed73105299 f76936a6998740778ea4eaed73105299--9fe4c28829064d10830b86ff47ba316f 02677acb320c4daea61ba68a5397ecca f76936a6998740778ea4eaed73105299--02677acb320c4daea61ba68a5397ecca e29ce84c219948668f50470ef38cd883 RX(iia_\u03b3\u2081\u2081) 02677acb320c4daea61ba68a5397ecca--e29ce84c219948668f50470ef38cd883 e095075c32024766b2e1c7e677b9a92c e29ce84c219948668f50470ef38cd883--e095075c32024766b2e1c7e677b9a92c f866046b438143ae81b369990ab0dc1a X e095075c32024766b2e1c7e677b9a92c--f866046b438143ae81b369990ab0dc1a f866046b438143ae81b369990ab0dc1a--2a049c311ab542b3970f31b1687d22d8 532b46d5a1dd40278308fd5ee874c840 RY(iia_\u03b2\u2081\u2084) f866046b438143ae81b369990ab0dc1a--532b46d5a1dd40278308fd5ee874c840 d7de53e0310e41f98582966208d59b10 RX(iia_\u03b2\u2081\u2081) 532b46d5a1dd40278308fd5ee874c840--d7de53e0310e41f98582966208d59b10 d7de53e0310e41f98582966208d59b10--c94f60b79c6a40c9b3eef82534606ecb d9166cdcac404bbf97e98c6ef35c1bc0 efa44d4eab46493084307daebfa0626d RX(iia_\u03b1\u2080\u2082) 327b2bf18b0849358327ea10389bf590--efa44d4eab46493084307daebfa0626d 81984ce5564e4f51918d65193a162f30 RY(iia_\u03b1\u2080\u2085) efa44d4eab46493084307daebfa0626d--81984ce5564e4f51918d65193a162f30 e2ad4e20fda64a4ea972ffe57556ad0c 81984ce5564e4f51918d65193a162f30--e2ad4e20fda64a4ea972ffe57556ad0c b65364d5fd0c4c31a6cc25ec08f4cf85 X e2ad4e20fda64a4ea972ffe57556ad0c--b65364d5fd0c4c31a6cc25ec08f4cf85 b65364d5fd0c4c31a6cc25ec08f4cf85--4490510c4f034b87bb54267a64887745 af55b431b39643d0803da553efafdedd RX(iia_\u03b3\u2080\u2082) b65364d5fd0c4c31a6cc25ec08f4cf85--af55b431b39643d0803da553efafdedd b00b30521192489492e12f85e4946694 X af55b431b39643d0803da553efafdedd--b00b30521192489492e12f85e4946694 b00b30521192489492e12f85e4946694--8dbd9d438a3a43ce8c0ce21ebfd92130 d0459feed0bd4617817a7ed5a22bed41 b00b30521192489492e12f85e4946694--d0459feed0bd4617817a7ed5a22bed41 be9beb3b44d24007804a298555f3a4bd RY(iia_\u03b2\u2080\u2085) d0459feed0bd4617817a7ed5a22bed41--be9beb3b44d24007804a298555f3a4bd 4c72ba7380fc401d816bc73aff07f104 RX(iia_\u03b2\u2080\u2082) be9beb3b44d24007804a298555f3a4bd--4c72ba7380fc401d816bc73aff07f104 6de7387212e6407b99720b8d4cddf6bf RX(iia_\u03b1\u2081\u2082) 4c72ba7380fc401d816bc73aff07f104--6de7387212e6407b99720b8d4cddf6bf 60a393b74e164da3b15af783356c8861 RY(iia_\u03b1\u2081\u2085) 6de7387212e6407b99720b8d4cddf6bf--60a393b74e164da3b15af783356c8861 2a8cf302b75944149726f4db9dd40ac4 60a393b74e164da3b15af783356c8861--2a8cf302b75944149726f4db9dd40ac4 fd84af6ecf354189a42b6e73aa284084 X 2a8cf302b75944149726f4db9dd40ac4--fd84af6ecf354189a42b6e73aa284084 fd84af6ecf354189a42b6e73aa284084--02677acb320c4daea61ba68a5397ecca cb2bb28f2c8f4e2c89cb9d2e2f0bbce9 RX(iia_\u03b3\u2081\u2082) fd84af6ecf354189a42b6e73aa284084--cb2bb28f2c8f4e2c89cb9d2e2f0bbce9 3c0880bc535645fea9bbdf3ac7266746 X cb2bb28f2c8f4e2c89cb9d2e2f0bbce9--3c0880bc535645fea9bbdf3ac7266746 3c0880bc535645fea9bbdf3ac7266746--e095075c32024766b2e1c7e677b9a92c 839846042b774371bd6e8c01db2aef45 3c0880bc535645fea9bbdf3ac7266746--839846042b774371bd6e8c01db2aef45 fbaa47965283428b8d9db9e37c9dc3f0 RY(iia_\u03b2\u2081\u2085) 839846042b774371bd6e8c01db2aef45--fbaa47965283428b8d9db9e37c9dc3f0 e662d985593845ad908805aada3cb539 RX(iia_\u03b2\u2081\u2082) fbaa47965283428b8d9db9e37c9dc3f0--e662d985593845ad908805aada3cb539 e662d985593845ad908805aada3cb539--d9166cdcac404bbf97e98c6ef35c1bc0"},{"location":"content/quantummodels/","title":"Quantum models","text":"<p>A quantum program can be expressed and executed using the <code>QuantumModel</code> type. It serves three primary purposes:</p> <p>Parameter handling: by conveniently handling and embedding the two parameter types that Qadence supports: feature and variational (see more details in the previous section).</p> <p>Differentiability: by enabling a differentiable backend that supports two differentiable modes: automatic differentiation (AD) and parameter shift rules (PSR). The former is used general differentiation in statevector simulators based on PyTorch and JAX. The latter is a quantum specific method used to differentiate gate parameters, and is enabled for all backends.</p> <p>Execution: by defining which backend the program is expected to be executed on. Qadence supports circuit compilation to the native backend representation.</p> <p>Backends</p> <p>The goal is for quantum models to be executed seemlessly on a number of different purpose backends: simulators, emulators or real hardware. By default, Qadence executes on the PyQTorch backend which implements a state vector simulator. Currently, this is the most feature rich backend. The Pulser backend is being developed, and currently supports a more limited set of functionalities (pulse sequences on programmable neutral atom arrays). The Horqrux backend, built on JAX, is also available, but currently not supported with the <code>QuantumModel</code> interface. For more information see the backend section.</p> <p>The base <code>QuantumModel</code> exposes the following methods:</p> <ul> <li><code>QuantumModel.run()</code>: To extract the wavefunction after circuit execution. Not supported by all backends.</li> <li><code>QuantumModel.sample()</code>: Sample a bitstring from the resulting quantum state after circuit execution. Supported by all backends.</li> <li><code>QuantumModel.expectation()</code>: Compute the expectation value of an observable.</li> </ul> <p>Every <code>QuantumModel</code> is an instance of a <code>torch.nn.Module</code> that enables differentiability for its <code>expectation</code> method. For statevector simulators, AD also works for the statevector itself.</p> <p>To construct a <code>QuantumModel</code>, the program block must first be initialized into a <code>QuantumCircuit</code> instance by combining it with a <code>Register</code>. An integer number can also be passed for the total number of qubits, which instantiates a <code>Register</code> automatically. The qubit register also includes topological information on the qubit layout, essential for digital-analog computations. However, we will explore that in a later tutorial. For now, let's construct a simple parametrized quantum circuit.</p> <pre><code>from qadence import QuantumCircuit, RX, RY, chain, kron\nfrom qadence import FeatureParameter, VariationalParameter\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, theta), RY(1, theta)),\n    kron(RX(0, phi), RY(1, phi)),\n)\n\ncircuit = QuantumCircuit(2, block)\nunique_params = circuit.unique_parameters\n</code></pre> <pre><code>unique_params = [theta, phi]\n</code></pre> <p>The model can then be instantiated. Similarly to the direct execution functions shown in the previous tutorial, the <code>run</code>, <code>sample</code> and <code>expectation</code> methods are available directly from the model.</p> <pre><code>import torch\nfrom qadence import QuantumModel, PI, Z\n\nobservable = Z(0) + Z(1)\n\nmodel = QuantumModel(circuit, observable)\n\nvalues = {\"phi\": torch.tensor([PI, PI/2])}\n\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\n</code></pre> <pre><code>wf = tensor([[ 0.0560+0.0000j, -0.2299+0.0000j,  0.0000+0.2299j,  0.0000-0.9440j],\n        [ 0.2701+0.0000j,  0.4440+0.0000j,  0.0000-0.4440j,  0.0000-0.7299j]])\nxs = [OrderedCounter({'11': 84, '10': 8, '01': 7, '00': 1}), OrderedCounter({'11': 51, '10': 26, '01': 21, '00': 2})]\nex = tensor([[-1.7760],\n        [-0.9198]])\n</code></pre> <p>By default, the <code>forward</code> method of <code>QuantumModel</code> calls <code>model.run()</code>. To define custom quantum models, the best way is to inherit from <code>QuantumModel</code> and override the <code>forward</code> method, as typically done with custom PyTorch Modules.</p> <p>The <code>QuantumModel</code> class provides convenience methods to manipulate parameters. Being a <code>torch.nn.Module</code>, all torch methods are also available. As shown in the example below, you can pass, check and reset the model parameters. When entering new values for the <code>VariationalParameter</code>, they must match the number of existing variables.</p> <pre><code># To pass onto a torch optimizer\nparameter_generator = model.parameters()\n\n# Number of variational parameters\nnum_vparams = model.num_vparams\n\n# Dictionary to see all the parameter values\nparams_values = model.params\n\n# Dictionary to easily inspect variational parameters (parameters with gradient)\nvparams_values = model.vparams\n\n\n# To reset current variational parameter to other values\nmodel.reset_vparams([torch.rand(1).item()])\n\nvparams_values = model.vparams\n</code></pre> <pre><code>old vparams_values = OrderedDict([('theta', tensor([0.4779]))])\nnew vparams_values = OrderedDict([('theta', tensor([0.3384]))])\n</code></pre>"},{"location":"content/quantummodels/#backend-configuration-in-quantum-models","title":"Backend configuration in quantum models","text":"<p>When initializing a quantum model, available configuration options are determined by the backend, with current support for <code>PyQTorch</code> and <code>Pulser</code>. Information on each configuration option can be found with <code>model.show_config</code> as in below example:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, RX, RY, kron\nfrom qadence import FeatureParameter, VariationalParameter\nfrom qadence import BackendConfiguration\nfrom qadence import BackendName, DiffMode\n\n# Create a quantum circuit\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\nblock = kron(RX(0, theta), RY(1, phi))\ncircuit = QuantumCircuit(2, block)\n\n# Choose your backend (PYQTORCH or PULSER)\nbackend=BackendName.PYQTORCH\n# backend=BackendName.PULSER\n\nmodel = QuantumModel(circuit, backend=backend, diff_mode=DiffMode.GPSR)\n# Check your available configuration options and current values\n</code></pre> <pre><code>Name: use_sparse_observable - Type: bool - Current value: False - Default value: False\nName: use_gradient_checkpointing - Type: bool - Current value: False - Default value: False\nName: use_single_qubit_composition - Type: bool - Current value: True - Default value: False\nName: transpilation_passes - Type: list[Callable] | None - Current value: None - Default value: None\nName: algo_hevo - Type: AlgoHEvo - Current value: EXP - Default value: EXP\nName: ode_solver - Type: SolverType - Current value: dp5_se - Default value: dp5_se\nName: n_steps_hevo - Type: int - Current value: 100 - Default value: 100\nName: loop_expectation - Type: bool - Current value: False - Default value: False\nName: noise - Type: NoiseHandler | None - Current value: None - Default value: None\nName: dropout_probability - Type: float - Current value: 0.0 - Default value: 0.0\nName: dropout_mode - Type: DropoutMode - Current value: rotational_dropout - Default value: rotational_dropout\nName: n_eqs - Type: int | None - Current value: None - Default value: None\nName: shift_prefac - Type: float - Current value: 0.5 - Default value: 0.5\nName: gap_step - Type: float - Current value: 1.0 - Default value: 1.0\nName: lb - Type: float | None - Current value: None - Default value: None\nName: ub - Type: float | None - Current value: None - Default value: None\n</code></pre> <p>The configuration of the quantum model can be changed by passing <code>options_names</code> and <code>value</code> in dictionary format. You can update the existing configuration values using <code>model.change_config()</code>.</p> <pre><code># change dropout_probability from 0 to 0.3\nmodel.change_config({\"dropout_probability\": 0.3})\n# shows modified configuration\n</code></pre> <pre><code>Name: use_sparse_observable - Type: bool - Current value: False - Default value: False\nName: use_gradient_checkpointing - Type: bool - Current value: False - Default value: False\nName: use_single_qubit_composition - Type: bool - Current value: True - Default value: False\nName: transpilation_passes - Type: list[Callable] | None - Current value: None - Default value: None\nName: algo_hevo - Type: AlgoHEvo - Current value: EXP - Default value: EXP\nName: ode_solver - Type: SolverType - Current value: dp5_se - Default value: dp5_se\nName: n_steps_hevo - Type: int - Current value: 100 - Default value: 100\nName: loop_expectation - Type: bool - Current value: False - Default value: False\nName: noise - Type: NoiseHandler | None - Current value: None - Default value: None\nName: dropout_probability - Type: float - Current value: 0.3 - Default value: 0.0\nName: dropout_mode - Type: DropoutMode - Current value: rotational_dropout - Default value: rotational_dropout\nName: n_eqs - Type: int | None - Current value: None - Default value: None\nName: shift_prefac - Type: float - Current value: 0.5 - Default value: 0.5\nName: gap_step - Type: float - Current value: 1.0 - Default value: 1.0\nName: lb - Type: float | None - Current value: None - Default value: None\nName: ub - Type: float | None - Current value: None - Default value: None\n</code></pre>"},{"location":"content/quantummodels/#model-output","title":"Model output","text":"<p>The output of a quantum model is typically encoded in the measurement of an expectation value. In Qadence, one way to customize the number of outputs is by batching the number of observables at model creation by passing a list of blocks.</p> <pre><code>from torch import tensor\nfrom qadence import chain, kron, VariationalParameter, FeatureParameter\nfrom qadence import QuantumModel, QuantumCircuit, PI, Z, RX, CNOT\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, phi), RX(1, phi)),\n    CNOT(0, 1)\n)\n\ncircuit = QuantumCircuit(2, block)\n\nmodel = QuantumModel(circuit, [Z(0), Z(0) + Z(1)])\n\nvalues = {\"phi\": tensor(PI)}\n\nex = model.expectation(values)\n</code></pre> <pre><code>ex = tensor([[-1.0000e+00, -7.4988e-33]])\n</code></pre> <p>As mentioned in the previous tutorial, blocks can also be arbitrarily parameterized through multiplication, which allows the inclusion of trainable parameters in the definition of the observable.</p> <pre><code>from qadence import I, Z\n\na = VariationalParameter(\"a\")\nb = VariationalParameter(\"b\")\n\n# Magnetization with a trainable shift and scale\nobservable = a * I(0) + b * Z(0)\n\nmodel = QuantumModel(circuit, observable)\n</code></pre>"},{"location":"content/quantummodels/#quantum-neural-network-qnn","title":"Quantum Neural Network (QNN)","text":"<p>The <code>QNN</code> is a subclass of the <code>QuantumModel</code> geared towards quantum machine learning and parameter optimisation. See the quantum machine learning section section or the <code>QNN</code> API reference for more detailed information. There are three main differences in interface when compared with the <code>QuantumModel</code>:</p> <ul> <li>It is initialized with a list of the input parameter names, and then supports direct <code>torch.Tensor</code> inputs instead of the values dictionary shown above. The ordering of the input values should respect the order given in the input names.</li> <li>Passing an observable is mandatory.</li> <li>The <code>forward</code> method calls <code>model.expectation()</code>.</li> </ul> <pre><code>from torch import tensor\nfrom qadence import chain, kron, VariationalParameter, FeatureParameter\nfrom qadence import QNN, QuantumCircuit, PI, Z, RX, RY, CNOT\n\ntheta = FeatureParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, phi), RX(1, phi)),\n    kron(RY(0, theta), RY(1, theta)),\n    CNOT(0, 1)\n)\n\ncircuit = QuantumCircuit(2, block)\nobservable = Z(0) + Z(1)\n\nmodel = QNN(circuit, observable, inputs = [\"phi\", \"theta\"])\n\n# \"phi\" = PI, PI/2, \"theta\" = 0.0, 1.0\nvalues = tensor([[PI, 0.0], [PI/2, 1.0]])\n\nex = model(values)\n</code></pre> <pre><code>ex = tensor([[-7.4988e-33],\n        [ 1.1102e-16]])\n</code></pre>"},{"location":"content/register/","title":"Quantum registers","text":"<p>In Qadence, quantum programs can be executed by specifying the layout of a register of resources as a lattice. Built-in <code>Register</code> types can be used or constructed for arbitrary topologies. Common register topologies are available and illustrated in the plot below.</p> 2025-05-12T10:16:59.018311 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"content/register/#building-and-drawing-registers","title":"Building and drawing registers","text":"<p>Built-in topologies are directly accessible in the <code>Register</code> methods:</p> <pre><code>from qadence import Register\n\nreg = Register.all_to_all(n_qubits = 4)\nreg_line = Register.line(n_qubits = 4)\nreg_circle = Register.circle(n_qubits = 4)\nreg_squre = Register.square(qubits_side = 2)\nreg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\nreg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\nreg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n</code></pre> <p>The <code>Register</code> class builds on top of the NetworkX <code>Graph</code>, and the graphs can be visualized with the <code>reg.draw()</code> method</p> <p>Qubit coordinates are saved as node properties in the underlying NetworkX graph, but can be accessed directly with the <code>coords</code> property.</p> <p><pre><code>reg = Register.square(2)\nprint(reg.coords)\n</code></pre> <pre><code>{0: (0.5, -0.5), 1: (0.5, 0.5), 2: (-0.5, 0.5), 3: (-0.5, -0.5)}\n</code></pre>  By default, the coords are scaled such that the minimum distance between any two qubits is 1, unless the register is created directly from specific coordinates as shown below. The <code>spacing</code> argument can be used to set the minimum spacing. The <code>rescale_coords</code> method can be used to create a new register by rescaling the coordinates of an already created register.</p> <pre><code>scaled_reg_1 = Register.square(2, spacing = 4.0)\nscaled_reg_2 = reg.rescale_coords(scaling = 4.0)\nprint(scaled_reg_1.coords)\nprint(scaled_reg_2.coords)\n</code></pre> <pre><code>{0: (2.0, -2.0), 1: (2.0, 2.0), 2: (-2.0, 2.0), 3: (-2.0, -2.0)}\n{0: (2.0, -2.0), 1: (2.0, 2.0), 2: (-2.0, 2.0), 3: (-2.0, -2.0)}\n</code></pre> <p>The distance between qubits can also be directly accessed with the <code>distances</code> and <code>edge_distances</code> properties.</p> <pre><code>print(reg.distances)\nprint(reg.edge_distances)\n</code></pre> <pre><code>Distance between all qubit pairs:\n{(0, 1): 1.0, (0, 2): 1.4142135623730951, (0, 3): 1.0, (1, 2): 1.0, (1, 3): 1.4142135623730951, (2, 3): 1.0}\nDistance between qubits connect by an edge in the graph\n{(0, 1): 1.0, (0, 3): 1.0, (1, 2): 1.0, (2, 3): 1.0}\n</code></pre> <p>By calling the <code>Register</code> directly, either the number of nodes or a specific graph can be given as input. If passing a custom graph directly, the node positions will not be defined automatically, and should be previously saved in the <code>\"pos\"</code> node property. If not, <code>reg.coords</code> will return empty tuples and all distances will be 0.</p> <pre><code>import networkx as nx\n\n# Same as Register.all_to_all(n_qubits = 2):\nreg = Register(2)\n\n# Register from a custom graph:\ngraph = nx.complete_graph(3)\n\n# Set node positions, in this case a simple line:\nfor i, node in enumerate(graph.nodes):\n    graph.nodes[node][\"pos\"] = (1.0 * i, 0.0)\n\nreg = Register(graph)\n\nprint(reg.distances)\n</code></pre> <pre><code>{(0, 1): 1.0, (0, 2): 2.0, (1, 2): 1.0}\n</code></pre> <p>Alternatively, arbitrarily shaped registers can also be constructed by providing the node coordinates. In this case, there will be no edges automatically created in the connectivity graph.</p> <pre><code>import numpy as np\nfrom qadence import Register, PI\n\nreg = Register.from_coordinates(\n    [(x, np.sin(x)) for x in np.linspace(0, 2*PI, 10)]\n)\n\nreg.draw(show=False)\n</code></pre> 2025-05-12T10:16:59.229052 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>Units for qubit coordinates</p> <p>In general, Qadence makes no assumption about the units for qubit coordinates and distances. However, if used in the context of a Hamiltonian coefficient, care should be taken by the user to guarantee the quantity \\(H.t\\) is dimensionless for exponentiation in the PyQTorch backend, where it is assumed that \\(\\hbar = 1\\). For registers passed to the Pulser backend, coordinates are in \\(\\mu \\textrm{m}\\).</p>"},{"location":"content/register/#connectivity-graphs","title":"Connectivity graphs","text":"<p>Register topology is often assumed in digital simulations to be an all-to-all qubit connectivity. When running on real devices that enable the digital-analog computing paradigm, qubit interactions must be specified either by specifying distances between qubits, or by defining edges in the register connectivity graph.</p> <p>The abstract graph nodes and edges are accessible for direct usage.</p> <pre><code>from qadence import Register\n\nreg = Register.rectangular_lattice(2,3)\n</code></pre> <pre><code>reg.nodes = NodeView((0, 1, 2, 3, 4, 5))\nreg.edges = EdgeView([(0, 2), (0, 1), (1, 3), (2, 4), (2, 3), (3, 5), (4, 5)])\n</code></pre> <p>There is also an <code>all_node_pairs</code> property for convenience:</p> <pre><code>print(reg.all_node_pairs)\n</code></pre> <pre><code>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)]\n</code></pre> <p>More details about the usage of <code>Register</code> types in the digital-analog paradigm can be found in the digital-analog basics section.</p>"},{"location":"content/serializ_and_prep/","title":"Serialization","text":"<p>Qadence offers convenience functions for serializing and deserializing any quantum program. This is useful for storing quantum programs and sending them for execution over the network via an API.</p> <p>Note</p> <p>Qadence currently uses a custom JSON serialization as interchange format. Support for QASM format for digital quantum programs is currently under consideration.</p> <ul> <li><code>serialize/deserialize</code>: serialize and deserialize a Qadence object into a dictionary</li> <li><code>save/load</code>: save and load a Qadence object to a file with one of the supported   formats. Currently, these are <code>.json</code> and the PyTorch-compatible <code>.pt</code> format.</li> </ul> <p>Let's start with serialization into a dictionary.</p> <pre><code>import torch\nfrom qadence import QuantumCircuit, QuantumModel, DiffMode\nfrom qadence import chain, hamiltonian_factory, feature_map, hea, Z\nfrom qadence.serialization import serialize, deserialize\n\nn_qubits = 4\n\nmy_block = chain(feature_map(n_qubits, param=\"x\"), hea(n_qubits, depth=2))\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n\n# Use the block defined above to create a quantum circuit\n# serialize/deserialize it\nqc = QuantumCircuit(n_qubits, my_block)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n# Let's wrap it in a QuantumModel\n# and serialize it\nqm = QuantumModel(qc, obs, diff_mode=DiffMode.AD)\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n\n# Check if the loaded QuantumModel returns the same expectation\nvalues = {\"x\": torch.rand(10)}\nassert torch.allclose(qm.expectation(values=values), qm_deserialized.expectation(values=values))\n</code></pre> <p>Finally, we can save the quantum circuit and the model with the two supported formats.</p> <pre><code>from qadence.serialization import serialize, deserialize, save, load, SerializationFormat\n\nqc_fname = \"circuit\"\nsave(qc, folder=\".\", file_name=qc_fname, format=SerializationFormat.PT)\nloaded_qc = load(f\"{qc_fname}.pt\")\nassert qc == loaded_qc\n\nqm_fname = \"model\"\nsave(qm, folder=\".\", file_name=qm_fname, format=SerializationFormat.JSON)\nmodel = load(f\"{qm_fname}.json\")\nassert isinstance(model, QuantumModel)\n</code></pre>"},{"location":"content/state_conventions/","title":"State Conventions","text":"<p>Here is an overview of the state conventions used in Qadence together with practical examples.</p>"},{"location":"content/state_conventions/#qubit-register-order","title":"Qubit register order","text":"<p>Qubit registers in quantum computing are often indexed in increasing or decreasing order from left to right. In Qadence, the convention is qubit indexation in increasing order. For example, a register of four qubits in bra-ket notation reads:</p> \\[|q_0, q_1, q_2, q_3\\rangle\\] <p>Furthermore, when displaying a quantum circuit, qubits are ordered from top to bottom.</p>"},{"location":"content/state_conventions/#basis-state-order","title":"Basis state order","text":"<p>Basis state ordering refers to how basis states are ordered when considering the conversion from bra-ket notation to the standard linear algebra basis. In Qadence, basis states are ordered in the following manner:</p> \\[ \\begin{align} |00\\rangle = [1, 0, 0, 0]^T\\\\ |01\\rangle = [0, 1, 0, 0]^T\\\\ |10\\rangle = [0, 0, 1, 0]^T\\\\ |11\\rangle = [0, 0, 0, 1]^T \\end{align} \\]"},{"location":"content/state_conventions/#endianness","title":"Endianness","text":"<p>Endianness refers to the storage convention for binary information (in bytes) in a classical memory register. In quantum computing, information is either stored in bits or in qubits. The most commonly used conventions are:</p> <ul> <li>A big-endian system stores the most significant bit of a binary word at the smallest memory address.</li> <li>A little-endian system stores the least significant bit of a binary word at the smallest memory address.</li> </ul> <p>Given the register convention in Qadence, the integer \\(2\\) written in binary big-endian as \\(10\\) can be encoded in a qubit register in both big-endian as \\(|10\\rangle\\) or little-endian as \\(|01\\rangle\\).</p> <p>The convention for Qadence is big-endian.</p>"},{"location":"content/state_conventions/#quantum-states","title":"Quantum states","text":"<p>In practical scenarios, conventions regarding register order, basis state order and endianness are very much intertwined, and identical results can be obtained by fixing or varying any of them. In Qadence, we assume that qubit ordering and basis state ordering is fixed, and allow an <code>endianness</code> argument that can be passed to control the expected result. Here are a few examples:</p> <p>A simple and direct way to exemplify the endianness convention is using convenience functions for state preparation.</p> <p>Bitstring convention as inputs</p> <p>When a bitstring is passed as input to a function for state preparation, it has to be understood in big-endian convention.</p> <pre><code>from qadence import Endianness, product_state\n\n# The state |10&gt;, the 3rd basis state.\nstate_big = product_state(\"10\", endianness=Endianness.BIG) # or just \"Big\"\n\n# The state |01&gt;, the 2nd basis state.\nstate_little = product_state(\"10\", endianness=Endianness.LITTLE) # or just \"Little\"\n</code></pre> <pre><code>State in big endian = tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\nState in little endian = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Here, a bitword expressed as a Python string to encode the integer 2 in big-endian is used to create the respective basis state in both conventions. However, note that the same results can be obtained by fixing the endianness convention as big-endian (thus creating the state \\(|10\\rangle\\) in both cases), and changing the basis state ordering. A similar argument holds for fixing both endianness and basis state ordering and simply changing the qubit index order.</p> <p>Another example where endianness directly comes into play is when measuring a register. A big- or little-endian measurement will choose the first or the last qubit, respectively, as the most significant bit. Let's see this in an example:</p> <pre><code>from qadence import I, H, sample\n\n# Create superposition state: |00&gt; + |01&gt; (normalized)\nblock = I(0) @ H(1)  # Identity on qubit 0, Hadamard on qubit 1\n\n# Generate bitword samples following both conventions\n# Samples \"00\" and \"01\"\nresult_big = sample(block, endianness=Endianness.BIG)\n# Samples \"00\" and \"10\"\nresult_little = sample(block, endianness=Endianness.LITTLE)\n</code></pre> <pre><code>Sample in big endian = [OrderedCounter({'01': 52, '00': 48})]\nSample in little endian = [Counter({'10': 52, '00': 48})]\n</code></pre> <p>In Qadence, endianness can be flipped for many relevant objects:</p> <pre><code>from qadence import invert_endianness\n\n# Equivalent to sampling in little-endian.\nflip_big_sample = invert_endianness(result_big)\n\n# Equivalent to a state created in little-endian.\nflip_big_state = invert_endianness(state_big)\n</code></pre> <pre><code>Flipped sample = [Counter({'10': 52, '00': 48})]\nFlipped state = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"content/state_conventions/#quantum-operations","title":"Quantum operations","text":"<p>When looking at the matricial form of quantum operations, the usage of the term endianness becomes slightly abusive. To exemplify, we may consider the <code>CNOT</code> operation with <code>control = 0</code> and <code>target = 1</code>. This operation is often described with two different matrices:</p> \\[ \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} \\qquad \\text{or} \\qquad \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] <p>The difference can be easily explained either by considering a different ordering of the qubit indices, or a different ordering of the basis states. In Qadence, both can be retrieved through the <code>endianness</code> argument:</p> <pre><code>from qadence import block_to_tensor, CNOT\n\nmatrix_big = block_to_tensor(CNOT(0, 1), endianness=Endianness.BIG)\nmatrix_little = block_to_tensor(CNOT(0, 1), endianness=Endianness.LITTLE)\n</code></pre> <pre><code>CNOT matrix in big endian =\n\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\n\nCNOT matrix in little endian =\n\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre>"},{"location":"content/state_conventions/#backends","title":"Backends","text":"<p>An important part of having clear state conventions is that we need to make sure our results are consistent accross different computational backends, which may have their own conventions. In Qadence, this is taken care of automatically: by calling operations for different backends, the result is expected to be equivalent up to qubit ordering.</p> <pre><code>from qadence import BackendName, RX, run, sample, PI\n\n# RX(PI/4) on qubit 1\nn_qubits = 2\nop = RX(1, PI/4)\n</code></pre> <pre><code>Same sampling order in big endian:\n\nOn PyQTorch = [OrderedCounter({'00': 83, '01': 17})]\nOn Pulser = [Counter({'00': 93, '01': 7})]\n\nSame wavefunction order:\n\nOn PyQTorch = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Pulser = tensor([[0.9239+0.0000j, 0.0000-0.3826j, 0.0000+0.0000j, 0.0000+0.0000j]])\n</code></pre>"},{"location":"content/state_init/","title":"State initialization","text":"<p>Qadence offers convenience routines for preparing initial quantum states. These routines are divided into two approaches:</p> <ul> <li>As a dense matrix.</li> <li>From a suitable quantum circuit. This is available for every backend and it should be added in front of the desired quantum circuit to simulate.</li> </ul> <p>Let's illustrate the usage of the state preparation routine.</p> <pre><code>from qadence import random_state, product_state, is_normalized, StateGeneratorType\n\n# Random initial state.\n# the default `type` is StateGeneratorType.HaarMeasureFast\nstate = random_state(n_qubits=2, type=StateGeneratorType.RANDOM_ROTATIONS)\n\n# Check the normalization.\nassert is_normalized(state)\n\n# Product state from a given bitstring.\n# NB: Qadence follows the big endian convention.\nstate = product_state(\"01\")\n</code></pre> <pre><code>Random initial state generated with rotations:\n\nstate = [ 0.86909607+0.j  0.48486511+0.j -0.08546558+0.j -0.0476809 +0.j]\n\nProduct state corresponding to bitstring '01':\n\nstate = [0.+0.j 1.+0.j 0.+0.j 0.+0.j]\n</code></pre> <p>Now we see how to generate the product state corresponding to the one above with a suitable quantum circuit.</p> <p><pre><code>from qadence import product_block, tag, hea, QuantumCircuit\nfrom qadence.draw import display\n\nstate_prep_block = product_block(\"01\")\n# display(state_prep_block)\n\n# Let's now prepare a circuit.\nn_qubits = 4\n\nstate_prep_block = product_block(\"0001\")\ntag(state_prep_block, \"Prep block\")\n\ncircuit_block = tag(hea(n_qubits, depth = 2), \"Circuit block\")\n\nqc_with_state_prep = QuantumCircuit(n_qubits, state_prep_block, circuit_block)\n</code></pre> %3 cluster_73c1e9b3c71c4e02973a86ab24c31b28 Circuit block cluster_7a0e1a60565649339e4980880e7966ec Prep block afcbe6bbab054ff0bff29bbdc4a296b0 0 8fa9be296be84173bdf1836cc2f573a2 afcbe6bbab054ff0bff29bbdc4a296b0--8fa9be296be84173bdf1836cc2f573a2 899410a8ad17425eb442348c0135f437 1 9304be08ee8d4d12ba2f46dc8867377f RX(theta\u2080) 8fa9be296be84173bdf1836cc2f573a2--9304be08ee8d4d12ba2f46dc8867377f 92a547a033cb48bb9a3a7210749b321e RY(theta\u2084) 9304be08ee8d4d12ba2f46dc8867377f--92a547a033cb48bb9a3a7210749b321e 9589523dfb644e4eb4ed919c9138750e RX(theta\u2088) 92a547a033cb48bb9a3a7210749b321e--9589523dfb644e4eb4ed919c9138750e 439c4fafb3994212959c721127431ef2 9589523dfb644e4eb4ed919c9138750e--439c4fafb3994212959c721127431ef2 b91a4a066e6e468680d06ae52c871640 439c4fafb3994212959c721127431ef2--b91a4a066e6e468680d06ae52c871640 bfe153fcaf724999af5e9bfcb3b467e3 RX(theta\u2081\u2082) b91a4a066e6e468680d06ae52c871640--bfe153fcaf724999af5e9bfcb3b467e3 168762f885c84451bee4665779e29dae RY(theta\u2081\u2086) bfe153fcaf724999af5e9bfcb3b467e3--168762f885c84451bee4665779e29dae 49ddc56bae9f4662b2fbe2f3695dad71 RX(theta\u2082\u2080) 168762f885c84451bee4665779e29dae--49ddc56bae9f4662b2fbe2f3695dad71 bbb3b3af8e73499fbb29ed168d07c4d4 49ddc56bae9f4662b2fbe2f3695dad71--bbb3b3af8e73499fbb29ed168d07c4d4 0cd41a185a774a428508fc74081fc86b bbb3b3af8e73499fbb29ed168d07c4d4--0cd41a185a774a428508fc74081fc86b 2b74daf7c77b4b0f9674b767b9af732e 0cd41a185a774a428508fc74081fc86b--2b74daf7c77b4b0f9674b767b9af732e e6d61d9bf069406ba22b7dc6ee84a434 9993d886346a4500a017c3061af59639 899410a8ad17425eb442348c0135f437--9993d886346a4500a017c3061af59639 1a9b2533b2d24b39a38eccf74fd67332 2 e0c419b74c314436a26f8fd4f0b2091d RX(theta\u2081) 9993d886346a4500a017c3061af59639--e0c419b74c314436a26f8fd4f0b2091d 0bdeccf339344fda9f02c9ab6360d8ba RY(theta\u2085) e0c419b74c314436a26f8fd4f0b2091d--0bdeccf339344fda9f02c9ab6360d8ba 94e4a6402fde48b080c50be4339540ca RX(theta\u2089) 0bdeccf339344fda9f02c9ab6360d8ba--94e4a6402fde48b080c50be4339540ca cc615c31046f48ca9f636dd6fa20a866 X 94e4a6402fde48b080c50be4339540ca--cc615c31046f48ca9f636dd6fa20a866 cc615c31046f48ca9f636dd6fa20a866--439c4fafb3994212959c721127431ef2 1dd6688fea024c398adf6470f06f7447 cc615c31046f48ca9f636dd6fa20a866--1dd6688fea024c398adf6470f06f7447 5807187dd5fa4b6abbd5354504d9cab2 RX(theta\u2081\u2083) 1dd6688fea024c398adf6470f06f7447--5807187dd5fa4b6abbd5354504d9cab2 793c7059d6b64961b34956406e8323e2 RY(theta\u2081\u2087) 5807187dd5fa4b6abbd5354504d9cab2--793c7059d6b64961b34956406e8323e2 8d1ab062ab874e90b3d2d0c582404357 RX(theta\u2082\u2081) 793c7059d6b64961b34956406e8323e2--8d1ab062ab874e90b3d2d0c582404357 125a7681a01046c491e3fab4c65f80d1 X 8d1ab062ab874e90b3d2d0c582404357--125a7681a01046c491e3fab4c65f80d1 125a7681a01046c491e3fab4c65f80d1--bbb3b3af8e73499fbb29ed168d07c4d4 6b10607c6f8b43a29b005493d20717c8 125a7681a01046c491e3fab4c65f80d1--6b10607c6f8b43a29b005493d20717c8 6b10607c6f8b43a29b005493d20717c8--e6d61d9bf069406ba22b7dc6ee84a434 c710e97d09b54afea1f709f86543de43 b01d498ef6fd472c822200683bde7c6f 1a9b2533b2d24b39a38eccf74fd67332--b01d498ef6fd472c822200683bde7c6f 60211833675045f4b0f545e5dc7615c9 3 14b7fd69226e463a94f04a74f5bc0729 RX(theta\u2082) b01d498ef6fd472c822200683bde7c6f--14b7fd69226e463a94f04a74f5bc0729 f0ddcac3e1aa4c78bba36073113678b8 RY(theta\u2086) 14b7fd69226e463a94f04a74f5bc0729--f0ddcac3e1aa4c78bba36073113678b8 0aae466d5ef146f8a2940065e28ed9d7 RX(theta\u2081\u2080) f0ddcac3e1aa4c78bba36073113678b8--0aae466d5ef146f8a2940065e28ed9d7 a534d2c655624393b88af57f5b05e280 0aae466d5ef146f8a2940065e28ed9d7--a534d2c655624393b88af57f5b05e280 1782855c511f4426aeb03b011e6c95ed X a534d2c655624393b88af57f5b05e280--1782855c511f4426aeb03b011e6c95ed 1782855c511f4426aeb03b011e6c95ed--1dd6688fea024c398adf6470f06f7447 a54d1fb7a63b43aa83aab1d3ace36768 RX(theta\u2081\u2084) 1782855c511f4426aeb03b011e6c95ed--a54d1fb7a63b43aa83aab1d3ace36768 7c6343d236544da1847d0c5f5587addd RY(theta\u2081\u2088) a54d1fb7a63b43aa83aab1d3ace36768--7c6343d236544da1847d0c5f5587addd 19060c44bb9c45df883cdd01f5208a1e RX(theta\u2082\u2082) 7c6343d236544da1847d0c5f5587addd--19060c44bb9c45df883cdd01f5208a1e a26664b2bd734f9e84d4e795754b0c3b 19060c44bb9c45df883cdd01f5208a1e--a26664b2bd734f9e84d4e795754b0c3b fa22feb660cc48fea5b24e34031d7098 X a26664b2bd734f9e84d4e795754b0c3b--fa22feb660cc48fea5b24e34031d7098 fa22feb660cc48fea5b24e34031d7098--6b10607c6f8b43a29b005493d20717c8 fa22feb660cc48fea5b24e34031d7098--c710e97d09b54afea1f709f86543de43 9c962614efc6470693772856c105b69d 6c9b127801744440b1f060be8eac5e1c X 60211833675045f4b0f545e5dc7615c9--6c9b127801744440b1f060be8eac5e1c 206ef64717ac4653a46eadf6b3894757 RX(theta\u2083) 6c9b127801744440b1f060be8eac5e1c--206ef64717ac4653a46eadf6b3894757 d7239c8fdbf84aababc8e0fd6c67285a RY(theta\u2087) 206ef64717ac4653a46eadf6b3894757--d7239c8fdbf84aababc8e0fd6c67285a 308c6d9aa1864508ad0441eeab4eca12 RX(theta\u2081\u2081) d7239c8fdbf84aababc8e0fd6c67285a--308c6d9aa1864508ad0441eeab4eca12 11ba1e3274d64e17b67de868c17d0fca X 308c6d9aa1864508ad0441eeab4eca12--11ba1e3274d64e17b67de868c17d0fca 11ba1e3274d64e17b67de868c17d0fca--a534d2c655624393b88af57f5b05e280 f1d215b304e649cc85f9d4c434c0ef30 11ba1e3274d64e17b67de868c17d0fca--f1d215b304e649cc85f9d4c434c0ef30 9761bd09490b4be88a1bbc90a2453b4e RX(theta\u2081\u2085) f1d215b304e649cc85f9d4c434c0ef30--9761bd09490b4be88a1bbc90a2453b4e 535fa61903b34b5f80a5ace6a4b101b4 RY(theta\u2081\u2089) 9761bd09490b4be88a1bbc90a2453b4e--535fa61903b34b5f80a5ace6a4b101b4 3abd46ad66474dc9878b1fb2638b2d50 RX(theta\u2082\u2083) 535fa61903b34b5f80a5ace6a4b101b4--3abd46ad66474dc9878b1fb2638b2d50 078e6d29e1cd4888843f995bc7efcf5a X 3abd46ad66474dc9878b1fb2638b2d50--078e6d29e1cd4888843f995bc7efcf5a 078e6d29e1cd4888843f995bc7efcf5a--a26664b2bd734f9e84d4e795754b0c3b 92f6703d38234325b41336acb848a500 078e6d29e1cd4888843f995bc7efcf5a--92f6703d38234325b41336acb848a500 92f6703d38234325b41336acb848a500--9c962614efc6470693772856c105b69d  Several standard quantum states can be conveniently initialized in Qadence, both in statevector form as well as in block form as shown in following.</p>"},{"location":"content/state_init/#state-vector-initialization","title":"State vector initialization","text":"<p>Qadence offers a number of constructor functions for state vector preparation.</p> <pre><code>from qadence import uniform_state, zero_state, one_state\n\nn_qubits = 3\nbatch_size = 2\n\nuniform_state = uniform_state(n_qubits, batch_size)\nzero_state = zero_state(n_qubits, batch_size)\none_state = one_state(n_qubits, batch_size)\n</code></pre> <pre><code>Uniform state = \n\ntensor([[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n         0.3536+0.j],\n        [0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n         0.3536+0.j]])\nZero state = \n\ntensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nOne state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> <p>As already seen, product states can be easily created, even in batches:</p> <pre><code>from qadence import product_state, rand_product_state\n\n# From a bitsring \"100\"\nprod_state = product_state(\"100\", batch_size)\n\n# Or a random product state\nrand_state = rand_product_state(n_qubits, batch_size)\n</code></pre> <pre><code>Product state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n\nRandom state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Creating a GHZ state:</p> <pre><code>from qadence import ghz_state\n\nghz = ghz_state(n_qubits, batch_size)\n</code></pre> <pre><code>GHZ state = \n\ntensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n         0.7071+0.j],\n        [0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n         0.7071+0.j]])\n</code></pre> <p>Creating a random state uniformly sampled from a Haar measure:</p> <pre><code>from qadence import random_state\n\nrand_haar_state = random_state(n_qubits, batch_size)\n</code></pre> <pre><code>Random state from Haar = \n\ntensor([[ 0.2770+0.1293j, -0.0215-0.1989j, -0.0059-0.1722j, -0.0701-0.5453j,\n          0.1952-0.2482j,  0.0533-0.1674j,  0.3690+0.2146j,  0.3263+0.3397j],\n        [ 0.3077+0.1175j, -0.0426-0.1098j,  0.0193-0.5347j,  0.3126-0.4919j,\n         -0.0170+0.0276j, -0.2911+0.3312j, -0.1317-0.0877j, -0.0230+0.1749j]])\n</code></pre> <p>Custom initial states can then be passed to either <code>run</code>, <code>sample</code> and <code>expectation</code> through the <code>state</code> argument</p> <pre><code>from qadence import random_state, product_state, CNOT, run\n\ninit_state = product_state(\"10\")\nfinal_state = run(CNOT(0, 1), state=init_state)\n</code></pre> <pre><code>Final state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre>"},{"location":"content/state_init/#density-matrices-conversion","title":"Density matrices conversion","text":"<p>It is also possible to obtain density matrices from statevectors. They can be passed as inputs to quantum programs performing density matrix based operations such as noisy simulations, when the backend allows such as PyQTorch.</p> <pre><code>from qadence import product_state, density_mat\n\ninit_state = product_state(\"10\")\ninit_density_matrix = density_mat(init_state)\n\nfinal_density_matrix = run(CNOT(0, 1), state=init_density_matrix)\n</code></pre> <pre><code>Initial = DensityMatrix([[[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n                [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n                [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n                [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]])\nFinal = DensityMatrix([[[0.-0.j, 0.-0.j, 0.-0.j, 0.-0.j],\n                [0.-0.j, 0.-0.j, 0.-0.j, 0.-0.j],\n                [0.-0.j, 0.-0.j, 0.-0.j, 0.-0.j],\n                [0.-0.j, 0.-0.j, 0.-0.j, 1.-0.j]]])\n</code></pre>"},{"location":"content/state_init/#block-initialization","title":"Block initialization","text":"<p>Not all backends support custom statevector initialization, however previous utility functions have their counterparts to initialize the respective blocks:</p> <pre><code>from qadence import uniform_block, one_block\n\nn_qubits = 3\n\nuniform_block = uniform_block(n_qubits)\n\none_block = one_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u251c\u2500\u2500 H(1)\n\u2514\u2500\u2500 H(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>Similarly, for product states:</p> <pre><code>from qadence import product_block, rand_product_block\n\nproduct_block = product_block(\"100\")\n\nrand_product_block = rand_product_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 I(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>And GHZ states:</p> <pre><code>from qadence import ghz_block\n\nghz_block = ghz_block(n_qubits)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n    \u251c\u2500\u2500 CNOT(0, 1)\n    \u2514\u2500\u2500 CNOT(1, 2)\n</code></pre> <p>Initial state blocks can simply be chained at the start of a given circuit.</p>"},{"location":"content/state_init/#utility-functions","title":"Utility functions","text":"<p>Some state vector utility functions are also available. We can easily create the probability mass function of a given statevector using <code>torch.distributions.Categorical</code></p> <pre><code>from qadence import random_state, pmf\n\nn_qubits = 3\n\nstate = random_state(n_qubits)\ndistribution = pmf(state)\n</code></pre> <pre><code>Categorical(probs: torch.Size([1, 8]))\n</code></pre> <p>We can also check if a state is normalized:</p> <pre><code>from qadence import random_state, is_normalized\n\nstate = random_state(n_qubits)\nprint(is_normalized(state))\n</code></pre> <pre><code>True\n</code></pre> <p>Or normalize a state:</p> <pre><code>import torch\nfrom qadence import normalize, is_normalized\n\nstate = torch.tensor([[1, 1, 1, 1]], dtype = torch.cdouble)\nprint(normalize(state))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre>"},{"location":"content/time_dependent/","title":"Time-dependent generators","text":"<p>For use cases when the Hamiltonian of the system is time-dependent, Qadence provides a special parameter <code>TimeParameter(\"t\")</code> that denotes the explicit time dependence. Using this time parameter, one can define a parameterized block acting as the generator passed to <code>HamEvo</code> that encapsulates the required time dependence function.</p>"},{"location":"content/time_dependent/#noiseless-time-dependent-hamiltonian-evolution","title":"Noiseless time-dependent Hamiltonian evolution","text":"<pre><code>from qadence import X, Y, HamEvo, TimeParameter, FeatureParameter, run\nfrom pyqtorch.utils import SolverType\nimport torch\n\n# Simulation parameters\node_solver = SolverType.DP5_SE  # time-dependent Schrodinger equation solver method\nn_steps_hevo = 500  # integration time steps used by solver\n\n# Define block parameters\nt = TimeParameter(\"t\")\nomega_param = FeatureParameter(\"omega\")\n\n# Arbitrarily compose a time-dependent generator\ntd_generator = omega_param * (t * X(0) + t**2 * Y(1))\n\n# Create parameterized HamEvo block\nhamevo = HamEvo(td_generator, t)\n</code></pre> <p>Note that when using <code>HamEvo</code> with a time-dependent generator, the actual time parameter that was used to construct the generator must be passed for the second argument <code>parameter</code>.</p> <p>By default, the code above will initialize an internal parameter <code>FeatureParameter(\"duration\")</code> in the <code>HamEvo</code>. Alternatively, the <code>duration</code> argument can be used to rename this parameter, or to pass a fixed value directly. If no fixed value is passed, it must then be set in the <code>values</code> dictionary at runtime.</p> <p>Future improvements</p> <p>Currently it is only possible to pass a single value for the duration, and the only result obtained will be the one corresponding to the state at end of the integration. In the future we will change the interface to allow directly passing some array of save values to obtain expectation values or statevectors at intermediate steps during the evolution.</p> <pre><code>values = {\"omega\": torch.tensor(10.0), \"duration\": torch.tensor(1.0)}\n\nconfig = {\"ode_solver\": ode_solver, \"n_steps_hevo\": n_steps_hevo}\n\nout_state = run(hamevo, values = values, configuration = config)\n\nprint(out_state)\n</code></pre> <pre><code>tensor([[-0.2785+0.0000j, -0.0541+0.0000j,  0.0000-0.9414j,  0.0000-0.1827j]])\n</code></pre> <p>Note that Qadence makes no assumption on units. The unit of passed duration value \\(\\tau\\) must be aligned with the units of other parameters in the time-dependent generator so that the integral of generator \\(\\overset{\\tau}{\\underset{0}{\\int}}\\mathcal{\\hat{H}}(t){\\rm d}t\\) is dimensionless.</p>"},{"location":"content/time_dependent/#noisy-time-dependent-hamiltonian-evolution","title":"Noisy time-dependent Hamiltonian evolution","text":"<p>To perform noisy time-dependent Hamiltonian evolution, one needs to pass a list of noise operators to the <code>noise_operators</code> argument in <code>HamEvo</code>. They correspond to the jump operators used within the time-dependent Schrodinger equation solver method <code>SolverType.DP5_ME</code>:</p> <pre><code>from qadence import X, Y, HamEvo, TimeParameter, FeatureParameter, run\nfrom pyqtorch.utils import SolverType\nimport torch\n\n# Simulation parameters\node_solver = SolverType.DP5_ME  # time-dependent Schrodinger equation solver method\nn_steps_hevo = 500  # integration time steps used by solver\n\n# Define block parameters\nt = TimeParameter(\"t\")\nomega_param = FeatureParameter(\"omega\")\n\n# Arbitrarily compose a time-dependent generator\ntd_generator = omega_param * (t * X(0) + t**2 * Y(1))\n\n# Create parameterized HamEvo block\nnoise_operators = [X(i) for i in td_generator.qubit_support]\nhamevo = HamEvo(td_generator, t, noise_operators = noise_operators)\n\nvalues = {\"omega\": torch.tensor(10.0), \"duration\": torch.tensor(1.0)}\n\nconfig = {\"ode_solver\": ode_solver, \"n_steps_hevo\": n_steps_hevo}\n\nout_state = run(hamevo, values = values, configuration = config)\n\nprint(out_state)\n</code></pre>   DensityMatrix([[[0.2734+0.0000j, 0.0297+0.0000j, 0.0000-0.0227j, 0.0000-0.0025j],                 [0.0297+0.0000j, 0.1698+0.0000j, 0.0000-0.0025j, 0.0000-0.0141j],                 [0.0000+0.0227j, 0.0000+0.0025j, 0.3435+0.0000j, 0.0373+0.0000j],                 [0.0000+0.0025j, 0.0000+0.0141j, 0.0373+0.0000j, 0.2133+0.0000j]]])    <p>Noise operators definition</p> <p>Note it is not possible to define <code>noise_operators</code> with parametric operators. If you want to do so, we recommend obtaining the tensors via run and set <code>noise_operators</code> using <code>MatrixBlock</code>. Also, <code>noise_operators</code> should have the same or a subset of the qubit support of the <code>HamEvo</code> instance.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"getting_started/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"getting_started/CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"getting_started/CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in Qadence. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"getting_started/CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence, feel free to create an issue on qadence's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"getting_started/CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>We're excited that you're eager to contribute to Qadence. To contribute, fork the <code>main</code> branch of qadence repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/qadence</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/qadence.git\n</code></pre> <p>Next, navigate to your new qadence fork directory and mark the main qadence repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/qadence.git\n</code></pre>"},{"location":"getting_started/CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within qadence, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run qadence tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\npip install -e .\npytest\n</code></pre>"},{"location":"getting_started/CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful things for your workflow: linting and testing","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"getting_started/LICENSE/","title":"License","text":"<p>PASQAL OPEN-SOURCE SOFTWARE LICENSE AGREEMENT (MIT-derived)</p> <p>The author of the License is:   Pasqal, a Soci\u00e9t\u00e9 par Actions Simplifi\u00e9e (Simplified Joint Stock Company) registered under number 849 441 522 at the Registre du commerce et des soci\u00e9t\u00e9s (Trade and Companies Register) of Evry \u2013 France, headquartered at 24 rue \u00c9mile Baudot \u2013 91120 \u2013 Palaiseau \u2013 France, duly represented by its Pr\u00e9sident, M. Georges-Olivier REYMOND, Hereafter referred to as \u00ab the Licensor \u00bb</p> <ul> <li> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software (the \u201cLicensee\u201d) and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. The Software is \u201cas is\u201d, without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and non-infringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise arising from, out of or in connection with the Software or the use or other dealings in the Software.</p> </li> <li> <p>If use of the Software leads to the necessary use of any patent of the Licensor and/or any of its Affiliates (defined as a company owned or controlled by the Licensor), the Licensee is granted a royalty-free license, in any country where such patent is in force, to use the object of such patent; or use the process covered by such patent,</p> </li> <li> <p>Such a patent license is granted for internal research or academic use of the Licensee's, which includes use by employees and students of the Licensee, acting on behalf of the Licensee, for research purposes only.</p> </li> <li> <p>The License is governed by the laws of France. Any dispute relating to the License, notably its execution, performance and/or termination shall be brought to, heard and tried by the Tribunal Judiciaire de Paris, regardless of the rules of jurisdiction in the matter.</p> </li> </ul>"},{"location":"getting_started/installation/","title":"Installation","text":""},{"location":"getting_started/installation/#requirements","title":"Requirements","text":"<p>Qadence is fully tested on Linux/MacOS operating systems. For Windows users, we recommend using WSL2 to install a Linux distribution of choice.</p>"},{"location":"getting_started/installation/#installation","title":"Installation","text":"<p>Qadence can be installed from PyPI with <code>pip</code> as follows:</p> <pre><code>pip install qadence\n</code></pre> <p>By default, this will also install PyQTorch, a differentiable state vector simulator which serves as the main numerical backend for Qadence.</p> <p>It is possible to install additional backends and the circuit visualization library using the following extras:</p> <ul> <li><code>visualization</code>: to display quantum circuits.</li> <li><code>pulser</code>: the Pulser backend for composing, simulating and executing pulse sequences for neutral-atom quantum devices (in development).</li> </ul> <p>To install other backends or the visualization tool, please use:</p> <pre><code>pip install \"qadence[pulser, visualization]\"\n</code></pre> <p>Note</p> <p>In order to correctly install the <code>visualization</code> extra, the <code>graphviz</code> package needs to be installed in your system:</p> <pre><code># on Ubuntu\nsudo apt install graphviz\n\n# on MacOS\nbrew install graphviz\n\n# via conda\nconda install python-graphviz\n</code></pre>"},{"location":"getting_started/installation/#install-from-source","title":"Install from source","text":"<p>We recommend to use the <code>hatch</code> environment manager to install <code>qadence</code> from source:</p> <pre><code>python -m pip install hatch\n\n# get into a shell with all the dependencies\npython -m hatch shell\n\n# run a command within the virtual environment with all the dependencies\npython -m hatch run python my_script.py\n</code></pre> <p>Warning</p> <p><code>hatch</code> will not combine nicely with other environment managers such Conda. If you want to use Conda, install it from source using <code>pip</code>:</p> <pre><code># within the Conda environment\npython -m pip install -e .\n</code></pre>"},{"location":"getting_started/installation/#citation","title":"Citation","text":"<p>If you use Qadence for a publication, we kindly ask you to cite our work using the following BibTex entry:</p> <pre><code>@article{qadence2024pasqal,\n  title = {Qadence: a differentiable interface for digital-analog programs.},\n  author={Dominik Seitz and Niklas Heim and Jo\u00e3o P. Moutinho and Roland Guichard and Vytautas Abramavicius and Aleksander Wennersteen and Gert-Jan Both and Anton Quelle and Caroline de Groot and Gergana V. Velikova and Vincent E. Elfving and Mario Dagrada},\n  journal={arXiv:2401.09915},\n  url = {https://github.com/pasqal-io/qadence},\n  year = {2024}\n}\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This section is undergoing changes and most of the information here will be reorganized.</p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"tutorials/advanced_tutorials/","title":"Advanced Tutorials","text":"<p>In this section, advanced programming concepts and implementations in Qadence are examplified.</p>"},{"location":"tutorials/advanced_tutorials/cloud-submission/","title":"Submission of Qadence Jobs to Pasqal Cloud","text":"<p>It is possible to submit quantum computational jobs to execute remotely on Pasqal's cloud platform from Qadence. This feature can only be used if you have an account on the cloud platform, which has access to the Qadence workload. The qadence module <code>qadence.pasqal_cloud_connection</code> offers functionality to specify the computation easily, upload the specification and retrieve the result when the computation has finished execution on the cloud platform. In this tutorial, a simple quantum circuit will be defined as an example to showcase the submission process for remote computations. The same process can be applied to run more complex quantum circuits on the cloud platform.</p> <p>Let's first define a very simple quantum circuit that creates a Bell state.</p> <pre><code>from qadence import CNOT, H, QuantumCircuit\n\ncircuit = QuantumCircuit(2, H(0), CNOT(0, 1))\n</code></pre> <p>If we want to upload this circuit to the cloud platform we need to follow 4 steps: - Authentication and connection to cloud - Defining workload specification - Submission - Retrieval of results</p>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#authentication-and-connection","title":"Authentication and connection","text":"<p>To setup a connection the cloud platform, use the <code>SDK</code> object present in <code>qadence.pasqal_cloud_connection</code>. The email and password are the ones used to login to the webportal. The project-id can be found in the webportal under \"Projects\".</p> <pre><code>from qadence.pasqal_cloud_connection import SDK\n\nconnection = SDK(\"john.doe@email.com\", \"my-password\", project_id=\"proj1\")\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#defining-workload-specification","title":"Defining workload specification","text":"<p>A workload is a quantum calculation to execute on a Pasqal cloud backend. To create a workload specification, we need some extra information on top the circuit itself. We need to specify the backend, chosen here to be PyQTorch. The cloud platform currently only supports PyQTorch. Moreover, the requested result type needs to be defined. Based on the workload specification, the appropriate run methods (<code>run</code>, <code>sample</code> or <code>expectation</code>) will be called by the <code>QuantumModel</code> by passing them through the enum value <code>ResultTypes</code> argument. Moreover, the requested result type needs to be defined. These are provided in a list, so that multiple result types can be requested in a single submission.</p> <pre><code>from qadence import BackendName\nfrom qadence.pasqal_cloud_connection import WorkloadSpec, ResultType\n\nworkload = WorkloadSpec(circuit, BackendName.PYQTORCH, [ResultType.SAMPLE, ResultType.RUN])\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#using-a-quantum-model","title":"Using a Quantum Model","text":"<p>If you already have your quantum computation defined as a <code>QuantumModel</code>, it is possible to create a workload specification directly from the model using <code>get_workload_spec</code>. Then, the circuit and backend specifications will be extracted from the model, the other values need to be provided as extra arguments.</p> <pre><code>from qadence import QuantumModel\nfrom qadence.pasqal_cloud_connection import get_workload_spec\n\nmodel = QuantumModel(circuit)\nworkload = get_workload_spec(model, [ResultType.SAMPLE])\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#observable-expectation-value","title":"Observable Expectation Value","text":"<p>For the result type <code>ResultType.EXPECTATION</code> it is mandatory to provide an observable to the workload specification. In the example below we use the trivial identity observable <code>I(0) @ I(1)</code>.</p> <pre><code>from qadence import I\n\nworkload = WorkloadSpec(circuit, BackendName.PYQTORCH, [ResultType.EXPECTATION], observable=I(0)*I(1))\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#parametric-circuits","title":"Parametric Circuits","text":"<p>In the case of a parametric circuit, i.e. a circuit that contains feature parameters or variational parameters, values for these parameters need to be provided. The parameter values are defined in a dictionary, where keys are the parameter name and values are parameter value passed as torch tensors. The parameter values are defined in a dictionary, where keys are the parameter name and values are parameter value passed as torch tensors. It is possible to set multiple values by using a 1-D tensor, to the parameters, in that case the computation is executed for each value in the tensor. A mix of 0-D and 1-D tensors can be provided to keep some parameters constant and others changed during this process. However, all 1-D tensors need to have the same length. An exception will be raised if the dimensions and lengths are invalid.</p> <pre><code>from torch import tensor\n\nparametric_circuit = ...\nparameter_values = {\"param1\": tensor(0), \"param2\": tensor([0, 1, 2]), \"param3\": tensor([5, 6, 7])}\nworkload = WorkloadSpec(parametric_circuit, BackendName.PYQTORCH, [ResultType.SAMPLE], parameter_values=parameter_values)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#submission","title":"Submission","text":"<p>Submission to the cloud platform is done very easily using the <code>submit_workload</code> function. The workload id will be provided by executing the function. This id is needed later, to request the status of the given workload.</p> <pre><code>from qadence.pasqal_cloud_connection import submit_workload\n\nworkload_id = submit_workload(connection, workload)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#check-workload-status","title":"Check Workload Status","text":"<p>The status of a workload can be: done, pending, running, paused, canceled, timed out or error. The <code>check_status</code> function can be used to see if the workload is finished already. If so, the results of the computation will be provided in a <code>WorkloadResult</code> object. The result of the computation itself can be found in the <code>result</code> attribute of this object. If the workload has not finished yet, or resulted in an error, <code>check_status</code> will raise an exception, either a <code>WorkloadStoppedError</code> or <code>WorkloadNotDoneError</code>.</p> <pre><code>from qadence.pasqal_cloud_connection import check_status\n\nworkload_result = check_status(connection, workload_id)\nprint(workload_result.result)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/cloud-submission/#retrieval-of-results","title":"Retrieval of Results","text":"<p>If you wish to wait for the workload to be finished, before moving further with your code, you can use the <code>get_result</code> function. This function checks in set intervals the status of the workload until the workload is finished or the function has timed out. The polling rate as well as the time out duration can be set optionally.</p> <pre><code>from qadence.pasqal_cloud_connection import get_result\n\nworkload_result = get_result(connection, workload_id, timeout=60, refresh_time=1)\nprint(workload_result.result)\n</code></pre>"},{"location":"tutorials/advanced_tutorials/custom-models/","title":"Custom quantum models","text":"<p>In <code>qadence</code>, the <code>QuantumModel</code> is the central class point for executing <code>QuantumCircuit</code>s.  The idea of a <code>QuantumModel</code> is to decouple the backend execution from the management of circuit parameters and desired quantum computation output.</p> <p>In the following, we create a custom <code>QuantumModel</code> instance which introduces some additional optimizable parameters: *  an adjustable scaling factor in front of the observable to measured *  adjustable scale and shift factors to be applied to the model output before returning the result</p> <p>This can be easily done using PyTorch flexible model definition, and it will automatically work with the rest of <code>qadence</code> infrastructure.</p> <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit\n\n\nclass CustomQuantumModel(QuantumModel):\n\n    def __init__(self, circuit: QuantumCircuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\"):\n        super().__init__(circuit, observable=observable, backend=backend, diff_mode=diff_mode)\n\n        self.n_qubits = circuit.n_qubits\n\n        # define some additional parameters which will scale and shift (variationally) the\n        # output of the QuantumModel\n        # you can use all torch machinery for building those\n        self.scale_out = torch.nn.Parameter(torch.ones(1))\n        self.shift_out = torch.nn.Parameter(torch.ones(1))\n\n    # override the forward pass of the model\n    # the forward pass is the output of your QuantumModel and in this case\n    # it's the (scaled) expectation value of the total magnetization with\n    # a variable coefficient in front\n    def forward(self, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n\n        # scale the observable\n        res = self.expectation(values)\n\n        # scale and shift the result before returning\n        return self.shift_out + res * self.scale_out\n</code></pre> <p>The custom model can be used like any other <code>QuantumModel</code>: <pre><code>from qadence import Parameter, RX, CNOT, QuantumCircuit\nfrom qadence import chain, kron, hamiltonian_factory, Z\nfrom sympy import acos\n\ndef quantum_circuit(n_qubits):\n\n    x = Parameter(\"x\", trainable=False)\n    fm = kron(RX(i, acos(x) * (i+1)) for i in range(n_qubits))\n\n    ansatz = kron(RX(i, f\"theta{i}\") for i in range(n_qubits))\n    ansatz = chain(ansatz, CNOT(0, n_qubits-1))\n\n    block = chain(fm, ansatz)\n    block.tag = \"circuit\"\n    return QuantumCircuit(n_qubits, block)\n\nn_qubits = 4\nbatch_size = 10\ncircuit = quantum_circuit(n_qubits)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)  # Total magnetization\n\nmodel = CustomQuantumModel(circuit, observable, backend=\"pyqtorch\")\n\nvalues = {\"x\": torch.rand(batch_size)}\nres = model(values)\nprint(\"Model output: \", res)\nassert len(res) == batch_size\n</code></pre> <pre><code>Model output:  tensor([[ 1.1663],\n        [-0.6281],\n        [-0.5949],\n        [-0.6028],\n        [-0.5702],\n        [-0.6378],\n        [-0.5716],\n        [ 0.2103],\n        [-0.5436],\n        [-0.5053]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> </p>"},{"location":"tutorials/advanced_tutorials/custom-models/#quantum-model-with-wavefunction-overlaps","title":"Quantum model with wavefunction overlaps","text":"<p><code>QuantumModel</code>'s can also use different quantum operations in their forward pass, such as wavefunction overlaps described here. Beware that the resulting overlap tensor has to be differentiable to apply gradient-based optimization. This is only applicable to the <code>\"EXACT\"</code> overlap method.</p> <p>Here we show how to use overlap calculation when fitting a parameterized quantum circuit to act as a standard Hadamard gate.</p> <pre><code>from qadence import RY, RX, H, Overlap\n\n# create a quantum model which acts as an Hadamard gate after training\nclass LearnHadamard(QuantumModel):\n    def __init__(\n        self,\n        train_circuit: QuantumCircuit,\n        target_circuit: QuantumCircuit,\n        backend=\"pyqtorch\",\n    ):\n        super().__init__(circuit=train_circuit, backend=backend)\n        self.overlap_fn = Overlap(train_circuit, target_circuit, backend=backend, method=\"exact\", diff_mode='ad')\n\n    def forward(self):\n        return self.overlap_fn()\n\n    # compute the wavefunction of the associated train circuit\n    def wavefunction(self):\n        return model.overlap_fn.run({})\n\n\ntrain_circuit = QuantumCircuit(1, chain(RX(0, \"phi\"), RY(0, \"theta\")))\ntarget_circuit = QuantumCircuit(1, H(0))\n\nmodel = LearnHadamard(train_circuit, target_circuit)\n\n# get the overlap between model and target circuit wavefunctions\nprint(model())\n</code></pre> <pre><code>tensor([[0.6163]], grad_fn=&lt;UnsqueezeBackward0&gt;)\n</code></pre> <p>This model can then be trained with the standard Qadence helper functions.</p> <pre><code>from qadence import run\nfrom qadence.ml_tools import Trainer, TrainConfig\nTrainer.set_use_grad(True)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n\ndef loss_fn(model: LearnHadamard, _unused) -&gt; tuple[torch.Tensor, dict]:\n    loss = criterion(torch.tensor([[1.0]]), model())\n    return loss, {}\n\nconfig = TrainConfig(max_iter=2500)\ntrainer = Trainer(\n    model, optimizer, config, loss_fn\n)\nmodel, optimizer = trainer.fit()\n\nwf_target = run(target_circuit)\nassert torch.allclose(wf_target, model.wavefunction(), atol=1e-2)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/advanced_tutorials/differentiability/","title":"Differentiability","text":"<p>Many application in quantum computing and quantum machine learning more specifically requires the differentiation of a quantum circuit with respect to its parameters.</p> <p>In Qadence, we perform quantum computations via the <code>QuantumModel</code> interface. The derivative of the outputs of quantum models with respect to feature and variational parameters in the quantum circuit can be implemented in Qadence with two different modes:</p> <ul> <li>Automatic differentiation (AD) mode <sup>1</sup>. This mode allows to differentiation both <code>run()</code> and <code>expectation()</code> methods of the <code>QuantumModel</code> and it is the fastest available differentiation method. Under the hood, it is based on the PyTorch autograd engine wrapped by the <code>DifferentiableBackend</code> class. This mode is not working on quantum devices.</li> <li>Generalized parameter shift rule (GPSR) mode. This is general implementation of the well known parameter  shift rule algorithm <sup>2</sup> which works for arbitrary quantum operations <sup>3</sup>. This mode is only applicable to  the <code>expectation()</code> method of <code>QuantumModel</code> but it is compatible with execution or quantum devices.</li> </ul>"},{"location":"tutorials/advanced_tutorials/differentiability/#automatic-differentiation","title":"Automatic differentiation","text":"<p>Automatic differentiation <sup>1</sup> is a procedure to derive a complex function defined as a sequence of elementary mathematical operations in the form of a computer program. Automatic differentiation is a cornerstone of modern machine learning and a crucial ingredient of its recent successes. In its so-called reverse mode, it follows this sequence of operations in reverse order by systematically applying the chain rule to recover the exact value of derivative. Reverse mode automatic differentiation is implemented in Qadence leveraging the PyTorch <code>autograd</code> engine.</p> <p>Only available via the PyQTorch or Horqrux backends</p> <p>Currently, automatic differentiation mode is only available when the <code>pyqtorch</code> or <code>horqrux</code> backends are selected.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#generalized-parameter-shift-rule","title":"Generalized parameter shift rule","text":"<p>The generalized parameter shift rule implementation in Qadence was introduced in <sup>3</sup>. Here the standard parameter shift rules, which only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, was generalized to work with arbitrary generators of quantum operations.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\left\\{ \\lambda_n\\right\\}\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\(\\left\\{ \\Delta_s\\right\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> <p>\\(\\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation}\\)</p> <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> <p>\\(\\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation}\\)</p> <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#adjoint-differentiation","title":"Adjoint Differentiation","text":"<p>Qadence also offers a memory-efficient, non-device compatible alternative to automatic differentation, called 'Adjoint Differentiation' <sup>4</sup> and allows for precisely calculating the gradients of variational parameters in O(P) time and using O(1) state-vectors. Adjoint Differentation is currently only supported by the Torch Engine and allows for first-order derivatives only.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#usage","title":"Usage","text":""},{"location":"tutorials/advanced_tutorials/differentiability/#basics","title":"Basics","text":"<p>In Qadence, the differentiation modes can be selected via the <code>diff_mode</code> argument of the QuantumModel class. It either accepts a <code>DiffMode</code>(<code>DiffMode.GSPR</code>, <code>DiffMode.AD</code> or <code>DiffMode.ADJOINT</code>) or a string (<code>\"gpsr\"\"</code>, <code>\"ad\"</code> or <code>\"adjoint\"</code>). The code in the box below shows how to create <code>QuantumModel</code> instances with all available differentiation modes.</p> <pre><code>from qadence import (FeatureParameter, RX, Z, hea, chain,\n                    hamiltonian_factory, QuantumCircuit,\n                    QuantumModel, BackendName, DiffMode)\nimport torch\n\nn_qubits = 2\n\n# Define a symbolic parameter to differentiate with respect to\nx = FeatureParameter(\"x\")\n\nblock = chain(hea(n_qubits, 1), RX(0, x))\n\n# create quantum circuit\ncircuit = QuantumCircuit(n_qubits, block)\n\n# create total magnetization cost operator\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n\n# create models with AD, ADJOINT and GPSR differentiation engines\nmodel_ad = QuantumModel(circuit, obs,\n                        backend=BackendName.PYQTORCH,\n                        diff_mode=DiffMode.AD)\nmodel_adjoint = QuantumModel(circuit, obs,\n                        backend=BackendName.PYQTORCH,\n                        diff_mode=DiffMode.ADJOINT)\nmodel_gpsr = QuantumModel(circuit, obs,\n                          backend=BackendName.PYQTORCH,\n                          diff_mode=DiffMode.GPSR)\n\n# Create concrete values for the parameter we want to differentiate with respect to\nxs = torch.linspace(0, 2*torch.pi, 100, requires_grad=True)\nvalues = {\"x\": xs}\n\n# calculate function f(x)\nexp_val_ad = model_ad.expectation(values)\nexp_val_adjoint = model_adjoint.expectation(values)\nexp_val_gpsr = model_gpsr.expectation(values)\n\n# calculate derivative df/dx using the PyTorch\n# autograd engine\ndexpval_x_ad = torch.autograd.grad(\n    exp_val_ad, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_adjoint = torch.autograd.grad(\n    exp_val_adjoint, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_gpsr = torch.autograd.grad(\n    exp_val_gpsr, values[\"x\"], torch.ones_like(exp_val_gpsr), create_graph=True\n)[0]\n</code></pre> <p>We can plot the resulting derivatives and see that in both cases they coincide.</p> <pre><code>import matplotlib.pyplot as plt\n\n# plot f(x) and df/dx derivatives calculated using AD ,ADJOINT and GPSR\n# differentiation engines\nfig, ax = plt.subplots()\nax.scatter(xs.detach().numpy(),\n           exp_val_ad.detach().numpy(),\n           label=\"f(x)\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_ad.detach().numpy(),\n           label=\"df/dx AD\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_adjoint.detach().numpy(),\n           label=\"df/dx ADJOINT\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_gpsr.detach().numpy(),\n           s=5,\n           label=\"df/dx GPSR\")\nplt.legend()\n</code></pre> 2025-05-12T10:17:09.061696 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/advanced_tutorials/differentiability/#low-level-control-on-the-shift-values","title":"Low-level control on the shift values","text":"<p>In order to get a finer control over the GPSR differentiation engine we can use the low-level Qadence API to define a <code>DifferentiableBackend</code>.</p> <pre><code>from qadence.engines.torch import DifferentiableBackend\nfrom qadence.backends.pyqtorch import Backend as PyQBackend\n\n# define differentiable quantum backend\nquantum_backend = PyQBackend()\nconv = quantum_backend.convert(circuit, obs)\npyq_circ, pyq_obs, embedding_fn, params = conv\ndiff_backend = DifferentiableBackend(quantum_backend, diff_mode=DiffMode.GPSR, shift_prefac=0.2)\n\n# calculate function f(x)\nexpval = diff_backend.expectation(pyq_circ, pyq_obs, embedding_fn(params, values))\n</code></pre> <p>Here we passed an additional argument <code>shift_prefac</code> to the <code>DifferentiableBackend</code> instance that governs the magnitude of shifts \\(\\delta\\equiv\\alpha\\delta^\\prime\\) shown in equation (2) above. In this relation \\(\\delta^\\prime\\) is set internally and \\(\\alpha\\) is the value passed by <code>shift_prefac</code> and the resulting shift value \\(\\delta\\) is then used in all the following GPSR calculations.</p> <p>Tuning parameter \\(\\alpha\\) is useful to improve results when the generator \\(\\hat{G}\\) or the quantum operation is a dense matrix, for example a complex <code>HamEvo</code> operation; if many entries of this matrix are sufficiently larger than 0 the operation is equivalent to a strongly interacting system. In such case parameter \\(\\alpha\\) should be gradually lowered in order to achieve exact derivative values.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#low-level-differentiation-of-qadence-circuits-using-jax","title":"Low-level differentiation of qadence circuits using JAX","text":"<p>For users interested in using the <code>JAX</code> engine instead, we show how to run and differentiate qadence programs using the <code>horqrux</code> backend under qadence examples.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#parametrized-observable-differentiation","title":"Parametrized observable differentiation","text":"<p>To allow differentiating observable parameters only, we need to specify the <code>values</code> argument as a dictionary with one of the two keys <code>circuit</code> and <code>observables</code>, each being a dictionary of corresponding parameters and values:</p> <pre><code>parametric_obs = \"z\" * obs\nz = torch.tensor([2.0], requires_grad=True)\nvalues = {\"circuit\": {\"x\": xs}, \"observables\": {\"z\": z}}\n\nmodel_ad = QuantumModel(\n    circuit, parametric_obs, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD\n)\nexp_val_ad = model_ad.expectation(values)\n\ndexpval_z_ad = torch.autograd.grad(\n    exp_val_ad, z, torch.ones_like(exp_val_ad), create_graph=True\n)[0]\n</code></pre> <p>Only available via the PyQTorch backend</p> <p>Currently, differentiating with separated parameters is only possible when the <code>pyqtorch</code> backend is selected.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#differentiating-only-with-circuit-parameters","title":"Differentiating only with circuit parameters","text":"<p>We can also specify only the <code>circuit</code> key if the observable has no parameters.</p> <pre><code>obs = hamiltonian_factory(n_qubits, detuning=Z)\nxs = torch.linspace(0, 2*torch.pi, 100, requires_grad=True)\nvalues = {\"circuit\": {\"x\": xs}}\n\nmodel_ad = QuantumModel(\n    circuit, obs, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD\n)\nexp_val_ad = model_ad.expectation(values)\n\ndexpval_x_ad = torch.autograd.grad(\n    exp_val_ad, values[\"circuit\"][\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\n</code></pre>"},{"location":"tutorials/advanced_tutorials/differentiability/#differentiating-only-with-observable-parameters","title":"Differentiating only with observable parameters","text":"<p>We can also specify only the <code>observables</code> key if the circuit has no parameters.</p> <pre><code>block = chain(\n    hea(n_qubits, 1), RX(0, torch.rand(1, requires_grad=False))\n)\ncircuit = QuantumCircuit(n_qubits, block)\n\nparametric_obs = \"z\" * obs\nz = torch.tensor([2.0], requires_grad=True)\nvalues = {\"observables\": {\"z\": z}}\n\nmodel_ad = QuantumModel(\n    circuit, parametric_obs, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD\n)\nexp_val_ad = model_ad.expectation(values)\n\ndexpval_z_ad = torch.autograd.grad(\n    exp_val_ad,\n    values[\"observables\"][\"z\"],\n    torch.ones_like(exp_val_ad),\n    create_graph=True,\n)[0]\n</code></pre>"},{"location":"tutorials/advanced_tutorials/differentiability/#references","title":"References","text":"<ol> <li> <p>A. G. Baydin et al., Automatic Differentiation in Machine Learning: a Survey \u21a9\u21a9</p> </li> <li> <p>Schuld et al., Evaluating analytic gradients on quantum hardware (2018). \u21a9</p> </li> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9\u21a9</p> </li> <li> <p>Tyson et al., Efficient calculation of gradients in classical simulations of variational quantum algorithms \u21a9</p> </li> </ol>"},{"location":"tutorials/advanced_tutorials/profiling-and-debugging/","title":"Profiling and debugging on CUDA devices","text":"<p>For this to work, you'll have to have the right to access perf counters on your machine (for example with sudo or inside a Docker container). See: https://docs.nvidia.com/deeplearning/frameworks/dlprof-user-guide/index.html.</p> <pre><code>$ pip install nvidia-pyindex\n$ pip install nvidia-dlprof[pytorch]\n</code></pre> <p>Make sure that your entrypoint is an executable script. That means that it must start with a she-bang on the top line, e.g. <pre><code>#!/bin/python\n</code></pre> and have execution rights <pre><code>$ chmod +x your_script.py\n</code></pre></p> <p>Lastly it's recommended to add <pre><code>import nvidia_dlprof_pytorch_nvtx\nnvidia_dlprof_pytorch_nvtx.init()\n</code></pre> To your script in the beginning enable extra annotations of PyTorch functions.</p> <p>You can then use dlprof to profile. <pre><code>dlprof --mode=pytorch your_script.py\n</code></pre></p> <pre><code>PYQ_LOG_LEVEL=info QADENCE_LOG_LEVEL=debug dlprof --mode=pytorch examples/backends/differentiable_backend.py\n</code></pre> <p>For example to achieve this through Docker we can start a session in the shell, also mounting our local Qadence version and PyQTorch (Both optional, but you probably need to mount your script at least) <pre><code>$ docker run --rm --gpus=1 --shm-size=1g --ulimit memlock=-1 \\\n --ulimit stack=67108864 -it -p8000:8000 -v./:/opt/qadence -v ../PyQ:/opt/pyqtorch pytorch:24.02-py3 bash\n</code></pre> (You may need to jump through extra hoops to make Docker access the GPUs if you have error messages like <code>docker: Error response from daemon: could not select device driver \"\" with capabilities: [[gpu]].</code>)</p> <p>After this you should have a shell inside the container and you can <pre><code>root@2a85826c4e7b:/workspace# cd /opt/qadence/\nroot@2a85826c4e7b:/opt/qadence# pip3 install -e .\nroot@2a85826c4e7b:/opt/qadence# pip3 install -e ../pyqtorch/\nroot@2a85826c4e7b:/opt/qadence# pip3 install nvidia-dlprof[pytorch]\nroot@2a85826c4e7b:/opt/qadence# PYQ_LOG_LEVEL=debug QADENCE_LOG_LEVEL=debug dlprof --mode=pytorch --nsys_opts=\"-t cuda,nvtx,cublas,cusparse,cusparse-verbose,cublas-verbose --force-overwrite true\" examples/models/quantum_model.py\n</code></pre></p> <p>Where we have <code>--force-overwrite true</code> to always store the latest profiling result (hence you must rename the file) if you wish to keep several. We add <code>cublas,cusparse,cusparse-verbose,cublas-verbose</code> do get more details about the numerical backend pacakges being used.</p>"},{"location":"tutorials/advanced_tutorials/projectors/","title":"Projector blocks","text":"<p>This section introduces the <code>ProjectorBlock</code> as an implementation for the quantum mechanical projection operation onto the subspace spanned by \\(|a\\rangle\\): \\(\\mathbb{\\hat{P}}=|a\\rangle \\langle a|\\). It evaluates the outer product for bras and kets expressed as bitstrings for a given qubit support. They have to possess matching lengths.</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence.operations import Projector  # Projector as an operation.\n\n# Define a projector for |1&gt; onto the qubit labelled 0.\nprojector_block = Projector(ket=\"1\", bra=\"1\", qubit_support=0)\n\n# As any block, the matrix representation can be retrieved.\nprojector_matrix = block_to_tensor(projector_block)\n</code></pre> <pre><code>projector matrix = tensor([[[0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j]]])\n</code></pre> <p>Other standard operations are expressed as projectors in Qadence. For instance, the number operator is the projector onto the 1-subspace, \\(N=|1\\rangle\\langle 1|\\).</p> <p>In fact, projectors can be used to compose any arbitrary operator. For example, the <code>CNOT</code> can be defined as \\(\\textrm{CNOT}(i,j)=|0\\rangle\\langle 0|_i\\otimes \\mathbb{I}_j+|1\\rangle\\langle 1|_i\\otimes X_j\\) and we can compare its matrix representation with the native one in Qadence:</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence import kron, I, X, CNOT\n\n# Define a projector for |0&gt; onto the qubit labelled 0.\nprojector0 = Projector(ket=\"0\", bra=\"0\", qubit_support=0)\n\n# Define a projector for |1&gt; onto the qubit labelled 0.\nprojector1 = Projector(ket=\"1\", bra=\"1\", qubit_support=0)\n\n# Construct the projector controlled CNOT.\nprojector_cnot = kron(projector0, I(1)) + kron(projector1, X(1))\n\n# Get the underlying unitary.\nprojector_cnot_matrix = block_to_tensor(projector_cnot)\n\n# Qadence CNOT unitary.\nqadence_cnot_matrix = block_to_tensor(CNOT(0,1))\n</code></pre> <pre><code>projector cnot matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\nqadence cnot matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> <p>Another example is the canonical SWAP unitary that can be defined as \\(SWAP=|00\\rangle\\langle 00|+|01\\rangle\\langle 10|+|10\\rangle\\langle 01|+|11\\rangle\\langle 11|\\). Indeed, it can be shown that their matricial representations are again identical:</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence import SWAP\n\n# Define all projectors.\nprojector00 = Projector(ket=\"00\", bra=\"00\", qubit_support=(0, 1))\nprojector01 = Projector(ket=\"01\", bra=\"10\", qubit_support=(0, 1))\nprojector10 = Projector(ket=\"10\", bra=\"01\", qubit_support=(0, 1))\nprojector11 = Projector(ket=\"11\", bra=\"11\", qubit_support=(0, 1))\n\n# Construct the SWAP gate.\nprojector_swap = projector00 + projector10 + projector01 + projector11\n\n# Get the underlying unitary.\nprojector_swap_matrix = block_to_tensor(projector_swap)\n\n# Qadence SWAP unitary.\nqadence_swap_matrix = block_to_tensor(SWAP(0,1))\n</code></pre> <pre><code>projector swap matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]]])\nqadence swap matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]]], grad_fn=&lt;UnsafeViewBackward0&gt;)\n</code></pre> <p>Warning</p> <p>Projectors are non-unitary operators, only supported by the PyQTorch backend.</p> <p>To examplify this point, let's run some non-unitary computation involving projectors.</p> <pre><code>from qadence import chain, run\nfrom qadence.operations import H, CNOT\n\n# Define a projector for |1&gt; onto the qubit labelled 1.\nprojector_block = Projector(ket=\"1\", bra=\"1\", qubit_support=1)\n\n# Some non-unitary computation.\nnon_unitary_block = chain(H(0), CNOT(0,1), projector_block)\n\n# Projected wavefunction becomes unnormalized\nprojected_wf = run(non_unitary_block)  # Run on PyQTorch.\n</code></pre> <pre><code>projected_wf = tensor([[0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre>"},{"location":"tutorials/development/architecture/","title":"Architecture and sharp bits","text":"<p>Qadence as a software library mixes functional and object-oriented programming. We do that by maintaining core objects and operating on them with functions.</p> <p>Furthermore, Qadence strives at keeping the lower level abstraction layers for automatic differentiation and quantum computation fully stateless while only the frontend layer which is the main user-facing interface is stateful.</p> <p>Code design philosopy</p> <p>Functional, stateless core with object-oriented, stateful user interface.</p>"},{"location":"tutorials/development/architecture/#abstraction-layers","title":"Abstraction layers","text":"<p>In Qadence there are 4 main objects spread across 3 different levels of abstraction:</p> <ul> <li> <p>Frontend layer: The user facing layer and encompasses two objects:</p> <ul> <li><code>QuantumCircuit</code>: A class representing an abstract quantum   circuit not tight not any particular framework. Parameters are represented symbolically using   <code>sympy</code> expressions.</li> <li><code>QuantumModel</code>: The models are higher-level abstraction   providing an interface for executing different kinds of common quantum computing models such   quantum neural networks (QNNs), quantum kernels etc.</li> </ul> </li> <li> <p>Differentiation layer: Intermediate layer has the purpose of integrating quantum   computation with a given automatic differentiation engine. It is meant to be purely stateless and   contains one object:</p> <ul> <li><code>DifferentiableBackend</code>:   An abstract class whose concrete implementation wraps a quantum backend and make it   automatically differentiable using different engines (e.g. PyTorch or Jax).   Note, that today only PyTorch is supported but there is plan to add also a Jax   differentiable backend which will require some changes in the base class implementation.</li> </ul> </li> <li> <p>Quantum layer: The lower-level layer which directly interfaces with quantum emulators   and processing units. It is meant to be purely stateless and it contains one base object which is   specialized for each supported backend:</p> <ul> <li><code>Backend</code>: An abstract class whose concrete implementation   enables the execution of quantum circuit with a variety of quantum backends (normally non   automatically differentiable by default) such as PyQTorch, or Pulser.</li> </ul> </li> </ul>"},{"location":"tutorials/development/architecture/#main-components","title":"Main components","text":""},{"location":"tutorials/development/architecture/#quantumcircuit","title":"<code>QuantumCircuit</code>","text":"<p>We consider <code>QuantumCircuit</code> to be an abstract object, i.e. it is not tied to any backend. However, it blocks are even more abstract. This is because we consider <code>QuantumCircuit</code>s \"real\", whereas the blocks are largely considered just syntax.</p> <p>Unitary <code>QuantumCircuits</code> (this encompasses digital, or gate-based, circuits as well as analog circuits) are constructed by [<code>PrimitiveBlocks</code>] using a syntax that allows you to execute them in sequence, dubbed <code>ChainBlock</code> in the code, or in parallel (i.e. at the same time) where applicable, dubbed <code>KronBlock</code> in the code. Notice that this differs from other packages by providing more control of the layout of the circuit than conventional packages like Qiskit, and from Yao where the blocks are the primary type.</p>"},{"location":"tutorials/development/architecture/#quantummodel","title":"<code>QuantumModel</code>","text":"<p><code>QuantumModel</code>s are meant to be the main entry point for quantum computations in <code>qadence</code>. In general, they take one or more quantum circuit as input and they wrap all the necessary boiler plate code to make the circuit executable and differentiable on the chosen backend.</p> <p>Models are meant to be specific for a certain kind of quantum problem or algorithm and you can easily create new ones starting from the base class <code>QuantumModel</code>, as explained in the custom model tutorial. Currently, Qadence offers a <code>QNN</code> model class which provides convenient methods to work with quantum neural networks with multi-dimensional inputs and outputs.</p>"},{"location":"tutorials/development/architecture/#differentiablebackend","title":"<code>DifferentiableBackend</code>","text":"<p>The differentiable backend is a thin wrapper which takes as input a <code>QuantumCircuit</code> instance and a chosen quantum backend and make the circuit execution routines (expectation value, overalap, etc.) differentiable. Qadence offers both a PyTorch and Jax differentiation engine.</p>"},{"location":"tutorials/development/architecture/#quantum-backend","title":"Quantum <code>Backend</code>","text":"<p>For execution the primary object is the <code>Backend</code>. Backends maintain the same user-facing interface, and internally connects to other libraries to execute circuits. Those other libraries can execute the code on QPUs and local or cloud-based emulators. The <code>Backends</code> use PyTorch tensors to represent data and leverages PyTorchs autograd to help compute derivatives of circuits.</p>"},{"location":"tutorials/development/architecture/#symbolic-parameters","title":"Symbolic parameters","text":"<p>To illustrate how parameters work in Qadence, let's consider the following simple block composed of just two rotations:</p> <pre><code>import sympy\nfrom qadence import Parameter, RX\n\nparam = Parameter(\"phi\", trainable=False)\nblock = RX(0, param) * RX(1, sympy.acos(param))\n</code></pre> <p>The rotation angles assigned to <code>RX</code> (and to any Qadence quantum operation) are defined as arbitrary expressions of <code>Parameter</code>'s. <code>Parameter</code> is a subclass of <code>sympy.Symbol</code>, thus fully interoperable with it.</p> <p>To assign values of the parameter <code>phi</code> in a quantum model, one should use a dictionary containing the a key with parameter name and the corresponding values values:</p> <pre><code>import torch\nfrom qadence import run\n\nvalues = {\"phi\": torch.rand(10)}\nwf = run(block, values=values)\n</code></pre> <p>This is the only interface for parameter assignment exposed to the user. Under the hood, parameters applied to every quantum operation are identified in different ways:</p> <ul> <li> <p>By default, with a stringified version of the <code>sympy</code> expression supplied to the quantum operation. Notice that multiple operations can have the same expression.</p> </li> <li> <p>In certain case, e.g. for constructing parameter shift rules, one must access a unique identifier of the parameter for each quantum operation. Therefore, Qadence also creates unique identifiers for each parametrized operation (see the <code>ParamMap</code> class).</p> </li> </ul> <p>By default, when one constructs a new backend, the parameter identifiers are the <code>sympy</code> expressions which are used when converting an abstract block into a native circuit for the chosen backend. However, one can use the unique identifiers as parameter names by setting the private flag <code>_use_gate_params</code> to <code>True</code> in the backend configuration <code>BackendConfiguration</code>. This is automatically set when PSR differentiation is selected (see next section for more details).</p> <p>You can see the logic for choosing the parameter identifier in <code>get_param_name</code>.</p>"},{"location":"tutorials/development/architecture/#differentiation-with-parameter-shift-rules-psr","title":"Differentiation with parameter shift rules (PSR)","text":"<p>In Qadence, parameter shift rules are applied by implementing a custom <code>torch.autograd.Function</code> class for PyTorch and the <code>custom_vjp</code> in the Jax Engine, respectively.</p> <p>A custom PyTorch <code>Function</code> looks like this:</p> <pre><code>import torch\nfrom torch.autograd import Function\n\nclass CustomFunction(Function):\n\n    # forward pass implementation giving the output of the module\n    @staticmethod\n    def forward(ctx, inputs: torch.Tensor, params: torch.Tensor):\n        ctx.save_for_backward(inputs, params)\n        ...\n\n    # backward pass implementation giving the derivative of the module\n    # with respect to the parameters. This must return the whole vector-jacobian\n    # product to integrate within the autograd engine\n    @staticmethod\n    def backward(ctx, grad_output: torch.Tensor):\n        inputs, params = ctx.saved_tensors\n        ...\n</code></pre> <p>The class <code>PSRExpectation</code> under <code>qadence.engines.torch.differentiable_expectation</code> implements parameter shift rules for all parameters using a custom function as the one above. There are a few implementation details to keep in mind if you want to modify the PSR code:</p> <ul> <li> <p>PyTorch <code>Function</code> only works with tensor arguments. Parameters in Qadence are passed around as   dictionaries with parameter names as keys and current parameter values (tensors)   as values. This works for both variational and feature parameters. However, the <code>Function</code> class   only work with PyTorch tensors as input, not dictionaries. Therefore, the forward pass of   <code>PSRExpectation</code> accepts one argument <code>param_keys</code> with the   parameter keys and a variadic positional argument <code>param_values</code> with the parameter values one by   one. The dictionary is reconstructed within the <code>forward()</code> pass body.</p> </li> <li> <p>Higher-order derivatives with PSR. Higher-order PSR derivatives can be tricky. Parameter shift   rules calls, under the hood, the <code>QuantumBackend</code> expectation value routine that usually yield a   non-differentiable output. Therefore, a second call to the backward pass would not work. However,   Qadence employs a very simple trick to make higher-order derivatives work: instead of using   directly the expectation value of the quantum backend, the PSR backward pass uses the PSR forward   pass itself as expectation value function (see the code below). In this way, multiple calls to the   backward pass are allowed since the <code>expectation_fn</code> routine is always differentiable by   definition. Notice that this implementation is simple but suboptimal since, in some corner cases,   higher-order derivates might include some repeated terms that, with this implementation, are   always recomputed.</p> </li> </ul> <pre><code># expectation value used in the PSR backward pass\ndef expectation_fn(params: dict[str, Tensor]) -&gt; Tensor:\n    return PSRExpectation.apply(\n        ctx.expectation_fn,\n        ctx.param_psrs,\n        params.keys(),\n        *params.values(),\n    )\n</code></pre> <ul> <li> <p>Operation parameters must be uniquely identified for PSR to work. Parameter shift rules work at the level of individual quantum operations. This means that, given a parameter <code>x</code>, one needs to sum the contributions from shifting the parameter values of all the operation where the parameter <code>x</code> appears. When constructing the PSR rules, one must access a unique parameter identifier for each operation even if the corresponding user-facing parameter is the same. Therefore, when PSR differentiation is selected, the flag <code>_use_gate_params</code> is automatically set to <code>True</code> in the backend configuration <code>BackendConfiguration</code> (see previous section).</p> </li> <li> <p>PSR must not be applied to observable parameters. In Qadence, Pauli observables can also be parametrized. However, the tunable parameters of observables are purely classical and should not be included in the differentiation with PSRs. However, the quantum expectation value depends on them, thus they still need to enter into the PSR evaluation. To solve this issue, the code sets the <code>requires_grad</code> attribute of all observable parameters to <code>False</code> when constructing the PSRs for the circuit as in the snippet below:</p> </li> </ul> <pre><code>for obs in observable:\n    for param_id, _ in uuid_to_eigen(obs).items():\n        param_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\n</code></pre>"},{"location":"tutorials/development/draw/","title":"<code>qadence.draw</code> example plots","text":"<p>Mostly for quick, manual checking of correct plotting output.</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\n</code></pre> %3 d66389610169455e90a2bccb0306e422 0 e8386bdd26ff41caa9291f25d1d608b1 X d66389610169455e90a2bccb0306e422--e8386bdd26ff41caa9291f25d1d608b1 287f87305c8344229d76afc6aea3610d 1 c927a3dedb2b40c2ae2a08a15ef767e7 e8386bdd26ff41caa9291f25d1d608b1--c927a3dedb2b40c2ae2a08a15ef767e7 40fd501fa2a342389a46404c3ba92e81 59d6d000f15644e8b084a7a6f5d9acf7 Y 287f87305c8344229d76afc6aea3610d--59d6d000f15644e8b084a7a6f5d9acf7 59d6d000f15644e8b084a7a6f5d9acf7--40fd501fa2a342389a46404c3ba92e81 <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\n\nb = chain(X(0), Y(0))\n</code></pre> %3 d717d83f3d624c229ac3049806333eb8 0 775e38b582c44a8d92ec831be3ab7af5 X d717d83f3d624c229ac3049806333eb8--775e38b582c44a8d92ec831be3ab7af5 10c07a57b39641e1a4548949bb5428da Y 775e38b582c44a8d92ec831be3ab7af5--10c07a57b39641e1a4548949bb5428da 5fa429581bec4b7ba07e7f7e0f20d933 10c07a57b39641e1a4548949bb5428da--5fa429581bec4b7ba07e7f7e0f20d933 <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\n\nb = chain(X(0), Y(1))\n</code></pre> %3 ed88e7a3b565464485b336dde897cd4e 0 ddc4e78b7c4e43e2bb1b02e1f1da5f6f X ed88e7a3b565464485b336dde897cd4e--ddc4e78b7c4e43e2bb1b02e1f1da5f6f 4391fdcf48b5405789a3922acace3f8f 1 9493a614b4b94ff692a1c77c50b4c88f ddc4e78b7c4e43e2bb1b02e1f1da5f6f--9493a614b4b94ff692a1c77c50b4c88f fef25cc4602c4139ad423532a61ea2e3 9493a614b4b94ff692a1c77c50b4c88f--fef25cc4602c4139ad423532a61ea2e3 0e1d584286294c718582835a7fd7e311 0c7a76de5abe4b6e997b8233ba5f715d 4391fdcf48b5405789a3922acace3f8f--0c7a76de5abe4b6e997b8233ba5f715d 3ad48618c1214fdd9082c0d893574222 Y 0c7a76de5abe4b6e997b8233ba5f715d--3ad48618c1214fdd9082c0d893574222 3ad48618c1214fdd9082c0d893574222--0e1d584286294c718582835a7fd7e311 <pre><code>from qadence import X, Y, add\nfrom qadence.draw import display\n\nb = add(X(0), Y(1), X(2))\n</code></pre> %3 cluster_d84ad78bb0ba45c6904a5ac7bb21e90d 8f18ea3dee92470eb5dcf9bbe1fe987e 0 6fc689545dba4c49b3c4fd5c051471d2 8f18ea3dee92470eb5dcf9bbe1fe987e--6fc689545dba4c49b3c4fd5c051471d2 7d954b523a3b46e0b23514088f6007ba 1 f3a6d9d4323e412487952e1f8eaa12c9 6fc689545dba4c49b3c4fd5c051471d2--f3a6d9d4323e412487952e1f8eaa12c9 842f4ab03eed4342a93f3480b41f77af 9aeafc8818424e73bd38b4c2e445d77b AddBlock 7d954b523a3b46e0b23514088f6007ba--9aeafc8818424e73bd38b4c2e445d77b 75676125fc984a1ba585bbe809a114f3 2 9aeafc8818424e73bd38b4c2e445d77b--842f4ab03eed4342a93f3480b41f77af 4b3b32b8ebe8446f8733376703ff053b e33e6d75c6694f71ba347883616dba60 75676125fc984a1ba585bbe809a114f3--e33e6d75c6694f71ba347883616dba60 e33e6d75c6694f71ba347883616dba60--4b3b32b8ebe8446f8733376703ff053b <pre><code>from qadence import CNOT, RX, HamEvo, X, Y, Z, chain, kron\n\nrx = kron(RX(3,0.5), RX(2, \"x\"))\nrx.tag = \"rx\"\ngen = chain(Z(i) for i in range(4))\n\n# `chain` puts things in sequence\nblock = chain(\n    kron(X(0), Y(1), rx),\n    CNOT(2,3),\n    HamEvo(gen, 10)\n)\n</code></pre> %3 cluster_9567ffd434444d9dbb3b9ff3b8a91b40 cluster_e47f83a192ae443e8bedef0210eb955c rx d9124056732c4718b4ccb9863b16db43 0 41e0214593f54408a5554185ac16acfa X d9124056732c4718b4ccb9863b16db43--41e0214593f54408a5554185ac16acfa 2885f4833fb9498e8b7fa7f70436d1cd 1 c82c4025deb649648f68e2dbb546e722 41e0214593f54408a5554185ac16acfa--c82c4025deb649648f68e2dbb546e722 1e2730828dd3412bb832a4f7cfe32b2a c82c4025deb649648f68e2dbb546e722--1e2730828dd3412bb832a4f7cfe32b2a daf3c5933fdf47a0b05928522bd8b376 1e2730828dd3412bb832a4f7cfe32b2a--daf3c5933fdf47a0b05928522bd8b376 629c4e250b2d4f328330d7693c97e7a1 bb9d379d54554a2fac0e80f7ec9611ce Y 2885f4833fb9498e8b7fa7f70436d1cd--bb9d379d54554a2fac0e80f7ec9611ce 4d77aa3f4a6640878f8739845efdda6a 2 c0e869f756634b4aa4475dfb063ca0c5 bb9d379d54554a2fac0e80f7ec9611ce--c0e869f756634b4aa4475dfb063ca0c5 15d014206c9e484d8b6cd56d071340d5 HamEvo c0e869f756634b4aa4475dfb063ca0c5--15d014206c9e484d8b6cd56d071340d5 15d014206c9e484d8b6cd56d071340d5--629c4e250b2d4f328330d7693c97e7a1 5561e8fa78ed462c877c6b95c783b9bb eda7de2b01ab4a5c9172e34f82d82922 RX(x) 4d77aa3f4a6640878f8739845efdda6a--eda7de2b01ab4a5c9172e34f82d82922 d09c0849a02a4540803e506656a6fd55 3 c700b0a9cf3e4e0794f569378bcd8cb5 eda7de2b01ab4a5c9172e34f82d82922--c700b0a9cf3e4e0794f569378bcd8cb5 33c7c50431724c6e9e25adcb6f4db5dd t = 10 c700b0a9cf3e4e0794f569378bcd8cb5--33c7c50431724c6e9e25adcb6f4db5dd 33c7c50431724c6e9e25adcb6f4db5dd--5561e8fa78ed462c877c6b95c783b9bb e6eb498f01f24ee9887aee49b42fe61a d7b22840fb65442d9f97322ca0b4ae3b RX(0.5) d09c0849a02a4540803e506656a6fd55--d7b22840fb65442d9f97322ca0b4ae3b 247ace5d1b3d456b9bcd3bcf4e2da07a X d7b22840fb65442d9f97322ca0b4ae3b--247ace5d1b3d456b9bcd3bcf4e2da07a 247ace5d1b3d456b9bcd3bcf4e2da07a--c700b0a9cf3e4e0794f569378bcd8cb5 1e532f10473240ef94943560c58b5fdc 247ace5d1b3d456b9bcd3bcf4e2da07a--1e532f10473240ef94943560c58b5fdc 1e532f10473240ef94943560c58b5fdc--e6eb498f01f24ee9887aee49b42fe61a <pre><code>from qadence import feature_map, hea, chain\n\nblock = chain(feature_map(4, reupload_scaling=\"Tower\"), hea(4,2))\n</code></pre> %3 cluster_6a29ff9f4e7a4facbfa12273fab1e0d9 HEA cluster_5ccc2de578a54bff860066399f58788e Tower Fourier FM 84d500b827fb48e79ebc108617815708 0 e4581187cfa94c14b46725cdc003b67e RX(1.0*phi) 84d500b827fb48e79ebc108617815708--e4581187cfa94c14b46725cdc003b67e dc391a5fe5d34523baf3abd20b1151cc 1 5a9604cce24c4e85b6998362bb284922 RX(theta\u2080) e4581187cfa94c14b46725cdc003b67e--5a9604cce24c4e85b6998362bb284922 d4e2218217fe4941a844cf0913429286 RY(theta\u2084) 5a9604cce24c4e85b6998362bb284922--d4e2218217fe4941a844cf0913429286 44e4404328654239bf7d627213ebe9c1 RX(theta\u2088) d4e2218217fe4941a844cf0913429286--44e4404328654239bf7d627213ebe9c1 55afd4773a08409aa6d51d93658d6c17 44e4404328654239bf7d627213ebe9c1--55afd4773a08409aa6d51d93658d6c17 abf1b33550bc4c5594fa55db9300311e 55afd4773a08409aa6d51d93658d6c17--abf1b33550bc4c5594fa55db9300311e f7a65bcceb7d45be841aa05f208fe10b RX(theta\u2081\u2082) abf1b33550bc4c5594fa55db9300311e--f7a65bcceb7d45be841aa05f208fe10b c6fbb6de30744f1a92cccf8ba6c51c63 RY(theta\u2081\u2086) f7a65bcceb7d45be841aa05f208fe10b--c6fbb6de30744f1a92cccf8ba6c51c63 8e98056ed4a14d8982dc9680ee79fbbc RX(theta\u2082\u2080) c6fbb6de30744f1a92cccf8ba6c51c63--8e98056ed4a14d8982dc9680ee79fbbc 3fddf2dd054c41c294155c93bda9a17e 8e98056ed4a14d8982dc9680ee79fbbc--3fddf2dd054c41c294155c93bda9a17e 8407d22db15a4afd8da8e5ec2cc732ef 3fddf2dd054c41c294155c93bda9a17e--8407d22db15a4afd8da8e5ec2cc732ef 8115fc211ab54c76bcc216fe3b34b9c2 8407d22db15a4afd8da8e5ec2cc732ef--8115fc211ab54c76bcc216fe3b34b9c2 28320fd1ac66464091644e77a0bc054a c466ac4bc1ec4a77aee15b7df6618de2 RX(2.0*phi) dc391a5fe5d34523baf3abd20b1151cc--c466ac4bc1ec4a77aee15b7df6618de2 b356827202e54078af290d7807263fa8 2 d422441eae9a4dbba56e74dd55f88ac0 RX(theta\u2081) c466ac4bc1ec4a77aee15b7df6618de2--d422441eae9a4dbba56e74dd55f88ac0 5cc5cc39337a4f40a053cb36f1852e82 RY(theta\u2085) d422441eae9a4dbba56e74dd55f88ac0--5cc5cc39337a4f40a053cb36f1852e82 b49b975d77bb421fa63a82da73e9e185 RX(theta\u2089) 5cc5cc39337a4f40a053cb36f1852e82--b49b975d77bb421fa63a82da73e9e185 82052471f3804bbaa26a87767bc37a91 X b49b975d77bb421fa63a82da73e9e185--82052471f3804bbaa26a87767bc37a91 82052471f3804bbaa26a87767bc37a91--55afd4773a08409aa6d51d93658d6c17 2d371f9e703041ca8b89fafd1f9ea603 82052471f3804bbaa26a87767bc37a91--2d371f9e703041ca8b89fafd1f9ea603 bfbd5cf7a33b450994e2dbee41f661fb RX(theta\u2081\u2083) 2d371f9e703041ca8b89fafd1f9ea603--bfbd5cf7a33b450994e2dbee41f661fb 8e93366490224b61b84d5dcc0c208028 RY(theta\u2081\u2087) bfbd5cf7a33b450994e2dbee41f661fb--8e93366490224b61b84d5dcc0c208028 f1c1fb8e4e25471e8c0e37685501b7df RX(theta\u2082\u2081) 8e93366490224b61b84d5dcc0c208028--f1c1fb8e4e25471e8c0e37685501b7df 69b474117163457391eeaa4fd386606c X f1c1fb8e4e25471e8c0e37685501b7df--69b474117163457391eeaa4fd386606c 69b474117163457391eeaa4fd386606c--3fddf2dd054c41c294155c93bda9a17e 1de72c5a573f46618004c21e0edb6c52 69b474117163457391eeaa4fd386606c--1de72c5a573f46618004c21e0edb6c52 1de72c5a573f46618004c21e0edb6c52--28320fd1ac66464091644e77a0bc054a 22077de29a8a4deeadefcb40d05cd295 bbf3691d667c46c4a90e43e126865992 RX(3.0*phi) b356827202e54078af290d7807263fa8--bbf3691d667c46c4a90e43e126865992 34f29064f8d9425385745cd68ab98a69 3 7885a0c466674b96a3369d92d903cf70 RX(theta\u2082) bbf3691d667c46c4a90e43e126865992--7885a0c466674b96a3369d92d903cf70 1f5d3313c733450690be27d9cd193ade RY(theta\u2086) 7885a0c466674b96a3369d92d903cf70--1f5d3313c733450690be27d9cd193ade 2311b3d1bc0244308b6a7c6485ce9a49 RX(theta\u2081\u2080) 1f5d3313c733450690be27d9cd193ade--2311b3d1bc0244308b6a7c6485ce9a49 55eac790dbf144d7bffac43f7b9ad27f 2311b3d1bc0244308b6a7c6485ce9a49--55eac790dbf144d7bffac43f7b9ad27f 5d6e59f2f271411198620aab99e7f4e9 X 55eac790dbf144d7bffac43f7b9ad27f--5d6e59f2f271411198620aab99e7f4e9 5d6e59f2f271411198620aab99e7f4e9--2d371f9e703041ca8b89fafd1f9ea603 6fe5e1dab49d43d7a077dbc608681019 RX(theta\u2081\u2084) 5d6e59f2f271411198620aab99e7f4e9--6fe5e1dab49d43d7a077dbc608681019 23436408275e4385a9d78c5f85835740 RY(theta\u2081\u2088) 6fe5e1dab49d43d7a077dbc608681019--23436408275e4385a9d78c5f85835740 4829188d88d543ea842f3a40eec0830a RX(theta\u2082\u2082) 23436408275e4385a9d78c5f85835740--4829188d88d543ea842f3a40eec0830a f87dc24cc8da47d1afe9ebd64ad02b2f 4829188d88d543ea842f3a40eec0830a--f87dc24cc8da47d1afe9ebd64ad02b2f 1a947255eb7c42a3b589c387bd8cb6c1 X f87dc24cc8da47d1afe9ebd64ad02b2f--1a947255eb7c42a3b589c387bd8cb6c1 1a947255eb7c42a3b589c387bd8cb6c1--1de72c5a573f46618004c21e0edb6c52 1a947255eb7c42a3b589c387bd8cb6c1--22077de29a8a4deeadefcb40d05cd295 14ae3cc07fff4ccb80def03a9856b4a9 d618f233a7364651aaf309eae0e0d63c RX(4.0*phi) 34f29064f8d9425385745cd68ab98a69--d618f233a7364651aaf309eae0e0d63c 0b9f446078f1430fb1704c249222c056 RX(theta\u2083) d618f233a7364651aaf309eae0e0d63c--0b9f446078f1430fb1704c249222c056 b06d79559bc2436082ad1e85ef424f1c RY(theta\u2087) 0b9f446078f1430fb1704c249222c056--b06d79559bc2436082ad1e85ef424f1c 1a744b6e23804a95a6a8977b95b2b1cf RX(theta\u2081\u2081) b06d79559bc2436082ad1e85ef424f1c--1a744b6e23804a95a6a8977b95b2b1cf b20dcaba858c4b6487ceb5dc0c976f9b X 1a744b6e23804a95a6a8977b95b2b1cf--b20dcaba858c4b6487ceb5dc0c976f9b b20dcaba858c4b6487ceb5dc0c976f9b--55eac790dbf144d7bffac43f7b9ad27f a33f125068e045c4b3cf6d9bd22db98d b20dcaba858c4b6487ceb5dc0c976f9b--a33f125068e045c4b3cf6d9bd22db98d f1616c06bb454610b80d10f958e0fa8a RX(theta\u2081\u2085) a33f125068e045c4b3cf6d9bd22db98d--f1616c06bb454610b80d10f958e0fa8a 436b01b2f2844b6f89748acd1b7d8732 RY(theta\u2081\u2089) f1616c06bb454610b80d10f958e0fa8a--436b01b2f2844b6f89748acd1b7d8732 526e8577bc5e49adbe37be972b47ed62 RX(theta\u2082\u2083) 436b01b2f2844b6f89748acd1b7d8732--526e8577bc5e49adbe37be972b47ed62 03db57457a7048709589f3704c7a1125 X 526e8577bc5e49adbe37be972b47ed62--03db57457a7048709589f3704c7a1125 03db57457a7048709589f3704c7a1125--f87dc24cc8da47d1afe9ebd64ad02b2f 228e989b302e4cf4a5a078801335eeba 03db57457a7048709589f3704c7a1125--228e989b302e4cf4a5a078801335eeba 228e989b302e4cf4a5a078801335eeba--14ae3cc07fff4ccb80def03a9856b4a9 <pre><code>from qadence import QuantumModel, QuantumCircuit, total_magnetization, hea\n\nmodel = QuantumModel(QuantumCircuit(3, hea(3,2)), total_magnetization(3))\n</code></pre> %3 cluster_439542b5e145489cbe8a47f7759e3338 Obs. cluster_628e919401404a128a128d624c79acad cluster_61c650be8ab44beb9676805e8fb5c8f1 HEA e3ea3d7f54094e00880c02839864abc4 0 54c1fb6a785b4c44863fc6c6c48196c4 RX(theta\u2080) e3ea3d7f54094e00880c02839864abc4--54c1fb6a785b4c44863fc6c6c48196c4 fe050bc59516478aaa82005fe338a80d 1 550acbab1e004aa59ccf083f2c003af0 RY(theta\u2083) 54c1fb6a785b4c44863fc6c6c48196c4--550acbab1e004aa59ccf083f2c003af0 ee992cdfe85e467ab5dbaeebacd6e66e RX(theta\u2086) 550acbab1e004aa59ccf083f2c003af0--ee992cdfe85e467ab5dbaeebacd6e66e 0cf00ad113ee41a5aca9c2ca7a99feb7 ee992cdfe85e467ab5dbaeebacd6e66e--0cf00ad113ee41a5aca9c2ca7a99feb7 c0bf70085832401c92a34c0ea3dc40ba 0cf00ad113ee41a5aca9c2ca7a99feb7--c0bf70085832401c92a34c0ea3dc40ba ac859b42a3714410ae4538947fb6e94a RX(theta\u2089) c0bf70085832401c92a34c0ea3dc40ba--ac859b42a3714410ae4538947fb6e94a c059865d9a234a5d84784986b197a4f0 RY(theta\u2081\u2082) ac859b42a3714410ae4538947fb6e94a--c059865d9a234a5d84784986b197a4f0 4d774394667b4edcaa3f462e0e9e36a5 RX(theta\u2081\u2085) c059865d9a234a5d84784986b197a4f0--4d774394667b4edcaa3f462e0e9e36a5 2fa7d683c2164fb7af564c56685b0422 4d774394667b4edcaa3f462e0e9e36a5--2fa7d683c2164fb7af564c56685b0422 377247eb46be4c4c986cfaaf4649331c 2fa7d683c2164fb7af564c56685b0422--377247eb46be4c4c986cfaaf4649331c 5027ceb33629494cb4a1a4b3d2f951ad 377247eb46be4c4c986cfaaf4649331c--5027ceb33629494cb4a1a4b3d2f951ad 9d3b12ce71fc4f54b852d81612994b42 5027ceb33629494cb4a1a4b3d2f951ad--9d3b12ce71fc4f54b852d81612994b42 f8e67b67e35147e184b2cd49b8439ea3 3eac8800427f429bbfd14b63e7da5f13 RX(theta\u2081) fe050bc59516478aaa82005fe338a80d--3eac8800427f429bbfd14b63e7da5f13 b42f54b6cf504a93ac7ed6c0d4b37572 2 223cc6a9716b4f6293aea46c3ac2e492 RY(theta\u2084) 3eac8800427f429bbfd14b63e7da5f13--223cc6a9716b4f6293aea46c3ac2e492 e663cc94ac65455396dd56d92d8ad332 RX(theta\u2087) 223cc6a9716b4f6293aea46c3ac2e492--e663cc94ac65455396dd56d92d8ad332 b9974a227fc940fd8fc735df43b75cb7 X e663cc94ac65455396dd56d92d8ad332--b9974a227fc940fd8fc735df43b75cb7 b9974a227fc940fd8fc735df43b75cb7--0cf00ad113ee41a5aca9c2ca7a99feb7 4d2d126565394058a6fd711a57ef9f62 b9974a227fc940fd8fc735df43b75cb7--4d2d126565394058a6fd711a57ef9f62 74e366d99be047d3a54b9cf010433100 RX(theta\u2081\u2080) 4d2d126565394058a6fd711a57ef9f62--74e366d99be047d3a54b9cf010433100 06cad5bac7aa4f4687a70b6f2d61a6ca RY(theta\u2081\u2083) 74e366d99be047d3a54b9cf010433100--06cad5bac7aa4f4687a70b6f2d61a6ca e831d72d5f814b1e88caf5d7f6d1bc09 RX(theta\u2081\u2086) 06cad5bac7aa4f4687a70b6f2d61a6ca--e831d72d5f814b1e88caf5d7f6d1bc09 a67762baf337497f8b1d7533a70be3b4 X e831d72d5f814b1e88caf5d7f6d1bc09--a67762baf337497f8b1d7533a70be3b4 a67762baf337497f8b1d7533a70be3b4--2fa7d683c2164fb7af564c56685b0422 1df1295f47b6434ea9b223646060e9cc a67762baf337497f8b1d7533a70be3b4--1df1295f47b6434ea9b223646060e9cc 1a88fdbd39df43c3a5e84a78f888395f AddBlock 1df1295f47b6434ea9b223646060e9cc--1a88fdbd39df43c3a5e84a78f888395f 1a88fdbd39df43c3a5e84a78f888395f--f8e67b67e35147e184b2cd49b8439ea3 c933f6bfb28348e9b3271b2ea460d823 a253b4f577454a6ebbf7cc7af028ff81 RX(theta\u2082) b42f54b6cf504a93ac7ed6c0d4b37572--a253b4f577454a6ebbf7cc7af028ff81 9781ffd6da984f67acba80264ad04bc4 RY(theta\u2085) a253b4f577454a6ebbf7cc7af028ff81--9781ffd6da984f67acba80264ad04bc4 7594a098858c4fb2a140739a3aa8cb53 RX(theta\u2088) 9781ffd6da984f67acba80264ad04bc4--7594a098858c4fb2a140739a3aa8cb53 f46f3652a60e47ac81215a35e3db6d7b 7594a098858c4fb2a140739a3aa8cb53--f46f3652a60e47ac81215a35e3db6d7b 5d85ad7544db44ddb11a4dc81c3d71c3 X f46f3652a60e47ac81215a35e3db6d7b--5d85ad7544db44ddb11a4dc81c3d71c3 5d85ad7544db44ddb11a4dc81c3d71c3--4d2d126565394058a6fd711a57ef9f62 55b8fa6856b341d89aea06b88287cef8 RX(theta\u2081\u2081) 5d85ad7544db44ddb11a4dc81c3d71c3--55b8fa6856b341d89aea06b88287cef8 11cc4c1bda0b47518648b2a6538d78cd RY(theta\u2081\u2084) 55b8fa6856b341d89aea06b88287cef8--11cc4c1bda0b47518648b2a6538d78cd 965dea99dcdb487fb0fe3e574aebb613 RX(theta\u2081\u2087) 11cc4c1bda0b47518648b2a6538d78cd--965dea99dcdb487fb0fe3e574aebb613 259054af9da0495993441e8a2e47875f 965dea99dcdb487fb0fe3e574aebb613--259054af9da0495993441e8a2e47875f cb498311a7294687a272b029703fd644 X 259054af9da0495993441e8a2e47875f--cb498311a7294687a272b029703fd644 cb498311a7294687a272b029703fd644--1df1295f47b6434ea9b223646060e9cc d2aaad1f6327444693f091ae505c54fa cb498311a7294687a272b029703fd644--d2aaad1f6327444693f091ae505c54fa d2aaad1f6327444693f091ae505c54fa--c933f6bfb28348e9b3271b2ea460d823 <pre><code>from qadence import *\n\nb = chain(SWAP(0,1), SWAP(0,3))\n</code></pre> %3 f97ee7d5e7aa478eb36ba9b5e3c5a1b5 0 8dd3e3437cd14017b9f4e7bb1e4a0db7 f97ee7d5e7aa478eb36ba9b5e3c5a1b5--8dd3e3437cd14017b9f4e7bb1e4a0db7 95de8e3c4f174e1abef73c24c255d7c5 1 6f5ccbf3f4864ad38bf6fc0e9b6441b4 0433fdb6c5bd4daf88565eb6749d1981 8dd3e3437cd14017b9f4e7bb1e4a0db7--0433fdb6c5bd4daf88565eb6749d1981 a2ccda30b0204795a90bc73207b13882 6f5ccbf3f4864ad38bf6fc0e9b6441b4--a2ccda30b0204795a90bc73207b13882 c7e645185ec142629cfd05358382a245 743a2444eece4ab981fd4013ced10b05 a2ccda30b0204795a90bc73207b13882--743a2444eece4ab981fd4013ced10b05 9b7614feddee46c8bc20b7cd7c796640 c7e645185ec142629cfd05358382a245--9b7614feddee46c8bc20b7cd7c796640 035a43288d5b4d97abb341ae51d93c78 c2276a13d72e416285d8a395f0aed00b 95de8e3c4f174e1abef73c24c255d7c5--c2276a13d72e416285d8a395f0aed00b db1d0092cab54e5a9851ce96c942ecd6 2 c2276a13d72e416285d8a395f0aed00b--6f5ccbf3f4864ad38bf6fc0e9b6441b4 d0418198613541c585147085f5d07cdd 0433fdb6c5bd4daf88565eb6749d1981--d0418198613541c585147085f5d07cdd b54066957e9e496499575478ada07b0d d0418198613541c585147085f5d07cdd--b54066957e9e496499575478ada07b0d b54066957e9e496499575478ada07b0d--035a43288d5b4d97abb341ae51d93c78 25f1879b0ebb4fbd98777c014fa7701b f30f49f939504c01a873839c711c4887 db1d0092cab54e5a9851ce96c942ecd6--f30f49f939504c01a873839c711c4887 07dcad433fcc4569a38bb4a40d451bb2 3 2da6406ad1ad40bca3f83f0408c5d3c2 f30f49f939504c01a873839c711c4887--2da6406ad1ad40bca3f83f0408c5d3c2 21d60dc06fe64ae4afa2d07dd6010517 2da6406ad1ad40bca3f83f0408c5d3c2--21d60dc06fe64ae4afa2d07dd6010517 64a069ddc40040e08081f0a76113f9ec 21d60dc06fe64ae4afa2d07dd6010517--64a069ddc40040e08081f0a76113f9ec 64a069ddc40040e08081f0a76113f9ec--25f1879b0ebb4fbd98777c014fa7701b 355c041f786d40cf86a207f20d1dc12e 1096f3f842474797a44dcb4d2e0ef58f 07dcad433fcc4569a38bb4a40d451bb2--1096f3f842474797a44dcb4d2e0ef58f 321a94818747454096a817a694b62c00 1096f3f842474797a44dcb4d2e0ef58f--321a94818747454096a817a694b62c00 741bc24939174d009eb9415c8eea70a0 321a94818747454096a817a694b62c00--741bc24939174d009eb9415c8eea70a0 741bc24939174d009eb9415c8eea70a0--c7e645185ec142629cfd05358382a245 743a2444eece4ab981fd4013ced10b05--355c041f786d40cf86a207f20d1dc12e <pre><code>from qadence import *\n\nb = chain(CPHASE(0, 1, 0.5), CPHASE(0, 2, 0.5), CPHASE(0, 3, 0.5))\n</code></pre> %3 a95da574835d46868764f102977978b2 0 28e822a62bae4c41a6269d82f028edd2 a95da574835d46868764f102977978b2--28e822a62bae4c41a6269d82f028edd2 80330103b1b74abab63bb87ae322cc39 1 d8cef006c85c4d54bd11d2dde59dc362 28e822a62bae4c41a6269d82f028edd2--d8cef006c85c4d54bd11d2dde59dc362 a850ecc91337492aa40c402d32632d7d d8cef006c85c4d54bd11d2dde59dc362--a850ecc91337492aa40c402d32632d7d 8a2199a2675040edb3c3213154c41d1e a850ecc91337492aa40c402d32632d7d--8a2199a2675040edb3c3213154c41d1e 7885917924dd4cd58ac3f5adee993069 4de6b006076241128dd513b233718943 PHASE(0.5) 80330103b1b74abab63bb87ae322cc39--4de6b006076241128dd513b233718943 cf4d2a1509ce443e93f834d6af4d2c50 2 4de6b006076241128dd513b233718943--28e822a62bae4c41a6269d82f028edd2 e701f84e017e4707bff787ad1e885ff3 4de6b006076241128dd513b233718943--e701f84e017e4707bff787ad1e885ff3 9c98a02411504e18bb4359022bd4be22 e701f84e017e4707bff787ad1e885ff3--9c98a02411504e18bb4359022bd4be22 9c98a02411504e18bb4359022bd4be22--7885917924dd4cd58ac3f5adee993069 9b91e474be3b47ecb7390537f4bb45a9 bae2dd09bbd04c729b9d158fc573c6b3 cf4d2a1509ce443e93f834d6af4d2c50--bae2dd09bbd04c729b9d158fc573c6b3 457f6b106ac047b6b95ba567fcc6f48c 3 e24586fbf99541b897717b28dd925295 PHASE(0.5) bae2dd09bbd04c729b9d158fc573c6b3--e24586fbf99541b897717b28dd925295 e24586fbf99541b897717b28dd925295--d8cef006c85c4d54bd11d2dde59dc362 1b606f82bfb64bbb96c0b7c28844fa17 e24586fbf99541b897717b28dd925295--1b606f82bfb64bbb96c0b7c28844fa17 1b606f82bfb64bbb96c0b7c28844fa17--9b91e474be3b47ecb7390537f4bb45a9 b29ac5ffc012467cae83758dfe32fbf6 e00c1ab0950940159fa8ab8cc3e05ce6 457f6b106ac047b6b95ba567fcc6f48c--e00c1ab0950940159fa8ab8cc3e05ce6 ec4ee73f1d0a4a4f98f05162e2fe2c92 e00c1ab0950940159fa8ab8cc3e05ce6--ec4ee73f1d0a4a4f98f05162e2fe2c92 fb0ffdfab2c04189b51c8a7e0d9b9ed1 PHASE(0.5) ec4ee73f1d0a4a4f98f05162e2fe2c92--fb0ffdfab2c04189b51c8a7e0d9b9ed1 fb0ffdfab2c04189b51c8a7e0d9b9ed1--a850ecc91337492aa40c402d32632d7d fb0ffdfab2c04189b51c8a7e0d9b9ed1--b29ac5ffc012467cae83758dfe32fbf6"},{"location":"tutorials/development/draw/#developer-documentation","title":"Developer documentation","text":"<p>This section contains examples in pure graphviz that can be used to understand roughly what is done in the actual drawing backend.</p> <pre><code>import graphviz\n\nfont_name = \"Sans-Serif\"\nfont_size = \"8\"\n\ngraph_attr = {\n    \"rankdir\": \"LR\",  # LR = left to right, TB = top to bottom\n    \"nodesep\": \"0.1\",  # In inches, tells distance between nodes without edges\n    \"compound\": \"true\",  # Needed to draw properly edges in hamevo when content is hidden\n    \"splines\": \"false\",  # Needed to draw control gates vertical lines one over the other\n}  # These are the default values for graphs\n\nnode_attr = {\n    \"shape\": \"box\",  # 'box' for normal nodes, 'point' for control gates or 'plaintext' for starting nodes (the qubit label).\n    \"style\": \"rounded\",  # Unfortunately we can't specify the radius of the rounded, at least for this version\n    \"fontname\": font_name,\n    \"fontsize\": font_size,\n    \"width\": \"0.1\",  # In inches, it doesn't get tinier than the label font.\n    \"height\": \"0.1\"  # In inches, it doesn't get tinier than the label font.\n}  # These are the defaults values that can be overridden at node declaration.\n\ndefault_cluster_attr = {\n    \"fontname\": font_name,\n    \"fontsize\": font_size,\n    \"labelloc\": \"b\",  # location of cluster label. b as bottom, t as top\n    \"style\": \"rounded\"\n} # These are the defaults values that can be overridden at sub graph declaration\n\nhamevo_cluster_attr = {\n    \"label\": \"HamEvo(t=10)\"\n}\nhamevo_cluster_attr.update(default_cluster_attr)\n\nh = graphviz.Graph(graph_attr=graph_attr, node_attr=node_attr)\nh.node(\"Hello World!\")\nh\n</code></pre> <pre><code>\n</code></pre> <pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n\n# Add start and end nodes\nfor i in range(4):\n    h.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\n    h.node(f'e{i}', style='invis', group=f\"{i}\")\n\n# Add nodes\nh.node('X', group=\"0\")\nh.node('Y', group=\"1\")\n\n# Add hamevo and its nodes\nhamevo = graphviz.Graph(name='cluster_hamevo', graph_attr=hamevo_cluster_attr)\nfor i in range(4):\n    hamevo.node(f'z{i}', shape=\"box\", style=\"invis\", label=f'{i}', group=f\"{i}\")\nh.subgraph(hamevo)\n\n# Add rx gates cluster and its nodes\ncluster_attr = {\"label\": \"RX gates\"}\ncluster_attr.update(default_cluster_attr)\ncluster = graphviz.Graph(name=\"cluster_0\", graph_attr=cluster_attr)\ncluster.node('RX(x)', group=\"2\")\ncluster.node('RX(0.5)', group=\"3\")\nh.subgraph(cluster)\n\nh.node('cnot0', label='', shape='point', width='0.1', group='0')\nh.node('cnot1', label='X', group='1')\nh.node('cnot2', label='', shape='point', width='0.1', group='2')\nh.node('cnot3', label='', shape='point', width='0.1', group='3')\n\n# Add edges\nh.edge('s0', 'X')\nh.edge('X', 'cnot0')\nh.edge('cnot0', 'z0', lhead='cluster_hamevo')\nh.edge('z0', 'e0', ltail='cluster_hamevo')\nh.edge('s1', 'Y')\nh.edge('Y', 'cnot1')\nh.edge('cnot1', 'z1', lhead='cluster_hamevo')\nh.edge('z1', 'e1', ltail='cluster_hamevo')\nh.edge('s2', 'RX(x)')\nh.edge('RX(x)', 'cnot2')\nh.edge('cnot2', 'z2', lhead='cluster_hamevo')\nh.edge('z2', 'e2', ltail='cluster_hamevo')\nh.edge('s3', 'RX(0.5)')\nh.edge('RX(0.5)', 'cnot3')\nh.edge('cnot3', 'z3', lhead='cluster_hamevo')\nh.edge('z3', 'e3', ltail='cluster_hamevo')\nh.edge('cnot1', 'cnot0', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot2', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot3', constraint='false')  # constraint: false is needed to draw vertical edges\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/development/draw/#example-of-cluster-of-clusters","title":"Example of cluster of clusters","text":"<pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n\n# Define start and end nodes\nfor i in range(4):\n    h.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\n    h.node(f'e{i}', style='invis', group=f\"{i}\")\n\n# Define outer cluster\ncluster_attr = {\"label\": \"Outer cluster\"}\ncluster_attr.update(default_cluster_attr)\nouter_cluster = graphviz.Graph(name=\"cluster_outer\", graph_attr=cluster_attr)\n\n# Define inner cluster 1 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 1\"}\ncluster_attr.update(default_cluster_attr)\ninner1_cluster = graphviz.Graph(name=\"cluster_inner1\", graph_attr=cluster_attr)\ninner1_cluster.node(\"a0\", group=\"0\")\ninner1_cluster.node(\"a1\", group=\"1\")\nouter_cluster.subgraph(inner1_cluster)\n\n# Define inner cluster 2 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 2\"}\ncluster_attr.update(default_cluster_attr)\ninner2_cluster = graphviz.Graph(name=\"cluster_inner2\", graph_attr=cluster_attr)\ninner2_cluster.node(\"a2\", group=\"2\")\ninner2_cluster.node(\"a3\", group=\"3\")\nouter_cluster.subgraph(inner2_cluster)\n\n# This has to be done here, after inner clusters definitions\nh.subgraph(outer_cluster)\n\n# Define more nodes\nfor i in range(4):\n    h.node(f\"b{i}\", group=f\"{i}\")\n\nfor i in range(4):\n    h.edge(f's{i}', f'a{i}')\n    h.edge(f'a{i}', f'b{i}')\n    h.edge(f'b{i}', f'e{i}')\n\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/digital_analog_qc/","title":"Digital-Analog Quantum Computation","text":"<p>Digital-analog quantum computation (DAQC) is a universal quantum computing paradigm<sup>1</sup>, based on two primary computations:</p> <ul> <li>Fast single-qubit operations (digital).</li> <li>Multi-partite entangling operations acting on all qubits (analog).</li> </ul> <p>A promising quantum computing platform for the implementation of the DAQC paradigm is neutral-atoms, where both these computations are realizable.</p>"},{"location":"tutorials/digital_analog_qc/#digital-analog-emulation","title":"Digital-analog emulation","text":"<p>Qadence simplifies the execution of DAQC programs on either emulated or real devices by providing a simplified interface for customizing interactions and interfacing with pulse-level programming in <code>Pulser</code><sup>3</sup>.</p>"},{"location":"tutorials/digital_analog_qc/#digital-analog-transformation","title":"Digital-analog transformation","text":"<p>Furthermore, the essence of digital-analog computation is the ability to represent any analog operation, i.e. any arbitrary Hamiltonian, using an auxiliary device-amenable Hamiltonian, such as the ubiquitous Ising model<sup>2</sup>. This is at the core of the DAQC implementation in Qadence.</p>"},{"location":"tutorials/digital_analog_qc/#execution-on-rydberg-atom-arrays-with-restriced-addressability","title":"Execution on Rydberg atom arrays with restriced addressability","text":"<p>Finally, Qadence offers some convenience constructors and interfaces to execute programs compatible with a DAQC flavor featuring only a restricted access to individual qubit addressability with always-on interaction. This regime is common in currently available neutral atom quantum computers.</p>"},{"location":"tutorials/digital_analog_qc/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/analog-basics/","title":"Basic operations on neutral-atoms","text":"<p>Warning</p> <p>The digital-analog emulation framework is under construction and more changes to the interface may still occur.</p> <p>Qadence includes primitives for the construction of programs implemented on a set of interacting qubits. The goal is to build digital-analog programs that better represent the reality of interacting qubit platforms, such as neutral-atoms, while maintaining a simplified interface for users coming from a digital quantum computing background that may not be as familiar with pulse-level programming.</p> <p>To build the intuition for the interface in Qadence, it is important to go over some of the underlying physics. We can write a general Hamiltonian for a set of \\(n\\) interacting qubits as</p> \\[ \\mathcal{H} = \\sum_{i=0}^{n-1}\\left(\\mathcal{H}^\\text{d}_{i}(t) + \\sum_{j&lt;i}\\mathcal{H}^\\text{int}_{ij}\\right), \\] <p>where the driving Hamiltonian \\(\\mathcal{H}^\\text{d}_{i}\\) describes the pulses used to control single-qubit rotations, and the interaction Hamiltonian \\(\\mathcal{H}^\\text{int}_{ij}\\) describes the natural interaction between qubits.</p>"},{"location":"tutorials/digital_analog_qc/analog-basics/#rydberg-atoms","title":"Rydberg atoms","text":"<p>For the purpose of digital-analog emulation of neutral-atom systems in Qadence, we now consider a simplified time-independent global driving Hamiltonian, written as</p> \\[ \\mathcal{H}^\\text{d}_{i} = \\frac{\\Omega}{2}\\left(\\cos(\\phi) X_i - \\sin(\\phi) Y_i \\right) - \\delta N_i \\] <p>where \\(\\Omega\\) is the Rabi frequency, \\(\\delta\\) is the detuning, \\(\\phi\\) is the phase, \\(X_i\\) and \\(Y_i\\) are the standard Pauli operators, and \\(N_i=\\frac{1}{2}(I_i-Z_i)\\) is the number operator. This Hamiltonian allows arbitrary global single-qubit rotations to be written, meaning that the values set for \\((\\Omega,\\phi,\\delta)\\) are the same accross the qubit support.</p> <p>For the interaction term, Rydberg atoms typically allow both an Ising and an XY mode of operation. For now, we focus on the Ising interaction, where the Hamiltonian is written as</p> \\[ \\mathcal{H}^\\text{int}_{ij} = \\frac{C_6}{r_{ij}^6}N_iN_j \\] <p>where \\(r_{ij}\\) is the distance between atoms \\(i\\) and \\(j\\), and \\(C_6\\) is a coefficient depending on the specific Rydberg level of the excited state used in the computational logic states. A typical value for rydberg level of 60 is \\(C_6\\approx 866~[\\text{rad} . \\mu \\text{m}^6 / \\text{ns}]\\).</p> <p>For a given register of atoms prepared in some spatial coordinates, the Hamiltonians described will generate the dynamics of some unitary operation as</p> \\[ U(t, \\Omega, \\delta, \\phi) = \\exp(-i\\mathcal{H}t) \\] <p>where we specify the final parameter \\(t\\), the duration of the operation.</p> <p>Qadence uses the following units for user-specified parameters:</p> <ul> <li>Rabi frequency and detuning \\(\\Omega\\), \\(\\delta\\): \\([\\text{rad}/\\mu \\text{s}]\\)</li> <li>Phase \\(\\phi\\): \\([\\text{rad}]\\)</li> <li>Duration \\(t\\): \\([\\text{ns}]\\)</li> <li>Atom coordinates: \\([\\mu \\text{m}]\\)</li> </ul>"},{"location":"tutorials/digital_analog_qc/analog-basics/#in-practice","title":"In practice","text":"<p>Given the Hamiltonian description in the previous section, we will now go over a few examples of the standard operations available in Qadence.</p>"},{"location":"tutorials/digital_analog_qc/analog-basics/#arbitrary-rotation","title":"Arbitrary rotation","text":"<p>To start, we will exemplify the a general rotation on a set of atoms. To create an arbitrary register of atoms, we refer the user to the register creation tutorial. Below, we create a line register of three qubits with a separation of \\(8~\\mu\\text{m}\\). This is a typical value used in combination with a standard experimental setup of neutral atoms such that the interaction term in the Hamiltonian can effectively be used for computations.</p> <pre><code>from qadence import Register\n\nreg = Register.line(3, spacing=8.0)  # Atom spacing in \u03bcm\n</code></pre> <p>Currently, the most general rotation operation uses the <code>AnalogRot</code> operation, which essentially implements \\(U(t, \\Omega, \\delta, \\phi)\\) defined above.</p> <pre><code>from qadence import AnalogRot, PI\n\nrot_op = AnalogRot(\n    duration = 500., # [ns]\n    omega = PI, # [rad/\u03bcs]\n    delta = PI, # [rad/\u03bcs]\n    phase = PI, # [rad]\n)\n</code></pre> <p>Note that in the code above a specific qubit support is not defined. By default this operation applies a global rotation on all qubits. We can define a circuit using the 3-qubit register and run it in the pyqtorch backend:</p> <pre><code>from qadence import BackendName, run\n\nwf = run(reg, rot_op, backend = BackendName.PYQTORCH)\n\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4248-0.2411j, -0.1687+0.3156j, -0.1696+0.2676j, -0.2040-0.2671j,\n         -0.1687+0.3156j,  0.0014-0.2721j, -0.2040-0.2671j,  0.3034-0.1130j]])\n</code></pre> Under the hood of AnalogRot      To be fully explicit about what goes on under the hood of `AnalogRot`, we can look at the example     code below.      <pre><code>from qadence import BackendName, HamEvo, X, Y, N, add, run, PI\nfrom qadence.analog.constants import C6_DICT\nfrom math import cos, sin\n\n# Following the 3-qubit register above\nn_qubits = 3\ndx = 8.0\n\n# Parameters used in the AnalogRot\nduration = 500.\nomega = PI\ndelta = PI\nphase = PI\n\n# Building the terms in the driving Hamiltonian\nh_x = (omega / 2) * cos(phase) * add(X(i) for i in range(n_qubits))\nh_y = (-1.0 * omega / 2) * sin(phase) * add(Y(i) for i in range(n_qubits))\nh_n = -1.0 * delta * add(N(i) for i in range(n_qubits))\n\n# Building the interaction Hamiltonian\n\n# Dictionary of coefficient values for each Rydberg level, which is 60 by default\nc_6 = C6_DICT[60]\n\nh_int = c_6 * (\n    1/(dx**6) * (N(0)@N(1)) +\n    1/(dx**6) * (N(1)@N(2)) +\n    1/((2*dx)**6) * (N(0)@N(2))\n)\n\nhamiltonian = h_x + h_y + h_n + h_int\n\n# Convert duration to \u00b5s due to the units of the Hamiltonian\nexplicit_rot = HamEvo(hamiltonian, duration / 1000)\n\nwf = run(n_qubits, explicit_rot, backend = BackendName.PYQTORCH)\n\n# We get the same final wavefunction\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4248-0.2411j, -0.1687+0.3156j, -0.1696+0.2676j, -0.2040-0.2671j,\n         -0.1687+0.3156j,  0.0014-0.2721j, -0.2040-0.2671j,  0.3034-0.1130j]])\n</code></pre> <p>When sending the <code>AnalogRot</code> operation to the pyqtorch backend, Qadence automatically builds the correct Hamiltonian and the corresponding <code>HamEvo</code> operation with the added qubit interactions, as shown explicitly in the minimized section above. However, this operation is also supported in the Pulser backend, where the correct pulses are automatically created.</p> <pre><code>wf = run(\n    reg,\n    rot_op,\n    backend = BackendName.PULSER,\n)\n\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4253-0.2408j, -0.1688+0.3157j, -0.1698+0.2678j, -0.2044-0.2667j,\n         -0.1688+0.3157j,  0.0011-0.2721j, -0.2044-0.2667j,  0.3026-0.1137j]])\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#rx-ry-rz-rotations","title":"RX / RY / RZ rotations","text":"<p>The <code>AnalogRot</code> provides full control over the parameters of \\(\\mathcal{H}^\\text{d}\\), but users coming from a digital quantum computing background may be more familiar with the standard <code>RX</code>, <code>RY</code> and <code>RZ</code> rotations, also available in Qadence. For the emulated analog interface, Qadence provides alternative <code>AnalogRX</code>, <code>AnalogRY</code> and <code>AnalogRZ</code> operations which call <code>AnalogRot</code> under the hood to represent the rotations accross the respective axis.</p> <p>For a given angle of rotation \\(\\theta\\) provided to each of these operations, currently a set of hardcoded assumptions are made on the tunable Hamiltonian parameters:</p> \\[ \\begin{aligned} \\text{RX}:&amp; \\quad \\Omega = \\pi, \\quad \\delta = 0, \\quad \\phi = 0, \\quad t = (\\theta/\\Omega)\\times 10^3 \\\\ \\text{RY}:&amp; \\quad \\Omega = \\pi, \\quad \\delta = 0, \\quad \\phi = -\\pi/2, \\quad t = (\\theta/\\Omega)\\times 10^3 \\\\ \\text{RZ}:&amp; \\quad \\Omega = 0, \\quad \\delta = \\pi, \\quad \\phi = 0, \\quad t = (\\theta/\\delta)\\times 10^3 \\\\ \\end{aligned} \\] <p>Note that the \\(\\text{RZ}\\) operation as defined above includes a global phase compared to the standard \\(\\text{RZ}\\) rotation since it evolves \\(\\exp\\left(-i\\frac{\\theta}{2}\\frac{I-Z}{2}\\right)\\) instead of \\(\\exp\\left(-i\\frac{\\theta}{2}Z\\right)\\) given the detuning operator in \\(\\mathcal{H}^\\text{d}\\).</p> <p>Warning</p> <p>As shown above, the values of \\(\\Omega\\) and \\(\\delta\\) are currently hardcoded in these operators, and the effective angle of rotation is controlled by varying the duration of the evolution. Currently, the best way to overcome this is to use <code>AnalogRot</code> directly, but more general and convenient options will be provided soon in an improved interface.</p> <p>Below we exemplify the usage of <code>AnalogRX</code>:</p> <pre><code>from qadence import Register, BackendName\nfrom qadence import RX, AnalogRX, random_state, equivalent_state, kron, run, PI\n\nn_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\n# Rotation angle\ntheta = PI\n\n# Analog rotation using the Rydberg Hamiltonian\nrot_analog = AnalogRX(angle = theta)\n\n# Equivalent full-digital global rotation\nrot_digital = kron(RX(i, theta) for i in range(n_qubits))\n\n# Some random initial state\ninit_state = random_state(n_qubits)\n\n# Compare the final state using the full digital and the AnalogRX\nwf_analog_pyq = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\n\nwf_digital_pyq = run(\n    reg,\n    rot_digital,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_digital_pyq, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  False\n</code></pre> <p>As we can see, running a global <code>RX</code> or the <code>AnalogRX</code> does not result in equivalent states at the end, given that the digital <code>RX</code> operation does not include the interaction between the qubits. By setting <code>dx</code> very high in the code above the interaction will be less significant and the results will match.</p> <p>However, if we compare with the Pulser backend, we see that the results for <code>AnalogRX</code> are consistent with the expected results from a real device:</p> <pre><code>wf_analog_pulser = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PULSER,\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_analog_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#evolving-the-interaction-term","title":"Evolving the interaction term","text":"<p>Finally, besides applying specific qubit rotations, we can also choose to evolve only the interaction term \\(\\mathcal{H}^\\text{int}\\), equivalent to setting \\(\\Omega = \\delta = \\phi = 0\\). To do so, Qadence provides the function <code>AnalogInteraction</code> which does exactly this.</p> <pre><code>from qadence import Register, BackendName, random_state, equivalent_state, AnalogInteraction, run\n\nn_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\nduration = 1000.\nop = AnalogInteraction(duration = duration)\n\ninit_state = random_state(n_qubits)\n\nwf_pyq = run(reg, op, state = init_state, backend = BackendName.PYQTORCH)\nwf_pulser = run(reg, op, state = init_state, backend = BackendName.PULSER)\n\nbool_equiv = equivalent_state(wf_pyq, wf_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#device-specifications-in-qadence","title":"Device specifications in Qadence","text":"<p>As a way to control other specifications of the interacting Rydberg atoms, Qadence provides a <code>RydbergDevice</code> class, which is currently used for both the pyqtorch and the pulser backends. Below we initialize a Rydberg device showcasing all the possible options.</p> <pre><code>from qadence import RydbergDevice, DeviceType, Interaction, PI\n\ndevice_specs = RydbergDevice(\n    interaction=Interaction.NN, # Or Interaction.XY, supported only for pyqtorch\n    rydberg_level=60, # Integer value affecting the C_6 coefficient\n    coeff_xy=3700.00, # C_3 coefficient for the XY interaction\n    max_detuning=2 * PI * 4, # Max value for delta, currently only used in pulser\n    max_amp=2 * PI * 3, # Max value for omega, currently only used in pulser\n    pattern=None, # Semi-local addressing pattern, see the relevant tutorial\n    type=DeviceType.IDEALIZED, # Pulser device to which the qadence device is converted in that backend\n)\n</code></pre> <p>The values above are the defaults when simply running <code>device_specs = RydbergDevice()</code>. The convenience wrappers <code>IdealDevice()</code> or <code>RealisticDevice()</code> can also be used which simply change the <code>type</code> for the Pulser backend, but also allow an <code>AddressingPattern</code> passed in the <code>pattern</code> argument (see the relevant tutorial here).</p> <p>Warning</p> <p>Currently, the options above are not fully integrated in both backends and this class should mostly be used if a user wishes to experiment with a different <code>rydberg_level</code>, or to change the device type for the pulser backend.</p> <p>Planned features to add to the RydbergDevice include the definition of custom interaction functions, the control of other drive Hamiltonian parameters so that \\(\\Omega\\), \\(\\delta\\) and \\(\\phi\\) are not hardcoded when doing analog rotations, and the usage of the <code>max_detuning</code> and <code>max_amp</code> to control those respective parameters when training models in the pyqtorch backend.</p> <p>Finally, to change a given simulation, the device specifications are integrated in the Qadence <code>Register</code>. By default, all registers initialize an <code>IdealDevice()</code> under the hood. Below we run a quick test for a different rydberg level.</p> <pre><code>from qadence import Register, BackendName, random_state, equivalent_state, run\nfrom qadence import AnalogRX, RydbergDevice, PI\n\ndevice_specs = RydbergDevice(rydberg_level = 70)\n\nn_qubits_side = 2\nreg = Register.square(\n    n_qubits_side,\n    spacing = 8.0,\n    device_specs = device_specs\n)\n\nrot_analog = AnalogRX(angle = PI)\n\ninit_state = random_state(n_qubits = 4)\n\nwf_analog_pyq = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\nwf_analog_pulser = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PULSER\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_analog_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#technical-details","title":"Technical details","text":"<p>Warning</p> <p>The details described here are relevant in the current version but will be lifted soon for the next version of the emulated analog interface.</p> <p>In the previous section we have exemplified the main ingredients of the current user-facing functionalities of the emulated analog interface, and in the next tutorial on Quantum Circuit Learning we will exmplify its usage in a simple QML example. Here we specify some extra details of this interface.</p> <p>In the block system, all analog rotation operators initialize a <code>ConstantAnalogRotation</code> block, while the <code>AnalogInteraction</code> operation initializes an <code>InteractionBlock</code>. As we have shown, by default, these blocks use a global qubit support, which can be passed explicitly by setting <code>qubit_support = QubitSupportType.GLOBAL</code>. However, composing blocks using <code>kron</code> with local qubit supports and different durations is not allowed.</p> <pre><code>from qadence import AnalogRX, AnalogRY, Register, kron\n\ndx = 8.0\nreg = Register.from_coordinates([(0, 0), (dx, 0)])\n\n# Does not work (the angle affects the duration, as seen above):\nrot_0 = AnalogRX(angle = 1.0, qubit_support = (0,))\nrot_1 = AnalogRY(angle = 2.0, qubit_support = (1,))\n\ntry:\n    block = kron(rot_0, rot_1)\nexcept ValueError as error:\n    print(\"Error:\", error)\n\n# Works:\nrot_0 = AnalogRX(angle = 1.0, qubit_support = (0,))\nrot_1 = AnalogRY(angle = 1.0, qubit_support = (1,))\n\nblock = kron(rot_0, rot_1)\n</code></pre> <pre><code>Error: Kron'ed blocks have to have same duration.\n</code></pre> <p>Using <code>chain</code> is only supported between analog blocks with global qubit support:</p> <pre><code>from qadence import chain\n\nrot_0 = AnalogRX(angle = 1.0, qubit_support = \"global\")\nrot_1 = AnalogRY(angle = 2.0, qubit_support = \"global\")\n\nblock = chain(rot_0, rot_1)\n</code></pre> <p>The restrictions above only apply to the analog blocks, and analog and digital blocks can currently be composed.</p> <pre><code>from qadence import RX\n\nrot_0 = AnalogRX(angle = 1.0, qubit_support = \"global\")\nrot_1 = AnalogRY(angle = 2.0, qubit_support = (0,))\nrot_digital = RX(1, 1.0)\n\nblock_0 = chain(rot_0, rot_digital)\nblock_1 = kron(rot_1, rot_digital)\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-blocks-qcl/","title":"Fitting a function with analog blocks","text":"<p>Analog blocks can be parametrized in the usual Qadence manner. Like any other parameters, they can be optimized. The next snippet exemplifies the creation of an analog and parameterized ansatz to fit a simple function. First, define a register and feature map block. We again use a default spacing of \\(8~\\mu\\text{m}\\) as done in the basic tutorial.</p> <pre><code>from qadence import Register, FeatureParameter, chain\nfrom qadence import AnalogRX, AnalogRY, AnalogRZ, AnalogInteraction\nfrom sympy import acos\n\n# Line register\nn_qubits = 2\nregister = Register.line(n_qubits, spacing = 8.0)\n\n# The input feature x for the circuit to learn f(x)\nx = FeatureParameter(\"x\")\n\n# Feature map with a few global analog rotations\nfm = chain(\n    AnalogRX(x),\n    AnalogRY(2*x),\n    AnalogRZ(3*x),\n)\n</code></pre> <p>Next, we define the ansatz with parameterized rotations.</p> <pre><code>from qadence import hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel, BackendName, DiffMode\nfrom qadence import VariationalParameter\n\nt_0 = 1000. * VariationalParameter(\"t_0\")\nt_1 = 1000. * VariationalParameter(\"t_1\")\nt_2 = 1000. * VariationalParameter(\"t_2\")\n\n# Creating the ansatz with parameterized rotations and wait time\nansatz = chain(\n    AnalogRX(\"tht_0\"),\n    AnalogRY(\"tht_1\"),\n    AnalogRZ(\"tht_2\"),\n    AnalogInteraction(t_0),\n    AnalogRX(\"tht_3\"),\n    AnalogRY(\"tht_4\"),\n    AnalogRZ(\"tht_5\"),\n    AnalogInteraction(t_1),\n    AnalogRX(\"tht_6\"),\n    AnalogRY(\"tht_7\"),\n    AnalogRZ(\"tht_8\"),\n    AnalogInteraction(t_2),\n)\n</code></pre> <p>We define the measured observable as the total magnetization, and build the <code>QuantumModel</code>.</p> <pre><code># Total magnetization observable\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n\n# Defining the circuit and observable\ncircuit = QuantumCircuit(register, fm, ansatz)\n\nmodel = QuantumModel(\n    circuit,\n    observable = observable,\n    backend = BackendName.PYQTORCH,\n    diff_mode = DiffMode.AD\n)\n</code></pre> <p>Now we can define the function to fit as well as our training and test data.</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\n\n# Function to fit:\ndef f(x):\n    return x**2\n\nx_test = torch.linspace(-1.0, 1.0, steps=100)\ny_test = f(x_test)\n\nx_train = torch.linspace(-1.0, 1.0, steps=10)\ny_train = f(x_train)\n\n# Initial prediction from the model, to be visualized later\ny_pred_initial = model.expectation({\"x\": x_test}).detach()\n</code></pre> <p>Finally we define a simple loss function and training loop.</p> <pre><code>mse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ndef loss_fn(x_train, y_train):\n    out = model.expectation({\"x\": x_train})\n    loss = mse_loss(out.squeeze(), y_train)\n    return loss\n\nn_epochs = 200\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_fn(x_train, y_train)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And with the model trained we can plot the final results.</p> <pre><code>y_pred_final = model.expectation({\"x\": x_test}).detach()\n\nplt.plot(x_test, y_pred_initial, label = \"Initial prediction\")\nplt.plot(x_test, y_pred_final, label = \"Final prediction\")\nplt.scatter(x_train, y_train, label = \"Training points\")\n</code></pre> 2025-05-12T10:17:31.067647 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/analog-qubo/","title":"Solve a QUBO problem","text":"<p>In this notebook, we solve a quadratic unconstrained binary optimization (QUBO) problem with Qadence. QUBOs are very popular combinatorial optimization problems with a wide range of applications. Here, we solve the problem using the QAOA <sup>1</sup> variational algorithm by embedding the QUBO problem weights onto a register as standard for neutral atom quantum devices.</p> <p>Additional background information on QUBOs can be found here, directly solved using the pulse-level interface Pulser.</p>"},{"location":"tutorials/digital_analog_qc/analog-qubo/#define-and-solve-qubo","title":"Define and solve QUBO","text":"Pre-requisite: optimal register coordinates for embedding the QUBO problem <p>A basic ingredient for solving a QUBO problem with a neutral atom device is to embed the problem onto the atomic register. In short, embedding algorithms cast the problem onto a graph mapped onto the register by optimally finding atomic coordinates. A discussion on the embedding algorithms is beyond the scope of this tutorial and a simplified version taken from here is added below.</p> <pre><code>import numpy as np\nimport numpy.typing as npt\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\nfrom qadence import RydbergDevice\n\ndef qubo_register_coords(Q: np.ndarray, device: RydbergDevice) -&gt; list:\n    \"\"\"Compute coordinates for register.\"\"\"\n\n    def evaluate_mapping(new_coords, *args):\n        \"\"\"Cost function to minimize. Ideally, the pairwise\n        distances are conserved\"\"\"\n        Q, shape = args\n        new_coords = np.reshape(new_coords, shape)\n        interaction_coeff = device.coeff_ising\n        new_Q = squareform(interaction_coeff / pdist(new_coords) ** 6)\n        return np.linalg.norm(new_Q - Q)\n\n    shape = (len(Q), 2)\n    np.random.seed(0)\n    x0 = np.random.random(shape).flatten()\n    res = minimize(\n        evaluate_mapping,\n        x0,\n        args=(Q, shape),\n        method=\"Nelder-Mead\",\n        tol=1e-6,\n        options={\"maxiter\": 200000, \"maxfev\": None},\n    )\n    return [(x, y) for (x, y) in np.reshape(res.x, (len(Q), 2))]\n</code></pre> <p>With the embedding routine define above, we can translate a matrix defining a QUBO problem to a set of atom coordinates for the register. The QUBO problem is initially defined by a graph of weighted edges and a cost function to be optimized. The weighted edges are represented by a real-valued symmetric matrix <code>Q</code> which is used throughout the tutorial.</p> <pre><code>import torch\nfrom qadence import QuantumModel\n\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\n# QUBO problem weights (real-value symmetric matrix)\nQ = np.array(\n    [\n        [-10.0, 19.7365809, 19.7365809, 5.42015853, 5.42015853],\n        [19.7365809, -10.0, 20.67626392, 0.17675796, 0.85604541],\n        [19.7365809, 20.67626392, -10.0, 0.85604541, 0.17675796],\n        [5.42015853, 0.17675796, 0.85604541, -10.0, 0.32306662],\n        [5.42015853, 0.85604541, 0.17675796, 0.32306662, -10.0],\n    ]\n)\n\n# Loss function to guide the optimization routine\ndef loss(model: QuantumModel, *args) -&gt; tuple[torch.Tensor, dict]:\n    to_arr_fn = lambda bitstring: np.array(list(bitstring), dtype=int)\n    cost_fn = lambda arr: arr.T @ Q @ arr\n    samples = model.sample({}, n_shots=1000)[0]\n    cost_fn = sum(samples[key] * cost_fn(to_arr_fn(key)) for key in samples)\n    return torch.tensor(cost_fn / sum(samples.values())), {}\n</code></pre> <p>The QAOA algorithm needs a variational quantum circuit with optimizable parameters. For that purpose, we use a fully analog circuit composed of two global rotations per layer on different axes of the Bloch sphere. The first rotation corresponds to the mixing Hamiltonian and the second one to the embedding Hamiltonian <sup>1</sup>. In this setting, the embedding is realized by the appropriate register coordinates and the resulting qubit interaction. Details on the analog blocks used here can be found in the analog basics tutorial.</p> Rydberg level <p>The Rydberg level is set to 70. We initialize the weighted register graph from the QUBO definition similarly to what is done in the original tutorial, and set the device specifications with the updated Rydberg level.</p> <pre><code>from qadence import QuantumCircuit, Register, RydbergDevice\nfrom qadence import chain, AnalogRX, AnalogRZ\n\n# Device specification and atomic register\ndevice = RydbergDevice(rydberg_level=70)\n\nreg = Register.from_coordinates(\n    qubo_register_coords(Q, device), device_specs=device\n)\n\n# Analog variational quantum circuit\nlayers = 2\nblock = chain(*[AnalogRX(f\"t{i}\") * AnalogRZ(f\"s{i}\") for i in range(layers)])\ncircuit = QuantumCircuit(reg, block)\n</code></pre> <p>By initializing the <code>QuantumModel</code> with this circuit we can check the initial counts where no clear solution can be found.</p> <pre><code>model = QuantumModel(circuit)\ninitial_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> <pre><code>initial_counts = OrderedCounter({'00000': 101, '10000': 87, '01000': 75, '00110': 72, '00100': 70, '01010': 64, '01001': 62, '00101': 53, '00010': 51, '00011': 48, '01011': 46, '00001': 45, '10010': 45, '00111': 38, '10001': 34, '11000': 29, '10100': 18, '01100': 14, '01110': 11, '01111': 10, '10110': 7, '11001': 7, '11010': 6, '01101': 4, '10101': 2, '10011': 1})\n</code></pre> <p>Finally, we can proceed with the variational optimization. The cost function defined above is derived from bitstring computations and therefore non differentiable. We use Qadence ML facilities to run gradient-free optimizations using the <code>nevergrad</code> library.</p> <pre><code>from qadence.ml_tools import Trainer, TrainConfig, num_parameters\nimport nevergrad as ng\n\nTrainer.set_use_grad(False)\n\nconfig = TrainConfig(max_iter=100)\n\noptimizer = ng.optimizers.NGOpt(\n    budget=config.max_iter, parametrization=num_parameters(model)\n)\n\ntrainer = Trainer(model, optimizer, config, loss)\n\ntrainer.fit()\n\noptimal_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> <p>Finally, let's plot the solution. The expected bitstrings are marked in red.</p> <pre><code>import matplotlib.pyplot as plt\n\n# Known solutions to the QUBO problem.\nsolution_bitstrings = [\"01011\", \"00111\"]\n\ndef plot_distribution(C, ax, title):\n    C = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n    color_dict = {key: \"r\" if key in solution_bitstrings else \"b\" for key in C}\n    ax.set_xlabel(\"bitstrings\")\n    ax.set_ylabel(\"counts\")\n    ax.set_xticks([i for i in range(len(C.keys()))], C.keys(), rotation=90)\n    ax.bar(C.keys(), C.values(), color=color_dict.values())\n    ax.set_title(title)\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 4))\nplot_distribution(initial_counts, axs[0], \"Initial counts\")\nplot_distribution(optimal_counts, axs[1], \"Optimal counts\")\n</code></pre> 2025-05-12T10:17:34.919148 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/analog-qubo/#references","title":"References","text":"<ol> <li> <p>Edward Farhi, Jeffrey Goldstone, Sam Gutmann, A Quantum Approximate Optimization Algorithm, arXiv:1411.4028 (2014) \u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/","title":"<code>CNOT</code> with interacting qubits","text":"<p>Digital-analog quantum computing focuses on using single qubit digital gates combined with more complex and device-dependent analog interactions to represent quantum programs. This paradigm has been shown to be universal for quantum computation<sup>1</sup>. However, while this approach may have advantages when adapting quantum programs to real devices, known quantum algorithms are very often expressed in a fully digital paradigm. As such, it is also important to have concrete ways to transform from one paradigm to another.</p> <p>This tutorial will exemplify the DAQC transformation starting with the representation of a simple digital <code>CNOT</code> using the universality of the Ising Hamiltonian<sup>2</sup>.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#cnot-with-cphase","title":"<code>CNOT</code> with <code>CPHASE</code>","text":"<p>Let's look at a single example of how the digital-analog transformation can be used to perform a <code>CNOT</code> on two qubits inside a register of globally interacting qubits.</p> <p>First, note that the <code>CNOT</code> can be decomposed with two Hadamard and a <code>CPHASE</code> gate with \\(\\phi=\\pi\\):</p> <pre><code>import torch\nfrom qadence import chain, sample, product_state\n\nfrom qadence.draw import display\nfrom qadence import X, I, Z, H, N, CPHASE, CNOT, HamEvo, PI\n\nn_qubits = 2\n\n# CNOT gate\ncnot_gate = CNOT(0, 1)\n\n# CNOT decomposed\nphi = PI\ncnot_decomp = chain(H(1), CPHASE(0, 1, phi), H(1))\n\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample from CNOT gate and 100 shots = [OrderedCounter({'11': 100})]\nsample from decomposed CNOT gate and 100 shots = [OrderedCounter({'11': 100})]\n</code></pre> <p>The <code>CPHASE</code> matrix is diagonal, and can be implemented by exponentiating an Ising-like Hamiltonian, or generator,</p> \\[\\text{CPHASE}(i,j,\\phi)=\\text{exp}\\left(-i\\phi \\mathcal{H}_\\text{CP}(i, j)\\right)\\] \\[\\begin{aligned} \\mathcal{H}_\\text{CP}&amp;=-\\frac{1}{4}(I_i-Z_i)(I_j-Z_j)\\\\ &amp;=-N_iN_j \\end{aligned}\\] <p>where the number operator \\(N_i = \\frac{1}{2}(I_i-Z_i)=\\hat{n}_i\\) is used, leading to an Ising-like interaction \\(\\hat{n}_i\\hat{n}_j\\) realisable in neutral-atom systems. Let's rebuild the <code>CNOT</code> using this evolution.</p> <pre><code>from qadence import kron, block_to_tensor\n\n# Hamiltonian for the CPHASE gate\nh_cphase = (-1.0) * kron(N(0), N(1))\n\n# Exponentiating and time-evolving the Hamiltonian until t=phi.\ncphase_evo = HamEvo(h_cphase, phi)\n\n# Check that we have the CPHASE gate:\ncphase_matrix = block_to_tensor(CPHASE(0, 1, phi))\ncphase_evo_matrix = block_to_tensor(cphase_evo)\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix: True\n</code></pre> <p>Now that the <code>CPHASE</code> generator is checked, it can be applied to the <code>CNOT</code>:</p> <pre><code># CNOT with Hamiltonian Evolution\ncnot_evo = chain(\n    H(1),\n    cphase_evo,\n    H(1)\n)\n\n# Initialize state to check CNOTs sample outcomes.\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample cnot_gate = [OrderedCounter({'11': 100})]\nsample cnot_evo = [OrderedCounter({'11': 100})]\n</code></pre> <p>Thus, a <code>CNOT</code> gate can be created by combining a few single-qubit gates together with a two-qubit Ising interaction between the control and the target qubit which is the essence of the Ising transform proposed in the seminal DAQC paper<sup>2</sup> for \\(ZZ\\) interactions. In Qadence, both \\(ZZ\\) and \\(NN\\) interactions are supported.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#cnot-in-an-interacting-system-of-three-qubits","title":"<code>CNOT</code> in an interacting system of three qubits","text":"<p>Consider a simple experimental setup with \\(n=3\\) interacting qubits laid out in a triangular grid. For the sake of simplicity, all qubits interact with each other with an \\(NN\\)-Ising interaction of constant strength \\(g_\\text{int}\\). The Hamiltonian for the system can be written by summing interaction terms over all pairs:</p> \\[\\mathcal{H}_\\text{sys}=\\sum_{i=0}^{n}\\sum_{j=0}^{i-1}g_\\text{int}N_iN_j,\\] <p>which in this case leads to only three interaction terms,</p> \\[\\mathcal{H}_\\text{sys}=g_\\text{int}(N_0N_1+N_1N_2+N_0N_2)\\] <p>This generator can be easily built in Qadence:</p> <pre><code>from qadence import add, kron\nn_qubits = 3\n\n# Interaction strength.\ng_int = 1.0\n\n# Build a list of interactions.\ninteraction_list = []\nfor i in range(n_qubits):\n    for j in range(i):\n        interaction_list.append(g_int * kron(N(i), N(j)))\n\nh_sys = add(*interaction_list)\n</code></pre> <pre><code>h_sys = AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(2)\n\u2502       \u2514\u2500\u2500 N(0)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(1)\n</code></pre> <p>Now let's consider that the experimental system is fixed, and qubits can not be isolated one from another. The options are:</p> <ul> <li>Turn on or off the global system Hamiltonian.</li> <li>Perform local single-qubit rotations.</li> </ul> <p>To perform a fully digital <code>CNOT(0,1)</code>, the interacting control on qubit 0 and target on qubit 1 must be isolated from the third one to implement the gate directly. While this can be achieved for a three-qubit system, it becomes experimentally untractable when scaling the qubit count.</p> <p>However, this is not the case within the digital-analog paradigm. In fact, the two qubit Ising interaction required for the <code>CNOT</code> can be represented with a combination of the global system Hamiltonian and a specific set of single-qubit rotations. Full details about this transformation are to be found in the DAQC paper<sup>2</sup> but a more succint yet in-depth description takes place in the next section. It is conveniently available in Qadence by calling the <code>daqc_transform</code> function.</p> <p>In the most general sense, the <code>daqc_transform</code> function will return a circuit that represents the evolution of a target Hamiltonian \\(\\mathcal{H}_\\text{target}\\) (here the unitary of the gate) until a specified time \\(t_f\\) by using only the evolution of a build Hamiltonian \\(\\mathcal{H}_\\text{build}\\) (here \\(\\mathcal{H}_\\text{sys}\\)) together with local \\(X\\)-gates. In Qadence, <code>daqc_transform</code> is applicable for \\(\\mathcal{H}_\\text{target}\\) and \\(\\mathcal{H}_\\text{build}\\) composed only of \\(ZZ\\)- or \\(NN\\)-interactions. These generators are parsed by the <code>daqc_transform</code> function and the appropriate type is automatically determined together with the appropriate single-qubit detunings and global phases.</p> <p>Let's apply it for the <code>CNOT</code> implementation:</p> <pre><code>from qadence import daqc_transform, Strategy\n\n# Settings for the target CNOT operation\ni = 0  # Control qubit\nj = 1  # Target qubit\nk = 2  # The extra qubit\n\n# Define the target CNOT operation\n# by composing with identity on the extra qubit.\ncnot_target = kron(CNOT(i, j), I(k))\n\n# The two-qubit NN-Ising interaction term for the CPHASE\nh_int = (-1.0) * kron(N(i), N(j))\n\n# Transforming the two-qubit Ising interaction using only our system Hamiltonian\ntransformed_ising = daqc_transform(\n    n_qubits=3,        # Total number of qubits in the transformation\n    gen_target=h_int,  # The target Ising generator\n    t_f=PI,            # The target evolution time\n    gen_build=h_sys,   # The building block Ising generator to be used\n    strategy=Strategy.SDAQC,   # Currently only sDAQC is implemented\n    ignore_global_phases=False  # Global phases from mapping between Z and N\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_1a9a2c6e383f4b4cad6252c5aef2466a cluster_9d0cefbc3a86408786f249cb2a9110e1 cluster_6510cf6f5f5a4211ac8b4968db582fa7 cluster_7c07c8c0de8d4fcf829f1b02f48b85c7 cluster_a34abdd372be4363a72dcbed4aae5bea cluster_e99ed4bb8daa493bbf34c4fae796dfad cluster_bf44306a9ade41fb97051690615a6cff d4e02561034a4e2299556b1bef6038dc 0 807da75a7c1e4ef187e6ae996504b297 HamEvo d4e02561034a4e2299556b1bef6038dc--807da75a7c1e4ef187e6ae996504b297 ef41e8f0c5194ebfac0667f03f2280da 1 b1ac888fdaeb4586ad3aba89ff0007bf HamEvo 807da75a7c1e4ef187e6ae996504b297--b1ac888fdaeb4586ad3aba89ff0007bf 39ea37fb3b734f068d4d6878e02bd9a6 HamEvo b1ac888fdaeb4586ad3aba89ff0007bf--39ea37fb3b734f068d4d6878e02bd9a6 14043022dc22463992f962f8fdbdecc3 X 39ea37fb3b734f068d4d6878e02bd9a6--14043022dc22463992f962f8fdbdecc3 ff2e9681f042491f87ed973aaf94276d HamEvo 14043022dc22463992f962f8fdbdecc3--ff2e9681f042491f87ed973aaf94276d f85b6cb1b0244c9da5782e1734ec06a3 HamEvo ff2e9681f042491f87ed973aaf94276d--f85b6cb1b0244c9da5782e1734ec06a3 936426cbb3254679b8da91a26310156e X f85b6cb1b0244c9da5782e1734ec06a3--936426cbb3254679b8da91a26310156e 74310359d5ca440da9d036f3019ad9ac 936426cbb3254679b8da91a26310156e--74310359d5ca440da9d036f3019ad9ac 19d8489c0eea415094d2042a02159e22 HamEvo 74310359d5ca440da9d036f3019ad9ac--19d8489c0eea415094d2042a02159e22 9d22f3dcf63a403d95bf13558a5d7ae0 HamEvo 19d8489c0eea415094d2042a02159e22--9d22f3dcf63a403d95bf13558a5d7ae0 56e3ee07ec244757a54f7e9bc4a5052e 9d22f3dcf63a403d95bf13558a5d7ae0--56e3ee07ec244757a54f7e9bc4a5052e 8be438c11414489d8846b078ddf03d02 56e3ee07ec244757a54f7e9bc4a5052e--8be438c11414489d8846b078ddf03d02 6a5ada6dd59645d4b2f303be9da09a5e 4f427c5eed544f79be8a49a87a4d672b t = -3.14 ef41e8f0c5194ebfac0667f03f2280da--4f427c5eed544f79be8a49a87a4d672b 61991f8937d24a8fb4f7f4c7229dc579 2 a5f1b0a2e75947628780a8cfacd239d0 t = 3.142 4f427c5eed544f79be8a49a87a4d672b--a5f1b0a2e75947628780a8cfacd239d0 5fc5bfaa37934ceb9be2aa4d800d92f7 t = -3.14 a5f1b0a2e75947628780a8cfacd239d0--5fc5bfaa37934ceb9be2aa4d800d92f7 808cd86c675549a1b40628501751ce1e 5fc5bfaa37934ceb9be2aa4d800d92f7--808cd86c675549a1b40628501751ce1e 1c16ff154e734fcba14b0a90af0a0a4d t = 1.571 808cd86c675549a1b40628501751ce1e--1c16ff154e734fcba14b0a90af0a0a4d 556ab6efde0347189c068cdb1807c6f1 t = 1.571 1c16ff154e734fcba14b0a90af0a0a4d--556ab6efde0347189c068cdb1807c6f1 38ab8ff6695d49739adcd24665792319 556ab6efde0347189c068cdb1807c6f1--38ab8ff6695d49739adcd24665792319 7fae0a6ab3c24a2e89fe01a8c19e9fd0 X 38ab8ff6695d49739adcd24665792319--7fae0a6ab3c24a2e89fe01a8c19e9fd0 470473f5bd6b4f38a428407ff936452f t = 1.571 7fae0a6ab3c24a2e89fe01a8c19e9fd0--470473f5bd6b4f38a428407ff936452f 100b31bdd88341c68f5681fddfe138b1 t = 1.571 470473f5bd6b4f38a428407ff936452f--100b31bdd88341c68f5681fddfe138b1 21153948a8e74b31a5c9ef4098817127 X 100b31bdd88341c68f5681fddfe138b1--21153948a8e74b31a5c9ef4098817127 21153948a8e74b31a5c9ef4098817127--6a5ada6dd59645d4b2f303be9da09a5e 403e291933a74f088b588b34e199bdbf cb3d1693647d4335aabd8f21d6bdfdcb 61991f8937d24a8fb4f7f4c7229dc579--cb3d1693647d4335aabd8f21d6bdfdcb 07bfb6384df14291bfa4d757bd509fcc cb3d1693647d4335aabd8f21d6bdfdcb--07bfb6384df14291bfa4d757bd509fcc 797059b0598a43eeb478ad29b8e8d5be 07bfb6384df14291bfa4d757bd509fcc--797059b0598a43eeb478ad29b8e8d5be ca6f2e6bc79a45958b0292014c1f6f11 X 797059b0598a43eeb478ad29b8e8d5be--ca6f2e6bc79a45958b0292014c1f6f11 916cdd3467944c8f8641940b112ba8e6 ca6f2e6bc79a45958b0292014c1f6f11--916cdd3467944c8f8641940b112ba8e6 0058b2a4684c4ea8b06bb179643191ae 916cdd3467944c8f8641940b112ba8e6--0058b2a4684c4ea8b06bb179643191ae 0899a798452a40f48a523087fcaa0c49 X 0058b2a4684c4ea8b06bb179643191ae--0899a798452a40f48a523087fcaa0c49 490609cbe92642e38e3609d6a5a2fe20 X 0899a798452a40f48a523087fcaa0c49--490609cbe92642e38e3609d6a5a2fe20 4d9f7019867f4e6bad2f1ba59d593cae 490609cbe92642e38e3609d6a5a2fe20--4d9f7019867f4e6bad2f1ba59d593cae aed071660b2a46e19b8960013cdf237f 4d9f7019867f4e6bad2f1ba59d593cae--aed071660b2a46e19b8960013cdf237f 6027ecd8e85149b9bc6976afccb37c6e X aed071660b2a46e19b8960013cdf237f--6027ecd8e85149b9bc6976afccb37c6e 6027ecd8e85149b9bc6976afccb37c6e--403e291933a74f088b588b34e199bdbf <p>The output circuit displays three groups of system Hamiltonian evolutions which account for global-phases and single-qubit detunings related to the mapping between the \\(Z\\) and \\(N\\) operators. Optionally, global phases can be ignored.</p> <p>In general, the mapping of a \\(n\\)-qubit Ising Hamiltonian to another will require at most \\(n(n-1)\\) evolutions. The transformed circuit performs these evolutions for specific times that are computed from the solution of a linear system of equations involving the set of interactions in the target and build Hamiltonians.</p> <p>In this case, the mapping is exact when using the step-wise DAQC strategy (<code>Strategy.SDAQC</code>) available in Qadence. In banged DAQC (<code>Strategy.BDAQC</code>) the mapping is approximate, but easier to implement on a physical device with always-on interactions such as neutral-atom systems.</p> <p>Just as before, the transformed Ising circuit can be checked to exactly recover the <code>CPHASE</code> gate:</p> <pre><code># CPHASE on (i, j), Identity on third qubit:\ncphase_matrix = block_to_tensor(kron(CPHASE(i, j, phi), I(k)))\n\n# CPHASE using the transformed circuit:\ncphase_evo_matrix = block_to_tensor(transformed_ising)\n\n# Check that it implements the CPHASE.\n# Will fail if global phases are ignored.\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix : True\n</code></pre> <p>The <code>CNOT</code> gate can now finally be built:</p> <pre><code>from qadence import equivalent_state, run, sample\n\ncnot_daqc = chain(\n    H(j),\n    transformed_ising,\n    H(j)\n)\n\n# And finally apply the CNOT on a specific 3-qubit initial state:\ninit_state = product_state(\"101\")\n\n# Check we get an equivalent wavefunction\nwf_cnot = run(n_qubits, block=cnot_target, state=init_state)\nwf_daqc = run(n_qubits, block=cnot_daqc, state=init_state)\n\n# Visualize the CNOT bit-flip in samples.\n</code></pre> <pre><code>wf_cnot == wf_dacq : True\nsample cnot_target = [OrderedCounter({'111': 100})]\nsample cnot_dacq = [OrderedCounter({'111': 100})]\n</code></pre> <p>As one can see, a <code>CNOT</code> operation has been succesfully implemented on the desired target qubits by using only the global system as the building block Hamiltonian and single-qubit rotations. Decomposing a single digital gate into an Ising Hamiltonian serves as a proof of principle for the potential of this technique to represent universal quantum computation.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#technical-details-on-the-daqc-transformation","title":"Technical details on the DAQC transformation","text":"<ul> <li>The mapping between target generator and final circuit is performed by solving a linear system of size \\(n(n-1)\\) where \\(n\\) is the number of qubits, so it can be computed efficiently (i.e., with a polynomial cost in the number of qubits).</li> <li>The linear system to be solved is actually not invertible for \\(n=4\\) qubits. This is very specific edge case requiring a workaround, that is currently not yet implemented.</li> <li>As mentioned, the final circuit has at most \\(n(n-1)\\) slices, so there is at most a quadratic overhead in circuit depth.</li> </ul> <p>Finally, and most important to its usage:</p> <ul> <li>The target Hamiltonian should be sufficiently represented in the building block Hamiltonian.</li> </ul> <p>To illustrate this point, consider the following target and build Hamiltonians:</p> <pre><code># Interaction between qubits 0 and 1\ngen_target = 1.0 * (Z(0) @ Z(1))\n\n# Fixed interaction between qubits 1 and 2, and customizable between 0 and 1\ndef gen_build(g_int):\n    return g_int * (Z(0) @ Z(1)) + 1.0 * (Z(1) @ Z(2))\n</code></pre> <p>And now we perform the DAQC transform by setting <code>g_int=1.0</code>, exactly matching the target Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\n    n_qubits=3,\n    gen_target=gen_target,\n    t_f=1.0,\n    gen_build=gen_build(g_int=1.0),\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_27f1e0575f3f4ab8bbac4657e8e1dd32 cluster_24c79c3b889449cbaee0f7536e0fe7e4 6136fe3f64a74e82a51f06e046c4eabe 0 3d3f2d9bbc324aab86c14b712b69c5ce X 6136fe3f64a74e82a51f06e046c4eabe--3d3f2d9bbc324aab86c14b712b69c5ce 5e823c23b35345569e26f1d463c54859 1 43df8415e77c421ebb7c4ca47cb7aa62 HamEvo 3d3f2d9bbc324aab86c14b712b69c5ce--43df8415e77c421ebb7c4ca47cb7aa62 2fda70f8085f4f3c86b3372cd470933f X 43df8415e77c421ebb7c4ca47cb7aa62--2fda70f8085f4f3c86b3372cd470933f c7af00d5d25d4334b506fbd09a293376 2fda70f8085f4f3c86b3372cd470933f--c7af00d5d25d4334b506fbd09a293376 66877e84d88c41dc938ad8692d009257 HamEvo c7af00d5d25d4334b506fbd09a293376--66877e84d88c41dc938ad8692d009257 3e59733b923c480bb49a563337929757 66877e84d88c41dc938ad8692d009257--3e59733b923c480bb49a563337929757 6c39e91fb0b04aaea8f280934b8896fe 3e59733b923c480bb49a563337929757--6c39e91fb0b04aaea8f280934b8896fe 78ebe36828e24493b1e5e7863ef301fe 19f123b5d64e46cf938036469aa129a8 5e823c23b35345569e26f1d463c54859--19f123b5d64e46cf938036469aa129a8 b21ecaad6bcf463a9a14f4cb9d096a32 2 ce49b7e5cd12413c9a1c98aa91a93886 t = -0.50 19f123b5d64e46cf938036469aa129a8--ce49b7e5cd12413c9a1c98aa91a93886 29505e5fb76c456082023ed56b4c406a ce49b7e5cd12413c9a1c98aa91a93886--29505e5fb76c456082023ed56b4c406a 6cf3bd0dda5349619f75e765d14f7082 X 29505e5fb76c456082023ed56b4c406a--6cf3bd0dda5349619f75e765d14f7082 393256e6ce344c3aad55d4bf55d809a5 t = -0.50 6cf3bd0dda5349619f75e765d14f7082--393256e6ce344c3aad55d4bf55d809a5 9270ab53fa734e52bdace0bbe818b9af X 393256e6ce344c3aad55d4bf55d809a5--9270ab53fa734e52bdace0bbe818b9af 9270ab53fa734e52bdace0bbe818b9af--78ebe36828e24493b1e5e7863ef301fe 9f4d402d785847638d78063f5325cef1 85313c265d944f7cb2f6ec52174d89aa X b21ecaad6bcf463a9a14f4cb9d096a32--85313c265d944f7cb2f6ec52174d89aa 02b865f5a79c4fc4a87225deae892040 85313c265d944f7cb2f6ec52174d89aa--02b865f5a79c4fc4a87225deae892040 0555a96267194a69bd0a4f952eccb77c X 02b865f5a79c4fc4a87225deae892040--0555a96267194a69bd0a4f952eccb77c 539fe2f6a6694e0ebf8dd691ba0792c4 X 0555a96267194a69bd0a4f952eccb77c--539fe2f6a6694e0ebf8dd691ba0792c4 d95dce9f47e74d35b1d3004842c7ae22 539fe2f6a6694e0ebf8dd691ba0792c4--d95dce9f47e74d35b1d3004842c7ae22 fd9c57ebd64a4667982cd0d387478de9 X d95dce9f47e74d35b1d3004842c7ae22--fd9c57ebd64a4667982cd0d387478de9 fd9c57ebd64a4667982cd0d387478de9--9f4d402d785847638d78063f5325cef1 <p>Now, if the interaction between qubits 0 and 1 is weakened in the build Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\n    n_qubits=3,\n    gen_target=gen_target,\n    t_f=1.0,\n    gen_build=gen_build(g_int=0.001),\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_a73cf69fd4ac4def96adaac2ce969661 cluster_027c7fc1723e4bbdb512b821be9cdb6b e0a3475897114840a9f5f7b5a9a393fc 0 7b1dadb260bb4284a3ba92acea371ae5 X e0a3475897114840a9f5f7b5a9a393fc--7b1dadb260bb4284a3ba92acea371ae5 870da743fd58492e934797fb3c4c585f 1 e9dc3bf74cf74f468b300f36d1a2702d HamEvo 7b1dadb260bb4284a3ba92acea371ae5--e9dc3bf74cf74f468b300f36d1a2702d 8d93a8cb967e441188017930eb9862c1 X e9dc3bf74cf74f468b300f36d1a2702d--8d93a8cb967e441188017930eb9862c1 a8f0a1fd07154935a10f9cc155809c89 8d93a8cb967e441188017930eb9862c1--a8f0a1fd07154935a10f9cc155809c89 058765ccbae34c5ca17ced35f115e134 HamEvo a8f0a1fd07154935a10f9cc155809c89--058765ccbae34c5ca17ced35f115e134 c6e25d14857d4580898a114c0ba35339 058765ccbae34c5ca17ced35f115e134--c6e25d14857d4580898a114c0ba35339 c1bcb925d0174487a44daf505170586f c6e25d14857d4580898a114c0ba35339--c1bcb925d0174487a44daf505170586f 61eb2815e8a6484ca8e1186cd9e6f7f5 bb8660fd047a48ae9dc39ed341c709da 870da743fd58492e934797fb3c4c585f--bb8660fd047a48ae9dc39ed341c709da 7b02531641f2449793b5ae596bded429 2 c4f2fe34215a470fad4ee12c49bc40fb t = -500. bb8660fd047a48ae9dc39ed341c709da--c4f2fe34215a470fad4ee12c49bc40fb 49ac249295314dc088a58aa9f44fc8c8 c4f2fe34215a470fad4ee12c49bc40fb--49ac249295314dc088a58aa9f44fc8c8 49420b3645594cad9f26422d4282701c X 49ac249295314dc088a58aa9f44fc8c8--49420b3645594cad9f26422d4282701c c3a07437e7d64d57b940313bdaf8032b t = -500. 49420b3645594cad9f26422d4282701c--c3a07437e7d64d57b940313bdaf8032b e0d3fe1670bb4df29e3582307c3d3918 X c3a07437e7d64d57b940313bdaf8032b--e0d3fe1670bb4df29e3582307c3d3918 e0d3fe1670bb4df29e3582307c3d3918--61eb2815e8a6484ca8e1186cd9e6f7f5 50961bb953bf4c3b8be6c96813e2ced2 80abee229f524592b050cb26996c68eb X 7b02531641f2449793b5ae596bded429--80abee229f524592b050cb26996c68eb 4a7d0ad5e9c244abb20281b9c7995a43 80abee229f524592b050cb26996c68eb--4a7d0ad5e9c244abb20281b9c7995a43 e0642bca9db442aca2fc25170d9cd9b6 X 4a7d0ad5e9c244abb20281b9c7995a43--e0642bca9db442aca2fc25170d9cd9b6 e03c3f13c1ed40bf927bcf0fc432a6ac X e0642bca9db442aca2fc25170d9cd9b6--e03c3f13c1ed40bf927bcf0fc432a6ac 94346723241f49a7939915c4dcfca437 e03c3f13c1ed40bf927bcf0fc432a6ac--94346723241f49a7939915c4dcfca437 16225461f112482db5f3d8504d3db250 X 94346723241f49a7939915c4dcfca437--16225461f112482db5f3d8504d3db250 16225461f112482db5f3d8504d3db250--50961bb953bf4c3b8be6c96813e2ced2 <p>The times slices using the build Hamiltonian need now to evolve for much longer to represent the same interaction since it is not sufficiently represented in the building block Hamiltonian.</p> <p>In the limit where that interaction is not present, the transform will not work:</p> <pre><code>try:\n    transformed_ising = daqc_transform(\n        n_qubits=3,\n        gen_target=gen_target,\n        t_f=1.0,\n        gen_build=gen_build(g_int = 0.0),\n    )\nexcept ValueError as error:\n    print(\"Error:\", error)\n</code></pre> <pre><code>Error: Incompatible interactions between target and build Hamiltonians.\n</code></pre>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/","title":"Fitting a function with a Hamiltonian ansatz","text":"<p>In the analog QCL tutorial we used analog blocks to learn a function of interest. The analog blocks are a direct abstraction of device execution with global addressing. However, we may want to directly program an Hamiltonian-level ansatz to have a finer control on our model. In Qadence this can easily be done through digital-analog programs. In this tutorial we will solve a simple QCL problem with this approach.</p>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#setting-up-the-problem","title":"Setting up the problem","text":"<p>The example problem considered is to fit a function of interest in a specified range. Below we define and plot the function \\(f(x)=x^5\\).</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\n\n# Function to fit:\ndef f(x):\n    return x**5\n\nxmin = -1.0\nxmax = 1.0\nn_test = 100\n\nx_test = torch.linspace(xmin, xmax, steps = n_test)\ny_test = f(x_test)\n\nplt.plot(x_test, y_test)\nplt.xlim((-1.1, 1.1))\nplt.ylim((-1.1, 1.1))\n</code></pre> 2025-05-12T10:17:35.360078 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#digital-analog-ansatz","title":"Digital-Analog Ansatz","text":"<p>We start by defining the register of qubits. The topology we use now will define the interactions in the entangling Hamiltonian. As an example, we can define a rectangular lattice with 6 qubits.</p> <pre><code>from qadence import Register\n\nreg = Register.rectangular_lattice(\n    qubits_row = 3,\n    qubits_col = 2,\n)\n</code></pre> <p>Inspired by the Ising interaction mode of Rydberg atoms, we can now define an interaction Hamiltonian as \\(\\mathcal{H}_{ij}=\\frac{1}{r_{ij}^6}N_iN_j\\), where \\(N_i=(1/2)(I_i-Z_i)\\) is the number operator and and \\(r_{ij}\\) is the distance between qubits \\(i\\) and \\(j\\). We can easily instatiate this interaction Hamiltonian from the register information:</p> <pre><code>from qadence import N, add\n\ndef h_ij(i: int, j: int):\n    return N(i)@N(j)\n\nh_int = add(h_ij(*edge)/r**6 for edge, r in reg.edge_distances.items())\n</code></pre> <p>To build the digital-analog ansatz we can make use of the standard <code>hea</code> function by specifying we want to use the <code>Strategy.SDAQC</code> and passing the Hamiltonian we created as the entangler, as see in the QML constructors tutorial. The entangling operation will be replaced by the evolution of this Hamiltonian <code>HamEvo(h_int, t)</code>, where the time parameter <code>t</code> is considered to be a variational parameter at each layer.</p> <pre><code>from qadence import hea, Strategy, RX, RY\n\ndepth = 2\n\nda_ansatz = hea(\n    n_qubits = reg.n_qubits,\n    depth = depth,\n    operations = [RX, RY, RX],\n    entangler = h_int,\n    strategy = Strategy.SDAQC,\n)\n\nprint(html_string(da_ansatz))\n</code></pre> %3 cluster_81689b3ef4094d5da60621de9c4080f2 cluster_71484cdc44284ad9b30537d57f057db9 09644ab682e54fa19c0fe2f13210e071 0 55043911588e4139a350fd1c256044af RX(theta\u2080) 09644ab682e54fa19c0fe2f13210e071--55043911588e4139a350fd1c256044af 9c10f0ce5a7e40c9bd74661b3ae4fbdc 1 99bc91d1d5924b209043f5aa6f554280 RY(theta\u2086) 55043911588e4139a350fd1c256044af--99bc91d1d5924b209043f5aa6f554280 f697589205b94c90869bfd1df423afa0 RX(theta\u2081\u2082) 99bc91d1d5924b209043f5aa6f554280--f697589205b94c90869bfd1df423afa0 ce8880ecc0214cac8063988078e500fd f697589205b94c90869bfd1df423afa0--ce8880ecc0214cac8063988078e500fd 1e2d7b076ef94415900db5f1fac6d8fe RX(theta\u2081\u2088) ce8880ecc0214cac8063988078e500fd--1e2d7b076ef94415900db5f1fac6d8fe 602a57ca410f4d1c901bf4715aee149d RY(theta\u2082\u2084) 1e2d7b076ef94415900db5f1fac6d8fe--602a57ca410f4d1c901bf4715aee149d 430e7f2ec30c4d8cb7efca58e71490e5 RX(theta\u2083\u2080) 602a57ca410f4d1c901bf4715aee149d--430e7f2ec30c4d8cb7efca58e71490e5 9cb12ffc222d4d81a81fcd35f11537e3 430e7f2ec30c4d8cb7efca58e71490e5--9cb12ffc222d4d81a81fcd35f11537e3 85e09466df7947899b5b9481c67154ad 9cb12ffc222d4d81a81fcd35f11537e3--85e09466df7947899b5b9481c67154ad 1326351bae4742359a162f4f6eee917c 1d2627c14b574dc4aab01f0de59dac82 RX(theta\u2081) 9c10f0ce5a7e40c9bd74661b3ae4fbdc--1d2627c14b574dc4aab01f0de59dac82 44d604782414460ab803515caf8ea18c 2 97658ef1838b4f82b769c6e0f75869be RY(theta\u2087) 1d2627c14b574dc4aab01f0de59dac82--97658ef1838b4f82b769c6e0f75869be 8e0c356ffd2543bc9592cc4d6a38b280 RX(theta\u2081\u2083) 97658ef1838b4f82b769c6e0f75869be--8e0c356ffd2543bc9592cc4d6a38b280 cf2e6c729b9543b49888e6e6f2f97c9b 8e0c356ffd2543bc9592cc4d6a38b280--cf2e6c729b9543b49888e6e6f2f97c9b 1794e04eb677432388e4ffdafad025b3 RX(theta\u2081\u2089) cf2e6c729b9543b49888e6e6f2f97c9b--1794e04eb677432388e4ffdafad025b3 084e8274226d4312b5b56382f40d0ead RY(theta\u2082\u2085) 1794e04eb677432388e4ffdafad025b3--084e8274226d4312b5b56382f40d0ead 892ad86f8ac4471594cd53107f7d91c9 RX(theta\u2083\u2081) 084e8274226d4312b5b56382f40d0ead--892ad86f8ac4471594cd53107f7d91c9 a09154af52504d8093bb519da14517f4 892ad86f8ac4471594cd53107f7d91c9--a09154af52504d8093bb519da14517f4 a09154af52504d8093bb519da14517f4--1326351bae4742359a162f4f6eee917c 7d99eb94f63647edb74fb1fae5286bc5 46f8e0b7dd81413fb9dcecac39d4e38d RX(theta\u2082) 44d604782414460ab803515caf8ea18c--46f8e0b7dd81413fb9dcecac39d4e38d 6b73aaab203f460b8de66058eb1d2789 3 08e79903cae843d09f61d5b18e42cfbc RY(theta\u2088) 46f8e0b7dd81413fb9dcecac39d4e38d--08e79903cae843d09f61d5b18e42cfbc d8fed52e943941348096b4eabbe1c8a9 RX(theta\u2081\u2084) 08e79903cae843d09f61d5b18e42cfbc--d8fed52e943941348096b4eabbe1c8a9 05382f0cefed4475956643dd12a90be8 HamEvo d8fed52e943941348096b4eabbe1c8a9--05382f0cefed4475956643dd12a90be8 91a9aa956b174c12abd87b61d2f58651 RX(theta\u2082\u2080) 05382f0cefed4475956643dd12a90be8--91a9aa956b174c12abd87b61d2f58651 ba783dc4876d4052a2200f90a8f64033 RY(theta\u2082\u2086) 91a9aa956b174c12abd87b61d2f58651--ba783dc4876d4052a2200f90a8f64033 d67b9518867a409e8c957d347411808e RX(theta\u2083\u2082) ba783dc4876d4052a2200f90a8f64033--d67b9518867a409e8c957d347411808e 0c50cfbcf0aa4a8b902be02ac8128904 HamEvo d67b9518867a409e8c957d347411808e--0c50cfbcf0aa4a8b902be02ac8128904 0c50cfbcf0aa4a8b902be02ac8128904--7d99eb94f63647edb74fb1fae5286bc5 839993a7b4804bafa49aa985b667ad5a 114cfd5e087a4c1882e3fc8ff44272dd RX(theta\u2083) 6b73aaab203f460b8de66058eb1d2789--114cfd5e087a4c1882e3fc8ff44272dd 3b26f38562284fbda02c08bc22adf012 4 c71745b7383d435d95d5787aac6e3d20 RY(theta\u2089) 114cfd5e087a4c1882e3fc8ff44272dd--c71745b7383d435d95d5787aac6e3d20 ae5421017625445590afa5f2c3da495b RX(theta\u2081\u2085) c71745b7383d435d95d5787aac6e3d20--ae5421017625445590afa5f2c3da495b 6385ab0bd4a14578b400e9453a7bca5c t = theta_t\u2080 ae5421017625445590afa5f2c3da495b--6385ab0bd4a14578b400e9453a7bca5c 8d7f0d17822f4f7c92b72d06642f69e2 RX(theta\u2082\u2081) 6385ab0bd4a14578b400e9453a7bca5c--8d7f0d17822f4f7c92b72d06642f69e2 b55d103471394442a66016769967c83f RY(theta\u2082\u2087) 8d7f0d17822f4f7c92b72d06642f69e2--b55d103471394442a66016769967c83f 28f4e7b2edf94f61a17216c7bd4aa264 RX(theta\u2083\u2083) b55d103471394442a66016769967c83f--28f4e7b2edf94f61a17216c7bd4aa264 3cb7e1c2057d4993b4feaff82bb8d0c0 t = theta_t\u2081 28f4e7b2edf94f61a17216c7bd4aa264--3cb7e1c2057d4993b4feaff82bb8d0c0 3cb7e1c2057d4993b4feaff82bb8d0c0--839993a7b4804bafa49aa985b667ad5a e1294bf16f0f4c9aa6dbf4e6e8b93208 b4aa4f606ca647e488a4fad419bd93b6 RX(theta\u2084) 3b26f38562284fbda02c08bc22adf012--b4aa4f606ca647e488a4fad419bd93b6 d13c4c0814ac45e78dd254aabe689d01 5 1af0773c90614b6f8b76b7b53ec9c950 RY(theta\u2081\u2080) b4aa4f606ca647e488a4fad419bd93b6--1af0773c90614b6f8b76b7b53ec9c950 722f5d9e8f614ef2a203b639dd53f943 RX(theta\u2081\u2086) 1af0773c90614b6f8b76b7b53ec9c950--722f5d9e8f614ef2a203b639dd53f943 a94940d2d548423d9530d5c0c0f09835 722f5d9e8f614ef2a203b639dd53f943--a94940d2d548423d9530d5c0c0f09835 f339645c1ebc47b8a9625bed40d1af21 RX(theta\u2082\u2082) a94940d2d548423d9530d5c0c0f09835--f339645c1ebc47b8a9625bed40d1af21 158efc7d0b964ba0844e68ea2bb015a5 RY(theta\u2082\u2088) f339645c1ebc47b8a9625bed40d1af21--158efc7d0b964ba0844e68ea2bb015a5 937021b5431f4b7caccc91fbefbf6040 RX(theta\u2083\u2084) 158efc7d0b964ba0844e68ea2bb015a5--937021b5431f4b7caccc91fbefbf6040 78f36de39a184113b7bb8b4884b17845 937021b5431f4b7caccc91fbefbf6040--78f36de39a184113b7bb8b4884b17845 78f36de39a184113b7bb8b4884b17845--e1294bf16f0f4c9aa6dbf4e6e8b93208 d4514e5b2c5b41d6855aad684a0cc3b6 f8e04edf874f4285bf3363b7fc8d9ee3 RX(theta\u2085) d13c4c0814ac45e78dd254aabe689d01--f8e04edf874f4285bf3363b7fc8d9ee3 c7b3435838204d0d9133b1550dd9d5e2 RY(theta\u2081\u2081) f8e04edf874f4285bf3363b7fc8d9ee3--c7b3435838204d0d9133b1550dd9d5e2 50991cc5ed0942f88d555512262a4c4c RX(theta\u2081\u2087) c7b3435838204d0d9133b1550dd9d5e2--50991cc5ed0942f88d555512262a4c4c a4c38b6aaa0f4ef6bc6cc3b108fdc506 50991cc5ed0942f88d555512262a4c4c--a4c38b6aaa0f4ef6bc6cc3b108fdc506 efbccc8de2064a2199aabede41d6e5d5 RX(theta\u2082\u2083) a4c38b6aaa0f4ef6bc6cc3b108fdc506--efbccc8de2064a2199aabede41d6e5d5 6b548e67b0c24123ae6cb733019253d3 RY(theta\u2082\u2089) efbccc8de2064a2199aabede41d6e5d5--6b548e67b0c24123ae6cb733019253d3 35085fa2b8914b05885a38fe71e114ae RX(theta\u2083\u2085) 6b548e67b0c24123ae6cb733019253d3--35085fa2b8914b05885a38fe71e114ae e0891a0af0cd449593c5bab34e0ea1a9 35085fa2b8914b05885a38fe71e114ae--e0891a0af0cd449593c5bab34e0ea1a9 e0891a0af0cd449593c5bab34e0ea1a9--d4514e5b2c5b41d6855aad684a0cc3b6"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#creating-the-quantummodel","title":"Creating the QuantumModel","text":"<p>The rest of the procedure is the same as any other Qadence workflow. We start by defining a feature map for input encoding and an observable for output decoding.</p> <pre><code>from qadence import feature_map, BasisSet, ReuploadScaling\nfrom qadence import Z, I\n\nfm = feature_map(\n    n_qubits = reg.n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Total magnetization\nobservable = add(Z(i) for i in range(reg.n_qubits))\n</code></pre> <p>And we have all the ingredients to initialize the <code>QuantumModel</code>:</p> <pre><code>from qadence import QuantumCircuit, QuantumModel\n\ncircuit = QuantumCircuit(reg, fm, da_ansatz)\n\nmodel = QuantumModel(circuit, observable = observable)\n</code></pre>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#training-the-model","title":"Training the model","text":"<p>We can now train the model. We use a set of 20 equally spaced training points.</p> <pre><code># Chebyshev FM does not accept x = -1, 1\nxmin = -0.99\nxmax = 0.99\nn_train = 20\n\nx_train = torch.linspace(xmin, xmax, steps = n_train)\ny_train = f(x_train)\n\n# Initial model prediction\ny_pred_initial = model.expectation({\"x\": x_test}).detach()\n</code></pre> <p>And we use a simple custom training loop.</p> <pre><code>criterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nn_epochs = 200\n\ndef loss_fn(x_train, y_train):\n    out = model.expectation({\"x\": x_train})\n    loss = criterion(out.squeeze(), y_train)\n    return loss\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_fn(x_train, y_train)\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#results","title":"Results","text":"<p>Finally we can plot the resulting trained model.</p> <pre><code>y_pred_final = model.expectation({\"x\": x_test}).detach()\n\nplt.plot(x_test, y_pred_initial, label = \"Initial prediction\")\nplt.plot(x_test, y_pred_final, label = \"Final prediction\")\nplt.scatter(x_train, y_train, label = \"Training points\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend()\nplt.xlim((-1.1, 1.1))\nplt.ylim((-1.1, 1.1))\n</code></pre> 2025-05-12T10:17:43.497555 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/","title":"Pulse-level programming with Pulser","text":"<p>Qadence offers a direct interface with Pulser<sup>1</sup>, an open-source pulse-level interface written in Python and specifically designed for programming neutral atom quantum computers.</p> <p>Using directly Pulser requires advanced knowledge on pulse-level programming and on how neutral atom devices work. Qadence abstracts this complexity out by using the familiar block-based interface for building pulse sequences in Pulser while leaving the possibility to directly manipulate them if required by, for instance, optimal pulse shaping.</p> <p>Note</p> <p>The Pulser backend is still experimental and the interface might change in the future. Please note that it does not support <code>DiffMode.AD</code>.</p> <p>Note</p> <p>With the Pulser backend, <code>qadence</code> simulations can be executed on the cloud emulators available on the PASQAL cloud platform. In order to do so, make to have valid credentials for the PASQAL cloud platform and use the following configuration for the Pulser backend:</p> <pre><code>config = {\n    \"cloud_configuration\": {\n        \"username\": \"&lt;changeme&gt;\",\n        \"password\": \"&lt;changeme&gt;\",\n        \"project_id\": \"&lt;changeme&gt;\",  # the project should have access to emulators\n        \"platform\": \"EMU_FREE\"  # choose between `EMU_TN` and `EMU_FREE`\n    }\n}\n</code></pre> <p>For inquiries and more details on the cloud credentials, please contact info@pasqal.com.</p>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#default-qubit-interaction","title":"Default qubit interaction","text":"<p>When simulating pulse sequences written using Pulser, the underlying constructed Hamiltonian is equivalent to a digital-analog quantum computing program (see digital-analog emulation for more details) with the following interaction term:</p> \\[ \\mathcal{H}_{\\textrm{int}} = \\sum_{i&lt;j} \\frac{C_6}{|R_i - R_j|^6} \\hat{n}_i \\hat{n}_j \\] <p>where \\(C_6\\) is an interaction strength coefficient dependent on the principal quantum number of chosen the neutral atom system, \\(R_i\\) are atomic positions in Cartesian coordinates and \\(\\hat{n} = \\frac{1-\\sigma^z_i}{2}\\) the number operator.</p> <p>Note</p> <p>The Ising interaction is always-on for all computations performed with the Pulser backend. It cannot be switched off.</p>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#available-quantum-operations","title":"Available quantum operations","text":"<p>Currently, the Pulser backend supports the following operations:</p> gate description trainable parameter <code>RX</code>, <code>RY</code> Single qubit rotations. Notice that the interaction is on and this affects the resulting gate fidelity. rotation angle <code>AnalogRX</code>, <code>AnalogRY</code>, <code>AnalogRZ</code> Span a single qubit rotation among the entire register. rotation angle <code>entangle</code> Fully entangle the register. interaction time <code>AnalogInteraction</code> An idle block to to free-evolve for a duration according to the interaction. free evolution time"},{"location":"tutorials/digital_analog_qc/pulser-basic/#sequence-the-bell-state-on-a-two-qubit-register","title":"Sequence the Bell state on a two qubit register","text":"<p>The next example illustrates how to create a pulse sequence to prepare a Bell state. This is a sequence of an entanglement operation, represented as an <code>entangle</code> gate (using <code>CZ</code> interactions) in the \\(X\\)-basis and a \\(Y\\) rotation for readout in the \\(Z\\)-basis:</p> <pre><code>from qadence import chain, entangle, RY\n\nbell_state = chain(\n   entangle(\"t\", qubit_support=(0,1)),\n   RY(0, \"y\"),\n)\n</code></pre> <pre><code>bell_state = ChainBlock(0,1)\n\u251c\u2500\u2500 AnalogEntanglement(t=0.9007440457171584, support=(0, 1))\n\u2514\u2500\u2500 RY(0) [params: ['y']]\n</code></pre> <p>Next, a <code>Register</code> with two qubits is combined with the resulting <code>ChainBlock</code> to form a circuit. Then, the <code>QuantumModel</code> converts the circuit into a proper parametrized pulse sequence with the Pulser backend. Supplying the parameter values allows to sample the pulse sequence outcome:</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom qadence import Register, QuantumCircuit, QuantumModel, PI\n\nregister = Register.line(2, spacing = 8.0)  # Two qubits with a distance of 8\u00b5m\ncircuit = QuantumCircuit(register, bell_state)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\n\nparams = {\n    \"t\": torch.tensor([1000]),  # ns\n    \"y\": torch.tensor([3*PI/2]),\n}\n\n# Return the final state vector\nfinal_vector = model.run(params)\n\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>final_vector = tensor([[-0.7114-0.0169j, -0.0338+0.0155j,  0.0110-0.0457j,  0.6631-0.2245j]])\nsample = Counter({'00': 27, '11': 23})\n</code></pre> <p>Plot the distribution:</p> <p><pre><code>\n</code></pre> 2025-05-12T10:17:43.713148 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/  One can visualise the pulse sequence with different parameters using the <code>assign_paramters</code> method.</p> <pre><code>model.assign_parameters(params).draw(show=False)\n</code></pre> 2025-05-12T10:17:43.831728 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#change-device-specifications","title":"Change device specifications","text":"<p>At variance with other backends, Pulser provides the concept of <code>Device</code>. A <code>Device</code> instance encapsulates all the properties for the definition of a real neutral atoms processor, including but not limited to the maximum laser amplitude for pulses, the maximum distance between two qubits and the maximum duration of the pulse. For more information, please check this tutorial.</p> <p>Qadence offers a simplified interface with only two devices which are detailed here:</p> <ul> <li><code>IDEALIZED</code> (default): ideal device which should be used only for testing purposes. It does not restrict the simulation of pulse sequences.</li> <li><code>REALISTIC</code>: device specification close to real neutral atom quantum processors.</li> </ul> <p>Note</p> <p>If you want to perform simulations closer to the specifications of real neutral atom machines, always select the <code>REALISTIC</code> device.</p> <p>One can use the <code>Configuration</code> of the Pulser backend to select the appropriate device:</p> <pre><code>from qadence import BackendName, DiffMode\nfrom qadence import RealisticDevice\n\n# Choose a realistic device\nregister = Register.line(2, spacing = 8.0, device_specs = RealisticDevice())\n\ncircuit = QuantumCircuit(register, bell_state)\n\nmodel = QuantumModel(\n    circuit,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR,\n)\n\nparams = {\n    \"t\": torch.tensor([1000]),  # ns\n    \"y\": torch.tensor([3*PI/2]),\n}\n\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>sample = Counter({'11': 26, '00': 24})\n</code></pre>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#create-a-custom-gate","title":"Create a custom gate","text":"<p>A major advantage of the block-based interface in Qadence is the ease to compose complex operations from a restricted set of primitive ones. In the following, a custom entanglement operation is used as an example.</p> <p>The operation consists of moving all the qubits to the \\(X\\)-basis. This is realized when the atomic interaction performs a controlled-\\(Z\\) operation during the free evolution. As seen before, this is implemented with the <code>AnalogInteraction</code> and <code>AnalogRY</code> blocks together with appropriate parameters.</p> <pre><code>from qadence import AnalogRY, chain, AnalogInteraction\n\n# Custom entanglement operation.\ndef my_entanglement(duration):\n    return chain(\n        AnalogRY(-PI / 2),\n        AnalogInteraction(duration)\n    )\n\nprotocol = chain(\n   my_entanglement(\"t\"),\n   RY(0, \"y\"),\n)\n\nregister = Register.line(2, spacing = 8.0)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\n\nparams = {\n    \"t\": torch.tensor([500]),  # ns\n    \"y\": torch.tensor([PI / 2]),\n}\n\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> 2025-05-12T10:17:44.217281 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#digital-analog-qnn-circuit","title":"Digital-analog QNN circuit","text":"<p>Finally, let's put all together by constructing a digital-analog version of a quantum neural network circuit with feature map and variational ansatz.</p> <pre><code>from qadence import kron, feature_map, BasisSet\nfrom qadence.operations import RX, RY, AnalogRX\n\nhea_one_layer = chain(\n    kron(RY(0, \"th00\"), RY(1, \"th01\")),\n    kron(RX(0, \"th10\"), RX(1, \"th11\")),\n    kron(RY(0, \"th20\"), RY(1, \"th21\")),\n    entangle(\"t\", qubit_support=(0,1)),\n)\n\nprotocol = chain(\n    feature_map(1, param=\"x\", fm_type=BasisSet.FOURIER),\n    hea_one_layer,\n    AnalogRX(PI/4)\n)\n\nregister = Register.line(2, spacing=8.0)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\n\nparams = {\n    \"x\": torch.tensor([0.8]), # rad\n    \"t\": torch.tensor([900]), # ns\n    \"th00\":  torch.rand(1), # rad\n    \"th01\":  torch.rand(1), # rad\n    \"th10\":  torch.rand(1), # rad\n    \"th11\":  torch.rand(1), # rad\n    \"th20\":  torch.rand(1), # rad\n    \"th21\":  torch.rand(1), # rad\n}\n\nmodel.assign_parameters(params).draw(draw_phase_area=True, show=False)\n</code></pre> 2025-05-12T10:17:44.388663 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#references","title":"References","text":"<ol> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/","title":"Restricted local addressability","text":""},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#physics-behind-semi-local-addressing-patterns","title":"Physics behind semi-local addressing patterns","text":"<p>Recall that in Qadence the general neutral-atom Hamiltonian for a set of \\(n\\) interacting qubits is given by expression</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm drive} + \\mathcal{H}_{\\rm int} = \\sum_{i=0}^{n-1}\\left(\\mathcal{H}^\\text{d}_{i}(t) + \\sum_{j&lt;i}\\mathcal{H}^\\text{int}_{ij}\\right) \\] <p>as is described in detail in the analog interface basics documentation.</p> <p>The driving Hamiltonian term in priciple can model any local single-qubit rotation by addressing each qubit individually. However, some neutral-atom devices offer restricted local addressability using devices called spatial light modulators (SLMs).</p> <p>We refer to this regime as semi-local addressability. In this regime, the individual qubit addressing is restricted to a pattern of targeted qubits which is kept fixed during the execution of the quantum circuit. More formally, the addressing pattern appears as an additional term in the neutral-atom Hamiltonian:</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm drive} + \\mathcal{H}_{\\rm int} + \\mathcal{H}_{\\rm local} \\] <p>where \\(\\mathcal{H}_{\\rm pattern}\\) is given by</p> \\[ \\mathcal{H}_{\\rm local} = \\sum_{i=0}^{n-1}\\left(-\\Delta w_i^{\\rm det} \\hat{n}_i + \\Gamma w_i^{\\rm drive} \\hat{\\sigma}^x_i\\right). \\] <p>Here \\(\\Delta\\) specifies the maximal negative detuning that each qubit in the register can be exposed to. The weight \\(w_i^{\\rm det}\\in [0, 1]\\) determines the actual value of detuning that \\(i\\)-th qubit feels and this way the detuning pattern is emulated. Similarly, for the amplitude pattern \\(\\Gamma\\) determines the maximal additional positive drive that acts on qubits. In this case the corresponding weights \\(w_i^{\\rm drive}\\) can vary in the interval \\([0, 1]\\).</p> <p>Using the detuning and amplitude patterns described above one can modify the behavior of a selected set of qubits, thus achieving semi-local addressing.</p> <p>Qadence implements semi-local addressing in two different flavors of increasing complexity: either as a circuit constructor or directly as a pattern added to the general evolution Hamiltonian described by the circuit.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#using-circuit-constructors","title":"Using circuit constructors","text":"<p>The <code>rydberg_hea</code> constructor routine allows to build a circuit instance implementing a basic version of the Hamiltonian evolution described above where both \\(\\Delta\\) and \\(\\tilde{\\Omega}\\) coefficients are considered constants. Furthemore, no global drive and detuning are explicitly added to the Hamiltonian. Therefore, the final Hamiltonian generator of the circuit reads as follows:</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm local}(w^{\\rm drive}, w^{\\rm det}) + \\mathcal{H}_{\\textrm{int}} \\] <p>This implementation does not perform any checks on the weights normalization, thus making it not realistic. This implies that global drive and detuning can be retrieved by appropriately choosing the weights.</p> <p>You can easily create a Rydberg hardware efficient ansatz implementing multiple layers of the evolution generated by the local addressing Hamiltonian:</p> \\[ \\mathcal{H}_{\\rm evo} = \\sum_j \\mathcal{H}_{\\textrm{local}}(w_{j}^{\\rm drive}, w_{j}^{\\rm det}) \\] <p>Notice that in real-device implementation, one layer only is usually achievable.</p> <pre><code>import qadence as qd\nfrom qadence import rydberg_hea, rydberg_hea_layer\n\nn_qubits = 4\nn_layers = 2\nregister = qd.Register.line(n_qubits)\n\n# ansatz constructor\n# the evolution time is parametrized for each layer of the evolution\nansatz = rydberg_hea(\n    register,\n    n_layers=n_layers,  # number of subsequent layers of Hamiltonian evolution\n    addressable_detuning=True,  # make the local detuning weights w_i^{det} as variational parameters\n    addressable_drive=True, # make the local drive weights w_i^{drv} as variational parameters\n    tunable_phase=True, # make the phase \\phi as a variational parameter\n)\n\n# alternatively, a single ansatz layer can also be created for\n# better flexibility\n\n# these can be variational parameters\ntevo_drive = 1.0  # evolution time for the locally addressed drive term\ntevo_det = 1.0 # evolution time for the locally addressed detuning term\ntevo_int = 1.0  # evolution time for the interaction term\n\n# these can be list of variational parameters\nweights_drive = [0.0, 0.25, 0.5, 0.25]\nweights_det = [0.0, 0.0, 0.5, 0.5]\n\nansatz_layer = rydberg_hea_layer(\n    register,\n    tevo_det,\n    tevo_drive,\n    tevo_int,\n    detunings=weights_det,\n    drives=weights_drive,\n)\n</code></pre> <pre><code>\n</code></pre> <p>This circuit constructor is meant to be used with fully differentiable backends such as <code>pyqtorch</code> and mainly for quick experimentation with neutral atom compatible ansatze.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#using-addressing-patterns","title":"Using addressing patterns","text":"<p>In Qadence semi-local addressing patterns can be created by either specifying fixed values for the weights of the qubits being addressed or defining them as trainable parameters that can be optimized later in some training loop. Semi-local addressing patterns can be defined with the <code>AddressingPattern</code> dataclass.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#fixed-weights","title":"Fixed weights","text":"<p>With fixed weights, detuning/amplitude addressing patterns can be defined in the following way:</p> <pre><code>import torch\nfrom qadence.analog import AddressingPattern\n\nn_qubits = 3\n\nw_det = {0: 0.9, 1: 0.5, 2: 1.0}\nw_amp = {0: 0.1, 1: 0.4, 2: 0.8}\ndet = 9.0\namp = 6.5\npattern = AddressingPattern(\n    n_qubits=n_qubits,\n    det=det,\n    amp=amp,\n    weights_det=w_det,\n    weights_amp=w_amp,\n)\n</code></pre> <p>If only detuning or amplitude pattern is needed - the corresponding weights for all qubits can be set to 0.</p> <p>The created addressing pattern can now be passed as an argument to any Qadence device class, or to the <code>IdealDevice</code> or <code>RealisticDevice</code> to make use of the pre-defined options in those devices,</p> <pre><code>import torch\nfrom qadence import (\n    AnalogRX,\n    AnalogRY,\n    BackendName,\n    DiffMode,\n    Parameter,\n    QuantumCircuit,\n    QuantumModel,\n    Register,\n    chain,\n    total_magnetization,\n    IdealDevice,\n    PI\n)\n\n# define register and circuit\nspacing = 8.0\nx = Parameter(\"x\")\nblock = chain(AnalogRX(3 * x), AnalogRY(0.5 * x))\n\ndevice_specs = IdealDevice(pattern = pattern)\n\nreg = Register.line(\n    n_qubits,\n    spacing=spacing,\n    device_specs=device_specs,\n)\n\ncirc = QuantumCircuit(reg, block)\n\nobs = total_magnetization(n_qubits)\n\nmodel_pyq = QuantumModel(\n    circuit=circ, observable=obs, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD\n)\n\n# calculate expectation value of the circuit for random input value\nvalue = {\"x\": 1.0 + torch.rand(1)}\nexpval_pyq = model_pyq.expectation(values = value)\n</code></pre>   Expectation value on PyQ:  tensor([1.8976])     <p>The same configuration can also be seamlessly used to create a model with the Pulser backend.</p> <pre><code>model_pulser = QuantumModel(\n    circuit=circ,\n    observable=obs,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR\n)\n\n# calculate expectation value of the circuit for same random input value\nexpval_pulser = model_pulser.expectation(values = value)\n</code></pre>   Expectation value on Pulser:  tensor([1.8952])     <p>Note that by default the addressing pattern terms are added to every analog operation in the circuit. However, it is possible to turn the addressing pattern off for specific operations by passing <code>add_pattern=False</code> in the operation. For example <code>AnalogRX(pi)</code> will get the extra addressing pattern term, but <code>AnalogRX(pi, add_pattern=False)</code> will not. This is currently only implemented for the PyQTorch backend. If an addressing pattern is specified for the Pulser backend, it will be added to all the blocks.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#trainable-weights","title":"Trainable weights","text":"<p>Note</p> <p>Trainable parameters currently are supported only by <code>pyqtorch</code> backend.</p> <p>Since both the maximum detuning/amplitude value of the addressing pattern and the corresponding weights can be user specified, they can be variationally used in some QML setting. This can be achieved by defining pattern weights as trainable <code>Parameter</code> instances or strings specifying weight names.</p> <pre><code>n_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\n# some random target function value\nf_value = torch.rand(1)\n\n# define trainable addressing pattern\nw_amp = {i: f\"w_amp{i}\" for i in range(n_qubits)}\nw_det = {i: f\"w_det{i}\" for i in range(n_qubits)}\namp = \"max_amp\"\ndet = \"max_det\"\n\npattern = AddressingPattern(\n    n_qubits=n_qubits,\n    det=det,\n    amp=amp,\n    weights_det=w_det,\n    weights_amp=w_amp,\n)\n\n# some fixed analog operation\nblock = AnalogRX(PI)\n\ndevice_specs = IdealDevice(pattern = pattern)\n\nreg = Register.line(\n    n_qubits,\n    spacing=spacing,\n    device_specs=device_specs,\n)\n\ncirc = QuantumCircuit(reg, block)\n\n# define quantum model\nobs = total_magnetization(n_qubits)\nmodel = QuantumModel(circuit=circ, observable=obs, backend=BackendName.PYQTORCH)\n\n# prepare for training\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nloss_criterion = torch.nn.MSELoss()\nn_epochs = 200\nloss_save = []\n\n# train model\nfor _ in range(n_epochs):\n    optimizer.zero_grad()\n    out = model.expectation()\n    loss = loss_criterion(f_value, out)\n    loss.backward()\n    optimizer.step()\n    loss_save.append(loss.item())\n\n# get final results\nf_value_model = model.expectation().detach()\n\nassert torch.isclose(f_value, f_value_model, atol=0.01)\n</code></pre>   The target function value:  tensor([0.8421]) The trained function value:  tensor([[0.8421]])    <p>Here, the expectation value of the circuit is fitted by varying the parameters of the addressing pattern.</p>"},{"location":"tutorials/qml/","title":"Variational quantum algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML)[^1] in particular are one of the main target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> (see here for more details) and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Furthermore, Qadence offers a wide range of utilities for helping building and researching quantum machine learning algorithms, including:</p> <ul> <li>a set of constructors for circuits commonly used in quantum machine learning such as feature maps and ansatze</li> <li>a set of tools for training and optimizing quantum neural networks and loading classical data into a QML algorithm</li> </ul>"},{"location":"tutorials/qml/#some-simple-examples","title":"Some simple examples","text":"<p>Qadence symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\n\nn_qubits = 4\n\n# Example feature map, also directly available with the `feature_map` function\nfp = qd.FeatureParameter(\"phi\")\nfm = qd.kron(RX(i, acos(fp)) for i in range(n_qubits))\n\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(fm, values=inputs)\n</code></pre> <pre><code>samples = OrderedCounter({'0001': 14, '0110': 11, '0000': 8, '0010': 8, '0100': 8, '0101': 8, '1011': 8, '1001': 7, '0011': 5, '0111': 4, '1000': 4, '1010': 4, '1100': 4, '1110': 4, '1111': 2, '1101': 1})\n</code></pre> <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle. This function will be further demonstrated in the QML constructors tutorial.</p> <p>Furthermore, Qadence is natively integrated with PyTorch automatic differentiation engine thus Qadence quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansatz (also explained here) and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, fm, ansatz)\nobservable = qd.kron(X(0), X(1))\n\nmodel = qd.QNN(circuit, observable)\n\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>True\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\n\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre> <pre><code>Quantum model output: \ntensor([[0.3909],\n        [0.1425],\n        [0.2557],\n        [0.1526],\n        [0.0645],\n        [0.0770],\n        [0.0471],\n        [0.0822],\n        [0.0470],\n        [0.3569]], grad_fn=&lt;CatBackward0&gt;)\n\nFirst-order derivative w.r.t. the feature parameter: \ntensor([ 0.2611,  0.5502, -3.8846,  0.5627,  0.3917,  0.4266,  0.3326,  0.4398,\n         0.3324, -0.9242], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>To run QML on real devices, Qadence offers generalized parameter shift rules (GPSR) <sup>1</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qd.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\n\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n</code></pre> <pre><code>First-order derivative w.r.t. the feature parameter: \ntensor([ 0.2611,  0.5502, -3.8846,  0.5627,  0.3917,  0.4266,  0.3326,  0.4398,\n         0.3324, -0.9242], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>See here for more details on how the parameter shift rules implementation works in Qadence.</p>"},{"location":"tutorials/qml/#references","title":"References","text":"<p>[^1] Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)</p> <ol> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/classification/","title":"Classification with QNN","text":"<p>In this tutorial we will show how to use Qadence to solve a basic classification task using a hybrid quantum-classical model composed of a QNN and classical layers.</p>"},{"location":"tutorials/qml/classification/#dataset","title":"Dataset","text":"<p>We will use the Iris dataset separated into training and testing sets. The task is to classify iris plants presented as a multivariate dataset of 4 features into 3 labels (Iris Setosa, Iris Versicolour, or Iris Virginica). When applying machine learning models, and particularly neural networks, it is recommended to normalize the data. As such, we use a common StandardScaler (we transform the data \\(x\\) to \\(z = (x - u) / s\\) where \\(u, s\\) are respectively the mean and standard deviation of the training samples).</p> <pre><code>import random\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom torch import Tensor\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom qadence import QNN, RX, FeatureParameter, QuantumCircuit, Z, chain, hea, kron\nfrom qadence.ml_tools import TrainConfig, Trainer\n\nclass IrisDataset(Dataset):\n    \"\"\"The Iris dataset split into a training set and a test set.\n\n    A StandardScaler is applied prior to applying models.\n    \"\"\"\n\n    def __init__(self):\n        X, y = load_iris(return_X_y=True)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n        self.scaler = StandardScaler()\n        self.scaler.fit(X_train)\n        self.X = torch.tensor(self.scaler.transform(X_train), requires_grad=False)\n        self.y = torch.tensor(y_train, requires_grad=False)\n\n        self.X_test = torch.tensor(self.scaler.transform(X_test), requires_grad=False)\n        self.y_test = torch.tensor(y_test, requires_grad=False)\n\n    def __getitem__(self, index) -&gt; tuple[Tensor, Tensor]:\n        return self.X[index], self.y[index]\n\n    def __len__(self) -&gt; int:\n        return len(self.y)\n\nn_features = 4  # sepal length, sepal width, petal length, petal width\nn_layers = 3\nn_neurons_final_linear_layer = 3\nn_epochs = 1000\nlr = 1e-1\ndataset = IrisDataset()\n\ndataloader = DataLoader(dataset, batch_size=20, shuffle=True)\n</code></pre>"},{"location":"tutorials/qml/classification/#hybrid-qnn","title":"Hybrid QNN","text":"<p>We set up the QNN part composed of multiple feature map layers, each followed by a variational layer. The type of variational layer we use is the hardware-efficient-ansatz (HEA). You can check the qml constructors tutorial to see how you can customize these components. The output will be the expectation value with respect to a \\(Z\\) observable on qubit \\(0\\). Then we add a simple linear layer serving as a classification head. This is equivalent to applying a weight matrix \\(W\\) and bias vector \\(b\\) to the output of the QNN denoted \\(o\\), \\(l = W * o + b\\). To obtain probabilities, we can apply the softmax function defined as: \\(p_i = \\exp(l_i) / \\sum_{j=1}^3 \\exp(l_i)\\). Note softmax is not applied during training with the cross-entropy loss.</p> <pre><code>feature_parameters = [FeatureParameter(f\"x_{i}\") for i in range(n_features)]\nfm_layer = RX(0, feature_parameters[0])\nfor q in range(1, n_features):\n    fm_layer = kron(fm_layer, RX(q, feature_parameters[q]))\n\nansatz_layers = [\n    hea(n_qubits=n_features, depth=1, param_prefix=f\"theta_{layer}\")\n    for layer in range(n_layers)\n]\nblocks = chain(fm_layer, ansatz_layers[0])\nfor layer in range(1, n_layers):\n    blocks = chain(blocks, fm_layer, ansatz_layers[layer])\n\nqc = QuantumCircuit(n_features, blocks)\nqnn = QNN(circuit=qc, observable=Z(0), inputs=[f\"x_{i}\" for i in range(n_features)])\nmodel = nn.Sequential(qnn, nn.Linear(1, n_neurons_final_linear_layer))\n</code></pre> <p>Below is a visualization of the QNN:</p> <pre><code>\n</code></pre> %3 cluster_4520a4655b6a4883bcf93f9be901fe60 HEA cluster_f61d0e2136f64afea30d57129a1f57d8 Obs. cluster_4d8d9194641d4ec6b4a1dedd35b0c63b HEA cluster_0ad089ff759d4cd5bc7cbe46ad174481 HEA b26647b934f3459abc34ef6d16164774 0 dfbf56519f784ac997f79195ad879e20 RX(x\u2080) b26647b934f3459abc34ef6d16164774--dfbf56519f784ac997f79195ad879e20 acab9b5e6c6c4cd0b1a8a650eb8aff5b 1 b628078078e14a11ae25c41cdb98b216 RX(theta\u2080\u2080) dfbf56519f784ac997f79195ad879e20--b628078078e14a11ae25c41cdb98b216 1080d3114e894c169d3c6ce68a74d406 RY(theta\u2080\u2084) b628078078e14a11ae25c41cdb98b216--1080d3114e894c169d3c6ce68a74d406 420a8d70b31d4708979d1e74e768d0c0 RX(theta\u2080\u2088) 1080d3114e894c169d3c6ce68a74d406--420a8d70b31d4708979d1e74e768d0c0 746b72315f0245e6bfdece5bcaeab92e 420a8d70b31d4708979d1e74e768d0c0--746b72315f0245e6bfdece5bcaeab92e 467d7ec525794434a7f7fca3c9f515a0 746b72315f0245e6bfdece5bcaeab92e--467d7ec525794434a7f7fca3c9f515a0 b5649115193d4ee3915b841a98189597 RX(x\u2080) 467d7ec525794434a7f7fca3c9f515a0--b5649115193d4ee3915b841a98189597 607966122a9a49f4835fbdfe142e4b7c RX(theta\u2081\u2080) b5649115193d4ee3915b841a98189597--607966122a9a49f4835fbdfe142e4b7c eba3e33474fb4805825c5028d39a5002 RY(theta\u2081\u2084) 607966122a9a49f4835fbdfe142e4b7c--eba3e33474fb4805825c5028d39a5002 0dd6fcb6031a4a518986db1229f95de4 RX(theta\u2081\u2088) eba3e33474fb4805825c5028d39a5002--0dd6fcb6031a4a518986db1229f95de4 d2d9e5b45b9840f0b81b252de14f5389 0dd6fcb6031a4a518986db1229f95de4--d2d9e5b45b9840f0b81b252de14f5389 af5c40b72a284fafa3965c3268dbf4a6 d2d9e5b45b9840f0b81b252de14f5389--af5c40b72a284fafa3965c3268dbf4a6 cbf562c8e0384e269a81f391113491c7 RX(x\u2080) af5c40b72a284fafa3965c3268dbf4a6--cbf562c8e0384e269a81f391113491c7 a2ac4fd09c264dc482867b11f8955f32 RX(theta\u2082\u2080) cbf562c8e0384e269a81f391113491c7--a2ac4fd09c264dc482867b11f8955f32 fa2123a35664468d990241dfac1fc4fe RY(theta\u2082\u2084) a2ac4fd09c264dc482867b11f8955f32--fa2123a35664468d990241dfac1fc4fe 2af5ed1010f248c5acf385d7345469bf RX(theta\u2082\u2088) fa2123a35664468d990241dfac1fc4fe--2af5ed1010f248c5acf385d7345469bf ed7b071058504c10924bd56ce31d400a 2af5ed1010f248c5acf385d7345469bf--ed7b071058504c10924bd56ce31d400a ac92dc15a3b74978a79aa1606e291adc ed7b071058504c10924bd56ce31d400a--ac92dc15a3b74978a79aa1606e291adc fd4cfd8fd053413899bd1a97bd5a1891 Z ac92dc15a3b74978a79aa1606e291adc--fd4cfd8fd053413899bd1a97bd5a1891 d036cd5817b1497f8507ab3742275eb3 fd4cfd8fd053413899bd1a97bd5a1891--d036cd5817b1497f8507ab3742275eb3 bfa3d04baf274ee094056c273796e8c0 b47595787978471eb310b830c9ca6a12 RX(x\u2081) acab9b5e6c6c4cd0b1a8a650eb8aff5b--b47595787978471eb310b830c9ca6a12 13ef4fa0da034c6a96bd5277edd2b7a3 2 3b612a6ae8324b00b2ee05969cf153be RX(theta\u2080\u2081) b47595787978471eb310b830c9ca6a12--3b612a6ae8324b00b2ee05969cf153be 8f7a558a448f4a6ebf4c0df970e572e5 RY(theta\u2080\u2085) 3b612a6ae8324b00b2ee05969cf153be--8f7a558a448f4a6ebf4c0df970e572e5 f486d3aa43684b808700711d79f19dc4 RX(theta\u2080\u2089) 8f7a558a448f4a6ebf4c0df970e572e5--f486d3aa43684b808700711d79f19dc4 0fd498c40e6a49968b727b6caf19abbd X f486d3aa43684b808700711d79f19dc4--0fd498c40e6a49968b727b6caf19abbd 0fd498c40e6a49968b727b6caf19abbd--746b72315f0245e6bfdece5bcaeab92e dba17f81ea754d8f93d4e05a445f1276 0fd498c40e6a49968b727b6caf19abbd--dba17f81ea754d8f93d4e05a445f1276 de3785009912432ab5e8bf7d4bd9a285 RX(x\u2081) dba17f81ea754d8f93d4e05a445f1276--de3785009912432ab5e8bf7d4bd9a285 e05104567b2449678f9402d7290ed74d RX(theta\u2081\u2081) de3785009912432ab5e8bf7d4bd9a285--e05104567b2449678f9402d7290ed74d 60321051a02644c097244157ed6c2124 RY(theta\u2081\u2085) e05104567b2449678f9402d7290ed74d--60321051a02644c097244157ed6c2124 a8ffa82e279742f5aa89d4292d4654f8 RX(theta\u2081\u2089) 60321051a02644c097244157ed6c2124--a8ffa82e279742f5aa89d4292d4654f8 fa8bd10a76bf4b288eb3bbf318223348 X a8ffa82e279742f5aa89d4292d4654f8--fa8bd10a76bf4b288eb3bbf318223348 fa8bd10a76bf4b288eb3bbf318223348--d2d9e5b45b9840f0b81b252de14f5389 e199f8170521469daf7635302d89da8f fa8bd10a76bf4b288eb3bbf318223348--e199f8170521469daf7635302d89da8f 03cf49075fcd4c3fbfb0350655cca1ca RX(x\u2081) e199f8170521469daf7635302d89da8f--03cf49075fcd4c3fbfb0350655cca1ca 55f058d98d1f4caabc5778ae7059532a RX(theta\u2082\u2081) 03cf49075fcd4c3fbfb0350655cca1ca--55f058d98d1f4caabc5778ae7059532a ed8aa5c9209649bca64b057fd660d6f5 RY(theta\u2082\u2085) 55f058d98d1f4caabc5778ae7059532a--ed8aa5c9209649bca64b057fd660d6f5 882b9bac7ff44560a023d7342ed130e2 RX(theta\u2082\u2089) ed8aa5c9209649bca64b057fd660d6f5--882b9bac7ff44560a023d7342ed130e2 61a252c8a22c408bb474a7d67654c7bb X 882b9bac7ff44560a023d7342ed130e2--61a252c8a22c408bb474a7d67654c7bb 61a252c8a22c408bb474a7d67654c7bb--ed7b071058504c10924bd56ce31d400a 477b2051e1d44a2ca13aecdd82b178ef 61a252c8a22c408bb474a7d67654c7bb--477b2051e1d44a2ca13aecdd82b178ef 5804fa20a48e4777add588de1d168eee 477b2051e1d44a2ca13aecdd82b178ef--5804fa20a48e4777add588de1d168eee 5804fa20a48e4777add588de1d168eee--bfa3d04baf274ee094056c273796e8c0 09744697c0c44c1aad0610ee4b2b1a16 e26fc94d201c4cc4a3e5e54f9a927750 RX(x\u2082) 13ef4fa0da034c6a96bd5277edd2b7a3--e26fc94d201c4cc4a3e5e54f9a927750 93523748311e42d8a28471cc6df33e9b 3 6ea49af6ca20471b9636e531f80aef3b RX(theta\u2080\u2082) e26fc94d201c4cc4a3e5e54f9a927750--6ea49af6ca20471b9636e531f80aef3b 35987dacb63442d3be542a595d14d5d9 RY(theta\u2080\u2086) 6ea49af6ca20471b9636e531f80aef3b--35987dacb63442d3be542a595d14d5d9 d446da227d864a6ea016881056f865d5 RX(theta\u2080\u2081\u2080) 35987dacb63442d3be542a595d14d5d9--d446da227d864a6ea016881056f865d5 3c159608101d4541b444ce20d7d491b5 d446da227d864a6ea016881056f865d5--3c159608101d4541b444ce20d7d491b5 536a773c516b4ffcaba57e5e32c67817 X 3c159608101d4541b444ce20d7d491b5--536a773c516b4ffcaba57e5e32c67817 536a773c516b4ffcaba57e5e32c67817--dba17f81ea754d8f93d4e05a445f1276 9cbeaf399f6b48bebe34be69f51aaab3 RX(x\u2082) 536a773c516b4ffcaba57e5e32c67817--9cbeaf399f6b48bebe34be69f51aaab3 2ed471500dad400aaf3a4c2311930b7e RX(theta\u2081\u2082) 9cbeaf399f6b48bebe34be69f51aaab3--2ed471500dad400aaf3a4c2311930b7e c8431a8a740a4bd5bdbaa147a5db662f RY(theta\u2081\u2086) 2ed471500dad400aaf3a4c2311930b7e--c8431a8a740a4bd5bdbaa147a5db662f 7ff7b358913a4148b2fbb5920f13b1c4 RX(theta\u2081\u2081\u2080) c8431a8a740a4bd5bdbaa147a5db662f--7ff7b358913a4148b2fbb5920f13b1c4 abde8c59c62d4ebeb65241e316bb9fa9 7ff7b358913a4148b2fbb5920f13b1c4--abde8c59c62d4ebeb65241e316bb9fa9 7bece7363e534d6e9336650c6ddeb287 X abde8c59c62d4ebeb65241e316bb9fa9--7bece7363e534d6e9336650c6ddeb287 7bece7363e534d6e9336650c6ddeb287--e199f8170521469daf7635302d89da8f f6163e4a066d4bb892073f0ac561da93 RX(x\u2082) 7bece7363e534d6e9336650c6ddeb287--f6163e4a066d4bb892073f0ac561da93 14bf1b76022e4891881b6d3ece0948aa RX(theta\u2082\u2082) f6163e4a066d4bb892073f0ac561da93--14bf1b76022e4891881b6d3ece0948aa ef6d846e14674194a4d50e4e1f09bcda RY(theta\u2082\u2086) 14bf1b76022e4891881b6d3ece0948aa--ef6d846e14674194a4d50e4e1f09bcda d9a168e10fc04b1496017247d09472ea RX(theta\u2082\u2081\u2080) ef6d846e14674194a4d50e4e1f09bcda--d9a168e10fc04b1496017247d09472ea 9fe9b1fdbc164914bdd963c88489b703 d9a168e10fc04b1496017247d09472ea--9fe9b1fdbc164914bdd963c88489b703 95397166c70f42c69d125df3a706e2b4 X 9fe9b1fdbc164914bdd963c88489b703--95397166c70f42c69d125df3a706e2b4 95397166c70f42c69d125df3a706e2b4--477b2051e1d44a2ca13aecdd82b178ef b60abd46c94f48d79e0463398488fea9 95397166c70f42c69d125df3a706e2b4--b60abd46c94f48d79e0463398488fea9 b60abd46c94f48d79e0463398488fea9--09744697c0c44c1aad0610ee4b2b1a16 c5fbdbb7df604da5a075a0173402d14c 9890d0b5e77a472dbdd0a0625dbd70cf RX(x\u2083) 93523748311e42d8a28471cc6df33e9b--9890d0b5e77a472dbdd0a0625dbd70cf 41f7c7adcf874d25bb8f7108413d3297 RX(theta\u2080\u2083) 9890d0b5e77a472dbdd0a0625dbd70cf--41f7c7adcf874d25bb8f7108413d3297 cd710df9557b4fc19677546e90eefdff RY(theta\u2080\u2087) 41f7c7adcf874d25bb8f7108413d3297--cd710df9557b4fc19677546e90eefdff f6665c8cebd5447aaa4778ff123b7b66 RX(theta\u2080\u2081\u2081) cd710df9557b4fc19677546e90eefdff--f6665c8cebd5447aaa4778ff123b7b66 ac32cd465ef94eb5bfdb7cb0ed0bd9cb X f6665c8cebd5447aaa4778ff123b7b66--ac32cd465ef94eb5bfdb7cb0ed0bd9cb ac32cd465ef94eb5bfdb7cb0ed0bd9cb--3c159608101d4541b444ce20d7d491b5 cf26576c3ec34dd3bd5a308805c565f3 ac32cd465ef94eb5bfdb7cb0ed0bd9cb--cf26576c3ec34dd3bd5a308805c565f3 2fc3d7923a7e4e9bbf9aa01bbb129c1e RX(x\u2083) cf26576c3ec34dd3bd5a308805c565f3--2fc3d7923a7e4e9bbf9aa01bbb129c1e 64ae75bc16084249a32c7e54aff17de8 RX(theta\u2081\u2083) 2fc3d7923a7e4e9bbf9aa01bbb129c1e--64ae75bc16084249a32c7e54aff17de8 2969263868a6484582ecf586470c2251 RY(theta\u2081\u2087) 64ae75bc16084249a32c7e54aff17de8--2969263868a6484582ecf586470c2251 9a76c7a38055430aa13a7dd14c4e6177 RX(theta\u2081\u2081\u2081) 2969263868a6484582ecf586470c2251--9a76c7a38055430aa13a7dd14c4e6177 2f7edc1a9a9f422298b8f519b31f254f X 9a76c7a38055430aa13a7dd14c4e6177--2f7edc1a9a9f422298b8f519b31f254f 2f7edc1a9a9f422298b8f519b31f254f--abde8c59c62d4ebeb65241e316bb9fa9 de118637a35240cb9e0b7fa6acfa0e2b 2f7edc1a9a9f422298b8f519b31f254f--de118637a35240cb9e0b7fa6acfa0e2b 51a26f4c393f4c8fa36b7ff573b848e9 RX(x\u2083) de118637a35240cb9e0b7fa6acfa0e2b--51a26f4c393f4c8fa36b7ff573b848e9 361e6d3282994df9a58d2e843187ebe0 RX(theta\u2082\u2083) 51a26f4c393f4c8fa36b7ff573b848e9--361e6d3282994df9a58d2e843187ebe0 686fabdb10f14506a9d4202f989569ee RY(theta\u2082\u2087) 361e6d3282994df9a58d2e843187ebe0--686fabdb10f14506a9d4202f989569ee 99d0681933d04351949c1c8057434a00 RX(theta\u2082\u2081\u2081) 686fabdb10f14506a9d4202f989569ee--99d0681933d04351949c1c8057434a00 f759cba3e7bc4e5e84c3b683f899b295 X 99d0681933d04351949c1c8057434a00--f759cba3e7bc4e5e84c3b683f899b295 f759cba3e7bc4e5e84c3b683f899b295--9fe9b1fdbc164914bdd963c88489b703 34ecdd3e40c14c28b87bd45582ad493e f759cba3e7bc4e5e84c3b683f899b295--34ecdd3e40c14c28b87bd45582ad493e 93a4697f9d43442f89d02ab2fa7848f4 34ecdd3e40c14c28b87bd45582ad493e--93a4697f9d43442f89d02ab2fa7848f4 93a4697f9d43442f89d02ab2fa7848f4--c5fbdbb7df604da5a075a0173402d14c"},{"location":"tutorials/qml/classification/#training","title":"Training","text":"<p>Then we can set up the training part:</p> <pre><code>opt = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\ndef cross_entropy(model: nn.Module, data: Tensor) -&gt; tuple[Tensor, dict]:\n    x, y = data\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ntrain_config = TrainConfig(max_iter=n_epochs, print_every=10, create_subfolder_per_run=True)\nTrainer.set_use_grad(True)\ntrainer = Trainer(model=model, optimizer=opt, config=train_config, loss_fn=cross_entropy)\n\n\nres_train = trainer.fit(dataloader)\n</code></pre>"},{"location":"tutorials/qml/classification/#inference","title":"Inference","text":"<p>Finally, we can apply our model on the test set and check the score.</p> <pre><code>X_test, y_test = dataset.X_test, dataset.y_test\npreds_test = torch.argmax(torch.softmax(model(X_test), dim=1), dim=1)\naccuracy_test = (preds_test == y_test).type(torch.float32).mean()\n## Should reach higher than 0.9\n</code></pre>   Test Accuracy: 0.9200000166893005"},{"location":"tutorials/qml/config_qnn/","title":"Configuring a QNN","text":"<p>In <code>qadence</code>, the <code>QNN</code> is a variational quantum model that can potentially take multi-dimensional input.</p> <p>The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>The circuit has two parts, the feature map and the ansatz. The feature map is responsible for encoding the input data into the quantum state, while the ansatz is responsible for the variational part of the model. In addition, a third part of the QNN is the observables, which is (a list of) operators that are measured at the end of the circuit.</p> <p>In QML Constructors we have seen how to construct the feature map and the ansatz. In this tutorial, we will see how to do the same using configs.</p> <p>One convenient way to construct these three parts of the model is to use the config classes, namely, <code>ObservableConfig</code>, <code>FeatureMapConfig</code>, <code>AnsatzConfig</code>. These classes allow you to specify the type of circuit and the parameters of the circuit in a structured way.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-observable","title":"Defining the Observable","text":"<p>The model output is the expectation value of the defined observable(s). We use the <code>ObservableConfig</code> class to specify the observable.</p> <p>It can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings. Any Hamiltonian supported by <code>hamiltonian_factory</code> can be specified as an observable. For example, suppose we want to measure the Z operator:</p> <pre><code>from qadence import create_observable, ObservableConfig, Z\n\nobservable_config = ObservableConfig(\n    detuning=Z,\n    interaction = None,\n    scale = 2.0,\n    shift=-1.0,\n)\n\nobservable = create_observable(register=4, config=observable_config)\n</code></pre> %3 cluster_26383cb4c7944b74ba19b41944530150 bbe37f84ac87462583aeb43d802756c5 0 e73efe7ec1d54200be4c798ebda534c0 bbe37f84ac87462583aeb43d802756c5--e73efe7ec1d54200be4c798ebda534c0 8b5a9c02b803452bb46900e168c37648 1 34c720389144432e88b9843bda70b8a4 e73efe7ec1d54200be4c798ebda534c0--34c720389144432e88b9843bda70b8a4 135f8a92eb2b47d181b2ee5b965c795e ded5069a2aa94d6ea6354eeeb4ca08ee AddBlock 8b5a9c02b803452bb46900e168c37648--ded5069a2aa94d6ea6354eeeb4ca08ee 1c2e7f870e9c4ce3b3a4a68465994e50 2 ded5069a2aa94d6ea6354eeeb4ca08ee--135f8a92eb2b47d181b2ee5b965c795e b670635644074cb7a57b534f59e8a651 979070bc7bf04b9796bc9a39ab226e41 1c2e7f870e9c4ce3b3a4a68465994e50--979070bc7bf04b9796bc9a39ab226e41 55cab032965a44fc8c8c4ef9f831712e 3 979070bc7bf04b9796bc9a39ab226e41--b670635644074cb7a57b534f59e8a651 889cd1bb7ab8483f9cad5fd3f438c13a 6af7505ac38e430fbd383cf05b16185e 55cab032965a44fc8c8c4ef9f831712e--6af7505ac38e430fbd383cf05b16185e 6af7505ac38e430fbd383cf05b16185e--889cd1bb7ab8483f9cad5fd3f438c13a <p>We have specified the observable Hamiltonian to be one with \\(Z\\)-detuning. The result is linearly scaled by 2.0 and shifted by -1.0. The shift or the scale can optionally also be a VariationalParameter</p> <p>It is also possible to import some common Hamiltonians, such as <code>total_magnetization_config</code>, <code>zz_hamiltonian_config</code> and, <code>ising_hamiltonian_config</code>.</p> <p>For example, the total magnetization configuration:</p> <pre><code>from qadence import create_observable\nfrom qadence.constructors import total_magnetization_config\n\nobservable_total_magnetization  = create_observable(register=4, config=total_magnetization_config())\n</code></pre> <p>Alternatively, you can define the observable as a list of observables, in which case the QNN will output a list of values.</p>"},{"location":"tutorials/qml/config_qnn/#scaling-and-shifting-the-qnn-output","title":"Scaling and Shifting the QNN Output","text":"<p>For any observable, by appropriately choosing the scale \\(\\alpha\\) and shift \\(\\beta\\), you can constrain the QNN output within a desired range. This is particularly useful for normalizing measurements or ensuring that values remain within a meaningful interval for optimization. To accomplish this, you need to determine the maximum and minimum values that the QNN output can take. For an observable, these extreme values are the two extreme eigenvalues \\(\\lambda_{max}\\) and \\(\\lambda_{min}\\) of the concerned Hamiltonian. Using these values, you can set the scale \\(\\alpha\\) and shift \\(\\beta\\) so that the QNN output is mapped to a specific range \\([a,b]\\):</p> \\[\\alpha = \\frac{b-a}{\\lambda_{max}-\\lambda_{min}}\\] \\[\\beta = \\frac{a\\lambda_{max}-b\\lambda_{min}}{\\lambda_{max}-\\lambda_{min}}\\] <p>This transformation ensures that:</p> \\[ a \\leq \\alpha \\lambda + \\beta \\leq b,\\quad\\forall \\lambda \\in [\\lambda_{min},\\lambda_{max}] \\] <p>For full details on the <code>ObservableConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-feature-map","title":"Defining the Feature Map","text":"<p>Let us say we want to build a 4-qubit QNN that takes two inputs, namely, the \\(x\\) and the \\(y\\) coordinates of a point in the plane. We can use the <code>FeatureMapConfig</code> class to specify the feature map.</p> <pre><code>from qadence import BasisSet, chain, create_fm_blocks, FeatureMapConfig, ReuploadScaling\n\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs = [\"x\", \"y\"],\n    basis_set=BasisSet.CHEBYSHEV,\n    reupload_scaling=ReuploadScaling.TOWER,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\n\nfm_blocks = create_fm_blocks(register=4, config=fm_config)\nfeature_map = chain(*fm_blocks)\n</code></pre> %3 cluster_698e94597e654781a89b6030a54dcbc3 Tower Chebyshev FM cluster_7d948e03f41f48bdb96353419e63aa33 Tower Chebyshev FM 306e9d0d7e894f3a9c2b0f00e9dedde0 0 3a3b9e364cbb44c59eb93358c7b69460 RX(1.0*acos(x)) 306e9d0d7e894f3a9c2b0f00e9dedde0--3a3b9e364cbb44c59eb93358c7b69460 33c0218e7a8a4ff9b0efbfdc5472e7d3 1 757909a2069d451fa03ab653b470ba8d 3a3b9e364cbb44c59eb93358c7b69460--757909a2069d451fa03ab653b470ba8d 7fac6d74990b46e38d464f3b44bcf788 cb3ab84db1f24e9e85e474b06ee5bb28 RX(2.0*acos(x)) 33c0218e7a8a4ff9b0efbfdc5472e7d3--cb3ab84db1f24e9e85e474b06ee5bb28 4a78ec68d13147b0bc5ad5112a05cd9c 2 cb3ab84db1f24e9e85e474b06ee5bb28--7fac6d74990b46e38d464f3b44bcf788 d9140493bec9438fa0d3f8dbb615acbe c8ba775c051c4e0fb0bd01d66f04571d RX(1.0*acos(2.0*y - 1.0)) 4a78ec68d13147b0bc5ad5112a05cd9c--c8ba775c051c4e0fb0bd01d66f04571d c8de6edda43447aca3c50174d3699310 3 c8ba775c051c4e0fb0bd01d66f04571d--d9140493bec9438fa0d3f8dbb615acbe dd69c2725c1c418697865c6e6ca3ee84 4c21bcee24f64b1ea50e315661f62602 RX(2.0*acos(2.0*y - 1.0)) c8de6edda43447aca3c50174d3699310--4c21bcee24f64b1ea50e315661f62602 4c21bcee24f64b1ea50e315661f62602--dd69c2725c1c418697865c6e6ca3ee84 <p>We have specified that the feature map should take two features, and have named the <code>FeatureParameter</code> \"x\" and \"y\" respectively. Both these parameters are encoded using the Chebyshev basis set, and the reupload scaling is set to <code>ReuploadScaling.TOWER</code>. One can optionally add the basis and the reupload scaling for each parameter separately.</p> <p>The <code>feature_range</code> parameter is a dictionary that specifies the range of values that each feature comes from. This is useful for scaling the input data to the range that the encoding function can handle. In default case, this range is mapped to the target range of the Chebyshev basis set which is \\([-1, 1]\\). One can also specify the target range for each feature separately.</p> <p>For full details on the <code>FeatureMapConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-ansatz","title":"Defining the Ansatz","text":"<p>The next part of the QNN is the ansatz. We use <code>AnsatzConfig</code> class to specify the type of ansatz.</p> <p>Let us say, we want to follow this feature map with 2 layers of hardware efficient ansatz.</p> <pre><code>from qadence import AnsatzConfig, AnsatzType, create_ansatz, Strategy\n\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nansatz = create_ansatz(register=4, config=ansatz_config)\n</code></pre> %3 132bfe3a9d6649ab9ffef91b8b52d0f5 0 70b5f0b5f6c94d2eb352eb6a2d1501c7 RX(theta\u2080) 132bfe3a9d6649ab9ffef91b8b52d0f5--70b5f0b5f6c94d2eb352eb6a2d1501c7 b393696443b845b48b4cc4760a49485e 1 619ba3ff414d427b83ca3a44736dcefe RY(theta\u2084) 70b5f0b5f6c94d2eb352eb6a2d1501c7--619ba3ff414d427b83ca3a44736dcefe 625fab3adc1c45b1af85d19f16e99845 RX(theta\u2088) 619ba3ff414d427b83ca3a44736dcefe--625fab3adc1c45b1af85d19f16e99845 74669c1c54e14a7bab8f92695ae2a4da 625fab3adc1c45b1af85d19f16e99845--74669c1c54e14a7bab8f92695ae2a4da a0b0ffb4f0f340aba9ff49f167f764ad 74669c1c54e14a7bab8f92695ae2a4da--a0b0ffb4f0f340aba9ff49f167f764ad 59e60f267c964f849c7e3fd1a682eea3 RX(theta\u2081\u2082) a0b0ffb4f0f340aba9ff49f167f764ad--59e60f267c964f849c7e3fd1a682eea3 8e6ee9f66e0e457fa8c447bcd8fc649c RY(theta\u2081\u2086) 59e60f267c964f849c7e3fd1a682eea3--8e6ee9f66e0e457fa8c447bcd8fc649c 967d4b9fff4d4a859b014601f7fd505b RX(theta\u2082\u2080) 8e6ee9f66e0e457fa8c447bcd8fc649c--967d4b9fff4d4a859b014601f7fd505b d0919de523d34b33b1fa47f8df073e7e 967d4b9fff4d4a859b014601f7fd505b--d0919de523d34b33b1fa47f8df073e7e 60b779e6ae4241ca90d7cc9faf0f8d1d d0919de523d34b33b1fa47f8df073e7e--60b779e6ae4241ca90d7cc9faf0f8d1d f82c1460689147549e8ec29f832d3710 60b779e6ae4241ca90d7cc9faf0f8d1d--f82c1460689147549e8ec29f832d3710 e4a12802e48f4a6a8ef412981d82f0a3 0f8249b01f334b18813261a7f082d186 RX(theta\u2081) b393696443b845b48b4cc4760a49485e--0f8249b01f334b18813261a7f082d186 60c22ffb143f43079220c0a08e336d87 2 d207940765c8456ab904e53afb13dbbf RY(theta\u2085) 0f8249b01f334b18813261a7f082d186--d207940765c8456ab904e53afb13dbbf 3fa48c1666574f01876dbbacde338d10 RX(theta\u2089) d207940765c8456ab904e53afb13dbbf--3fa48c1666574f01876dbbacde338d10 161fbe5e995945f58dadbfda25d3def8 X 3fa48c1666574f01876dbbacde338d10--161fbe5e995945f58dadbfda25d3def8 161fbe5e995945f58dadbfda25d3def8--74669c1c54e14a7bab8f92695ae2a4da 504a84f035d4493ebe36e5aed7c9e7df 161fbe5e995945f58dadbfda25d3def8--504a84f035d4493ebe36e5aed7c9e7df a77d8fb7ed6644efb8ad4047a16b610f RX(theta\u2081\u2083) 504a84f035d4493ebe36e5aed7c9e7df--a77d8fb7ed6644efb8ad4047a16b610f 33742a1e36694e21a6e605efbef3b5d2 RY(theta\u2081\u2087) a77d8fb7ed6644efb8ad4047a16b610f--33742a1e36694e21a6e605efbef3b5d2 ff4a6517b53b427892fb3fa68d6c1469 RX(theta\u2082\u2081) 33742a1e36694e21a6e605efbef3b5d2--ff4a6517b53b427892fb3fa68d6c1469 44e295bbc8274300a8a80f263efc1528 X ff4a6517b53b427892fb3fa68d6c1469--44e295bbc8274300a8a80f263efc1528 44e295bbc8274300a8a80f263efc1528--d0919de523d34b33b1fa47f8df073e7e a0e2c0516db04948a0ba8bf33235da0e 44e295bbc8274300a8a80f263efc1528--a0e2c0516db04948a0ba8bf33235da0e a0e2c0516db04948a0ba8bf33235da0e--e4a12802e48f4a6a8ef412981d82f0a3 e8593ee0f6d04afd9e42456ad6cbf692 44bff90b00a04ab09c8cd784af46800e RX(theta\u2082) 60c22ffb143f43079220c0a08e336d87--44bff90b00a04ab09c8cd784af46800e 2353992cf0b643ba8283cd0f348ab188 3 b1219147395641e4a57559a4db027b89 RY(theta\u2086) 44bff90b00a04ab09c8cd784af46800e--b1219147395641e4a57559a4db027b89 ab3efb6b2a9644cf896b3d427cc99d27 RX(theta\u2081\u2080) b1219147395641e4a57559a4db027b89--ab3efb6b2a9644cf896b3d427cc99d27 a456f62482434e79bd7e39192c65c4f0 ab3efb6b2a9644cf896b3d427cc99d27--a456f62482434e79bd7e39192c65c4f0 1f9d8fc0055f4a19a4c6d40811afc468 X a456f62482434e79bd7e39192c65c4f0--1f9d8fc0055f4a19a4c6d40811afc468 1f9d8fc0055f4a19a4c6d40811afc468--504a84f035d4493ebe36e5aed7c9e7df 9f55eca9a2e342beba393fa3b05e9b21 RX(theta\u2081\u2084) 1f9d8fc0055f4a19a4c6d40811afc468--9f55eca9a2e342beba393fa3b05e9b21 5d0982a111c742b9adb8d2ab00c06a93 RY(theta\u2081\u2088) 9f55eca9a2e342beba393fa3b05e9b21--5d0982a111c742b9adb8d2ab00c06a93 311b64a6bb9f4deca47255346872d1b8 RX(theta\u2082\u2082) 5d0982a111c742b9adb8d2ab00c06a93--311b64a6bb9f4deca47255346872d1b8 336c95734fb340eaaa0b5860113a4cfb 311b64a6bb9f4deca47255346872d1b8--336c95734fb340eaaa0b5860113a4cfb 99e23f93704c42ee9d8f9b104c7e77d3 X 336c95734fb340eaaa0b5860113a4cfb--99e23f93704c42ee9d8f9b104c7e77d3 99e23f93704c42ee9d8f9b104c7e77d3--a0e2c0516db04948a0ba8bf33235da0e 99e23f93704c42ee9d8f9b104c7e77d3--e8593ee0f6d04afd9e42456ad6cbf692 e6760c6836864f24bdb95dadaba1961b 8880d9e984774ae9b5307e5a7e99947a RX(theta\u2083) 2353992cf0b643ba8283cd0f348ab188--8880d9e984774ae9b5307e5a7e99947a 99f871fc4fde444fb14fe2dc65eeb7b3 RY(theta\u2087) 8880d9e984774ae9b5307e5a7e99947a--99f871fc4fde444fb14fe2dc65eeb7b3 f020e3cc56bd4883be4d24ea3f2b7198 RX(theta\u2081\u2081) 99f871fc4fde444fb14fe2dc65eeb7b3--f020e3cc56bd4883be4d24ea3f2b7198 1c4b8290ccea40169cfdf6635dc5437d X f020e3cc56bd4883be4d24ea3f2b7198--1c4b8290ccea40169cfdf6635dc5437d 1c4b8290ccea40169cfdf6635dc5437d--a456f62482434e79bd7e39192c65c4f0 8ef504e6a1df4197ac445d9e7b6021dd 1c4b8290ccea40169cfdf6635dc5437d--8ef504e6a1df4197ac445d9e7b6021dd 219ea11e88854f029af41236f229b391 RX(theta\u2081\u2085) 8ef504e6a1df4197ac445d9e7b6021dd--219ea11e88854f029af41236f229b391 9df01775d57a4fec82217dc2b4347a57 RY(theta\u2081\u2089) 219ea11e88854f029af41236f229b391--9df01775d57a4fec82217dc2b4347a57 67cae51b5bec4c558875e8141adc582e RX(theta\u2082\u2083) 9df01775d57a4fec82217dc2b4347a57--67cae51b5bec4c558875e8141adc582e b9834dd515b8414aa64fd587510b0e8f X 67cae51b5bec4c558875e8141adc582e--b9834dd515b8414aa64fd587510b0e8f b9834dd515b8414aa64fd587510b0e8f--336c95734fb340eaaa0b5860113a4cfb d8481c64041f418b9c972af9280013c3 b9834dd515b8414aa64fd587510b0e8f--d8481c64041f418b9c972af9280013c3 d8481c64041f418b9c972af9280013c3--e6760c6836864f24bdb95dadaba1961b <p>We have specified that the ansatz should have a depth of 2, and the ansatz type is \"hea\" (Hardware Efficient Ansatz). The ansatz strategy is set to \"digital\", which means digital gates are being used. One could alternatively use \"analog\" or \"rydberg\" as the ansatz strategy.</p> <p>For full details on the <code>AnsatzConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-qnn-from-the-configs","title":"Defining the QNN from the Configs","text":"<p>To build the QNN, we can now use the <code>QNN</code> class as a <code>QuantumModel</code> subtype. In addition to the feature map, ansatz and the observable configs, we can also specify options such as the <code>backend</code>, <code>diff_mode</code>, etc. For full details on the <code>QNN</code> class, see the API documentation or the documentation on the config constructor here.</p> <pre><code>from qadence import BackendName, DiffMode, QNN\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.AD,\n)\n</code></pre> %3 cluster_9b16ef563a7d437f9c9de876094131f5 Obs. cluster_20285765561947fc920bdc13c0f3aed4 cluster_6a4aa5b13550428c8a221c2a3dcc2672 Tower Chebyshev FM cluster_066f40ab22f5405fbab170571c030fc8 Tower Chebyshev FM cluster_2ed6aa0f33dd4aa69616fa3acde58099 HEA 68cdfd1d0b99421c9f50cc62408f62a7 0 d7535e4b034b4b8c9c4120b60ac20a50 RX(1.0*acos(x)) 68cdfd1d0b99421c9f50cc62408f62a7--d7535e4b034b4b8c9c4120b60ac20a50 1e60991eca9948f0b52fab0c3d73486a 1 1823de43a3524be68dd7f919de34b120 RX(theta\u2080) d7535e4b034b4b8c9c4120b60ac20a50--1823de43a3524be68dd7f919de34b120 292cb10ae8934c1cbb4e5ec7b77ae49e RY(theta\u2084) 1823de43a3524be68dd7f919de34b120--292cb10ae8934c1cbb4e5ec7b77ae49e 45e7ab39cb124c509572e22df47d4b9f RX(theta\u2088) 292cb10ae8934c1cbb4e5ec7b77ae49e--45e7ab39cb124c509572e22df47d4b9f dbb974788d1c4a81bed3603cf0474f4e 45e7ab39cb124c509572e22df47d4b9f--dbb974788d1c4a81bed3603cf0474f4e c79a53437fcf44259fa9af5335e2f97c dbb974788d1c4a81bed3603cf0474f4e--c79a53437fcf44259fa9af5335e2f97c 1e5cade1da204e80bca5e79cb39c8698 RX(theta\u2081\u2082) c79a53437fcf44259fa9af5335e2f97c--1e5cade1da204e80bca5e79cb39c8698 c612fc7aca574ab5afc21702d12d356a RY(theta\u2081\u2086) 1e5cade1da204e80bca5e79cb39c8698--c612fc7aca574ab5afc21702d12d356a 5cf605a3208f4d3c8cb74c36158077eb RX(theta\u2082\u2080) c612fc7aca574ab5afc21702d12d356a--5cf605a3208f4d3c8cb74c36158077eb 1ef83be2e09a43c78f867854b67b6c38 5cf605a3208f4d3c8cb74c36158077eb--1ef83be2e09a43c78f867854b67b6c38 69e900c1eb7e4f21aea0770665220093 1ef83be2e09a43c78f867854b67b6c38--69e900c1eb7e4f21aea0770665220093 7e362d97a8984c04bb65ab3138e0c772 69e900c1eb7e4f21aea0770665220093--7e362d97a8984c04bb65ab3138e0c772 211c0defc7fa4a9d9b15be2039331e93 7e362d97a8984c04bb65ab3138e0c772--211c0defc7fa4a9d9b15be2039331e93 7cc92596c2554f528100dd76a4d100d3 fc3bc6c4dc054e2183bb22390263680e RX(2.0*acos(x)) 1e60991eca9948f0b52fab0c3d73486a--fc3bc6c4dc054e2183bb22390263680e 469dd72abf0d4359b61b07d4c21f34f8 2 8d60570ab7534991a8cba44987632d7d RX(theta\u2081) fc3bc6c4dc054e2183bb22390263680e--8d60570ab7534991a8cba44987632d7d 0d52b0cdfa7f4c129e4f20d6ce249bf8 RY(theta\u2085) 8d60570ab7534991a8cba44987632d7d--0d52b0cdfa7f4c129e4f20d6ce249bf8 885670a60c484541aa6ea09ee11e1825 RX(theta\u2089) 0d52b0cdfa7f4c129e4f20d6ce249bf8--885670a60c484541aa6ea09ee11e1825 7a10029b006c4d1aa24ddb6c87ff9124 X 885670a60c484541aa6ea09ee11e1825--7a10029b006c4d1aa24ddb6c87ff9124 7a10029b006c4d1aa24ddb6c87ff9124--dbb974788d1c4a81bed3603cf0474f4e 2b112b6f402848b0b15a46f88f831050 7a10029b006c4d1aa24ddb6c87ff9124--2b112b6f402848b0b15a46f88f831050 06e0e78c20c84450a09a5ba5812432f1 RX(theta\u2081\u2083) 2b112b6f402848b0b15a46f88f831050--06e0e78c20c84450a09a5ba5812432f1 0452609f94774577843f6dfbe6f36bde RY(theta\u2081\u2087) 06e0e78c20c84450a09a5ba5812432f1--0452609f94774577843f6dfbe6f36bde 82637cd1d43e4197b9b52b2bd5e4e011 RX(theta\u2082\u2081) 0452609f94774577843f6dfbe6f36bde--82637cd1d43e4197b9b52b2bd5e4e011 022bc1ad9fdd4ddfb3a81965befe3ca3 X 82637cd1d43e4197b9b52b2bd5e4e011--022bc1ad9fdd4ddfb3a81965befe3ca3 022bc1ad9fdd4ddfb3a81965befe3ca3--1ef83be2e09a43c78f867854b67b6c38 baa215ba1ad5401b861d78171b6f88ec 022bc1ad9fdd4ddfb3a81965befe3ca3--baa215ba1ad5401b861d78171b6f88ec d105c1bf3c6543d99b607cad3efa9bb4 AddBlock baa215ba1ad5401b861d78171b6f88ec--d105c1bf3c6543d99b607cad3efa9bb4 d105c1bf3c6543d99b607cad3efa9bb4--7cc92596c2554f528100dd76a4d100d3 25af084d2c4c486297a8c04f18a432a0 9d47abd303124806ba5074f478715be4 RX(1.0*acos(2.0*y - 1.0)) 469dd72abf0d4359b61b07d4c21f34f8--9d47abd303124806ba5074f478715be4 c228394540db472c9b968931538f54f7 3 2e6a5dd925454f0dbb5b1de222a8b77b RX(theta\u2082) 9d47abd303124806ba5074f478715be4--2e6a5dd925454f0dbb5b1de222a8b77b 0e9f589aad7b476fa1f42aba44974e20 RY(theta\u2086) 2e6a5dd925454f0dbb5b1de222a8b77b--0e9f589aad7b476fa1f42aba44974e20 9856f154f85543f58e743317ef24b40d RX(theta\u2081\u2080) 0e9f589aad7b476fa1f42aba44974e20--9856f154f85543f58e743317ef24b40d bb82eb022efb4f87a6bbc14b2dba75f8 9856f154f85543f58e743317ef24b40d--bb82eb022efb4f87a6bbc14b2dba75f8 1b1c84d51bc740e0b8ee8c730109c07f X bb82eb022efb4f87a6bbc14b2dba75f8--1b1c84d51bc740e0b8ee8c730109c07f 1b1c84d51bc740e0b8ee8c730109c07f--2b112b6f402848b0b15a46f88f831050 3ef3b98ac42243658a401ddec257e173 RX(theta\u2081\u2084) 1b1c84d51bc740e0b8ee8c730109c07f--3ef3b98ac42243658a401ddec257e173 730d47fd3b594fb8824718917b5a60b9 RY(theta\u2081\u2088) 3ef3b98ac42243658a401ddec257e173--730d47fd3b594fb8824718917b5a60b9 e9988ae35102420494f5360148a395d8 RX(theta\u2082\u2082) 730d47fd3b594fb8824718917b5a60b9--e9988ae35102420494f5360148a395d8 2bc7c4617dc34d509574f218cf8860f1 e9988ae35102420494f5360148a395d8--2bc7c4617dc34d509574f218cf8860f1 28fa29d821f14cc1a1a876253d3602b0 X 2bc7c4617dc34d509574f218cf8860f1--28fa29d821f14cc1a1a876253d3602b0 28fa29d821f14cc1a1a876253d3602b0--baa215ba1ad5401b861d78171b6f88ec 2dd12ff124324f9b9e406ac2e21d5408 28fa29d821f14cc1a1a876253d3602b0--2dd12ff124324f9b9e406ac2e21d5408 2dd12ff124324f9b9e406ac2e21d5408--25af084d2c4c486297a8c04f18a432a0 16ee5b0b26cd48d1beae869e77ac6783 0e3299e15db1482790d8cbf395162198 RX(2.0*acos(2.0*y - 1.0)) c228394540db472c9b968931538f54f7--0e3299e15db1482790d8cbf395162198 2ecd44eba0524ad8bb77bdc110e9b35c RX(theta\u2083) 0e3299e15db1482790d8cbf395162198--2ecd44eba0524ad8bb77bdc110e9b35c 67543411d83a4b1fbc45e806b0469a4e RY(theta\u2087) 2ecd44eba0524ad8bb77bdc110e9b35c--67543411d83a4b1fbc45e806b0469a4e 1da322d51edb4ae3a2d60f29c6da165a RX(theta\u2081\u2081) 67543411d83a4b1fbc45e806b0469a4e--1da322d51edb4ae3a2d60f29c6da165a 5cfdb78352414feaa70309da457d58d6 X 1da322d51edb4ae3a2d60f29c6da165a--5cfdb78352414feaa70309da457d58d6 5cfdb78352414feaa70309da457d58d6--bb82eb022efb4f87a6bbc14b2dba75f8 fa7f9a3f82dd4e18b13e315c8b63a8a8 5cfdb78352414feaa70309da457d58d6--fa7f9a3f82dd4e18b13e315c8b63a8a8 c986cafe310841449df2554f6917c3ec RX(theta\u2081\u2085) fa7f9a3f82dd4e18b13e315c8b63a8a8--c986cafe310841449df2554f6917c3ec b8c940464813430eb4ee383a2ee9ed9f RY(theta\u2081\u2089) c986cafe310841449df2554f6917c3ec--b8c940464813430eb4ee383a2ee9ed9f 6a76692778f945b798ce133ad9ef536c RX(theta\u2082\u2083) b8c940464813430eb4ee383a2ee9ed9f--6a76692778f945b798ce133ad9ef536c c1b31ffe97424351803ffc2e6d534ee7 X 6a76692778f945b798ce133ad9ef536c--c1b31ffe97424351803ffc2e6d534ee7 c1b31ffe97424351803ffc2e6d534ee7--2bc7c4617dc34d509574f218cf8860f1 61917834503c4dfc8941bf37eb5e5ee9 c1b31ffe97424351803ffc2e6d534ee7--61917834503c4dfc8941bf37eb5e5ee9 0037c5b9a9b1408c8eaf9ecf07966fba 61917834503c4dfc8941bf37eb5e5ee9--0037c5b9a9b1408c8eaf9ecf07966fba 0037c5b9a9b1408c8eaf9ecf07966fba--16ee5b0b26cd48d1beae869e77ac6783"},{"location":"tutorials/qml/dqc_1d/","title":"Solving a 1D ODE","text":"<p>In this tutorial we will show how to use Qadence to solve a basic 1D Ordinary Differential Equation (ODE) with a QNN using Differentiable Quantum Circuits (DQC) <sup>1</sup>.</p> <p>Consider the following non-linear ODE and boundary condition:</p> \\[ \\frac{df}{dx}= 5\\times(4x^3+x^2-2x-\\frac12), \\qquad f(0)=0 \\] <p>It admits an exact solution:</p> \\[ f(x)=5\\times(x^4+\\frac13x^3-x^2-\\frac12x) \\] <p>Our goal will be to find this solution for \\(x\\in[-1, 1]\\).</p> <pre><code>import torch\n\ndef dfdx_equation(x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Derivative as per the equation.\"\"\"\n    return 5*(4*x**3 + x**2 - 2*x - 0.5)\n</code></pre> <p>For the purpose of this tutorial, we will compute the derivative of the circuit using <code>torch.autograd</code>. The point of the DQC algorithm is to use differentiable circuits with parameter shift rules. In Qadence, PSR is implemented directly as custom overrides of the derivative function in the autograd engine, and thus we can later change the derivative method for the model itself if we wish.</p> <pre><code>def calc_deriv(outputs: torch.Tensor, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Compute a derivative of model that learns f(x), computes df/dx using torch.autograd.\"\"\"\n    grad = torch.autograd.grad(\n        outputs=outputs,\n        inputs=inputs,\n        grad_outputs = torch.ones_like(inputs),\n        create_graph = True,\n        retain_graph = True,\n    )[0]\n    return grad\n</code></pre>"},{"location":"tutorials/qml/dqc_1d/#defining-the-loss-function","title":"Defining the loss function","text":"<p>The essential part of solving this problem is to define the right loss function to represent our goal. In this case, we want to define a model that has the capacity to learn the target solution, and we want to minimize: - The derivative of this model in comparison with the exact derivative in the equation; - The output of the model at the boundary in comparison with the value for the boundary condition;</p> <p>We can write it like so:</p> <pre><code># Mean-squared error as the comparison criterion\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Loss function encoding the problem to solve.\"\"\"\n    # Equation loss\n    model_output = model(inputs)\n    deriv_model = calc_deriv(model_output, inputs)\n    deriv_exact = dfdx_equation(inputs)\n    ode_loss = criterion(deriv_model, deriv_exact)\n\n    # Boundary loss, f(0) = 0\n    boundary_model = model(torch.tensor([[0.0]]))\n    boundary_exact = torch.tensor([[0.0]])\n    boundary_loss = criterion(boundary_model, boundary_exact)\n\n    return ode_loss + boundary_loss\n</code></pre> <p>Different loss criterions could be considered, and we could also play with the balance between the sum of the two loss terms. For now, let's proceed with the definition above.</p> <p>Note that so far we have not used any quantum specific assumption, and we could in principle use the same loss function with a classical neural network.</p>"},{"location":"tutorials/qml/dqc_1d/#defining-a-qnn-with-qadence","title":"Defining a QNN with Qadence","text":"<p>Now, we can finally use Qadence to write a QNN. We will use a feature map to encode the input values, a trainable ansatz circuit, and an observable to measure as the output.</p> <pre><code>from qadence import feature_map, hea, chain\nfrom qadence import QNN, QuantumCircuit, Z\nfrom qadence.types import BasisSet, ReuploadScaling\n\nn_qubits = 3\ndepth = 3\n\n# Feature map\nfm = feature_map(\n    n_qubits = n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Ansatz\nansatz = hea(n_qubits = n_qubits, depth = depth)\n\n# Observable\nobservable = Z(0)\n\ncircuit = QuantumCircuit(n_qubits, chain(fm, ansatz))\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n</code></pre> <p>We used a Chebyshev feature map with a tower-like scaling of the input reupload, and a standard hardware-efficient ansatz. You can check the qml constructors tutorial to see how you can customize these components. In the observable, for now we consider the simple case of measuring the magnetization of the first qubit.</p> <pre><code>from qadence.draw import display\n\n# display(circuit)\n</code></pre> %3 cluster_c9aa0b9c81cb4ceaa7f4090d4ca0be51 HEA cluster_7f0b69c467f3461990f4a08612d6a7fb Tower Chebyshev FM 6aa0699223a14681b818e1d666a523d2 0 bf67e2a9d58446bea3144dca8fb132b8 RX(1.0*acos(x)) 6aa0699223a14681b818e1d666a523d2--bf67e2a9d58446bea3144dca8fb132b8 a3384e9a1c244545a8b873b2a1388f67 1 4b056c37dfc74a66b95340a6bfb33ba8 RX(theta\u2080) bf67e2a9d58446bea3144dca8fb132b8--4b056c37dfc74a66b95340a6bfb33ba8 e78928fec48840fb84d776c33947a6eb RY(theta\u2083) 4b056c37dfc74a66b95340a6bfb33ba8--e78928fec48840fb84d776c33947a6eb 5a81713aca774861ba9093e4049d7cc8 RX(theta\u2086) e78928fec48840fb84d776c33947a6eb--5a81713aca774861ba9093e4049d7cc8 cecf97cc6b5f47b0826b023b7ab2849f 5a81713aca774861ba9093e4049d7cc8--cecf97cc6b5f47b0826b023b7ab2849f 7ed678f0fd654043a7d4a49934d8127b cecf97cc6b5f47b0826b023b7ab2849f--7ed678f0fd654043a7d4a49934d8127b aba3b5585f224c56b467cf47cbae17c5 RX(theta\u2089) 7ed678f0fd654043a7d4a49934d8127b--aba3b5585f224c56b467cf47cbae17c5 cde064cb554c480baaaa1de517cd313b RY(theta\u2081\u2082) aba3b5585f224c56b467cf47cbae17c5--cde064cb554c480baaaa1de517cd313b 94cc89a95e4f48ff8e110110c5ed49dc RX(theta\u2081\u2085) cde064cb554c480baaaa1de517cd313b--94cc89a95e4f48ff8e110110c5ed49dc 9f8dd9ace4ba494fad1f2c96f639168a 94cc89a95e4f48ff8e110110c5ed49dc--9f8dd9ace4ba494fad1f2c96f639168a 77e017dabe5b4581802b3db76d5694e0 9f8dd9ace4ba494fad1f2c96f639168a--77e017dabe5b4581802b3db76d5694e0 d3285e2ac80646f39bd80b77eafb76ac RX(theta\u2081\u2088) 77e017dabe5b4581802b3db76d5694e0--d3285e2ac80646f39bd80b77eafb76ac 5ea17108ae3142f1a894123a24d6fe95 RY(theta\u2082\u2081) d3285e2ac80646f39bd80b77eafb76ac--5ea17108ae3142f1a894123a24d6fe95 16c61362eec948b1a727d581a2b1ce3f RX(theta\u2082\u2084) 5ea17108ae3142f1a894123a24d6fe95--16c61362eec948b1a727d581a2b1ce3f 766998eaa4144b318c839d363a9dbff6 16c61362eec948b1a727d581a2b1ce3f--766998eaa4144b318c839d363a9dbff6 43072707de4048d18442c2c2cc1737d0 766998eaa4144b318c839d363a9dbff6--43072707de4048d18442c2c2cc1737d0 7c54ecc096fb43e19fa843f3a74d1404 43072707de4048d18442c2c2cc1737d0--7c54ecc096fb43e19fa843f3a74d1404 890dc68a1c354dfdb8e7bace2b44f56a 19778ed6fd524c54889347b26626304e RX(2.0*acos(x)) a3384e9a1c244545a8b873b2a1388f67--19778ed6fd524c54889347b26626304e bd3ecc62f42548679287422202190a40 2 6f279d47752e428691f0359054eef991 RX(theta\u2081) 19778ed6fd524c54889347b26626304e--6f279d47752e428691f0359054eef991 9b5ca4e8dec04bae8199a5b4e91436ab RY(theta\u2084) 6f279d47752e428691f0359054eef991--9b5ca4e8dec04bae8199a5b4e91436ab 57083cb38bd1496f979b4462b9db331a RX(theta\u2087) 9b5ca4e8dec04bae8199a5b4e91436ab--57083cb38bd1496f979b4462b9db331a a3aebf4300b04966bc37838401f59a8d X 57083cb38bd1496f979b4462b9db331a--a3aebf4300b04966bc37838401f59a8d a3aebf4300b04966bc37838401f59a8d--cecf97cc6b5f47b0826b023b7ab2849f 8ae57c79b09b4e5f80ad78e417e98ad8 a3aebf4300b04966bc37838401f59a8d--8ae57c79b09b4e5f80ad78e417e98ad8 979a09671fa3428dad75d81b2d96705c RX(theta\u2081\u2080) 8ae57c79b09b4e5f80ad78e417e98ad8--979a09671fa3428dad75d81b2d96705c b3409530380b48f284adf6aada214649 RY(theta\u2081\u2083) 979a09671fa3428dad75d81b2d96705c--b3409530380b48f284adf6aada214649 d75ac42c0f5b4c638eac241d2e4357db RX(theta\u2081\u2086) b3409530380b48f284adf6aada214649--d75ac42c0f5b4c638eac241d2e4357db 45d2cc8de0d740f29231800837726ef3 X d75ac42c0f5b4c638eac241d2e4357db--45d2cc8de0d740f29231800837726ef3 45d2cc8de0d740f29231800837726ef3--9f8dd9ace4ba494fad1f2c96f639168a 0f6979527fd8466abceabee095cf9404 45d2cc8de0d740f29231800837726ef3--0f6979527fd8466abceabee095cf9404 ee871f80068640028adae55f772fd9bf RX(theta\u2081\u2089) 0f6979527fd8466abceabee095cf9404--ee871f80068640028adae55f772fd9bf 8f0968965f7e4f93a1eb315f4608c525 RY(theta\u2082\u2082) ee871f80068640028adae55f772fd9bf--8f0968965f7e4f93a1eb315f4608c525 74b174a871264452a322654e1808c9c8 RX(theta\u2082\u2085) 8f0968965f7e4f93a1eb315f4608c525--74b174a871264452a322654e1808c9c8 7d65bfa0dc81414d84b893ad5f8b2b4e X 74b174a871264452a322654e1808c9c8--7d65bfa0dc81414d84b893ad5f8b2b4e 7d65bfa0dc81414d84b893ad5f8b2b4e--766998eaa4144b318c839d363a9dbff6 b70722d81219424c856a8de344a1484b 7d65bfa0dc81414d84b893ad5f8b2b4e--b70722d81219424c856a8de344a1484b b70722d81219424c856a8de344a1484b--890dc68a1c354dfdb8e7bace2b44f56a 4ca1a54532894600993f431874452973 352f3bd475464775acebb1bb1bb6389e RX(3.0*acos(x)) bd3ecc62f42548679287422202190a40--352f3bd475464775acebb1bb1bb6389e c13580e4bb1643e49de1ff4f146d1213 RX(theta\u2082) 352f3bd475464775acebb1bb1bb6389e--c13580e4bb1643e49de1ff4f146d1213 641bf1755f714221ae679d2bf760e52a RY(theta\u2085) c13580e4bb1643e49de1ff4f146d1213--641bf1755f714221ae679d2bf760e52a 8c97d36aa72248f282b4d08637a67f94 RX(theta\u2088) 641bf1755f714221ae679d2bf760e52a--8c97d36aa72248f282b4d08637a67f94 dedcc77b1ecb4aa38e83c0fe7a48499e 8c97d36aa72248f282b4d08637a67f94--dedcc77b1ecb4aa38e83c0fe7a48499e ce0e70352d0c47bdabf843daf2f59cfd X dedcc77b1ecb4aa38e83c0fe7a48499e--ce0e70352d0c47bdabf843daf2f59cfd ce0e70352d0c47bdabf843daf2f59cfd--8ae57c79b09b4e5f80ad78e417e98ad8 6226d60d631f4d09a93230e859fd4b18 RX(theta\u2081\u2081) ce0e70352d0c47bdabf843daf2f59cfd--6226d60d631f4d09a93230e859fd4b18 9964c4eadb4b48949a549501486a5231 RY(theta\u2081\u2084) 6226d60d631f4d09a93230e859fd4b18--9964c4eadb4b48949a549501486a5231 b681847916e34d45987b2d6a34078982 RX(theta\u2081\u2087) 9964c4eadb4b48949a549501486a5231--b681847916e34d45987b2d6a34078982 0d75692f14eb4e7082d6578079aa410b b681847916e34d45987b2d6a34078982--0d75692f14eb4e7082d6578079aa410b af5fd4fad90f425da90b0278922fbfb2 X 0d75692f14eb4e7082d6578079aa410b--af5fd4fad90f425da90b0278922fbfb2 af5fd4fad90f425da90b0278922fbfb2--0f6979527fd8466abceabee095cf9404 cd90e9613ca5441c87a62983ce1fdf53 RX(theta\u2082\u2080) af5fd4fad90f425da90b0278922fbfb2--cd90e9613ca5441c87a62983ce1fdf53 0be8d809bcdf4eeab10d4fd8cbc69a8a RY(theta\u2082\u2083) cd90e9613ca5441c87a62983ce1fdf53--0be8d809bcdf4eeab10d4fd8cbc69a8a 54bb36e1ffb64a389f7961b11932d2ed RX(theta\u2082\u2086) 0be8d809bcdf4eeab10d4fd8cbc69a8a--54bb36e1ffb64a389f7961b11932d2ed f4619bd507014ebda2c5f50eb5044ea1 54bb36e1ffb64a389f7961b11932d2ed--f4619bd507014ebda2c5f50eb5044ea1 0b6a3a0e3a6649a9b0bb63bfe24d267e X f4619bd507014ebda2c5f50eb5044ea1--0b6a3a0e3a6649a9b0bb63bfe24d267e 0b6a3a0e3a6649a9b0bb63bfe24d267e--b70722d81219424c856a8de344a1484b 0b6a3a0e3a6649a9b0bb63bfe24d267e--4ca1a54532894600993f431874452973"},{"location":"tutorials/qml/dqc_1d/#training-the-model","title":"Training the model","text":"<p>Now that the model is defined we can proceed with the training. the <code>QNN</code> class can be used like any other <code>torch.nn.Module</code>. Here we write a simple training loop, but you can also look at the ml tools tutorial to use the convenience training functions that Qadence provides.</p> <p>To train the model, we will select a random set of collocation points uniformly distributed within \\(-1.0&lt; x &lt;1.0\\) and compute the loss function for those points.</p> <pre><code>n_epochs = 200\nn_points = 10\n\nxmin = -0.99\nxmax = 0.99\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data. We unsqueeze essentially making each batch have a single x value.\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>Note the values of \\(x\\) are only picked from \\(x\\in[-0.99, 0.99]\\) since we are using a Chebyshev feature map, and derivative of \\(\\text{acos}(x)\\) diverges at \\(-1\\) and \\(1\\).</p>"},{"location":"tutorials/qml/dqc_1d/#plotting-the-results","title":"Plotting the results","text":"<pre><code>import matplotlib.pyplot as plt\n\ndef f_exact(x: torch.Tensor) -&gt; torch.Tensor:\n    return 5*(x**4 + (1/3)*x**3 - x**2 - 0.5*x)\n\nx_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \" Trained model\")\n</code></pre> 2025-05-12T10:18:34.692717 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>Clearly, the result is not optimal.</p>"},{"location":"tutorials/qml/dqc_1d/#improving-the-solution","title":"Improving the solution","text":"<p>One point to consider when defining the QNN is the possible output range, which is bounded by the spectrum of the chosen observable. For the magnetization of a single qubit, this means that the output is bounded between -1 and 1, which we can clearly see in the plot.</p> <p>One option would be to define the observable as the total magnetization over all qubits, which would allow a range of -3 to 3.</p> <pre><code>from qadence import add\n\nobservable = add(Z(i) for i in range(n_qubits))\n\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And we again plot the result:</p> <pre><code>x_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \"Trained model\")\n</code></pre> 2025-05-12T10:18:41.757173 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/qml/dqc_1d/#references","title":"References","text":"<ol> <li> <p>Kyriienko et al., Solving nonlinear differential equations with differentiable quantum circuits. \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/qaoa/","title":"Solving MaxCut with QAOA","text":"<p>This tutorial shows how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA), first introduced by Farhi et al. in 2014 <sup>1</sup>.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a graph cut which partitions the nodes into two disjoint sets, such that the number of edges in the cut is maximized. This is a very common combinatorial optimization problem known to be computationally hard (NP-hard).</p> <p>The graph used for this tutorial is an unweighted graph randomly generated using the <code>networkx</code> library with a certain probability \\(p\\) of having an edge between two arbitrary nodes (known as Erd\u0151s\u2013R\u00e9nyi graph).</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\n\n# ensure reproducibility\nseed = 42\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Create random graph\nn_nodes = 4\nedge_prob = 0.8\ngraph = nx.gnp_random_graph(n_nodes, edge_prob)\n\nnx.draw(graph)\n</code></pre> 2025-05-12T10:18:41.858957 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[\\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p)\\] <p>where \\(p\\) is a given cut of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\). We will represent a cut \\(p\\) as a bitstring of length \\(N\\), where \\(N\\) is the number of nodes, and where the bit in position \\(i\\) shows to which partition node \\(i\\) belongs. We assign value 0 to one of the partitions defined by the cut and 1 to the other. Since this choice is arbitrary, every cut is represented by two bitstrings, e.g. \"0011\" and \"1100\" are equivalent.</p> <p>Since in this tutorial we are only dealing with small graphs, we can find the maximum cut by brute force to make sure QAOA works as intended. <pre><code># Function to calculate the cost associated with a cut\ndef calculate_cost(cut: str, graph: nx.graph) -&gt; float:\n    \"\"\"Returns the cost of a given cut (represented by a bitstring)\"\"\"\n    cost = 0\n    for edge in graph.edges():\n        (i, j) = edge\n        if cut[i] != cut[j]:\n            cost += 1\n    return cost\n\n\n# Function to get a binary representation of an int\nget_binary = lambda x, n: format(x, \"b\").zfill(n)\n\n# List of all possible cuts\nall_possible_cuts = [bin(k)[2:].rjust(n_nodes, \"0\") for k in range(2**n_nodes)]\n\n# List with the costs associated to each cut\nall_costs = [calculate_cost(cut, graph) for cut in all_possible_cuts]\n\n# Get the maximum cost\nmaxcost = max(all_costs)\n\n# Get all cuts that correspond to the maximum cost\nmaxcuts = [get_binary(i, n_nodes) for i, j in enumerate(all_costs) if j == maxcost]\nprint(f\"The maximum cut is represented by the bitstrings {maxcuts}, with a cost of {maxcost}\")\n</code></pre> <pre><code>The maximum cut is represented by the bitstrings ['0011', '0101', '0110', '1001', '1010', '1100'], with a cost of 4\n</code></pre> </p>"},{"location":"tutorials/qml/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>The Max-Cut problem can be solved by using the QAOA algorithm. QAOA belongs to the class of Variational Quantum Algorithms (VQAs), which means that its quantum circuit contains a certain number of parametrized quantum gates that need to be optimized with a classical optimizer. The QAOA circuit is composed of two operators:</p> <ul> <li>The cost operator \\(U_c\\): a circuit generated by the cost Hamiltonian which encodes the cost function described above into a quantum circuit. The solution to the optimization problem is encoded in the ground state of the cost Hamiltonian \\(H_c\\). The cost operator  is simply the evolution of the cost Hamiltonian parametrized by a variational parameter \\(\\gamma\\) so that \\(U_c = e^{i\\gamma H_c}.\\)</li> <li>The mixing operator \\(U_b\\): a simple set of single-qubit rotations with adjustable   angles which are tuned during the classical optimization loop to minimize the cost</li> </ul> <p>The cost Hamiltonian of the MaxCut problem can be written as:</p> \\[H_c = \\frac12 \\sum_{\\langle i,j\\rangle} (\\mathbb{1} - Z_iZ_j)\\] <p>where \\(\\langle i,j\\rangle\\) represents the edge between nodes \\(i\\) and \\(j\\). The solution of the MaxCut problem is encoded in the ground state of the above Hamiltonian.</p> <p>The QAOA quantum circuit consists of a number of layers, each layer containing a cost and a mixing operator. Below, the QAOA quantum circuit is defined using <code>qadence</code> operations. First, a layer of Hadamard gates is applied to all qubits to prepare the initial state \\(|+\\rangle ^{\\otimes n}\\). The cost operator of each layer can be built \"manually\", implementing the \\(e^{iZZ\\gamma}\\) terms with CNOTs and a \\(\\rm{RZ}(2\\gamma)\\) rotation, or it can also be automatically decomposed into digital single and two-qubits operations via the <code>.digital_decomposition()</code> method. The decomposition is exact since the Hamiltonian generator is diagonal.</p> <pre><code>from qadence import tag, kron, chain, RX, RZ, Z, H, CNOT, I, add\nfrom qadence import HamEvo, QuantumCircuit, Parameter\n\nn_qubits = graph.number_of_nodes()\nn_edges = graph.number_of_edges()\nn_layers = 6\n\n# Generate the cost Hamiltonian\nzz_ops = add(Z(edge[0]) @ Z(edge[1]) for edge in graph.edges)\ncost_ham = 0.5 * (n_edges * kron(I(i) for i in range(n_qubits)) - zz_ops)\n\n\n# QAOA circuit\ndef build_qaoa_circuit(n_qubits, n_layers, graph):\n    layers = []\n    # Layer of Hadamards\n    initial_layer = kron(H(i) for i in range(n_qubits))\n    layers.append(initial_layer)\n    for layer in range(n_layers):\n\n        # cost layer with digital decomposition\n        # cost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition(approximation=\"basic\")\n        cost_layer = []\n        for edge in graph.edges():\n            (q0, q1) = edge\n            zz_term = chain(\n                CNOT(q0, q1),\n                RZ(q1, Parameter(f\"g{layer}\")),\n                CNOT(q0, q1),\n            )\n            cost_layer.append(zz_term)\n        cost_layer = chain(*cost_layer)\n        cost_layer = tag(cost_layer, \"cost\")\n\n        # mixing layer with single qubit rotations\n        mixing_layer = kron(RX(i, f\"b{layer}\") for i in range(n_qubits))\n        mixing_layer = tag(mixing_layer, \"mixing\")\n\n        # putting all together in a single ChainBlock\n        layers.append(chain(cost_layer, mixing_layer))\n\n    final_b = chain(*layers)\n    return QuantumCircuit(n_qubits, final_b)\n\n\ncircuit = build_qaoa_circuit(n_qubits, n_layers, graph)\n\n# Print a single layer of the circuit\n</code></pre> %3 cluster_d66c2c90cb6641499a1a693024ca1cc6 mixing cluster_20afcd2ecb5045d797c0c13b53d2c49f cost b9247efaa99a48c99f65cd4e6ca9b256 0 115e38f6401447b3bea07e1fe67c5dd0 H b9247efaa99a48c99f65cd4e6ca9b256--115e38f6401447b3bea07e1fe67c5dd0 229ba5e511d44e2486f4f109f5e8a5cc 1 a930c54d605b40e7b6b6fb153affc7b2 115e38f6401447b3bea07e1fe67c5dd0--a930c54d605b40e7b6b6fb153affc7b2 2478b6d21e764f709bb192c3bbd946cf a930c54d605b40e7b6b6fb153affc7b2--2478b6d21e764f709bb192c3bbd946cf 12d4015849bb4368b0a1b7a170ff8720 2478b6d21e764f709bb192c3bbd946cf--12d4015849bb4368b0a1b7a170ff8720 978ac71240834b6dbe465a02350ddd3c 12d4015849bb4368b0a1b7a170ff8720--978ac71240834b6dbe465a02350ddd3c 33dd3174f7954e4996ec34d0d1ef7f24 978ac71240834b6dbe465a02350ddd3c--33dd3174f7954e4996ec34d0d1ef7f24 95602c41b5184ec88115a60093f66ecb 33dd3174f7954e4996ec34d0d1ef7f24--95602c41b5184ec88115a60093f66ecb c686634d52e34d6da6431a5175d6996e 95602c41b5184ec88115a60093f66ecb--c686634d52e34d6da6431a5175d6996e 3dae4adedd46417fba99e24eb5bcfcb5 c686634d52e34d6da6431a5175d6996e--3dae4adedd46417fba99e24eb5bcfcb5 2483515f1f7648a09464eedf60b541a0 3dae4adedd46417fba99e24eb5bcfcb5--2483515f1f7648a09464eedf60b541a0 e8a8d44bae54494c8ab32d88b34e163f 2483515f1f7648a09464eedf60b541a0--e8a8d44bae54494c8ab32d88b34e163f 83f273a212334518ae45b67b1447545b e8a8d44bae54494c8ab32d88b34e163f--83f273a212334518ae45b67b1447545b 7cbbc9a990864338943d749faeadc929 83f273a212334518ae45b67b1447545b--7cbbc9a990864338943d749faeadc929 a1ca02a588064011aea5d9a3ea9e97bd 7cbbc9a990864338943d749faeadc929--a1ca02a588064011aea5d9a3ea9e97bd 81d6e32c411d43d499d14a38f762e705 a1ca02a588064011aea5d9a3ea9e97bd--81d6e32c411d43d499d14a38f762e705 f104d9cc93c84638bd158c72972fbc15 81d6e32c411d43d499d14a38f762e705--f104d9cc93c84638bd158c72972fbc15 9e7509ce26e345ca97ba4a6011dce8e3 f104d9cc93c84638bd158c72972fbc15--9e7509ce26e345ca97ba4a6011dce8e3 ad9456f634474aa9aaabcb24a40edd35 9e7509ce26e345ca97ba4a6011dce8e3--ad9456f634474aa9aaabcb24a40edd35 b2b9af0901914bcb842450fca9c5a215 ad9456f634474aa9aaabcb24a40edd35--b2b9af0901914bcb842450fca9c5a215 360c5a3efdd84afe9a41c2ea750a706d RX(b0) b2b9af0901914bcb842450fca9c5a215--360c5a3efdd84afe9a41c2ea750a706d 21203d6aaf5840869249cfc7845fe5f4 360c5a3efdd84afe9a41c2ea750a706d--21203d6aaf5840869249cfc7845fe5f4 d6382a3216004bb19f74648f4b4affa8 cf7fc9e60c214af7bb7472f2cefa34b7 H 229ba5e511d44e2486f4f109f5e8a5cc--cf7fc9e60c214af7bb7472f2cefa34b7 2acede9000a1439f9e9f58139d6e6d0e 2 7528087378f9441fb4124156065fd338 X cf7fc9e60c214af7bb7472f2cefa34b7--7528087378f9441fb4124156065fd338 7528087378f9441fb4124156065fd338--a930c54d605b40e7b6b6fb153affc7b2 45258f62555a447191a5805de2a71b07 RZ(g0) 7528087378f9441fb4124156065fd338--45258f62555a447191a5805de2a71b07 38963bfdb19b4ac0a083368adf5595f0 X 45258f62555a447191a5805de2a71b07--38963bfdb19b4ac0a083368adf5595f0 38963bfdb19b4ac0a083368adf5595f0--12d4015849bb4368b0a1b7a170ff8720 248051d7864a418bbc8108e918865080 38963bfdb19b4ac0a083368adf5595f0--248051d7864a418bbc8108e918865080 90159149bffe4ee598b2787a3bfa3f99 248051d7864a418bbc8108e918865080--90159149bffe4ee598b2787a3bfa3f99 7695c1df2e3245e08572e0d9c27e9dda 90159149bffe4ee598b2787a3bfa3f99--7695c1df2e3245e08572e0d9c27e9dda fd750555f6864b0998a6258df59c5304 7695c1df2e3245e08572e0d9c27e9dda--fd750555f6864b0998a6258df59c5304 9da8c021061a4d88aa8963d169eb890a fd750555f6864b0998a6258df59c5304--9da8c021061a4d88aa8963d169eb890a 24539fe45cea41c58640f6b9f900e900 9da8c021061a4d88aa8963d169eb890a--24539fe45cea41c58640f6b9f900e900 2c10e086ffa44b80a7a6607ee07e23ab 24539fe45cea41c58640f6b9f900e900--2c10e086ffa44b80a7a6607ee07e23ab 16040445fb6342a8961f91b777a57cea 2c10e086ffa44b80a7a6607ee07e23ab--16040445fb6342a8961f91b777a57cea 1e906c56efbf49baa1932a30156efa81 16040445fb6342a8961f91b777a57cea--1e906c56efbf49baa1932a30156efa81 b06f5afef7a84ddfb21ed69cd41d6684 1e906c56efbf49baa1932a30156efa81--b06f5afef7a84ddfb21ed69cd41d6684 58b2322c1e5949c2a21e289c6ff0de53 b06f5afef7a84ddfb21ed69cd41d6684--58b2322c1e5949c2a21e289c6ff0de53 8270a255bbc04ba1a348f0836e5badfe 58b2322c1e5949c2a21e289c6ff0de53--8270a255bbc04ba1a348f0836e5badfe f509f16b8f2f4c19b889536e73053de4 8270a255bbc04ba1a348f0836e5badfe--f509f16b8f2f4c19b889536e73053de4 84fcc625c2174d63b1b4541a74dc8ab7 f509f16b8f2f4c19b889536e73053de4--84fcc625c2174d63b1b4541a74dc8ab7 1248775a044544ba9575f5eeb1ae4b04 84fcc625c2174d63b1b4541a74dc8ab7--1248775a044544ba9575f5eeb1ae4b04 70690f5a67eb426089b2d498d2c51f31 RX(b0) 1248775a044544ba9575f5eeb1ae4b04--70690f5a67eb426089b2d498d2c51f31 70690f5a67eb426089b2d498d2c51f31--d6382a3216004bb19f74648f4b4affa8 f1a5cc9d12224011b229940d90d0efa8 a15326e6bee3440a8c799dab877dbb11 H 2acede9000a1439f9e9f58139d6e6d0e--a15326e6bee3440a8c799dab877dbb11 e1d9ea1b28c3410ba9ce764eea479152 3 d3b1e2771d5040b69eef47f12638ef9d a15326e6bee3440a8c799dab877dbb11--d3b1e2771d5040b69eef47f12638ef9d e678520fe90d45edae1056fda70b8ec2 d3b1e2771d5040b69eef47f12638ef9d--e678520fe90d45edae1056fda70b8ec2 37028e8719714059a8e8e8edeabf0461 e678520fe90d45edae1056fda70b8ec2--37028e8719714059a8e8e8edeabf0461 160318c12d9947a88ed757eae744de58 X 37028e8719714059a8e8e8edeabf0461--160318c12d9947a88ed757eae744de58 160318c12d9947a88ed757eae744de58--978ac71240834b6dbe465a02350ddd3c 701f42a999b0419f8264261a0c8e41b2 RZ(g0) 160318c12d9947a88ed757eae744de58--701f42a999b0419f8264261a0c8e41b2 2ac3986fe3b6407b9d08b01d9cdb8467 X 701f42a999b0419f8264261a0c8e41b2--2ac3986fe3b6407b9d08b01d9cdb8467 2ac3986fe3b6407b9d08b01d9cdb8467--95602c41b5184ec88115a60093f66ecb d58107fb4cca4a2487092c6729c14796 2ac3986fe3b6407b9d08b01d9cdb8467--d58107fb4cca4a2487092c6729c14796 df13438a040348ad930c17bf56716c6c d58107fb4cca4a2487092c6729c14796--df13438a040348ad930c17bf56716c6c 9bc55faf35864da2b1bc9ecad0c9551d df13438a040348ad930c17bf56716c6c--9bc55faf35864da2b1bc9ecad0c9551d 1e239d386593429093321cc4e0c723bb X 9bc55faf35864da2b1bc9ecad0c9551d--1e239d386593429093321cc4e0c723bb 1e239d386593429093321cc4e0c723bb--2c10e086ffa44b80a7a6607ee07e23ab d0faa4614dd4434792edf6b7e7d0b2b5 RZ(g0) 1e239d386593429093321cc4e0c723bb--d0faa4614dd4434792edf6b7e7d0b2b5 0088e394dd2a4163b17231229c8aa6d9 X d0faa4614dd4434792edf6b7e7d0b2b5--0088e394dd2a4163b17231229c8aa6d9 0088e394dd2a4163b17231229c8aa6d9--1e906c56efbf49baa1932a30156efa81 6866261a0eed4ef583f2fc90ea79e058 0088e394dd2a4163b17231229c8aa6d9--6866261a0eed4ef583f2fc90ea79e058 4121f6c9ed494783bcf4e75cdc2e5d92 6866261a0eed4ef583f2fc90ea79e058--4121f6c9ed494783bcf4e75cdc2e5d92 c10aa8531b204fd0a191838bc05100ea 4121f6c9ed494783bcf4e75cdc2e5d92--c10aa8531b204fd0a191838bc05100ea 8ebe01187ae94e4aa47f03cbc13feeb4 c10aa8531b204fd0a191838bc05100ea--8ebe01187ae94e4aa47f03cbc13feeb4 eda9e7b9dc0a4a99875cb86333a26719 8ebe01187ae94e4aa47f03cbc13feeb4--eda9e7b9dc0a4a99875cb86333a26719 bb450626af894d688ac85d7227c3f8e1 eda9e7b9dc0a4a99875cb86333a26719--bb450626af894d688ac85d7227c3f8e1 42d1368f89be4e37b1703df4f114e0a6 RX(b0) bb450626af894d688ac85d7227c3f8e1--42d1368f89be4e37b1703df4f114e0a6 42d1368f89be4e37b1703df4f114e0a6--f1a5cc9d12224011b229940d90d0efa8 d8316a9722764ec7b0e3b2a3ab1eb52a bd4d90d466ff4c3389f3485dddd9b0ba H e1d9ea1b28c3410ba9ce764eea479152--bd4d90d466ff4c3389f3485dddd9b0ba 70c051bb73fb41dc93c01b0597342c87 bd4d90d466ff4c3389f3485dddd9b0ba--70c051bb73fb41dc93c01b0597342c87 371f2e09fdd84b4d90322183d6d3a316 70c051bb73fb41dc93c01b0597342c87--371f2e09fdd84b4d90322183d6d3a316 6e2bf09a2c964d41bdbc6cf960a677ac 371f2e09fdd84b4d90322183d6d3a316--6e2bf09a2c964d41bdbc6cf960a677ac 148eb55b4ca3410793d487d9f9c4d946 6e2bf09a2c964d41bdbc6cf960a677ac--148eb55b4ca3410793d487d9f9c4d946 6b1a821f36224e678b576ec5d6a9ee48 148eb55b4ca3410793d487d9f9c4d946--6b1a821f36224e678b576ec5d6a9ee48 eba7b82f9f564818a3b36708af96054c 6b1a821f36224e678b576ec5d6a9ee48--eba7b82f9f564818a3b36708af96054c 1dc981c07f344b87929d8a9301151c33 X eba7b82f9f564818a3b36708af96054c--1dc981c07f344b87929d8a9301151c33 1dc981c07f344b87929d8a9301151c33--c686634d52e34d6da6431a5175d6996e 6529fe0a47564b1688e4426c672f721f RZ(g0) 1dc981c07f344b87929d8a9301151c33--6529fe0a47564b1688e4426c672f721f cbf4d84a7a8b486c9937e21fa834c599 X 6529fe0a47564b1688e4426c672f721f--cbf4d84a7a8b486c9937e21fa834c599 cbf4d84a7a8b486c9937e21fa834c599--2483515f1f7648a09464eedf60b541a0 b26cdb6f52e5469b8f7b12fc5a1d35bf cbf4d84a7a8b486c9937e21fa834c599--b26cdb6f52e5469b8f7b12fc5a1d35bf 057be2eae7e6489d82d76c1a2287410d b26cdb6f52e5469b8f7b12fc5a1d35bf--057be2eae7e6489d82d76c1a2287410d a651a47f8996451abd2e76286cc9d660 057be2eae7e6489d82d76c1a2287410d--a651a47f8996451abd2e76286cc9d660 67ccec53584b481bba438be587ce1cb0 X a651a47f8996451abd2e76286cc9d660--67ccec53584b481bba438be587ce1cb0 67ccec53584b481bba438be587ce1cb0--b06f5afef7a84ddfb21ed69cd41d6684 84361462aec344eda5a782ad4cc7d362 RZ(g0) 67ccec53584b481bba438be587ce1cb0--84361462aec344eda5a782ad4cc7d362 fdedffbfe04c42f193089c8cd10d8eb4 X 84361462aec344eda5a782ad4cc7d362--fdedffbfe04c42f193089c8cd10d8eb4 fdedffbfe04c42f193089c8cd10d8eb4--8270a255bbc04ba1a348f0836e5badfe 3c0afd0d9ef74fb9824a89c58c898460 X fdedffbfe04c42f193089c8cd10d8eb4--3c0afd0d9ef74fb9824a89c58c898460 3c0afd0d9ef74fb9824a89c58c898460--8ebe01187ae94e4aa47f03cbc13feeb4 2cc156c6923e466ab0267248da75d3a3 RZ(g0) 3c0afd0d9ef74fb9824a89c58c898460--2cc156c6923e466ab0267248da75d3a3 19d0bd4c6593477db56240b5a04cb981 X 2cc156c6923e466ab0267248da75d3a3--19d0bd4c6593477db56240b5a04cb981 19d0bd4c6593477db56240b5a04cb981--bb450626af894d688ac85d7227c3f8e1 b5031ff9416d480ebb49d2891205e199 RX(b0) 19d0bd4c6593477db56240b5a04cb981--b5031ff9416d480ebb49d2891205e199 b5031ff9416d480ebb49d2891205e199--d8316a9722764ec7b0e3b2a3ab1eb52a"},{"location":"tutorials/qml/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Given the QAOA circuit above, one can construct the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization.</p> <p>The loss function to be minimized reads:</p> \\[\\mathcal{L} =-\\langle \\psi | H_c| \\psi \\rangle= -\\frac12 \\sum_{\\langle i,j\\rangle}  \\left(1 - \\langle \\psi | Z_i Z_j | \\psi \\rangle \\right)\\] <p>where \\(|\\psi\\rangle(\\beta, \\gamma)\\) is the wavefunction obtained by running the QAQA quantum circuit and the sum runs over the edges of the graph \\(\\langle i,j\\rangle\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\n\ntorch.manual_seed(seed)\n\n\ndef loss_function(model: QuantumModel):\n    # The loss corresponds to the expectation\n    # value of the cost Hamiltonian\n    return -1.0 * model.expectation().squeeze()\n\n\n# initialize the parameters to random values\nmodel = QuantumModel(circuit, observable=cost_ham)\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n\n# train the model\nn_epochs = 100\nlr = 0.1\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_function(model)\n    loss.backward()\n    optimizer.step()\n    if (i + 1) % (n_epochs // 10) == 0:\n        print(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -2.1782381363858794\nMaxCut cost at iteration 10: 3.7470706807026417\nMaxCut cost at iteration 20: 3.8378810288930216\nMaxCut cost at iteration 30: 3.9424197899236133\nMaxCut cost at iteration 40: 3.9981256255766002\nMaxCut cost at iteration 50: 3.996470528508214\nMaxCut cost at iteration 60: 3.9991374608876606\nMaxCut cost at iteration 70: 3.9994678542919555\nMaxCut cost at iteration 80: 3.999872558672829\nMaxCut cost at iteration 90: 3.9999475834121063\nMaxCut cost at iteration 100: 3.9999793311641003\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p>"},{"location":"tutorials/qml/qaoa/#results","title":"Results","text":"<p>Given the trained quantum model, one needs to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph.</p> <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\n\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\n    colors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\n    labels[node] = \"A\" if int(b) == 0 else \"B\"\n\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 1001  2025-05-12T10:18:45.635607 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/qml/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/qml/qcl/","title":"Quantum circuit learning","text":"<p>This tutorial shows how to apply <code>qadence</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning<sup>1</sup> (QCL) algorithm.</p> <p>QCL is a supervised quantum machine learning algorithm that uses a parametrized quantum neural network to learn the behavior of an arbitrary mathematical function using a set of function values as training data. This tutorial shows how to fit the \\(\\sin(x)\\) function in the \\([-1, 1]\\) domain.</p> <p>In the following, train and test data are defined.</p> <pre><code>import torch\nfrom torch.utils.data import random_split\n\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndef qcl_training_data(\n    domain: tuple = (0, 2*torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n\n    start, end = domain\n\n    x_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\n    y_rand = torch.sin(x_rand)\n\n    return x_rand, y_rand\n\nx, y = qcl_training_data()\n\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\n\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre>"},{"location":"tutorials/qml/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>Total qubit magnetization is used as observable:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <p>In the following the observable, quantum circuit and corresponding QNN model are constructed.</p> <pre><code>import qadence as qd\n\nn_qubits = 4\n\n# create a simple feature map to encode the input data\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(qd.RX(i, feature_param) for i in range(n_qubits))\nfeature_map = qd.tag(feature_map, \"feature_map\")\n\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits)\nansatz = qd.tag(ansatz, \"ansatz\")\n\n# total qubit magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning=qd.Z)\n\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qd.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\n</code></pre> <pre><code>tensor([[ 0.0092],\n        [-0.0207],\n        [-0.4616],\n        [-0.1845],\n        [-0.3761],\n        [-0.1463],\n        [-0.4563],\n        [-0.0016],\n        [-0.3436],\n        [-0.4252]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable universal function approximator. Standard PyTorch code is used for training the QNN using a mean-square error loss, Adam optimizer. Training is performend on the GPU if available:</p> <pre><code>n_epochs = 100\nlr = 0.25\n\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\n\nprint(f\"Initial loss: {mse_loss(model(values=x_train), y_train)}\")\ny_pred_initial = model(values=x_test)\n\nfor i in range(n_epochs):\n\n    optimizer.zero_grad()\n\n    # given a `n_batch` number of input points and a `n_observables`\n    # number of input observables to measure, the QNN returns\n    # an output of the following shape: [n_batch x n_observables]\n    # given that there is only one observable, a squeeze is applied to get\n    # a 1-dimensional tensor\n    loss = mse_loss(model(values=x_train).squeeze(), y_train)\n    loss.backward()\n    optimizer.step()\n\n    if (i+1) % 20 == 0:\n        print(f\"Epoch {i+1} - Loss: {loss.item()}\")\n\nassert loss.item() &lt; 1e-3\n</code></pre> <pre><code>Initial loss: 0.6272721767455237\nEpoch 20 - Loss: 0.008173087377230498\nEpoch 40 - Loss: 0.0011247726222838813\nEpoch 60 - Loss: 0.0001415308609619855\nEpoch 80 - Loss: 2.3606578815826947e-05\nEpoch 100 - Loss: 2.503287372853267e-06\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p> <p>The quantum model is now trained on the training data points. To determine the quality of the results, one can check to see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\n\ny_pred = model({\"phi\": x_test})\n\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_test_np = y_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\n\nfig, _ = plt.subplots()\nplt.scatter(x_test_np, y_test_np, label=\"Test points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2025-05-12T10:18:49.667829 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/qml/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/qcnn/","title":"QCNN model","text":""},{"location":"tutorials/qml/qcnn/#introduction","title":"Introduction","text":"<p>In this tutorial, we\u2019ll explore how to train a Quantum Convolutional Neural Network (QCNN) using Qadence, demonstrating its application on a simple yet insightful data structure. The tutorial begins by detailing the construction of the quantum circuit and the synthetic data generation process. Convolutional architectures excel at capturing spatial relationships in grid-like structures, so we design our data to emulate a system of five interconnected grid elements, where the collective behavior produces a single continuous output value. The key idea is to aggregate features from four neighboring elements into a fifth central node, generating a compact embedding that encodes structural information. By training the QCNN to predict the global property from this localized representation, we effectively enable the model to infer system-wide behavior from a single node\u2019s contextual features\u2014showcasing the potential of quantum machine learning for relational reasoning tasks.</p>"},{"location":"tutorials/qml/qcnn/#qcnn-circuitry","title":"QCNN circuitry","text":"<p>A generic QCNN is described as \\(\\Phi_{{\\theta},{\\lambda}} =\\bigcirc_{l=1}^{L} \\big(\\text{P}_{l}^{{\\lambda}_{l}} \\circ \\text{C}_{l}^{{\\theta}_{l}}\\big)\\)</p> <p>where \\(\\circ\\) denotes a single function composition, and \\(\\bigcirc_{l=1}^L\\) represents the composition of \\(L\\) functions applied sequentially. Each QGCN layer \\(l\\) comprises a quatnum convolutional layer \\(\\text{C}_l^{{\\theta}_{l}}\\) followed by a quantum pooling layer \\(\\text{P}_{l}^{{\\lambda}_{l}}\\), with \\({\\theta}_{l}\\) and \\({\\lambda}_{l}\\) being the convolution and pooling parameters, respectively. The alternating structure of the QGNN circuit processes and simplifies the input quantum state, starting with \\(\\text{C}_1\\) and ending with \\(\\text{P}_{L}\\).</p> <p>The convolutional layer \\(\\text{C}_l^{{\\theta}_l}: \\mathcal{S}(\\mathcal{H}_l) \\rightarrow \\mathcal{S}(\\mathcal{H}_l)\\) preserves the size of the quantum register. It reads \\(\\text{C}_l^{{\\theta}_l}(\\cdot) = \\bigcirc_{j=1}^{r}  \\left(\\bigotimes_{i \\in \\text{S}(j)} W_l^{(i, i+1)}\\left({\\theta}_l\\right)\\right)(\\cdot)\\)</p> <p>Each convolutional layer acts on an even number of qubits, since the unitary \\(W_l\\)<sup>1</sup> convolves a pairs of neighboring qubits \\((i, i+1)\\).  In general, the operator \\(W\\) acts on pairs of adjacent qubits defined by the set \\(S(j) = \\{(i, i+1) \\mid i \\equiv j \\!\\!\\!\\mod 2, \\ 0 \\leq i \\leq N-2\\}\\), where \\(N\\) denotes the total number of qubits<sup>2</sup>. This construction ensures an alternating nearest-neighbor interaction pattern. The alternation is determined by the parity of \\(j\\): for even \\(j\\), \\(W\\) acts on even-indexed pairs \\((0,1)\\), \\((2,3)\\), etc.; similarly, for odd values of \\(j\\), the same operation is performed on odd-indexed pairs in an analogous manner. Each convolutional layer \\(\\text{C}_l^{{\\theta}_l}\\) has an associated parameter \\(r\\), representing its depth. For example, in a two-layer QGCN architecture, the depths of \\(\\text{C}_1\\) and \\(\\text{C}_2\\) are denoted as \\(r_1\\) and \\(r_2\\), respectively.</p> <p>The pooling layer \\(\\text{P}_{l}^{{\\lambda}_l}: \\mathcal{S}(\\mathcal{H}_l) \\rightarrow \\mathcal{S}(\\mathcal{H}_{l+1})\\) reduces the size of the quantum register by tracing out specific qubits, such that \\(\\dim(\\mathcal{H}_{l+1}) &lt; \\dim(\\mathcal{H}_l)\\), and is defined as \\(\\text{P}_{l}^{{\\lambda}_l}(\\cdot) = Tr_{i}[(\\cdot)]\\)</p> <p>where the \\(i\\)-qubit is traced out in the \\(l\\)-th layer. The pooling layers typically discard half of the qubits at each step.</p> <p>We adopt a simple architecture for \\(\\text{C}_l^{{\\theta}_l}\\) and \\(\\text{P}_{l}^{{\\lambda}_l}\\). The unitary \\(W\\) is defined as in Ref. vatan_2004_optimal, where the \\(A\\) gates are defined similarly in terms of \\(R_G({\\theta}_l) = e^{-iX\\theta^1_{l}/2}e^{-iZ\\theta^2_{l}/2}e^{-iX\\theta^3_{l}/2}\\). Entanglement is achieved applying non-parametrized CZ gates. In the pooling layers, entanglement is followed by local measurements on \\(\\mathcal{O}\\), enabled by the deferred measurement principle as in Ref. Nielsen. The chosen design reduces the complexity of the QGCN circuit by \\(\\Phi_{{\\theta}, {\\lambda}} \\to \\Phi_{{\\theta}}\\)</p> <p>A schematic illustration of the full circuit can be found in our work on QGNNs which shares a similar circuit design</p>"},{"location":"tutorials/qml/qcnn/#dummy-data-description","title":"Dummy Data Description","text":"<ol> <li>4 grid elements (each with <code>n_qubits</code> features) influence a 5th element</li> <li>The relationship is encoded in a single continuous target value</li> </ol>"},{"location":"tutorials/qml/qcnn/#input-and-target-tensors-dummy_input-and-dummy_target","title":"Input and Target Tensors (<code>dummy_input</code> and <code>dummy_target</code>)","text":"<ol> <li>Input<ul> <li>Shape: <code>(4, n_qubits)</code>: 4 samples representing 4 grid elements with <code>n_qubits</code> features per grid element. Random values between [0, 1)</li> </ul> </li> <li>Target<ul> <li>Shape: <code>(1, 1)</code>: Single scalar value representing the aggregated property of the 5th connected grid element. Random value between [0, 1)</li> </ul> </li> </ol> <pre><code>import torch\nn_features = 8\ndummy_input = torch.rand(4, n_features).float()\ndummy_target = torch.rand(1, 1).float()\n</code></pre>"},{"location":"tutorials/qml/qcnn/#training-a-qcnn","title":"Training a QCNN","text":"<p>Now we perform the training of the QCNN on the dummy data generated earlier.</p>"},{"location":"tutorials/qml/qcnn/#define-the-qcnn-circuit-with-qadence","title":"Define the QCNN circuit with Qadence","text":"<p>First we define a class with mean pooling on the QCNN output to match target value <pre><code>class qcnn_msg_passing(torch.nn.Module):\n    def __init__(self, qcnn: torch.nn.Module, output_size: int = 1):\n        super(qcnn_msg_passing, self).__init__()\n        self.qcnn = qcnn\n        self.output_size = output_size\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        x = x.float()\n        x = self.qcnn(x).float().view(-1, self.output_size)\n        return torch.mean(x, dim=0, keepdim=True)\n</code></pre> </p> <p>The model is hence defined as <pre><code># QCNN model\nfrom qadence import RX, RZ, CZ, QCNN\n\nn_qubits = n_features\nhidden_depth = [1,1,1]\noperations = [RX, RZ, RX]\nentangler = CZ\nrandom_meas = True\n\n# qgcn_circuit = QGCN(\nqcnn_circuit = QCNN(\n    n_inputs=n_qubits,\n    n_qubits=n_qubits,\n    depth=hidden_depth,\n    operations=operations,\n    entangler=entangler,\n    random_meas=random_meas,\n    is_corr=False,\n)\n\nmodel = qcnn_msg_passing(qcnn_circuit, dummy_target.shape[1])\n</code></pre> </p>"},{"location":"tutorials/qml/qcnn/#training-loop","title":"Training loop:","text":"<p>The training is performed as follows:</p> <pre><code>n_epochs = 100\nlr = 0.01\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n# Training loop\nfor epoch in range(n_epochs + 1):\n    optimizer.zero_grad()\n    output = model(dummy_input)\n    loss = torch.nn.functional.mse_loss(output, dummy_target)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 10 == 0:\n        print(f\"Epoch={epoch:&gt;4d} | Loss={loss.item():&gt;10.6f}\")\n</code></pre>   Epoch=   0 | Loss=  0.361984 Epoch=  10 | Loss=  0.019123 Epoch=  20 | Loss=  0.002146 Epoch=  30 | Loss=  0.002778 Epoch=  40 | Loss=  0.000004 Epoch=  50 | Loss=  0.000360 Epoch=  60 | Loss=  0.000022 Epoch=  70 | Loss=  0.000027 Epoch=  80 | Loss=  0.000014 Epoch=  90 | Loss=  0.000000 Epoch= 100 | Loss=  0.000002    <ol> <li> <p>We also refer to \\(W\\) as convolutional cell.\u00a0\u21a9</p> </li> <li> <p>Qubit indexing is 0-based, i.e., \\(0, 1, \\dots, N-1\\).\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/qml/ml_tools/CPU/","title":"Training on CPU with <code>Trainer</code>","text":"<p>This guide explains how to train models on CPU using <code>Trainer</code> from <code>qadence.ml_tools</code>, covering single-process and multi-processing setups.</p>"},{"location":"tutorials/qml/ml_tools/CPU/#understanding-arguments","title":"Understanding Arguments","text":"<ul> <li>nprocs: Number of processes to run. To enable multi-processing and launch separate processes, set nprocs &gt; 1.</li> <li>compute_setup: The computational setup used for training. Options include <code>cpu</code>, <code>gpu</code>, and <code>auto</code>.</li> </ul> <p>For more details on the advanced training options, please refer to TrainConfig Documentation</p>"},{"location":"tutorials/qml/ml_tools/CPU/#configuring-trainconfig-for-cpu-training","title":"Configuring <code>TrainConfig</code> for CPU Training","text":"<p>By adjusting <code>TrainConfig</code>, you can seamlessly switch between single and multi-core CPU training. To enable CPU-based training, update these fields in <code>TrainConfig</code>:</p>"},{"location":"tutorials/qml/ml_tools/CPU/#single-process-training-configuration","title":"Single-Process Training Configuration:","text":"<ul> <li><code>backend=\"cpu\"</code>: Ensures training runs on the CPU.</li> <li><code>nprocs=1</code>: Uses one CPU core.</li> </ul> <pre><code>train_config = TrainConfig(\n    compute_setup=\"cpu\",\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/CPU/#multi-processing-configuration","title":"Multi-Processing Configuration","text":"<ul> <li><code>backend=\"gloo\"</code>: Uses the Gloo backend for CPU multi-processing.</li> <li><code>nprocs=4</code>: Utilizes 4 CPU cores.</li> </ul> <pre><code>train_config = TrainConfig(\n    compute_setup=\"cpu\",\n    backend=\"gloo\",\n    nprocs=4,\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/CPU/#examples","title":"Examples","text":""},{"location":"tutorials/qml/ml_tools/CPU/#single-process-cpu-training-example","title":"Single-Process CPU Training Example","text":"<p>Single-Process Training: Simple and suitable for small datasets. Use <code>backend=\"cpu\"</code>.</p> <pre><code>import torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import TrainConfig, Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nTrainer.set_use_grad(True)\n\n# Dataset, Model, and Optimizer\nx = torch.linspace(0, 1, 100).reshape(-1, 1)\ny = torch.sin(2 * torch.pi * x)\ndataloader = DataLoader(TensorDataset(x, y), batch_size=16, shuffle=True)\nmodel = nn.Sequential(nn.Linear(1, 16), nn.ReLU(), nn.Linear(16, 1))\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# Single-Process Training Configuration\ntrain_config = TrainConfig(compute_setup=\"cpu\", max_iter=5, print_every=1)\n\n# Training\ntrainer = Trainer(model, optimizer, train_config, loss_fn=\"mse\", optimize_step=optimize_step)\ntrainer.fit(dataloader)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/qml/ml_tools/CPU/#multi-processing-cpu-training-example","title":"Multi-Processing CPU Training Example","text":"<p>Multi-Processing Training: Best for large datasets, utilizes multiple CPU processes. Use <code>backend=\"gloo\"</code> and set <code>nprocs</code>.</p> <pre><code>import torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import TrainConfig, Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nTrainer.set_use_grad(True)\n\n# __main__ is recommended.\nif __name__ == \"__main__\":\n    x = torch.linspace(0, 1, 100).reshape(-1, 1)\n    y = torch.sin(2 * torch.pi * x)\n    dataloader = DataLoader(TensorDataset(x, y), batch_size=16, shuffle=True)\n    model = nn.Sequential(nn.Linear(1, 16), nn.ReLU(), nn.Linear(16, 1))\n    optimizer = optim.SGD(model.parameters(), lr=0.01)\n\n    # Multi-Process Training Configuration\n    train_config = TrainConfig(\n        compute_setup=\"cpu\",\n        backend=\"gloo\",\n        nprocs=4,\n        max_iter=5,\n        print_every=1)\n\n    trainer = Trainer(model, optimizer, train_config, loss_fn=\"mse\", optimize_step=optimize_step)\n    trainer.fit(dataloader)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/GPU/","title":"Training on GPU with <code>Trainer</code>","text":"<p>This guide explains how to train models on GPU using <code>Trainer</code> from <code>qadence.ml_tools</code>, covering single-GPU, multi-GPU (single node), and multi-node multi-GPU setups.</p>"},{"location":"tutorials/qml/ml_tools/GPU/#understanding-arguments","title":"Understanding Arguments","text":"<ul> <li>nprocs: Number of processes to run. To enable multi-processing and launch separate processes, set nprocs &gt; 1.</li> <li>compute_setup: The computational setup used for training. Options include <code>cpu</code>, <code>gpu</code>, and <code>auto</code>.</li> </ul> <p>For more details on the advanced training options, please refer to TrainConfig Documentation</p>"},{"location":"tutorials/qml/ml_tools/GPU/#configuring-trainconfig-for-gpu-training","title":"Configuring <code>TrainConfig</code> for GPU Training","text":"<p>By adjusting <code>TrainConfig</code>, you can switch between single and multi-GPU training setups. Below are the key settings for each configuration:</p>"},{"location":"tutorials/qml/ml_tools/GPU/#single-gpu-training-configuration","title":"Single-GPU Training Configuration:","text":"<ul> <li><code>compute_setup</code>: Selected training setup. (<code>gpu</code> or <code>auto</code>)</li> <li><code>backend=\"nccl\"</code>: Optimized backend for GPU training.</li> <li><code>nprocs=1</code>: Uses one GPU. <pre><code>train_config = TrainConfig(\n    compute_setup=\"auto\",\n    backend=\"nccl\",\n    nprocs=1,\n)\n</code></pre></li> </ul>"},{"location":"tutorials/qml/ml_tools/GPU/#multi-gpu-single-node-training-configuration","title":"Multi-GPU (Single Node) Training Configuration:","text":"<ul> <li><code>compute_setup</code>: Selected training setup. (<code>gpu</code> or <code>auto</code>)</li> <li><code>backend=\"nccl\"</code>: Multi-GPU optimized backend.</li> <li><code>nprocs=2</code>: Utilizes 2 GPUs on a single node. <pre><code>train_config = TrainConfig(\n    compute_setup=\"auto\",\n    backend=\"nccl\",\n    nprocs=2,\n)\n</code></pre></li> </ul>"},{"location":"tutorials/qml/ml_tools/GPU/#multi-node-multi-gpu-training-configuration","title":"Multi-Node Multi-GPU Training Configuration:","text":"<ul> <li><code>compute_setup</code>: Selected training setup. (<code>gpu</code> or <code>auto</code>)</li> <li><code>backend=\"nccl\"</code>: Required for multi-node setups.</li> <li><code>nprocs=4</code>: Uses 4 GPUs across nodes. <pre><code>train_config = TrainConfig(\n    compute_setup=\"auto\",\n    backend=\"nccl\",\n    nprocs=4,\n)\n</code></pre></li> </ul>"},{"location":"tutorials/qml/ml_tools/GPU/#examples","title":"Examples","text":"<p>The following sections provide Python scripts and training approach scripts for each setup.</p> <p>Some organizations use SLURM to manage resources. Slurm is an open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters. If you are using slurm, you can use the <code>Trainer</code> by submitting a batch script using sbatch. Further below, we also provide the sbatch scripts for each setup.</p> <p>You can also use <code>torchrun</code> to run the training process - which provides a superset of the functionality as <code>torch.distributed.launch</code>. Here you need to specify the torchrun arguments arguments to set up the distributed training setup. We also include the <code>torchrun</code> sbatch scripts for each setup below.</p>"},{"location":"tutorials/qml/ml_tools/GPU/#example-training-script-trainpy","title":"Example Training Script (<code>train.py</code>):","text":"<p>We are going to use the following training script for the examples below. Python Script: <pre><code>import torch\nimport argparse\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import TrainConfig, Trainer\nfrom qadence.ml_tools.optimize_step import optimize_step\nTrainer.set_use_grad(True)\n\n# __main__ is recommended.\nif __name__ == \"__main__\":\n    # simple dataset for y = 2\u03c0x\n    x = torch.linspace(0, 1, 100).reshape(-1, 1)\n    y = torch.sin(2 * torch.pi * x)\n    dataloader = DataLoader(TensorDataset(x, y), batch_size=16, shuffle=True)\n    # Simple model with no hidden layer and ReLU activation to fit the data for y = 2\u03c0x\n    model = nn.Sequential(nn.Linear(1, 16), nn.ReLU(), nn.Linear(16, 1))\n    # SGD optimizer with 0.01 learning rate\n    optimizer = optim.SGD(model.parameters(), lr=0.01)\n\n    # TrainConfig\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--nprocs\", type=int,\n                        default=1, help=\"Number of processes (GPUs) to use.\")\n    parser.add_argument(\"--compute_setup\", type=str,\n                        default=\"auto\", choices=[\"cpu\", \"gpu\", \"auto\"], help=\"Computational Setup.\")\n    parser.add_argument(\"--backend\", type=str,\n                        default=\"nccl\", choices=[\"nccl\", \"gloo\", \"mpi\"], help=\"Distributed backend.\")\n    args = parser.parse_args()\n    train_config = TrainConfig(\n                                backend=args.backend,\n                                nprocs=args.nprocs,\n                                compute_setup=args.compute_setup,\n                                print_every=5,\n                                max_iter=50\n                            )\n\n    trainer = Trainer(model, optimizer, train_config, loss_fn=\"mse\", optimize_step=optimize_step)\n    trainer.fit(dataloader)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#1-single-gpu","title":"1. Single-GPU:","text":"<p>Simple and suitable for single-card setups. - Assuming that you have 1 node with 1 GPU.</p> <p>You can train by calling this on the head node. <pre><code>python3 train.py --backend nccl --nprocs 1\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#slurm","title":"SLURM","text":"<p>Slurm can be used to train to train the model. <pre><code>#!/bin/bash\n#SBATCH --job-name=single_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nsrun python3 train.py --backend nccl --nprocs 1\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#torchrun","title":"TORCHRUN","text":"<p>Torchrun takes care of setting the <code>nprocs</code> based on the cluster setup. We only need to specify to use the <code>compute_setup</code>, which can be either <code>auto</code> or <code>gpu</code>. - <code>nnodes</code> for torchrun should be the number of nodes - <code>nproc_per_node</code> should be equal to the number of GPUs per node.</p> <p>Note: We use the first node of the allocated resources on the cluster as the head node. However, any other node can also be chosen. <pre><code>#!/bin/bash\n#SBATCH --job-name=single_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\nexport LOGLEVEL=INFO\n\nsrun torchrun \\\n--nnodes 1 \\\n--nproc_per_node 1 \\\n--rdzv_id $RANDOM \\\n--rdzv_backend c10d \\\n--rdzv_endpoint $head_node_ip:29501 \\\ntrain.py --compute_setup auto\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#2-multi-gpu-single-node","title":"2. Multi-GPU (Single Node):","text":"<p>For high performance using multiple GPUs in one node. - Assuming that you have 1 node with 2 GPU. These numbers can be changed depending on user needs.</p> <p>You can train by simply calling this on the head node. <pre><code>python3 train.py --backend nccl --nprocs 2\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#slurm_1","title":"SLURM","text":"<p>Slurm can be used to train the model but also to dispatch the workload on multiple GPUs or CPUs. - Here, we should have one task per gpu. i.e. <code>ntasks</code> is equal to the number of nodes - <code>nprocs</code> should be equal to the total number of gpus (world_size). which is this case is 2.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nsrun python3 train.py --backend nccl --nprocs 2\n</code></pre>"},{"location":"tutorials/qml/ml_tools/GPU/#torchrun_1","title":"TORCHRUN","text":"<p>Torchrun takes care of setting the <code>nprocs</code> based on the cluster setup. We only need to specify to use the <code>compute_setup</code>, which can be either <code>auto</code> or <code>gpu</code>. - <code>nnodes</code> for torchrun should be the number of nodes - <code>nproc_per_node</code> should be equal to the number of GPUs per node.</p> <p>Note: We use the first node of the allocated resources on the cluster as the head node. However, any other node can also be chosen. <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\nexport LOGLEVEL=INFO\n\nsrun torchrun \\\n--nnodes 1 \\\n--nproc_per_node 2 \\\n--rdzv_id $RANDOM \\\n--rdzv_backend c10d \\\n--rdzv_endpoint $head_node_ip:29501 \\\ntrain.py --compute_setup auto\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/GPU/#3-multi-node-multi-gpu","title":"3. Multi-Node Multi-GPU:","text":"<p>For high performance using multiple GPUs in multiple nodes. - Assuming that you have two nodes with two GPU each. These numbers can be customised on user needs.</p> <p>For multi-node, it is suggested to submit a sbatch script.</p>"},{"location":"tutorials/qml/ml_tools/GPU/#slurm_2","title":"SLURM","text":"<ul> <li>We should have one task per gpu. i.e. <code>ntasks</code> is equal to the number of nodes.</li> <li><code>nprocs</code> should be equal to the total number of gpus (world_size). which is this case is 4.</li> </ul> <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_node\n#SBATCH --nodes=2\n#SBATCH --ntasks=2\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nsrun python3 train.py --backend nccl --nprocs 4\n</code></pre>"},{"location":"tutorials/qml/ml_tools/GPU/#torchrun_2","title":"TORCHRUN","text":"<p>Torchrun takes care of setting the <code>nprocs</code> based on the cluster setup. We only need to specify to use the <code>compute_setup</code>, which can be either <code>auto</code> or <code>gpu</code>. - <code>nnodes</code> for torchrun should be the number of nodes - <code>nproc_per_node</code> should be equal to the number of GPUs per node.</p> <p>Note: We use the first node of the allocated resources on the cluster as the head node. However, any other node can also be chosen. <pre><code>#!/bin/bash\n#SBATCH --job-name=multi_node\n#SBATCH --nodes=2\n#SBATCH --ntasks=2\n#SBATCH --gpus-per-task=2\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=10G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\nexport LOGLEVEL=INFO\n\nsrun torchrun \\\n--nnodes 2 \\\n--nproc_per_node 2 \\\n--rdzv_id $RANDOM \\\n--rdzv_backend c10d \\\n--rdzv_endpoint $head_node_ip:29501 \\\ntrain.py --compute_setup auto\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/","title":"Accelerator for Distributed Training","text":""},{"location":"tutorials/qml/ml_tools/accelerator_doc/#overview","title":"Overview","text":"<p>The <code>Accelerator</code> class is designed to simplify distributed training with PyTorch's API. It allows for efficient training across multiple GPUs or processes while handling device placement, data distribution, and model synchronization. It uses <code>DistDataParallel</code> and <code>DistributedSampler</code> in the background to correctly distribute the model and training data across processes and devices.</p> <p>This tutorial will guide you through setting up and using <code>Accelerator</code> for distributed training.</p>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#accelerator","title":"Accelerator","text":"<p>The <code>Accelerator</code> class manages the training environment and process distribution. Here\u2019s how you initialize it:</p> <pre><code>from qadence.ml_tools.train_utils import Accelerator\nimport torch\n\naccelerator = Accelerator(\n    nprocs=4,               # Number of processes (e.g., GPUs). Enables multiprocessing.\n    compute_setup=\"auto\",   # Automatically selects available compute devices\n    log_setup=\"cpu\",        # Logs on CPU to avoid memory overhead\n    dtype=torch.float32,    # Data type for numerical precision\n    backend=\"nccl\"          # Backend for communication\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#using-accelerator-with-trainer","title":"Using Accelerator with Trainer","text":"<p><code>Accelerator</code> is already integrated into the <code>Trainer</code> class from <code>qadence.ml_tools</code>, and <code>Trainer</code> can automatically distribute the training process based on the configurations provided in <code>TrainConfig</code>.</p> <pre><code>from qadence.ml_tools.trainer import Trainer\nfrom qadence.ml_tools import TrainConfig\n\nconfig = TrainConfig(nprocs=4)\n\ntrainer = Trainer(model, optimizer, config)\nmodel, optimizer = trainer.fit(dataloader)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#accelerator-features","title":"Accelerator features","text":"<p>The <code>Accelerator</code> also provides a <code>distribute()</code> function wrapper that simplifies running distributed training across multiple processes. This method can be used to prepare or wrap a function that needs to be distributed.</p> <ul> <li> <p><code>distribute()</code></p> <p>This method allows you to wrap your training function so it runs across multiple processes, handling rank management and process spawning automatically.</p> <p>Example Usage: <pre><code>distributed_fun = accelerator.distribute(fun)\ndistributed_fun(*args, **kwargs)\n</code></pre></p> <p>The <code>distribute()</code> function ensures that each process runs on a designated device and synchronizes properly, making it easier to scale training with minimal code modifications.</p> <p>NOTE: <code>fun</code> should be Pickleable: Using <code>distribute</code> on <code>fun</code> allows user to spawn multiple processes that run <code>fun</code> using <code>torch.multiprocessing</code>. As a requirment for <code>torch.multiprocessing</code>,<code>fun</code> should be pickleable. It can either be a bounded class method, or an unabounded method defined in <code>__main__</code>.</p> </li> </ul> <p>The <code>Accelerator</code> further offers these key methods: <code>prepare</code>, <code>prepare_batch</code>, and <code>all_reduce_dict</code>.</p> <ul> <li> <p><code>prepare()</code></p> <p>This method ensures that models, optimizers, and dataloaders are properly placed on the correct devices for distributed training. It wraps models into <code>DistributedDataParallel</code> and synchronizes parameters across processes.</p> <pre><code>model, optimizer, dataloader = accelerator.prepare(model,\n                                                    optimizer,\n                                                    dataloader)\n</code></pre> </li> <li> <p><code>prepare_batch()</code>     Moves data batches to the correct device and formats them properly for distributed training.</p> <pre><code>batch_data, batch_targets = accelerator.prepare(batch)\n</code></pre> </li> <li> <p><code>all_reduce_dict()</code>     Aggregates and synchronizes metrics across all processes during training. Note: This will cause a synchronization overhead and slow down the training processes.</p> <pre><code>metrics = {\"loss\": torch.tensor(1.0)}\nreduced_metrics = accelerator.all_reduce_dict(metrics)\nprint(reduced_metrics)\n</code></pre> </li> </ul>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#example","title":"Example","text":"<p>To launch distributed training across multiple GPUs/CPUs, use the following approach: Each batch should be moved to the correct device. The <code>prepare_batch()</code> method simplifies this process.</p>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#example-code-train_scriptpy","title":"Example Code (train_script.py):","text":"<pre><code>import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools.train_utils import Accelerator\n\n\ndef train_epoch(epochs, model, dataloader, optimizer, accelerator):\n\n    # Prepare model, optimizer, and dataloader for distributed training\n    model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n\n    # accelerator.rank will provide you the rank of the process.\n    if accelerator.rank == 0:\n        print(\"Prepared model of type: \", type(model))\n        print(\"Prepared optimizer of type: \", type(optimizer))\n        print(\"Prepared dataloader of type: \", type(dataloader))\n\n    model.train()\n    for epoch in range(epochs):\n        for batch in dataloader:\n\n            # Move batch to the correct device\n            batch = accelerator.prepare_batch(batch)\n\n            batch_data, batch_targets = batch\n            optimizer.zero_grad()\n            output = model(batch_data)\n            loss = torch.nn.functional.mse_loss(output, batch_targets)\n            loss.backward()\n            optimizer.step()\n        print(\"Rank: \", accelerator.rank, \" | Epoch: \", epoch, \" | Loss: \", loss.item())\n\nif __name__ == \"__main__\":\n    n_epochs = 10\n    model = nn.Sequential(\n        nn.Linear(10, 100),  # Input Layer\n        nn.ReLU(),  # Activation Function\n        nn.Linear(100, 1)  # Output Layer\n    )\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    # A random dataset with 10 features and a target to predict.\n    dataset = TensorDataset(torch.randn(100, 10), torch.randn(100, 1))\n    dataloader = DataLoader(dataset, batch_size=32)\n\n    accelerator = Accelerator(\n        nprocs=4,               # Number of processes (e.g., GPUs). Enables multiprocessing.\n        compute_setup=\"cpu\",    # or choose GPU\n        backend=\"gloo\"          # choose `nccl` for GPU\n    )\n\n    distributed_train_epoch = accelerator.distribute(train_epoch)\n    distributed_train_epoch(n_epochs, model, dataloader, optimizer, accelerator)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#running-distributed-training","title":"Running Distributed Training","text":"<p>The above example can be directly run on the terminal as following:</p> <pre><code>python train_script.py\n</code></pre> <ul> <li> <p>SLURM:</p> <p>To launch distributed training across multiple GPUs</p> <p>Inside an interactive <code>srun</code> session, you can directly use: <pre><code>python train_script.py\n</code></pre></p> <p>Or submit the following sbatch script: <pre><code>#!/bin/bash\n#SBATCH --job-name=MG_slurm\n#SBATCH --nodes=1\n#SBATCH --ntasks=1              # tasks = number of nodes\n#SBATCH --gpus-per-task=4       # same as nprocs\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=56G\n\nsrun python3 train_script.py\n</code></pre></p> </li> <li> <p>Torchrun:</p> <p>To run distributed training with <code>torchrun</code> <pre><code>#!/bin/bash\n#SBATCH --job-name=MG_torchrun\n#SBATCH --nodes=1\n#SBATCH --ntasks=1              # tasks = number of nodes\n#SBATCH --gpus-per-task=2       # same as nprocs\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=56G\n\nnodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )\nnodes_array=($nodes)\nhead_node=${nodes_array[0]}\nhead_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname -I | awk '{print $1}')\n\nsrun torchrun --nnodes 1 --nproc_per_node 2 --rdzv_id $RANDOM --rdzv_backend c10d --rdzv_endpoint $head_node_ip:29522 train_script.py\n</code></pre></p> </li> </ul>"},{"location":"tutorials/qml/ml_tools/accelerator_doc/#conclusion","title":"Conclusion","text":"<p>The <code>Accelerator</code> class simplifies distributed training by handling process management, device setup, and data distribution. By integrating it into your PyTorch training workflow, you can efficiently scale training across multiple devices with minimal code modifications.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/","title":"Callbacks for Trainer","text":"<p>Qadence <code>ml_tools</code> provides a powerful callback system for customizing various stages of the training process. With callbacks, you can monitor, log, save, and alter your training workflow efficiently. A <code>CallbackManager</code> is used with <code>Trainer</code> to execute the training process with defined callbacks. Following default callbacks are already provided in the <code>Trainer</code>.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#default-callbacks","title":"Default Callbacks","text":"<p>Below is a list of the default callbacks already implemented in the <code>CallbackManager</code> used with <code>Trainer</code>:</p> <ul> <li><code>train_start</code>: <code>PlotMetrics</code>, <code>SaveCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_epoch_end</code>: <code>SaveCheckpoint</code>, <code>PrintMetrics</code>, <code>PlotMetrics</code>, <code>WriteMetrics</code></li> <li><code>val_epoch_end</code>: <code>SaveBestCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_end</code>: <code>LogHyperparameters</code>, <code>LogModelTracker</code>, <code>WriteMetrics</code>, <code>SaveCheckpoint</code>, <code>PlotMetrics</code></li> </ul> <p>This guide covers how to define and use callbacks in <code>TrainConfig</code>, integrate them with the <code>Trainer</code> class, and create custom callbacks using hooks.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#1-built-in-callbacks","title":"1. Built-in Callbacks","text":"<p>Qadence ml_tools offers several built-in callbacks for common tasks like saving checkpoints, logging metrics, and tracking models. Below is an overview of each.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#11-printmetrics","title":"1.1. <code>PrintMetrics</code>","text":"<p>Prints metrics at specified intervals.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PrintMetrics\n\nprint_metrics_callback = PrintMetrics(on=\"val_batch_end\", called_every=100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[print_metrics_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#12-writemetrics","title":"1.2. <code>WriteMetrics</code>","text":"<p>Writes metrics to a specified logging destination.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import WriteMetrics\n\nwrite_metrics_callback = WriteMetrics(on=\"train_epoch_end\", called_every=50)\n\nconfig = TrainConfig(\n    max_iter=5000,\n    callbacks=[write_metrics_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#13-plotmetrics","title":"1.3. <code>PlotMetrics</code>","text":"<p>Plots metrics based on user-defined plotting functions.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import PlotMetrics\n\nplot_metrics_callback = PlotMetrics(on=\"train_epoch_end\", called_every=100)\n\nconfig = TrainConfig(\n    max_iter=5000,\n    callbacks=[plot_metrics_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#14-loghyperparameters","title":"1.4. <code>LogHyperparameters</code>","text":"<p>Logs hyperparameters to keep track of training settings.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LogHyperparameters\n\nlog_hyper_callback = LogHyperparameters(on=\"train_start\", called_every=1)\n\nconfig = TrainConfig(\n    max_iter=1000,\n    callbacks=[log_hyper_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#15-savecheckpoint","title":"1.5. <code>SaveCheckpoint</code>","text":"<p>Saves model checkpoints at specified intervals.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveCheckpoint\n\nsave_checkpoint_callback = SaveCheckpoint(on=\"train_epoch_end\", called_every=100)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[save_checkpoint_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#16-savebestcheckpoint","title":"1.6. <code>SaveBestCheckpoint</code>","text":"<p>Saves the best model checkpoint based on a validation criterion.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveBestCheckpoint\n\nsave_best_checkpoint_callback = SaveBestCheckpoint(on=\"val_epoch_end\", called_every=10)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[save_best_checkpoint_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#17-loadcheckpoint","title":"1.7. <code>LoadCheckpoint</code>","text":"<p>Loads a saved model checkpoint at the start of training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LoadCheckpoint\n\nload_checkpoint_callback = LoadCheckpoint(on=\"train_start\")\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[load_checkpoint_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#18-logmodeltracker","title":"1.8. <code>LogModelTracker</code>","text":"<p>Logs the model structure and parameters.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LogModelTracker\n\nlog_model_callback = LogModelTracker(on=\"train_end\")\n\nconfig = TrainConfig(\n    max_iter=1000,\n    callbacks=[log_model_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#19-lrschedulerstepdecay","title":"1.9. <code>LRSchedulerStepDecay</code>","text":"<p>Reduces the learning rate by a factor at regular intervals.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerStepDecay\n\nlr_step_decay = LRSchedulerStepDecay(on=\"train_epoch_end\", called_every=100, gamma=0.5)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[lr_step_decay]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#110-lrschedulercyclic","title":"1.10. <code>LRSchedulerCyclic</code>","text":"<p>Applies a cyclic learning rate schedule during training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCyclic\n\nlr_cyclic = LRSchedulerCyclic(on=\"train_batch_end\", called_every=1, base_lr=0.001, max_lr=0.01, step_size=2000)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[lr_cyclic]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#111-lrschedulercosineannealing","title":"1.11. <code>LRSchedulerCosineAnnealing</code>","text":"<p>Applies cosine annealing to the learning rate during training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import LRSchedulerCosineAnnealing\n\nlr_cosine = LRSchedulerCosineAnnealing(on=\"train_batch_end\", called_every=1, t_max=5000, min_lr=1e-6)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[lr_cosine]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#112-earlystopping","title":"1.12. <code>EarlyStopping</code>","text":"<p>Stops training when a monitored metric has not improved for a specified number of epochs.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(on=\"val_epoch_end\", called_every=1, monitor=\"val_loss\", patience=5, mode=\"min\")\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[early_stopping]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#113-gradientmonitoring","title":"1.13. <code>GradientMonitoring</code>","text":"<p>Logs gradient statistics (e.g., mean, standard deviation, max) during training.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import GradientMonitoring\n\ngradient_monitoring = GradientMonitoring(on=\"train_batch_end\", called_every=10)\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[gradient_monitoring]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#2-custom-callbacks","title":"2. Custom Callbacks","text":"<p>The base <code>Callback</code> class in Qadence allows defining custom behavior that can be triggered at specified events (e.g., start of training, end of epoch). You can set parameters such as when the callback runs (<code>on</code>), frequency of execution (<code>called_every</code>), and optionally define a <code>callback_condition</code>.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#defining-callbacks","title":"Defining Callbacks","text":"<p>There are two main ways to define a callback: 1. Directly providing a function in the <code>Callback</code> instance. 2. Subclassing the <code>Callback</code> class and implementing custom logic.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#example-1-providing-a-callback-function-directly","title":"Example 1: Providing a Callback Function Directly","text":"<pre><code>from qadence.ml_tools.callbacks import Callback\n\n# Define a custom callback function\ndef custom_callback_function(trainer, config, writer):\n    print(\"Executing custom callback.\")\n\n# Create the callback instance\ncustom_callback = Callback(\n    on=\"train_end\",\n    callback=custom_callback_function\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#example-2-subclassing-the-callback","title":"Example 2: Subclassing the Callback","text":"<pre><code>from qadence.ml_tools.callbacks import Callback\n\nclass CustomCallback(Callback):\n    def run_callback(self, trainer, config, writer):\n        print(\"Custom behavior in run_callback method.\")\n\n# Create the subclassed callback instance\ncustom_callback = CustomCallback(on=\"train_batch_end\", called_every=10)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#3-adding-callbacks-to-trainconfig","title":"3. Adding Callbacks to <code>TrainConfig</code>","text":"<p>To use callbacks in <code>TrainConfig</code>, add them to the <code>callbacks</code> list when configuring the training process.</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.ml_tools.callbacks import SaveCheckpoint, PrintMetrics\n\nconfig = TrainConfig(\n    max_iter=10000,\n    callbacks=[\n        SaveCheckpoint(on=\"val_epoch_end\", called_every=50),\n        PrintMetrics(on=\"train_epoch_end\", called_every=100),\n    ]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/callbacks/#4-using-callbacks-with-trainer","title":"4. Using Callbacks with <code>Trainer</code>","text":"<p>The <code>Trainer</code> class in <code>qadence.ml_tools</code> provides built-in support for executing callbacks at various stages in the training process, managed through a callback manager. By default, several callbacks are added to specific hooks to automate common tasks, such as check-pointing, metric logging, and model tracking.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#default-callbacks_1","title":"Default Callbacks","text":"<p>Below is a list of the default callbacks and their assigned hooks:</p> <ul> <li><code>train_start</code>: <code>PlotMetrics</code>, <code>SaveCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_epoch_end</code>: <code>SaveCheckpoint</code>, <code>PrintMetrics</code>, <code>PlotMetrics</code>, <code>WriteMetrics</code></li> <li><code>val_epoch_end</code>: <code>SaveBestCheckpoint</code>, <code>WriteMetrics</code></li> <li><code>train_end</code>: <code>LogHyperparameters</code>, <code>LogModelTracker</code>, <code>WriteMetrics</code>, <code>SaveCheckpoint</code>, <code>PlotMetrics</code></li> </ul> <p>These defaults handle common needs, but you can also add custom callbacks to any hook.</p>"},{"location":"tutorials/qml/ml_tools/callbacks/#example-adding-a-custom-callback","title":"Example: Adding a Custom Callback","text":"<p>To create a custom <code>Trainer</code> that includes a <code>PrintMetrics</code> callback executed specifically at the end of each epoch, follow the steps below.</p> <pre><code>from qadence.ml_tools.trainer import Trainer\nfrom qadence.ml_tools.callbacks import PrintMetrics\n\nclass CustomTrainer(Trainer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.print_metrics_callback = PrintMetrics(on=\"train_epoch_end\", called_every = 10)\n\n    def on_train_epoch_end(self, train_epoch_loss_metrics):\n        self.print_metrics_callback.run_callback(self)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/data_and_config/","title":"Data and Configurations","text":""},{"location":"tutorials/qml/ml_tools/data_and_config/#1-dataloaders","title":"1. Dataloaders","text":"<p>When using Qadence, you can supply classical data to a quantum machine learning algorithm by using a standard PyTorch <code>DataLoader</code> instance. Qadence also provides the <code>DictDataLoader</code> convenience class which allows to build dictionaries of <code>DataLoader</code>s instances and easily iterate over them.</p> <pre><code>import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import DictDataLoader, to_dataloader\n\n\ndef dataloader(data_size: int = 25, batch_size: int = 5, infinite: bool = False) -&gt; DataLoader:\n    x = torch.linspace(0, 1, data_size).reshape(-1, 1)\n    y = torch.sin(x)\n    return to_dataloader(x, y, batch_size=batch_size, infinite=infinite)\n\n\ndef dictdataloader(data_size: int = 25, batch_size: int = 5) -&gt; DictDataLoader:\n    dls = {}\n    for k in [\"y1\", \"y2\"]:\n        x = torch.rand(data_size, 1)\n        y = torch.sin(x)\n        dls[k] = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n    return DictDataLoader(dls)\n\n\n# iterate over standard DataLoader\nfor (x,y) in dataloader(data_size=6, batch_size=2):\n    print(f\"Standard {x = }\")\n\n# construct an infinite dataset which will keep sampling indefinitely\nn_epochs = 5\ndl = iter(dataloader(data_size=6, batch_size=2, infinite=True))\nfor _ in range(n_epochs):\n    (x, y) = next(dl)\n    print(f\"Infinite {x = }\")\n\n# iterate over DictDataLoader\nddl = dictdataloader()\ndata = next(iter(ddl))\nprint(f\"{data = }\")\n</code></pre> <pre><code>Standard x = tensor([[0.0000],\n        [0.2000]])\nStandard x = tensor([[0.4000],\n        [0.6000]])\nStandard x = tensor([[0.8000],\n        [1.0000]])\nInfinite x = tensor([[0.6000],\n        [0.2000]])\nInfinite x = tensor([[0.],\n        [1.]])\nInfinite x = tensor([[0.8000],\n        [0.4000]])\nInfinite x = tensor([[0.6000],\n        [0.2000]])\nInfinite x = tensor([[0.],\n        [1.]])\ndata = {'y1': [tensor([[0.4171],\n        [0.1440],\n        [0.8342],\n        [0.4124],\n        [0.4072]]), tensor([[0.4051],\n        [0.1435],\n        [0.7408],\n        [0.4008],\n        [0.3961]])], 'y2': [tensor([[0.4978],\n        [0.8297],\n        [0.5417],\n        [0.6601],\n        [0.6967]]), tensor([[0.4775],\n        [0.7378],\n        [0.5156],\n        [0.6132],\n        [0.6417]])]}\n</code></pre> <p>Note:     In case of <code>infinite</code>=True, the dataloader iterator will provide a random sample from the dataset.</p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#2-training-configuration","title":"2. Training Configuration","text":"<p>The <code>TrainConfig</code> class provides a comprehensive configuration setup for training quantam machine learning models in Qadence. This configuration includes settings for batch size, logging, check-pointing, validation, and additional custom callbacks that control the training process's granularity and flexibility.</p> <p>The <code>TrainConfig</code> tells <code>Trainer</code>  what batch_size should be used, how many epochs to train, in which intervals to print/log metrics and how often to store intermediate checkpoints. It is also possible to provide custom callback functions by instantiating a <code>Callback</code> with a function <code>callback</code>.</p> <p>For example of how to use the TrainConfig with <code>Trainer</code>, please see Examples in Trainer</p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#21-explanation-of-trainconfig-attributes","title":"2.1 Explanation of <code>TrainConfig</code> Attributes","text":"Attribute Type Default Description <code>max_iter</code> <code>int</code> <code>10000</code> Total number of training epochs. <code>batch_size</code> <code>int</code> <code>1</code> Batch size for training. <code>print_every</code> <code>int</code> <code>0</code> Frequency of console output. Set to <code>0</code> to disable. <code>write_every</code> <code>int</code> <code>0</code> Frequency of logging metrics. Set to <code>0</code> to disable. <code>plot_every</code> <code>int</code> <code>0</code> Frequency of plotting metrics. Set to <code>0</code> to disable. <code>checkpoint_every</code> <code>int</code> <code>0</code> Frequency of saving checkpoints. Set to <code>0</code> to disable. <code>val_every</code> <code>int</code> <code>0</code> Frequency of validation checks. Set to <code>0</code> to disable. <code>val_epsilon</code> <code>float</code> <code>1e-5</code> Threshold for validation improvement. <code>validation_criterion</code> <code>Callable</code> <code>None</code> Function for validating metric improvement. <code>trainstop_criterion</code> <code>Callable</code> <code>None</code> Function to stop training early. <code>callbacks</code> <code>list[Callback]</code> <code>[]</code> List of custom callbacks. <code>root_folder</code> <code>Path</code> <code>\"./qml_logs\"</code> Root directory for saving logs and checkpoints. <code>log_folder</code> <code>Path</code> <code>\"./qml_logs\"</code> Logging directory for saving logs and checkpoints. <code>log_model</code> <code>bool</code> <code>False</code> Enables model logging. <code>verbose</code> <code>bool</code> <code>True</code> Enables detailed logging. <code>tracking_tool</code> <code>ExperimentTrackingTool</code> <code>TENSORBOARD</code> Tool for tracking training metrics. <code>plotting_functions</code> <code>tuple</code> <code>()</code> Functions for plotting metrics. <code>hyperparams</code> <code>dict</code> <code>{}</code> Dictionary of hyperparameters <code>nprocs</code> <code>int</code> <code>1</code> Number of processes to use when spawning subprocesses; for multi-GPU setups, set this to the total number of GPUs. <code>compute_setup</code> <code>str</code> <code>\"cpu\"</code> Specifies the compute device: <code>\"auto\"</code>, <code>\"gpu\"</code>, or <code>\"cpu\"</code>. <code>backend</code> <code>str</code> <code>\"gloo\"</code> Backend for distributed training communication (e.g., <code>\"gloo\"</code>, <code>\"nccl\"</code>, or <code>\"mpi\"</code>). <code>log_setup</code> <code>str</code> <code>\"cpu\"</code> Device setup for logging; use <code>\"cpu\"</code> to avoid GPU conflicts <code>dtype</code> <code>dtype</code> or <code>None</code> <code>None</code> Data type for computations (e.g., <code>torch.float32</code>) <code>all_reduce_metrics</code> <code>bool</code> <code>False</code> If <code>True</code>, aggregates metrics (e.g., loss) across processes <pre><code>from qadence.ml_tools import OptimizeResult, TrainConfig\nfrom qadence.ml_tools.callbacks import Callback\n\nbatch_size = 5\nn_epochs = 100\n\nprint_parameters = lambda opt_res: print(opt_res.model.parameters())\ncondition_print = lambda opt_res: opt_res.loss &lt; 1.0e-03\nmodify_extra_opt_res = {\"n_epochs\": n_epochs}\ncustom_callback = Callback(on=\"train_end\", callback = print_parameters, callback_condition=condition_print, modify_optimize_result=modify_extra_opt_res, called_every=10,)\n\nconfig = TrainConfig(\n    root_folder=\"some_path/\",\n    max_iter=n_epochs,\n    checkpoint_every=100,\n    write_every=100,\n    batch_size=batch_size,\n    callbacks = [custom_callback]\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/data_and_config/#22-key-configuration-options-in-trainconfig","title":"2.2 Key Configuration Options in <code>TrainConfig</code>","text":""},{"location":"tutorials/qml/ml_tools/data_and_config/#iterations-and-batch-size","title":"Iterations and Batch Size","text":"<ul> <li><code>max_iter</code> (int): Specifies the total number of training iterations (epochs). For an <code>InfiniteTensorDataset</code>, each epoch contains one batch; for a <code>TensorDataset</code>, it contains <code>len(dataloader)</code> batches.</li> <li><code>batch_size</code> (int): Defines the number of samples processed in each training iteration.</li> </ul> <p>Example: <pre><code>config = TrainConfig(max_iter=2000, batch_size=32)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#training-parameters","title":"Training Parameters","text":"<ul> <li><code>print_every</code> (int): Controls how often loss and metrics are printed to the console.</li> <li><code>write_every</code> (int): Determines how frequently metrics are written to the tracking tool, such as TensorBoard or MLflow.</li> <li><code>checkpoint_every</code> (int): Sets the frequency for saving model checkpoints.</li> </ul> <p>Note: Set 0 to diable.</p> <p>Example: <pre><code>config = TrainConfig(print_every=100, write_every=50, checkpoint_every=50)\n</code></pre></p> <p>The user can provide either the <code>root_folder</code> or the <code>log_folder</code> for saving checkpoints and logging. When neither are provided, the default <code>root_folder</code> \"./qml_logs\" is used.</p> <ul> <li><code>root_folder</code> (Path): The root directory for saving checkpoints and logs. All training logs will be saved inside a subfolder in this root directory. (The path to these subfolders can be accessed using config._subfolders, and the current logging folder is config.log_folder)</li> <li><code>create_subfolder_per_run</code> (bool): Creates a unique subfolder for each training run within the specified folder.</li> <li><code>tracking_tool</code> (ExperimentTrackingTool): Specifies the tracking tool to log metrics, e.g., TensorBoard or MLflow.</li> <li><code>log_model</code> (bool): Enables logging of a serialized version of the model, which is useful for model versioning. Thi happens at the end of training.</li> </ul> <p>Note     - The user can also provide <code>log_folder</code> argument - which will only be used when <code>create_subfolder_per_run</code> = False.     -  <code>log_folder</code> (Path): The log folder used for saving checkpoints and logs.</p> <p>Example: <pre><code>config = TrainConfig(root_folder=\"path/to/checkpoints\", tracking_tool=ExperimentTrackingTool.MLFLOW, checkpoint_best_only=True)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#validation-parameters","title":"Validation Parameters","text":"<ul> <li><code>checkpoint_best_only</code> (bool): If set to <code>True</code>, saves checkpoints only when there is an improvement in the validation metric.</li> <li><code>val_every</code> (int): Frequency of validation checks. Setting this to <code>0</code> disables validation.</li> <li><code>val_epsilon</code> (float): A small threshold used to compare the current validation loss with previous best losses.</li> <li><code>validation_criterion</code> (Callable): A custom function to assess if the validation metric meets a specified condition.</li> </ul> <p>Example: <pre><code>config = TrainConfig(val_every=200, checkpoint_best_only = True, validation_criterion=lambda current, best: current &lt; best - 0.001)\n</code></pre></p> <p>If it is desired to only the save the \"best\" checkpoint, the following must be ensured:</p> <pre><code>(a) `checkpoint_best_only = True` is used while creating the configuration through `TrainConfig`,\n(b) `val_every` is set to a valid integer value (for example, `val_every = 10`) which controls the no. of iterations after which the validation data should be used to evaluate the model during training, which can also be set through `TrainConfig`,\n(c) a validation criterion is provided through the `validation_criterion`, set through `TrainConfig` to quantify the definition of \"best\", and\n(d) the validation dataloader passed to `Trainer` is of type `DataLoader`. In this case, it is expected that a validation dataloader is also provided along with the train dataloader since the validation data will be used to decide the \"best\" checkpoint.\n</code></pre> <p>The criterion used to decide the \"best\" checkpoint can be customized by <code>validation_criterion</code>, which should be a function that can take val_loss, best_loss, and val_epsilon arguments and return a boolean value (True or False) indicating whether some validation metric is satisfied or not. An example of a simple <code>validation_criterion</code> is: <pre><code>def validation_criterion(val_loss: float, best_val_loss: float, val_epsilon: float) -&gt; bool:\n    return val_loss &lt; (best_val_loss - val_epsilon)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#custom-callbacks","title":"Custom Callbacks","text":"<p><code>TrainConfig</code> supports custom callbacks that can be triggered at specific stages of training. The <code>callbacks</code> attribute accepts a list of callback instances, which allow for custom behaviors like early stopping or additional logging. See Callbacks for more details.</p> <ul> <li><code>callbacks</code> (list[Callback]): List of custom callbacks to execute during training.</li> </ul> <p>Example: <pre><code>from qadence.ml_tools.callbacks import Callback\n\ndef callback_fn(trainer, config, writer):\n    if trainer.opt_res.loss &lt; 0.001:\n        print(\"Custom Callback: Loss threshold reached!\")\n\ncustom_callback = Callback(on = \"train_epoch_end\", called_every = 10, callback_function = callback_fn )\n\nconfig = TrainConfig(callbacks=[custom_callback])\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#hyperparameters-and-plotting","title":"Hyperparameters and Plotting","text":"<ul> <li><code>hyperparams</code> (dict): A dictionary of hyperparameters (e.g., learning rate, regularization) to be tracked by the tracking tool.</li> <li><code>plot_every</code> (int): Determines how frequently plots are saved to the tracking tool, such as TensorBoard or MLflow.</li> <li><code>plotting_functions</code> (tuple[LoggablePlotFunction, ...]): Functions for in-training plotting of metrics or model state.</li> </ul> <p>Note: Please ensure that plotting_functions are provided when plot_every &gt; 0</p> <p>Example: <pre><code>config = TrainConfig(\n    plot_every=10,\n    hyperparams={\"learning_rate\": 0.001, \"batch_size\": 32},\n    plotting_functions=(plot_loss_function,)\n)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#advanced-distributed-training","title":"Advanced Distributed Training","text":"<ul> <li> <p><code>nprocs</code> (int): Specifies the number of processes to be used. For multi-GPU training, this should match the total number of GPUs available. When nprocs is greater than 1, <code>Trainer</code> spawns additional subprocesses for training. This is useful for parallel or distributed training setups.</p> </li> <li> <p><code>compute_setup</code> (str): Determines the compute device configuration: 1.<code>\"auto\"</code> (automatically selects GPU if available), 2. <code>\"gpu\"</code> - (forces GPU usage and errors if no GPU is detected), and 3. <code>\"cpu\"</code> (Forces the use of the CPU).</p> </li> <li> <p><code>backend</code> (str): Specifies the communication backend for distributed training. Common options are <code>\"gloo\"</code> (default), <code>\"nccl\"</code> (optimized for GPUs), or <code>\"mpi\"</code>, depending on your setup. It should be one of the backends supported by <code>torch.distributed</code>. For further details, please look at torch backends</p> </li> </ul> <p>Notes: - Logging Specific Callbacks: Logging is available only through the main process, i.e. process 0.  Model logging, plotting, logging metrics will only be performed for a single process, even if multiple processes are run. - Training with specific callbacks: Callbacks specific to training, e.g., <code>EarlyStopping</code>, <code>LRSchedulerStepDecay</code>, etc will be called from each process. - <code>PrintMetrics</code> (set through the <code>print_every</code> argument in <code>TrainCongig</code>) is available from all processes.</p> <p>Example: For CPU MultiProcessing <pre><code>config = TrainConfig(\n    compute_setup=\"cpu\",\n    nprocs=5,\n    backend=\"gloo\"\n)\n</code></pre></p> <p>Example: For GPU multiprocessing training <pre><code>config = TrainConfig(\n    compute_setup=\"gpu\",\n    nprocs=2, # World-size/Total number of GPUs\n    backend=\"nccl\"\n)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#precision-options","title":"Precision Options","text":"<ul> <li> <p><code>dtype</code> (dtype or None): Sets the numerical precision (data type) for computations. For instance, you can use <code>torch.float32</code> or <code>torch.float16</code> depending on your performance and precision needs. Both model parameters, and dataset will be of the provided precision.</p> <ul> <li>If not specified or None, the default torch precision (usually torch.float32) is used.</li> <li>If provided dtype is complex dtype, appropriate precision for the data and model parameters will be used as follows:</li> </ul> Data Type (<code>dtype</code>) Data Precision Model Precision Model Parameters Precision  (Real Part  &amp; Imaginary Part ) <code>torch.float16</code> 16-bit 16-bit N/A <code>torch.float32</code> 32-bit 32-bit N/A <code>torch.float64</code> 64-bit 64-bit N/A <code>torch.complex32</code> 16-bit 32-bit 16-bit <code>torch.complex64</code> 32-bit 64-bit 32-bit <code>torch.complex128</code> 64-bit 128-bit 64-bit <p>Complex Dtypes: Complex data types are useful for Quantum Neural Networks - such as <code>QNN</code> provided by qadence. The industry standard is to use <code>torch.complex128</code>, however, the user can also specify a lower precision (<code>torch.complex64</code> or  <code>torch.complex32</code>) for faster training.</p> </li> </ul> <p>Furthermore, the user can also utilize the following options:</p> <ul> <li> <p><code>log_setup</code> (str): Configures the device used for logging. Using <code>\"cpu\"</code> ensures logging runs on the CPU (which may avoid conflicts with GPU operations), while <code>\"auto\"</code> aligns logging with the compute device.</p> </li> <li> <p><code>all_reduce_metrics</code> (bool): When enabled, aggregates metrics (such as loss or accuracy) across all training processes to provide a unified summary, though it may introduce additional synchronization overhead.</p> </li> </ul>"},{"location":"tutorials/qml/ml_tools/data_and_config/#3-experiment-tracking-with-mlflow","title":"3. Experiment tracking with mlflow","text":"<p>Qadence allows to track runs and log hyperparameters, models and plots with tensorboard and mlflow. In the following, we demonstrate the integration with mlflow.</p>"},{"location":"tutorials/qml/ml_tools/data_and_config/#mlflow-configuration","title":"mlflow configuration","text":"<p>We have control over our tracking configuration by setting environment variables. First, let's look at the tracking URI. For the purpose of this demo we will be working with a local database, in a similar fashion as described here, <pre><code>export MLFLOW_TRACKING_URI=sqlite:///mlruns.db\n</code></pre></p> <p>Qadence can also read the following two environment variables to define the mlflow experiment name and run name <pre><code>export MLFLOW_EXPERIMENT=test_experiment\nexport MLFLOW_RUN_NAME=run_0\n</code></pre></p> <p>If no tracking URI is provided, mlflow stores run information and artifacts in the local <code>./mlflow</code> directory and if no names are defined, the experiment and run will be named with random UUIDs.</p>"},{"location":"tutorials/qml/ml_tools/intro/","title":"Introduction to Qadence ML Tools","text":"<p>Welcome to the Qadence <code>ML Tools</code> documentation. This submodule is designed to streamline your machine learning workflows \u2014especially for quantum machine learning\u2014 by providing a set of robust tools for training, monitoring, and optimizing your models.</p>"},{"location":"tutorials/qml/ml_tools/intro/#what-this-documentation-is-about","title":"What this documentation is about","text":"<ul> <li> <p>Trainer Class   Learn how to leverage the versatile <code>Trainer</code> class to manage your training loops, handle data loading, and integrate with experiment tracking tools like TensorBoard and MLflow. Detailed guides cover:</p> <ul> <li>Setting up training on both GPUs and CPUs.</li> <li>Configuring single-process, multi-processing, and distributed training setups.</li> </ul> </li> <li> <p>Gradient Optimization Methods   Explore both gradient-based and gradient-free optimization strategies. Find examples demonstrating how to switch between these modes and how to use context managers for mixed optimization.</p> </li> <li> <p>Custom Loss Functions and Hooks   Discover how to define custom loss functions tailored to your tasks and use hooks to insert custom behaviors at various stages of the training process.</p> </li> <li> <p>Callbacks for Enhanced Training   Utilize built-in and custom callbacks to log metrics, save checkpoints, adjust learning rates, and more. This section explains how to integrate callbacks seamlessly into your training workflow.</p> </li> <li> <p>Experiment Tracking   Understand how to configure experiment tracking with tools such as TensorBoard and MLflow to monitor your model\u2019s progress and performance.</p> </li> </ul>"},{"location":"tutorials/qml/ml_tools/intro/#getting-started","title":"Getting Started","text":"<p>To dive in, explore the detailed sections below:</p> <ul> <li>Qadence Trainer Guide</li> <li>Training Configuration</li> <li>Callbacks for Trainer</li> <li>Accelerator for Distributed Training</li> <li>Training on GPU with Trainer</li> <li>Training on CPU with Trainer</li> </ul>"},{"location":"tutorials/qml/ml_tools/trainer/","title":"Qadence Trainer Guide","text":"<p>The <code>Trainer</code> class in <code>qadence.ml_tools</code> is a versatile tool designed to streamline the training of quantum machine learning models. It offers flexibility for both gradient-based and gradient-free optimization methods, supports custom loss functions, and integrates seamlessly with tracking tools like TensorBoard and MLflow. Additionally, it provides hooks for implementing custom behaviors during the training process.</p> <p>For training QML models, Qadence offers this out-of-the-box <code>Trainer</code> for optimizing differentiable models, e.g. <code>QNN</code>s and <code>QuantumModel</code>, containing either trainable and/or non-trainable parameters (see the parameters tutorial for detailed information about parameter types):</p>"},{"location":"tutorials/qml/ml_tools/trainer/#1-overview","title":"1. Overview","text":"<p>The <code>Trainer</code> class simplifies the training workflow by managing the training loop, handling data loading, and facilitating model evaluation. It is compatible with various optimization strategies and allows for extensive customization to meet specific training requirements.</p> <p>Example of initializing the <code>Trainer</code>:</p> <pre><code>from qadence.ml_tools import Trainer, TrainConfig\nfrom torch.optim import Adam\n\n# Initialize model and optimizer\nmodel = ...  # Define or load a quantum model here\noptimizer = Adam(model.parameters(), lr=0.01)\nconfig = TrainConfig(max_iter=100, print_every=10)\n\n# Initialize Trainer with model, optimizer, and configuration\ntrainer = Trainer(model=model, optimizer=optimizer, config=config)\n</code></pre> <p>Notes: <code>qadence</code> versions prior to 1.9.0 provided <code>train_with_grad</code> and <code>train_no_grad</code> functions, which are being replaced with <code>Trainer</code>. The user can transition as following. <pre><code>from qadence.ml_tools import train_with_grad\ntrain_with_grad(model=model, optimizer=optimizer, config=config, data = data)\n</code></pre> to <pre><code>from qadence.ml_tools import Trainer\ntrainer = Trainer(model=model, optimizer=optimizer, config=config)\ntrainer.fit(train_dataloader = data)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/trainer/#2-gradient-based-and-gradient-free-optimization","title":"2. Gradient-Based and Gradient-Free Optimization","text":"<p>The <code>Trainer</code> supports both gradient-based and gradient-free optimization methods. Default is gradient-based optimization.</p> <ul> <li>Gradient-Based Optimization: Utilizes optimizers from PyTorch's <code>torch.optim</code> module. This is the default behaviour of the <code>Trainer</code>, thus setting this is not necessary. However, it can be explicity mentioned as follows. Example of using gradient-based optimization:</li> </ul> <pre><code>from qadence.ml_tools import Trainer\n\n# set_use_grad(True) to enable gradient based training. This is the default behaviour of Trainer.\nTrainer.set_use_grad(True)\n</code></pre> <ul> <li>Gradient-Free Optimization: Employs optimization algorithms from the Nevergrad library.</li> </ul> <p>Example of using gradient-free optimization with Nevergrad:</p> <pre><code>from qadence.ml_tools import Trainer\n\n# set_use_grad(False) to disable gradient based training.\nTrainer.set_use_grad(False)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#using-context-managers-for-mixed-optimization","title":"Using Context Managers for Mixed Optimization","text":"<p>For cases requiring both optimization methods in a single training session, the <code>Trainer</code> class provides context managers to enable or disable gradients.</p> <pre><code># Temporarily switch to gradient-based optimization\nwith trainer.enable_grad_opt(optimizer):\n    print(\"Gradient Based Optimization\")\n    # trainer.fit(train_loader)\n\n# Switch to gradient-free optimization for specific steps\nwith trainer.disable_grad_opt(ng_optimizer):\n    print(\"Gradient Free Optimization\")\n    # trainer.fit(train_loader)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#3-custom-loss-functions","title":"3. Custom Loss Functions","text":"<p>Users can define custom loss functions tailored to their specific tasks. The <code>Trainer</code> accepts a <code>loss_fn</code> parameter, which should be a callable that takes the model and data as inputs and returns a tuple containing the loss tensor and a dictionary of metrics.</p> <p>Example of using a custom loss function:</p> <pre><code>import torch\nfrom itertools import count\ncnt = count()\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    x, y = data\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n</code></pre> <p>This custom loss function can be used in the trainer <pre><code>from qadence.ml_tools import Trainer, TrainConfig\nfrom torch.optim import Adam\n\n# Initialize model and optimizer\nmodel = ...  # Define or load a quantum model here\noptimizer = Adam(model.parameters(), lr=0.01)\nconfig = TrainConfig(max_iter=100, print_every=10)\n\ntrainer = Trainer(model=model, optimizer=optimizer, config=config, loss_fn=loss_fn)\n</code></pre></p>"},{"location":"tutorials/qml/ml_tools/trainer/#4-hooks-for-custom-behavior","title":"4. Hooks for Custom Behavior","text":"<p>The <code>Trainer</code> class provides several hooks that enable users to inject custom behavior at different stages of the training process. These hooks are methods that can be overridden in a subclass to execute custom code. The available hooks include:</p> <ul> <li><code>on_train_start</code>: Called at the beginning of the training process.</li> <li><code>on_train_end</code>: Called at the end of the training process.</li> <li><code>on_train_epoch_start</code>: Called at the start of each training epoch.</li> <li><code>on_train_epoch_end</code>: Called at the end of each training epoch.</li> <li><code>on_train_batch_start</code>: Called at the start of each training batch.</li> <li><code>on_train_batch_end</code>: Called at the end of each training batch.</li> </ul> <p>Each \"start\" and \"end\" hook receives data and loss metrics as arguments. The specific values provided for these arguments depend on the training stage associated with the hook. The context of the training stage (e.g., training, validation, or testing) determines which metrics are relevant and how they are populated. For details of inputs on each hook, please review the documentation of <code>BaseTrainer</code>.</p> <pre><code>- Example of what inputs are provided to training hooks.\n\n    ```\n    def on_train_batch_start(self, batch: Tuple[torch.Tensor, ...] | None) -&gt; None:\n        \"\"\"\n        Called at the start of each training batch.\n\n        Args:\n            batch: A batch of data from the DataLoader. Typically a tuple containing\n                input tensors and corresponding target tensors.\n        \"\"\"\n        pass\n    ```\n    ```\n    def on_train_batch_end(self, train_batch_loss_metrics: Tuple[torch.Tensor, Any]) -&gt; None:\n        \"\"\"\n        Called at the end of each training batch.\n\n        Args:\n            train_batch_loss_metrics: Metrics for the training batch loss.\n                Tuple of (loss, metrics)\n        \"\"\"\n        pass\n    ```\n</code></pre> <p>Example of using a hook to log a message at the end of each epoch:</p> <pre><code>from qadence.ml_tools import Trainer\n\nclass CustomTrainer(Trainer):\n    def on_train_epoch_end(self, train_epoch_loss_metrics):\n        print(f\"End of epoch - Loss and Metrics: {train_epoch_loss_metrics}\")\n</code></pre> <p>Notes: Trainer offers inbuilt callbacks as well. Callbacks are mainly for logging/tracking purposes, but the above mentioned hooks are generic. The workflow for every train batch looks like: 1. perform on_train_batch_start callbacks, 2. call the on_train_batch_start hook, 3. do the batch training, 4. call the on_train_batch_end hook, and 5. perform on_train_batch_end callbacks.</p> <p>The use of <code>on_</code>{phase}<code>_start</code> and <code>on_</code>{phase}<code>_end</code> hooks is not specifically to add extra callbacks, but for any other generic pre/post processing. For example, reshaping input batch in case of RNNs/LSTMs, post processing loss and adding an extra metric. They could also be used to add more callbacks (which is not recommended - as we provide methods to add extra callbacks in the TrainCofig)</p>"},{"location":"tutorials/qml/ml_tools/trainer/#5-experiment-tracking-with-tensorboard-and-mlflow","title":"5. Experiment Tracking with TensorBoard and MLflow","text":"<p>The <code>Trainer</code> integrates with TensorBoard and MLflow for experiment tracking:</p> <ul> <li> <p>TensorBoard: Logs metrics and visualizations during training, allowing users to monitor the training process.</p> </li> <li> <p>MLflow: Tracks experiments, logs parameters, metrics, and artifacts, and provides a user-friendly interface for comparing different runs.</p> </li> </ul> <p>To utilize these tracking tools, the <code>Trainer</code> can be configured with appropriate writers that handle the logging of metrics and other relevant information during training.</p> <p>Example of using TensorBoard tracking:</p> <pre><code>from qadence.ml_tools import TrainConfig\nfrom qadence.types import ExperimentTrackingTool\n\n# Set up tracking with TensorBoard\nconfig = TrainConfig(max_iter=100, tracking_tool=ExperimentTrackingTool.TENSORBOARD)\n</code></pre> <p>Example of using MLflow tracking:</p> <pre><code>from qadence.types import ExperimentTrackingTool\n\n# Set up tracking with MLflow\nconfig = TrainConfig(max_iter=100, tracking_tool=ExperimentTrackingTool.MLFLOW)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#6-examples","title":"6. Examples","text":""},{"location":"tutorials/qml/ml_tools/trainer/#61-training-with-trainer-and-trainconfig","title":"6.1. Training with <code>Trainer</code> and <code>TrainConfig</code>","text":""},{"location":"tutorials/qml/ml_tools/trainer/#setup","title":"Setup","text":"<p>Let's do the necessary imports and declare a <code>DataLoader</code>. We can already define some hyperparameters here, including the seed for random number generators. mlflow can log hyperparameters with arbitrary types, for example the observable that we want to monitor (<code>Z</code> in this case, which has a <code>qadence.Operation</code> type).</p> <pre><code>import random\nfrom itertools import count\n\nimport numpy as np\nimport torch\nfrom matplotlib import pyplot as plt\nfrom matplotlib.figure import Figure\nfrom torch.nn import Module\nfrom torch.utils.data import DataLoader\n\nfrom qadence import hea, QuantumCircuit, Z\nfrom qadence.constructors import feature_map, hamiltonian_factory\nfrom qadence.ml_tools import Trainer, TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\nfrom qadence.ml_tools.utils import rand_featureparameters\nfrom qadence.ml_tools.models import QNN, QuantumModel\nfrom qadence.types import ExperimentTrackingTool\n\nhyperparams = {\n    \"seed\": 42,\n    \"batch_size\": 10,\n    \"n_qubits\": 2,\n    \"ansatz_depth\": 1,\n    \"observable\": Z,\n}\n\nnp.random.seed(hyperparams[\"seed\"])\ntorch.manual_seed(hyperparams[\"seed\"])\nrandom.seed(hyperparams[\"seed\"])\n\n\ndef dataloader(batch_size: int = 25) -&gt; DataLoader:\n    x = torch.linspace(0, 1, batch_size).reshape(-1, 1)\n    y = torch.cos(x)\n    return to_dataloader(x, y, batch_size=batch_size, infinite=True)\n</code></pre> <p>We continue with the regular QNN definition, together with the loss function and optimizer.</p> <pre><code>obs = hamiltonian_factory(register=hyperparams[\"n_qubits\"], detuning=hyperparams[\"observable\"])\n\ndata = dataloader(hyperparams[\"batch_size\"])\nfm = feature_map(hyperparams[\"n_qubits\"], param=\"x\")\n\nmodel = QNN(\n    QuantumCircuit(\n        hyperparams[\"n_qubits\"], fm, hea(hyperparams[\"n_qubits\"], hyperparams[\"ansatz_depth\"])\n    ),\n    observable=obs,\n    inputs=[\"x\"],\n)\n\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ninputs = rand_featureparameters(model, 1)\n\ndef loss_fn(model: QuantumModel, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    out = model.expectation(inputs)\n    loss = criterion(out, torch.rand(1))\n    return loss, {}\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#trainconfig-specifications","title":"<code>TrainConfig</code> specifications","text":"<p>Qadence offers different tracking options via <code>TrainConfig</code>. Here we use the <code>ExperimentTrackingTool</code> type to specify that we want to track the experiment with mlflow. Tracking with tensorboard is also possible. We can then indicate what and how often we want to track or log.</p> <p>For Training <code>write_every</code> controls the number of epochs after which the loss values is logged. Thanks to the <code>plotting_functions</code> and <code>plot_every</code>arguments, we are also able to plot model-related quantities throughout training. Notice that arbitrary plotting functions can be passed, as long as the signature is the same as <code>plot_fn</code> below. Finally, the trained model can be logged by setting <code>log_model=True</code>. Here is an example of plotting function and training configuration</p> <pre><code>def plot_fn(model: Module, iteration: int) -&gt; tuple[str, Figure]:\n    descr = f\"ufa_prediction_epoch_{iteration}.png\"\n    fig, ax = plt.subplots()\n    x = torch.linspace(0, 1, 100).reshape(-1, 1)\n    out = model.expectation(x)\n    ax.plot(x.detach().numpy(), out.detach().numpy())\n    return descr, fig\n\n\nconfig = TrainConfig(\n    root_folder=\"mlflow_demonstration\",\n    max_iter=10,\n    checkpoint_every=1,\n    plot_every=2,\n    write_every=1,\n    log_model=True,\n    tracking_tool=ExperimentTrackingTool.MLFLOW,\n    hyperparams=hyperparams,\n    plotting_functions=(plot_fn,),\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#training-and-inspecting","title":"Training and inspecting","text":"<p>Model training happens as usual <pre><code>trainer = Trainer(model, optimizer, config, loss_fn)\ntrainer.fit(train_dataloader=data)\n</code></pre></p> <p>After training , we can inspect our experiment via the mlflow UI <pre><code>mlflow ui --port 8080 --backend-store-uri sqlite:///mlruns.db\n</code></pre> In this case, since we're running on a local server, we can access the mlflow UI by navigating to http://localhost:8080/.</p>"},{"location":"tutorials/qml/ml_tools/trainer/#62-fitting-a-function-with-a-qnn-using-ml_tools","title":"6.2. Fitting a function with a QNN using <code>ml_tools</code>","text":"<p>In Quantum Machine Learning, the general consensus is to use <code>complex128</code> precision for states and operators and <code>float64</code> precision for parameters. This is also the convention which is used in <code>qadence</code>. However, for specific usecases, lower precision can greatly speed up training and reduce memory consumption. When using the <code>pyqtorch</code> backend, <code>qadence</code> offers the option to move a <code>QuantumModel</code> instance to a specific precision using the torch <code>to</code> syntax.</p> <p>Let's look at a complete example of how to use <code>Trainer</code> now. Here we perform a validation check during training and use a validation criterion that checks whether the validation loss in the current iteration has decreased compared to the lowest validation loss from all previous iterations. For demonstration, the train and the validation data are kept the same here. However, it is beneficial and encouraged to keep them distinct in practice to understand model's generalization capabilities.</p> <pre><code>from pathlib import Path\nimport torch\nfrom functools import reduce\nfrom operator import add\nfrom itertools import count\nimport matplotlib.pyplot as plt\n\nfrom qadence import Parameter, QuantumCircuit, Z\nfrom qadence import hamiltonian_factory, hea, feature_map, chain\nfrom qadence import QNN\nfrom qadence.ml_tools import  TrainConfig, Trainer, to_dataloader\n\nTrainer.set_use_grad(True)\n\nn_qubits = 4\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\n\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 100\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    x, y = data[0], data[1]\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ndef validation_criterion(\n    current_validation_loss: float, current_best_validation_loss: float, val_epsilon: float\n) -&gt; bool:\n    return current_validation_loss &lt;= current_best_validation_loss - val_epsilon\n\nn_epochs = 300\n\nconfig = TrainConfig(\n    max_iter=n_epochs,\n    batch_size=batch_size,\n    checkpoint_best_only=True,\n    val_every=10,  # The model will be run on the validation data after every `val_every` epochs.\n    validation_criterion=validation_criterion\n)\n\nfn = lambda x, degree: .05 * reduce(add, (torch.cos(i*x) + torch.sin(i*x) for i in range(degree)), 0.)\nx = torch.linspace(0, 10, batch_size).reshape(-1, 1)\ny = fn(x, 5)\n\ntrain_dataloader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\nval_dataloader =  to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\ntrainer = Trainer(model, optimizer, config, loss_fn=loss_fn,\n                    train_dataloader=train_dataloader, val_dataloader=val_dataloader)\ntrainer.fit()\n\nplt.clf()\nplt.plot(x.numpy(), y.numpy(), label='truth')\nplt.plot(x.numpy(), model(x).detach().numpy(), \"--\", label=\"final\", linewidth=3)\nplt.legend()\n</code></pre> 2025-05-12T10:19:10.310802 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"tutorials/qml/ml_tools/trainer/#63-fitting-a-function-low-level-api","title":"6.3. Fitting a function - Low-level API","text":"<p>For users who want to use the low-level API of <code>qadence</code>, here an example written without <code>Trainer</code>.</p> <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence import QNN\nfrom qadence.ml_tools import TrainConfig\n\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\n\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nn_epochs=50\ncnt = count()\n\ntmp_path = Path(\"/tmp\")\n\nconfig = TrainConfig(\n    root_folder=tmp_path,\n    max_iter=n_epochs,\n    checkpoint_every=100,\n    write_every=100,\n    batch_size=batch_size,\n)\n\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\n\nfor i in range(n_epochs):\n    out = model(x)\n    loss = criterion(out, y)\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#64-performing-pre-training-exploratory-landscape-analysis-ela-with-information-content-ic","title":"6.4. Performing pre-training Exploratory Landscape Analysis (ELA) with Information Content (IC)","text":"<p>Before one embarks on training a model, one may wish to analyze the loss landscape to judge the trainability and catch vanishing gradient issues early. One way of doing this is made possible via calculating the Information Content of the loss landscape. This is done by discretizing the gradient in the loss landscapes and then calculating the information content therein. This serves as a measure of flatness or ruggedness of the loss landscape. Quantitatively, the information content allows us to get bounds on the average norm of the gradient in the loss landscape.</p> <p>Using the information content technique, we can get two types of bounds on the average of the norm of the gradient. 1. The bounds as achieved in the maximum Information Content regime: Gives us a lower and upper bound on the average norm of the gradient in case high Information Content is achieved. 2. The bounds as achieved in the sensitivity regime: Gives us an upper bound on the average norm of the gradient corresponding to the sensitivity IC achieved.</p> <p>Thus, we get 3 bounds. The upper and lower bounds for the maximum IC and the upper bound for the sensitivity IC.</p> <p>The <code>Trainer</code> class provides a method to calculate these gradient norms.</p> <pre><code>import torch\nfrom torch.optim.adam import Adam\n\nfrom qadence.constructors import ObservableConfig\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig, TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\nfrom qadence.ml_tools.models import QNN\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools.trainer import Trainer\nfrom qadence.operations.primitive import Z\n\nfm_config = FeatureMapConfig(num_features=1)\nansatz_config = AnsatzConfig(depth=4)\nobs_config = ObservableConfig(detuning=Z)\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=obs_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n)\n\noptimizer = Adam(qnn.parameters(), lr=0.001)\n\nbatch_size = 25\nx = torch.linspace(0, 1, 32).reshape(-1, 1)\ny = torch.sin(x)\ntrain_loader = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n\ntrain_config = TrainConfig(max_iter=100)\n\ntrainer = Trainer(\n    model=qnn,\n    optimizer=optimizer,\n    config=train_config,\n    loss_fn=\"mse\",\n    train_dataloader=train_loader,\n    optimize_step=optimize_step,\n)\n\n# Perform exploratory landscape analysis with Information Content\nic_sensitivity_threshold = 1e-4\nepsilons = torch.logspace(-2, 2, 10)\n\nmax_ic_lower_bound, max_ic_upper_bound, sensitivity_ic_upper_bound = (\n    trainer.get_ic_grad_bounds(\n        eta=ic_sensitivity_threshold,\n        epsilons=epsilons,\n    )\n)\n\nprint(\n    f\"Using maximum IC, the gradients are bound between {max_ic_lower_bound:.3f} and {max_ic_upper_bound:.3f}\\n\"\n)\nprint(\n    f\"Using sensitivity IC, the gradients are bounded above by {sensitivity_ic_upper_bound:.3f}\"\n)\n\n# Resume training as usual...\n\ntrainer.fit(train_loader)\n</code></pre>   Using maximum IC, the gradients are bound between 0.066 and 0.391  Using sensitivity IC, the gradients are bounded above by 0.421    <p>The <code>get_ic_grad_bounds</code> function returns a tuple containing a tuple containing the lower bound as achieved in maximum IC case, upper bound as achieved in maximum IC case, and the upper bound for the sensitivity IC case.</p> <p>The sensitivity IC bound is guaranteed to appear, while the usually much tighter bounds that we get via the maximum IC case is only meaningful in the case of the maximum achieved information content \\(H(\\epsilon)_{max} \\geq log_6(2)\\).</p>"},{"location":"tutorials/qml/ml_tools/trainer/#65-custom-train-loop","title":"6.5. Custom <code>train</code> loop","text":"<p>If you need custom training functionality that goes beyond what is available in <code>qadence.ml_tools.Trainer</code> you can write your own training loop based on the building blocks that are available in Qadence.</p> <p>A simplified version of Qadence's train loop is defined below. Feel free to copy it and modify at will.</p> <p>For logging we can use the <code>get_writer</code> from the <code>Writer Registry</code>. This will set up the default writer based on the experiment tracking tool. All writers from the <code>Writer Registry</code> offer <code>open</code>, <code>close</code>, <code>print_metrics</code>, <code>write_metrics</code>, <code>plot_metrics</code>, etc methods.</p> <pre><code>from typing import Callable, Union\n\nfrom torch.nn import Module\nfrom torch.optim import Optimizer\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom qadence.ml_tools.config import TrainConfig\nfrom qadence.ml_tools.data import DictDataLoader, data_to_device\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools.callbacks import get_writer\nfrom qadence.ml_tools.callbacks.saveload import load_checkpoint, write_checkpoint\n\n\ndef train(\n    model: Module,\n    data: DataLoader,\n    optimizer: Optimizer,\n    config: TrainConfig,\n    loss_fn: Callable,\n    device: str = \"cpu\",\n    optimize_step: Callable = optimize_step,\n    write_tensorboard: Callable = write_tensorboard,\n) -&gt; tuple[Module, Optimizer]:\n\n    # Move model to device before optimizer is loaded\n    model = model.to(device)\n\n    # load available checkpoint\n    init_iter = 0\n    if config.log_folder:\n        model, optimizer, init_iter = load_checkpoint(config.log_folder, model, optimizer)\n\n    # Initialize writer based on the tracking tool specified in the configuration\n    writer = get_writer(config.tracking_tool)  # Uses ExperimentTrackingTool to select writer\n    writer.open(config, iteration=init_iter)\n\n    dl_iter = iter(dataloader)\n\n    # outer epoch loop\n    for iteration in range(init_iter, init_iter + config.max_iter):\n        data = data_to_device(next(dl_iter), device)\n        loss, metrics = optimize_step(model, optimizer, loss_fn, data)\n\n        if iteration % config.print_every == 0 and config.verbose:\n            writer.print_metrics(OptimizeResult(iteration, model, optimizer, loss, metrics))\n\n        if iteration % config.write_every == 0:\n            writer.write(iteration, metrics)\n\n        if config.log_folder:\n            if iteration % config.checkpoint_every == 0:\n                write_checkpoint(config.log_folder, model, optimizer, iteration)\n\n    # Final writing and checkpointing\n    if config.log_folder:\n        write_checkpoint(config.log_folder, model, optimizer, iteration)\n    writer.write(iteration,metrics)\n    writer.close()\n\n    return model, optimizer\n</code></pre>"},{"location":"tutorials/qml/ml_tools/trainer/#66-gradient-free-optimization-using-trainer","title":"6.6. Gradient-free optimization using <code>Trainer</code>","text":"<p>We can achieve gradient free optimization with <code>Trainer.set_use_grad(False)</code> or <code>trainer.disable_grad_opt(ng_optimizer)</code>. An example solving a QUBO using gradient free optimization based on <code>Nevergrad</code> optimizers and <code>Trainer</code> is shown in the analog QUBO Tutorial.</p>"},{"location":"tutorials/realistic_sims/","title":"Realistic simulations","text":"<p>This section describes how to perform realistic simulations in Qadence.</p>"},{"location":"tutorials/realistic_sims/measurements/","title":"Measurement protocols","text":"<p>Sample-based measurement protocols are fundamental tools for the prediction and estimation of a quantum state as the result of NISQ programs executions. Their resource efficient implementation is a current and active research field. Qadence offers two main measurement protocols: quantum state tomography and classical shadows.</p>"},{"location":"tutorials/realistic_sims/measurements/#quantum-state-tomography","title":"Quantum state tomography","text":"<p>The fundamental task of quantum state tomography is to learn an approximate classical description of an output quantum state described by a density matrix \\(\\rho\\), from repeated measurements of copies on a chosen basis. To do so, \\(\\rho\\) is expanded in a basis of observables (the tomography step) and for a given observable \\(\\hat{\\mathcal{O}}\\), the expectation value is calculated with \\(\\langle \\hat{\\mathcal{O}} \\rangle=\\textrm{Tr}(\\hat{\\mathcal{O}}\\rho)\\). A number of measurement repetitions in a suitable basis is then required to estimate \\(\\langle \\hat{\\mathcal{O}} \\rangle\\).</p> <p>The main drawback is the scaling in measurements for the retrieval of the classical expression for a \\(n\\)-qubit quantum state as \\(2^n \\times 2^n\\), together with a large amount of classical post-processing.</p> <p>For an observable expressed as a Pauli string \\(\\hat{\\mathcal{P}}\\), the expectation value for a state \\(|\\psi \\rangle\\) can be derived as:</p> \\[ \\langle \\hat{\\mathcal{P}} \\rangle=\\langle \\psi | \\hat{\\mathcal{P}} |\\psi \\rangle=\\langle \\psi | \\hat{\\mathcal{R}}^\\dagger \\hat{\\mathcal{D}} \\hat{\\mathcal{R}} |\\psi \\rangle \\] <p>The operator \\(\\hat{\\mathcal{R}}\\) diagonalizes \\(\\hat{\\mathcal{P}}\\) and rotates the state into an eigenstate in the computational basis. Therefore, \\(\\hat{\\mathcal{R}}|\\psi \\rangle=\\sum\\limits_{z}a_z|z\\rangle\\) and the expectation value can finally be expressed as:</p> \\[ \\langle \\hat{\\mathcal{P}} \\rangle=\\sum_{z,z'}\\langle z |\\bar{a}_z\\hat{\\mathcal{D}}a_{z'}|z'\\rangle = \\sum_{z}|a_z|^2(-1)^{\\phi_z(\\hat{\\mathcal{P}})} \\] <p>In Qadence, running a tomographical experiment is made simple by defining a <code>Measurements</code> object that captures all options for execution:</p> <pre><code>from torch import tensor\nfrom qadence import hamiltonian_factory, BackendName, DiffMode\nfrom qadence import Parameter, chain, kron, RX, RY, Z, QuantumCircuit, QuantumModel\nfrom qadence.measurements import Measurements\n\n# Define parameters for a circuit.\ntheta1 = Parameter(\"theta1\", trainable=False)\ntheta2 = Parameter(\"theta2\", trainable=False)\ntheta3 = Parameter(\"theta3\", trainable=False)\ntheta4 = Parameter(\"theta4\", trainable=False)\n\nblocks = chain(\n    kron(RX(0, theta1), RY(1, theta2)),\n    kron(RX(0, theta3), RY(1, theta4)),\n)\n\nvalues = {\n    \"theta1\": tensor([0.5]),\n    \"theta2\": tensor([1.5]),\n    \"theta3\": tensor([2.0]),\n    \"theta4\": tensor([2.5]),\n}\n\n# Create a circuit and an observable.\ncircuit = QuantumCircuit(2, blocks)\nobservable = hamiltonian_factory(2, detuning=Z)\n\n# Create a model.\nmodel = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.GPSR,\n)\n\n# Define a measurement protocol by passing the shot budget as an option.\ntomo_options = {\"n_shots\": 100000}\ntomo_measurement = Measurements(protocol=Measurements.TOMOGRAPHY, options=tomo_options)\n\n# Get the exact expectation value.\nexact_values = model.expectation(\n    values=values,\n)\n\n# Run the tomography experiment.\nestimated_values_tomo = model.expectation(\n    values=values,\n    measurement=tomo_measurement,\n)\n</code></pre> <pre><code>Exact expectation value = tensor([[-1.4548]])\nEstimated expectation value tomo = tensor([[-1.4591]])\n</code></pre>"},{"location":"tutorials/realistic_sims/measurements/#classical-shadows","title":"Classical shadows","text":"<p>Recently, a much less resource demanding protocol based on classical shadows has been proposed<sup>1</sup>. It combines ideas from shadow tomography<sup>2</sup> and randomized measurement protocols capable of learning a classical shadow of an unknown quantum state \\(\\rho\\). It relies on deliberately discarding the full classical characterization of the quantum state, and instead focuses on accurately predicting a restricted set of properties that provide efficient protocols for the study of the system.</p> <p>A random measurement consists of applying random unitary rotations before a fixed measurement on each copy of a state. Appropriately averaging over these measurements produces an efficient estimator for the expectation value of an observable. This protocol therefore creates a robust classical representation of the quantum state or classical shadow. The captured measurement information is then reuseable for multiple purposes, i.e. any observable expected value and available for noise mitigation postprocessing.</p> <p>A classical shadow is therefore an unbiased estimator of a quantum state \\(\\rho\\). Such an estimator is obtained with the following procedure<sup>1</sup>: first, apply a random unitary gate \\(U\\) to rotate the state: \\(\\rho \\rightarrow U \\rho U^\\dagger\\) and then perform a basis measurement to obtain a \\(n\\)-bit measurement \\(|\\hat{b}\\rangle \\in \\{0, 1\\}^n\\). Both unitary gates \\(U\\) and the measurement outcomes \\(|\\hat{b}\\rangle\\) are stored on a classical computer for postprocessing v \\(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U\\), a classical snapshot of the state \\(\\rho\\). The whole procedure can be seen as a quantum channel \\(\\mathcal{M}\\) that maps the initial unknown quantum state \\(\\rho\\) to the average result of the measurement protocol:</p> \\[ \\mathbb{E}[U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U] = \\mathcal{M}(\\rho) \\Rightarrow \\rho = \\mathbb{E}[\\mathcal{M}^{-1}(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U)] \\] <p>It is worth noting that the single classical snapshot \\(\\hat{\\rho}=\\mathcal{M}^{-1}(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U)\\) equals \\(\\rho\\) in expectation: \\(\\mathbb{E}[\\hat{\\rho}]=\\rho\\) despite \\(\\mathcal{M}^{-1}\\) not being a completely positive map. Repeating this procedure \\(N\\) times results in an array of \\(N\\) independent, classical snapshots of \\(\\rho\\) called the classical shadow:</p> \\[ S(\\rho, N) = \\{ \\hat{\\rho}_1=\\mathcal{M}^{-1}(U_1^\\dagger |\\hat{b}_1\\rangle\\langle \\hat{b}_1|U_1),\\cdots,\\hat{\\rho}_N=\\mathcal{M}^{-1}(U_N^\\dagger |\\hat{b}_N\\rangle\\langle \\hat{b}_N|U_N)\\} \\] <p>Along the same lines as the example before, estimating the expectation value using classical shadows in Qadence only requires to pass the right set of parameters to the <code>Measurements</code> object:</p> <pre><code># Classical shadows are defined up to some accuracy and confidence.\nshadow_options = {\"accuracy\": 0.1, \"confidence\": 0.1}  # Shadow size N=54400.\nshadow_measurement = Measurements(protocol=Measurements.SHADOW, options=shadow_options)\n\n# Run the experiment with classical shadows.\nestimated_values_shadow = model.expectation(\n    values=values,\n    measurement=shadow_measurement,\n)\n</code></pre> <pre><code>Estimated expectation value shadow = tensor([[-1.4935]])\n</code></pre>"},{"location":"tutorials/realistic_sims/measurements/#references","title":"References","text":"<ol> <li> <p>Hsin-Yuan Huang, Richard Kueng and John Preskill, Predicting Many Properties of a Quantum System from Very Few Measurements (2020) \u21a9\u21a9</p> </li> <li> <p>S. Aaronson. Shadow tomography of quantum states. In Proceedings of the 50th Annual A ACM SIGACT Symposium on Theory of Computing, STOC 2018, pages 325\u2013338, New York, NY, USA, 2018. ACM\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/realistic_sims/mitigation/","title":"Error mitigation","text":"<p>Beyond running noisy simulations, Qadence offers a number of noise mitigation techniques to achieve better accuracy of simulation outputs. Currently, mitigation addresses readout errors and depolarizing and dephasing noise for analog blocks.</p>"},{"location":"tutorials/realistic_sims/mitigation/#readout-error-mitigation","title":"Readout error mitigation","text":"<p>The complete implementation of the mitigation technique is to measure \\(T\\) and classically apply \\(T^{\u22121}\\) to measured probability distributions. However there are several limitations of this approach:</p> <ul> <li>The complete implementation requires \\(2^n\\) characterization experiments (probability measurements), which is not scalable. The classical processing of the calibration data is also inefficient.</li> <li>The matrix \\(T\\) may become singular for large \\(n\\), preventing direct inversion.</li> <li>The inverse \\(T^{\u22121}\\) might not be a stochastic matrix, meaning that it can produce negative corrected probabilities.</li> <li>The correction is not rigorously justified, so we cannot be sure that we are only removing SPAM errors and not otherwise corrupting an estimated probability distribution.</li> </ul> <p>Qadence relies on the assumption of uncorrelated readout errors:</p> \\[ T=T_1\\otimes T_2\\otimes \\dots \\otimes T_n \\] <p>for which the inversion is straightforward:</p> \\[ T^{-1}=T_1^{-1}\\otimes T_2^{-1}\\otimes \\dots \\otimes T_n^{-1} \\] <p>However, even for a reduced \\(n\\) the third limitation holds. This can be avoided by reformulating into a minimization problem<sup>1</sup>:</p> \\[ \\lVert Tp_{\\textrm{corr}}-p_{\\textrm{raw}}\\rVert_{2}^{2} \\] <p>subjected to physicality constraints \\(0 \\leq p_{corr}(x) \\leq 1\\) and \\(\\lVert p_{corr} \\rVert = 1\\). At this point, two methods are implemented to solve this problem. The first one relies on solving using standard optimization tools, the second on Maximum-Likelihood Estimation<sup>2</sup>. In Qadence, this can be user defined using the mitigation protocol:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\nfrom qadence.noise import NoiseHandler\nfrom qadence.mitigations import Mitigations\nfrom qadence.types import ReadOutOptimization, NoiseProtocol\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use:\nnoise = NoiseHandler(NoiseProtocol.READOUT.INDEPENDENT)\n# Define the mitigation method solving the minimization problem:\noptions={\"optimization_type\": ReadOutOptimization.CONSTRAINED}  # ReadOutOptimization.MLE for the alternative method.\nmitigation = Mitigations(protocol=Mitigations.READOUT, options=options)\n\n# Run noiseless, noisy and mitigated simulations.\nn_shots = 100\nnoiseless_samples = model.sample(n_shots=n_shots)\nnoisy_samples = model.sample(noise=noise, n_shots=n_shots)\nmitigated_samples = model.sample(\n    noise=noise, mitigation=mitigation, n_shots=n_shots\n)\n\nprint(f\"noiseless {noiseless_samples}\")\nprint(f\"noisy {noisy_samples}\")\nprint(f\"mitigated {mitigated_samples}\")\n</code></pre> <pre><code>noiseless [OrderedCounter({'00': 56, '10': 44})]\nnoisy [OrderedCounter({'10': 53, '00': 45, '01': 1, '11': 1})]\nmitigated [Counter({'11': 61, '10': 31, '01': 8})]\n</code></pre>"},{"location":"tutorials/realistic_sims/mitigation/#wip-zero-noise-extrapolation-for-analog-blocks","title":"[WIP] Zero-noise extrapolation for analog blocks","text":"<p>Zero-noise extrapolation (ZNE) is an error mitigation technique in which an expectation value is computed at different noise levels and, as a second step, the ideal expectation value is inferred by extrapolating the measured results to the zero-noise limit. In digital computing, this is typically implemented by \"folding\" the circuit and its dagger to artificially increase the noise through sequences of identities<sup>3</sup>. In the analog ZNE variation, analog blocks are time stretched to again artificially increase noise<sup>3</sup>.</p>"},{"location":"tutorials/realistic_sims/mitigation/#references","title":"References","text":"<ol> <li> <p>Michael R. Geller and Mingyu Sun, Efficient correction of multiqubit measurement errors, (2020) \u21a9</p> </li> <li> <p>Smolin et al., Maximum Likelihood, Minimum Effort, (2011) \u21a9</p> </li> <li> <p>Mitiq: What's the theory behind ZNE? \u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/realistic_sims/noise/","title":"Simulated errors","text":"<p>Running programs on NISQ devices often leads to partially useful results due to the presence of noise. In order to perform realistic simulations, a number of noise models (for digital operations, analog operations and simulated readout errors) are supported in Qadence through their implementation in backends and corresponding error mitigation techniques whenever possible.</p>"},{"location":"tutorials/realistic_sims/noise/#noisehandler","title":"NoiseHandler","text":"<p>Noise models can be defined via the <code>NoiseHandler</code>. It is a container of several noise instances which require to specify a <code>protocols</code> and a dictionary of <code>options</code> (or lists). The <code>protocol</code> field is to be instantiated from <code>NoiseProtocol</code>.</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\n\nanalog_noise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options={\"noise_probs\": 0.1})\ndigital_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.DEPOLARIZING, options={\"error_probability\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\n</code></pre> <pre><code>\n</code></pre> <p>One can also define a <code>NoiseHandler</code> passing a list of protocols and a list of options (careful with the order):</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\n\nprotocols = [NoiseProtocol.DIGITAL.DEPOLARIZING, NoiseProtocol.READOUT]\noptions = [{\"error_probability\": 0.1}, {\"error_probability\": 0.1, \"seed\": 0}]\n\nnoise_combination = NoiseHandler(protocols, options)\nprint(noise_combination)\n</code></pre> <pre><code>Noise(Depolarizing, {'error_probability': 0.1})\nNoise(&lt;enum 'ReadoutNoise'&gt;, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>One can also append to a <code>NoiseHandler</code> other <code>NoiseHandler</code> instances:</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\n\ndepo_noise = NoiseHandler(protocol=NoiseProtocol.DIGITAL.DEPOLARIZING, options={\"error_probability\": 0.1})\nreadout_noise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options={\"error_probability\": 0.1, \"seed\": 0})\n\nnoise_combination = NoiseHandler(protocol=NoiseProtocol.DIGITAL.BITFLIP, options={\"error_probability\": 0.1})\nnoise_combination.append([depo_noise, readout_noise])\nprint(noise_combination)\n</code></pre> <pre><code>Noise(BitFlip, {'error_probability': 0.1})\nNoise(Depolarizing, {'error_probability': 0.1})\nNoise(Independent Readout, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>Finally, one can add directly a few pre-defined types using several <code>NoiseHandler</code> methods:</p> <pre><code>from qadence import NoiseHandler\nfrom qadence.types import NoiseProtocol\nnoise_combination = NoiseHandler(protocol=NoiseProtocol.DIGITAL.BITFLIP, options={\"error_probability\": 0.1})\nnoise_combination.digital_depolarizing({\"error_probability\": 0.1}).readout_independent({\"error_probability\": 0.1, \"seed\": 0})\nprint(noise_combination)\n</code></pre> <pre><code>Noise(BitFlip, {'error_probability': 0.1})\nNoise(Depolarizing, {'error_probability': 0.1})\nNoise(Independent Readout, {'error_probability': 0.1, 'seed': 0})\n</code></pre> <p>NoiseHandler scope</p> <p>Note it is not possible to define a <code>NoiseHandler</code> instances with both digital and analog noises, both readout and analog noises, several analog noises, several readout noises, or a readout noise that is not the last defined protocol within <code>NoiseHandler</code>.</p>"},{"location":"tutorials/realistic_sims/noise/#readout-errors","title":"Readout errors","text":"<p>State Preparation and Measurement (SPAM) in the hardware is a major source of noise in the execution of quantum programs. They are typically described using confusion matrices of the form:</p> \\[ T(x|x')=\\delta_{xx'} \\] <p>Two types of readout protocols are available:</p> <ul> <li><code>NoiseProtocol.READOUT.INDEPENDENT</code> where each bit can be corrupted independently of each other.</li> <li><code>NoiseProtocol.READOUT.CORRELATED</code> where we can define of confusion matrix of corruption between each possible bitstrings.</li> </ul> <p>Qadence offers to simulate readout errors with the <code>NoiseHandler</code> to corrupt the output samples of a simulation, through execution via a <code>QuantumModel</code>:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use.\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT)\n\n# Run noiseless and noisy simulations.\nnoiseless_samples = model.sample(n_shots=100)\nnoisy_samples = model.sample(noise=noise, n_shots=100)\n</code></pre> <pre><code>noiseless = [OrderedCounter({'10': 53, '00': 47})]\nnoisy = [OrderedCounter({'10': 56, '00': 39, '11': 3, '01': 2})]\n</code></pre> <p>It is possible to pass options to the noise model. In the previous example, a noise matrix is implicitly computed from a uniform distribution.</p> <p>For <code>NoiseProtocol.READOUT.INDEPENDENT</code>, the <code>option</code> dictionary argument accepts the following options:</p> <ul> <li><code>seed</code>: defaulted to <code>None</code>, for reproducibility purposes</li> <li><code>error_probability</code>: If float, the same probability is applied to every bit. By default, this is 0.1.     If a 1D tensor with the number of elements equal to the number of qubits, a different probability can be set for each qubit. If a tensor of shape (n_qubits, 2, 2) is passed, that is a confusion matrix obtained from experiments, we extract the error_probability.     and do not compute internally the confusion matrix as in the other cases.</li> <li><code>noise_distribution</code>: defaulted to <code>WhiteNoise.UNIFORM</code>, for non-uniform noise distributions</li> </ul> <p>For <code>NoiseProtocol.READOUT.CORRELATED</code>, the <code>option</code> dictionary argument accepts the following options:</p> <ul> <li><code>confusion_matrix</code>: The square matrix representing \\(T(x|x')\\) for each possible bitstring of length <code>n</code> qubits. Should be of size (\\(2^n, 2^n\\)).</li> <li><code>seed</code>: defaulted to <code>None</code>, for reproducibility purposes</li> </ul> <p>Noisy simulations go hand-in-hand with measurement protocols discussed in the measurements section, to assess the impact of noise on expectation values. In this case, both measurement and noise protocols have to be defined appropriately. Please note that a noise protocol without a measurement protocol will be ignored for expectation values computations.</p> <pre><code>from qadence.measurements import Measurements\n\n# Define a noise model with options.\noptions = {\"error_probability\": 0.01}\nnoise = NoiseHandler(protocol=NoiseProtocol.READOUT.INDEPENDENT, options=options)\n\n# Define a tomographical measurement protocol with options.\noptions = {\"n_shots\": 10000}\nmeasurement = Measurements(protocol=Measurements.TOMOGRAPHY, options=options)\n\n# Run noiseless and noisy simulations.\nnoiseless_exp = model.expectation(measurement=measurement)\nnoisy_exp = model.expectation(measurement=measurement, noise=noise)\n</code></pre> <pre><code>noiseless = tensor([[1.0024]], grad_fn=&lt;TransposeBackward0&gt;)\nnoisy = tensor([[0.9872]], grad_fn=&lt;TransposeBackward0&gt;)\n</code></pre>"},{"location":"tutorials/realistic_sims/noise/#analog-noisy-simulation","title":"Analog noisy simulation","text":"<p>At the moment, analog noisy simulations are only compatible with the Pulser backend. <pre><code>from qadence import DiffMode, NoiseHandler, QuantumModel\nfrom qadence.blocks import chain, kron\nfrom qadence.circuit import QuantumCircuit\nfrom qadence.operations import AnalogRX, AnalogRZ, Z\nfrom qadence.types import PI, BackendName, NoiseProtocol\n\n\nanalog_block = chain(AnalogRX(PI / 2.0), AnalogRZ(PI))\nobservable = Z(0) + Z(1)\ncircuit = QuantumCircuit(2, analog_block)\n\noptions = {\"noise_probs\": 0.1}\nnoise = NoiseHandler(protocol=NoiseProtocol.ANALOG.DEPOLARIZING, options=options)\nmodel_noisy = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR,\n    noise=noise,\n)\nnoisy_expectation = model_noisy.expectation()\n</code></pre> <pre><code>noisy = tensor([[0.3597]])\n</code></pre> </p>"},{"location":"tutorials/realistic_sims/noise/#digital-noisy-simulation","title":"Digital noisy simulation","text":"<p>When dealing with programs involving only digital operations, several options are made available from PyQTorch via the <code>NoiseProtocol.DIGITAL</code>. One can define noisy digital operations as follows:</p> <pre><code>from qadence import NoiseProtocol, RX, run\nimport torch\n\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.2})\nop = RX(0, torch.pi, noise = noise)\n\nprint(run(op))\n</code></pre> <pre><code>DensityMatrix([[[0.2000+0.0000e+00j, 0.0000+3.6739e-17j],\n                [0.0000-3.6739e-17j, 0.8000+0.0000e+00j]]])\n</code></pre> <p>It is also possible to set a noise configuration to all gates within a block or circuit as follows:</p> <pre><code>from qadence import set_noise, chain\n\nn_qubits = 2\n\nblock = chain(RX(i, f\"theta_{i}\") for i in range(n_qubits))\n\nnoise = NoiseHandler(NoiseProtocol.DIGITAL.BITFLIP, {\"error_probability\": 0.1})\n\n# The function changes the block in place:\nset_noise(block, noise)\nprint(run(block))\n</code></pre> <pre><code>DensityMatrix([[[ 0.6571+0.0000j,  0.0000+0.0096j,  0.0000+0.2943j,\n                 -0.0043+0.0000j],\n                [ 0.0000-0.0096j,  0.0732+0.0000j,  0.0043+0.0000j,\n                  0.0000+0.0328j],\n                [ 0.0000-0.2943j,  0.0043+0.0000j,  0.2427+0.0000j,\n                  0.0000+0.0035j],\n                [-0.0043+0.0000j,  0.0000-0.0328j,  0.0000-0.0035j,\n                  0.0270+0.0000j]]])\n</code></pre> <p>There is an extra optional argument to specify the type of block we want to apply a noise configuration to. E.g., let's say we want to apply noise only to <code>X</code> gates, a <code>target_class</code> argument can be passed with the corresponding block:</p> <pre><code>from qadence import X\nblock = chain(RX(0, \"theta\"), X(0))\nset_noise(block, noise, target_class = X)\n\nfor block in block.blocks:\n    print(block.noise)\n</code></pre> <pre><code>None\nNoise(BitFlip, {'error_probability': 0.1})\n</code></pre>"}]}