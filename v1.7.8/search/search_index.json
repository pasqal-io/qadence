{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api/blocks/","title":"Block system","text":"<p><code>qadence</code> offers a block-based system to construct quantum circuits in a flexible manner.</p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock","title":"<code>AbstractBlock(tag=None, __array_priority__=1000)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for both primitive and composite blocks.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>A human-readable name attached to the block type. Notice, this is the same for all the class instances so it cannot be used for identifying different blocks</p> <p> TYPE: <code>str</code> </p> <code>qubit_support</code> <p>The qubit support of the block expressed as a tuple of integers</p> <p> TYPE: <code>tuple[int, ...]</code> </p> <code>tag</code> <p>A tag identifying a particular instance of the block which can be used for identification and pretty printing</p> <p> TYPE: <code>str | None</code> </p> <code>eigenvalues</code> <p>The eigenvalues of the matrix representing the block. This is used mainly for primitive blocks and it's needed for generalized parameter shift rule computations. Currently unused.</p> <p> TYPE: <code>list[float] | None</code> </p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.is_identity","title":"<code>is_identity: bool</code>  <code>property</code>","text":"<p>Identity predicate for blocks.</p>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.n_qubits","title":"<code>n_qubits()</code>","text":"<p>The number of qubits in the whole system.</p> <p>A block acting on qubit N would has at least n_qubits &gt;= N + 1.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_qubits(self) -&gt; int:\n    \"\"\"The number of qubits in the whole system.\n\n    A block acting on qubit N would has at least n_qubits &gt;= N + 1.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.n_supports","title":"<code>n_supports()</code>","text":"<p>The number of qubits the block is acting on.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_supports(self) -&gt; int:\n    \"\"\"The number of qubits the block is acting on.\"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.abstract.AbstractBlock.qubit_support","title":"<code>qubit_support()</code>","text":"<p>The indices of the qubit(s) the block is acting on.</p> <p>Qadence uses the ordering [0..,N-1] for qubits.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef qubit_support(self) -&gt; Tuple[int, ...]:\n    \"\"\"The indices of the qubit(s) the block is acting on.\n\n    Qadence uses the ordering [0..,N-1] for qubits.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#primitive-blocks","title":"Primitive blocks","text":""},{"location":"api/blocks/#qadence.blocks.primitive.ControlBlock","title":"<code>ControlBlock(control, target_block)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The abstract ControlBlock.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: PrimitiveBlock) -&gt; None:\n    self.control = control\n    self.blocks = (target_block,)\n    self.target = target_block.qubit_support\n\n    # using tuple expansion because some control operations could\n    # have multiple targets, e.g. CSWAP\n    super().__init__((*control, *self.target))  # target_block.qubit_support[0]))\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricBlock","title":"<code>ParametricBlock(qubit_support)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>Parameterized primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\n    self._qubit_support = qubit_support\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricBlock.num_parameters","title":"<code>num_parameters()</code>  <code>abstractmethod</code>","text":"<p>The number of parameters required by the block.</p> <p>This is a class property since the number of parameters is defined automatically before instantiating the operation. Also, this could correspond to a larger number of actual user-facing parameters since any parameter expression is allowed</p> <p>Examples: - RX operation has 1 parameter - U operation has 3 parameters - HamEvo has 2 parameters (generator and time evolution)</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>@abstractmethod\ndef num_parameters(cls) -&gt; int:\n    \"\"\"The number of parameters required by the block.\n\n    This is a class property since the number of parameters is defined\n    automatically before instantiating the operation. Also, this could\n    correspond to a larger number of actual user-facing parameters\n    since any parameter expression is allowed\n\n    Examples:\n    - RX operation has 1 parameter\n    - U operation has 3 parameters\n    - HamEvo has 2 parameters (generator and time evolution)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ParametricControlBlock","title":"<code>ParametricControlBlock(control, target_block)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The abstract parametrized ControlBlock.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: ParametricBlock) -&gt; None:\n    self.blocks = (target_block,)\n    self.control = control\n    self.parameters = target_block.parameters\n    super().__init__((*control, *target_block.qubit_support))\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.PrimitiveBlock","title":"<code>PrimitiveBlock(qubit_support)</code>","text":"<p>               Bases: <code>AbstractBlock</code></p> <p>Primitive blocks represent elementary unitary operations.</p> <p>Examples are single/multi-qubit gates or Hamiltonian evolution. See <code>qadence.operations</code> for a full list of primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\n    self._qubit_support = qubit_support\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.PrimitiveBlock.digital_decomposition","title":"<code>digital_decomposition()</code>","text":"<p>Decomposition into purely digital gates.</p> <p>This method returns a decomposition of the Block in a combination of purely digital single-qubit and two-qubit 'gates', by manual/custom knowledge of how this can be done efficiently. :return:</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def digital_decomposition(self) -&gt; AbstractBlock:\n    \"\"\"Decomposition into purely digital gates.\n\n    This method returns a decomposition of the Block in a\n    combination of purely digital single-qubit and two-qubit\n    'gates', by manual/custom knowledge of how this can be done efficiently.\n    :return:\n    \"\"\"\n    return self\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ProjectorBlock","title":"<code>ProjectorBlock(ket, bra, qubit_support)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The abstract ProjectorBlock.</p> <p>Arguments:</p> <pre><code>ket (str): The ket given as a bitstring.\nbra (str): The bra given as a bitstring.\nqubit_support (int | tuple[int]): The qubit_support of the block.\n</code></pre> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(\n    self,\n    ket: str,\n    bra: str,\n    qubit_support: int | tuple[int, ...],\n) -&gt; None:\n    \"\"\"\n    Arguments:\n\n        ket (str): The ket given as a bitstring.\n        bra (str): The bra given as a bitstring.\n        qubit_support (int | tuple[int]): The qubit_support of the block.\n    \"\"\"\n    if isinstance(qubit_support, int):\n        qubit_support = (qubit_support,)\n    if len(bra) != len(ket):\n        raise ValueError(\n            \"Bra and ket must be bitstrings of same length in the 'Projector' definition.\"\n        )\n    elif len(bra) != len(qubit_support):\n        raise ValueError(\"Bra or ket must be of same length as the 'qubit_support'\")\n    for wf in [bra, ket]:\n        if not all(int(item) == 0 or int(item) == 1 for item in wf):\n            raise ValueError(\n                \"All qubits must be either in the '0' or '1' state\"\n                \" in the 'ProjectorBlock' definition.\"\n            )\n\n    self.ket = ket\n    self.bra = bra\n    super().__init__(qubit_support)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.ScaleBlock","title":"<code>ScaleBlock(block, parameter)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>Scale blocks are created when multiplying a block by a number or parameter.</p> <p>Example: <pre><code>from qadence import X\n\nprint(X(0) * 2)\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 X(0)\n</code></pre> </p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, block: AbstractBlock, parameter: Any):\n    self.block = block\n    # TODO: more meaningful name like `scale`?\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    super().__init__(block.qubit_support)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.primitive.TimeEvolutionBlock","title":"<code>TimeEvolutionBlock(qubit_support)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>Simple time evolution block with time-independent Hamiltonian.</p> <p>This class is just a convenience class which is used to label blocks which contains simple time evolution with time-independent Hamiltonian operators</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\n    self._qubit_support = qubit_support\n</code></pre>"},{"location":"api/blocks/#analog-blocks","title":"Analog blocks","text":"<p>To learn how to use analog blocks and how to mix digital &amp; analog blocks, check out the digital-analog section of the documentation.</p> <p>Examples on how to use digital-analog blocks can be found in the *examples folder of the qadence repo:</p> <ul> <li>Fit a simple sinus: <code>examples/digital-analog/fit-sin.py</code></li> <li>Solve a QUBO: <code>examples/digital-analog/qubo.py</code></li> </ul>"},{"location":"api/blocks/#qadence.blocks.analog.AnalogChain","title":"<code>AnalogChain(blocks)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogComposite</code></p> <p>A chain of analog blocks.</p> <p>Needed because analog blocks require stricter validation than the general <code>ChainBlock</code>.</p> <p><code>AnalogChain</code>s can only be constructed from <code>AnalogKron</code> blocks or globally supported, primitive, analog blocks (like <code>InteractionBlock</code>s and <code>ConstantAnalogRotation</code>s).</p> <p>Automatically constructed by the <code>chain</code> function if only analog blocks are given.</p> <p>Example: <pre><code>from qadence import X, chain, AnalogInteraction\n\nb = chain(AnalogInteraction(200), AnalogInteraction(200))\nprint(type(b))  # this is an `AnalogChain`\n\nb = chain(X(0), AnalogInteraction(200))\nprint(type(b))  # this is a general `ChainBlock`\n</code></pre> <pre><code>&lt;class 'qadence.blocks.analog.AnalogChain'&gt;\n&lt;class 'qadence.blocks.composite.ChainBlock'&gt;\n</code></pre> </p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...]):\n    \"\"\"A chain of analog blocks.\n\n    Needed because analog blocks require\n    stricter validation than the general `ChainBlock`.\n\n    `AnalogChain`s can only be constructed from `AnalogKron` blocks or\n    _**globally supported**_, primitive, analog blocks (like `InteractionBlock`s and\n    `ConstantAnalogRotation`s).\n\n    Automatically constructed by the [`chain`][qadence.blocks.utils.chain]\n    function if only analog blocks are given.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, chain, AnalogInteraction\n\n    b = chain(AnalogInteraction(200), AnalogInteraction(200))\n    print(type(b))  # this is an `AnalogChain`\n\n    b = chain(X(0), AnalogInteraction(200))\n    print(type(b))  # this is a general `ChainBlock`\n    ```\n    \"\"\"\n    for b in blocks:\n        if not (isinstance(b, AnalogKron) or b.qubit_support.is_global):\n            raise ValueError(\"Only KronBlocks or global blocks can be chain'ed.\")\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.analog.AnalogKron","title":"<code>AnalogKron(blocks, interaction=Interaction.NN)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogComposite</code></p> <p>Stack analog blocks vertically (i.e. in time).</p> <p>Needed because analog require stricter validation than the general <code>KronBlock</code>.</p> <p><code>AnalogKron</code>s can only be constructed from non-global, analog blocks with the same duration.</p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...], interaction: Interaction = Interaction.NN):\n    \"\"\"Stack analog blocks vertically (i.e. in time).\n\n    Needed because analog require\n    stricter validation than the general `KronBlock`.\n\n    `AnalogKron`s can only be constructed from _**non-global**_, analog blocks\n    with the _**same duration**_.\n    \"\"\"\n    if len(blocks) == 0:\n        raise NotImplementedError(\"Empty KronBlocks not supported\")\n\n    self.blocks = blocks\n    self.interaction = interaction\n\n    qubit_support = QubitSupport()\n    duration = blocks[0].duration\n    for b in blocks:\n        if not isinstance(b, AnalogBlock):\n            raise ValueError(\"Can only kron `AnalgoBlock`s with other `AnalgoBlock`s.\")\n\n        if b.qubit_support == QubitSupport(\"global\"):\n            raise ValueError(\"Blocks with global support cannot be kron'ed.\")\n\n        if not qubit_support.is_disjoint(b.qubit_support):\n            raise ValueError(\"Make sure blocks act on distinct qubits!\")\n\n        if not np.isclose(evaluate(duration), evaluate(b.duration)):\n            raise ValueError(\"Kron'ed blocks have to have same duration.\")\n\n        qubit_support += b.qubit_support\n\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.analog.ConstantAnalogRotation","title":"<code>ConstantAnalogRotation(tag=None, __array_priority__=1000, _eigenvalues_generator=None, parameters=ParamMap(alpha=0.0, duration=1000.0, omega=0.0, delta=0.0, phase=0.0), qubit_support=QubitSupport('global'), add_pattern=True)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogBlock</code></p> <p>Implements a constant analog rotation with interaction dictated by the chosen Hamiltonian.</p> <pre><code>H/h = \u2211\u1d62(\u03a9/2 cos(\u03c6)*X\u1d62 - sin(\u03c6)*Y\u1d62 - \u03b4n\u1d62) + H\u1d62\u2099\u209c.\n</code></pre> <p>To construct this block you can use of the following convenience wrappers: - The general rotation operation <code>AnalogRot</code> - Shorthands for rotatins around an axis:   <code>AnalogRX</code>,   <code>AnalogRY</code>,   <code>AnalogRZ</code></p> <p>WARNING: do not use <code>ConstantAnalogRotation</code> with <code>alpha</code> as differentiable parameter - use the convenience wrappers mentioned above.</p>"},{"location":"api/blocks/#qadence.blocks.analog.InteractionBlock","title":"<code>InteractionBlock(tag=None, __array_priority__=1000, _eigenvalues_generator=None, parameters=ParamMap(duration=1000.0), qubit_support=QubitSupport('global'), add_pattern=True)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AnalogBlock</code></p> <p>Free-evolution for the Hamiltonian interaction term of a register of qubits.</p> <p>In real interacting quantum devices, it means letting the system evolve freely according to the time-dependent Schrodinger equation. With emulators, this block is translated to an appropriate interaction Hamiltonian, for example, an Ising interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n</code></pre> <p>or an XY-interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2083/r\u2c7c\u2c7c\u00b3 (X\u1d62X\u2c7c + Z\u1d62Z\u2c7c)\n</code></pre> <p>with <code>n\u1d62 = (1-Z\u1d62)/2</code>.</p> <p>To construct, use the <code>AnalogInteraction</code> function.</p>"},{"location":"api/blocks/#composite-blocks","title":"Composite blocks","text":""},{"location":"api/blocks/#qadence.blocks.utils.chain","title":"<code>chain(*args)</code>","text":"<p>Chain blocks sequentially.</p> <p>On digital backends this can be interpreted loosely as a matrix mutliplication of blocks. In the analog case it chains blocks in time.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to chain. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator, List[AbstractBlock]]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>ChainBlock</p> <p>Example: <pre><code>from qadence import X, Y, chain\n\nb = chain(X(0), Y(0))\n\n# or use a generator\nb = chain(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def chain(*args: Union[AbstractBlock, Generator, List[AbstractBlock]]) -&gt; ChainBlock:\n    \"\"\"Chain blocks sequentially.\n\n    On digital backends this can be interpreted\n    loosely as a matrix mutliplication of blocks. In the analog case it chains\n    blocks in time.\n\n    Arguments:\n        *args: Blocks to chain. Can also be a generator.\n\n    Returns:\n        ChainBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, chain\n\n    b = chain(X(0), Y(0))\n\n    # or use a generator\n    b = chain(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    # ugly hack to use `AnalogChain` if we are dealing only with analog blocks\n    if len(args) and all(\n        isinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n    ):\n        return analog_chain(*args)  # type: ignore[return-value,arg-type]\n    return _construct(ChainBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.utils.kron","title":"<code>kron(*args)</code>","text":"<p>Stack blocks vertically.</p> <p>On digital backends this can be intepreted loosely as a kronecker product of blocks. In the analog case it executes blocks parallel in time.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to kron. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>KronBlock</p> <p>Example: <pre><code>from qadence import X, Y, kron\n\nb = kron(X(0), Y(1))\n\n# or use a generator\nb = kron(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def kron(*args: Union[AbstractBlock, Generator]) -&gt; KronBlock:\n    \"\"\"Stack blocks vertically.\n\n    On digital backends this can be intepreted\n    loosely as a kronecker product of blocks. In the analog case it executes\n    blocks parallel in time.\n\n    Arguments:\n        *args: Blocks to kron. Can also be a generator.\n\n    Returns:\n        KronBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, kron\n\n    b = kron(X(0), Y(1))\n\n    # or use a generator\n    b = kron(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    # ugly hack to use `AnalogKron` if we are dealing only with analog blocks\n    if len(args) and all(\n        isinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n    ):\n        return analog_kron(*args)  # type: ignore[return-value,arg-type]\n    return _construct(KronBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.utils.add","title":"<code>add(*args)</code>","text":"<p>Sums blocks.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Blocks to add. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>AddBlock</code> <p>AddBlock</p> <p>Example: <pre><code>from qadence import X, Y, add\n\nb = add(X(0), Y(0))\n\n# or use a generator\nb = add(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def add(*args: Union[AbstractBlock, Generator]) -&gt; AddBlock:\n    \"\"\"Sums blocks.\n\n    Arguments:\n        *args: Blocks to add. Can also be a generator.\n\n    Returns:\n        AddBlock\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, add\n\n    b = add(X(0), Y(0))\n\n    # or use a generator\n    b = add(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n    return _construct(AddBlock, args)\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.AddBlock","title":"<code>AddBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Adds blocks.</p> <p>Constructed via <code>add</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.ChainBlock","title":"<code>ChainBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Chains blocks sequentially.</p> <p>Constructed via <code>chain</code></p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#qadence.blocks.composite.CompositeBlock","title":"<code>CompositeBlock(tag=None, __array_priority__=1000)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AbstractBlock</code></p> <p>Block which composes multiple blocks into one larger block (which can again be composed).</p> <p>Composite blocks are constructed via <code>chain</code>, <code>kron</code>, and <code>add</code>.</p>"},{"location":"api/blocks/#qadence.blocks.composite.KronBlock","title":"<code>KronBlock(blocks)</code>","text":"<p>               Bases: <code>CompositeBlock</code></p> <p>Stacks blocks horizontally.</p> <p>Constructed via <code>kron</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\n    if len(blocks) == 0:\n        raise NotImplementedError(\"Empty KronBlocks not supported\")\n\n    qubit_support = QubitSupport()\n    for b in blocks:\n        assert (\n            QubitSupportType.GLOBAL,\n        ) != b.qubit_support, \"Blocks with global support cannot be kron'ed.\"\n        assert qubit_support.is_disjoint(\n            b.qubit_support\n        ), \"Make sure blocks act on distinct qubits!\"\n        qubit_support += b.qubit_support\n\n    self.blocks = blocks\n</code></pre>"},{"location":"api/blocks/#converting-blocks-to-matrices","title":"Converting blocks to matrices","text":""},{"location":"api/blocks/#qadence.blocks.block_to_tensor.block_to_tensor","title":"<code>block_to_tensor(block, values={}, qubit_support=None, use_full_support=True, tensor_type=TensorType.DENSE, endianness=Endianness.BIG, device=None)</code>","text":"<p>Convert a block into a torch tensor.</p> PARAMETER DESCRIPTION <code>block</code> <p>The block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>values</code> <p>A optional dict with values for parameters.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>qubit_support</code> <p>The qubit_support of the block.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>use_full_support</code> <p>True infers the total number of qubits.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>tensor_type</code> <p>the target tensor type.</p> <p> TYPE: <code>TensorType</code> DEFAULT: <code>DENSE</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n\nblock = hea(2,2)\nprint(block_to_tensor(block))\n\n# In case you have a diagonal observable, you can use\nobs = hamiltonian_factory(2, detuning = Z)\nprint(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n</code></pre> <pre><code>tensor([[[-0.1034+0.1705j, -0.4816-0.5640j, -0.5986-0.1553j,  0.0058+0.1665j],\n         [ 0.0336-0.5152j,  0.0353+0.3947j, -0.5215-0.1983j, -0.5120-0.0546j],\n         [-0.4573-0.4572j, -0.2579-0.3029j,  0.2179+0.2886j, -0.0982-0.5321j],\n         [-0.3450-0.3956j, -0.2664+0.2523j,  0.1325-0.3974j,  0.5320+0.3624j]]],\n       grad_fn=&lt;UnsafeViewBackward0&gt;)\ntensor(indices=tensor([[0, 3],\n                       [0, 3]]),\n       values=tensor([ 2.+0.j, -2.+0.j]),\n       size=(4, 4), nnz=2, layout=torch.sparse_coo)\n</code></pre> </p> Source code in <code>qadence/blocks/block_to_tensor.py</code> <pre><code>def block_to_tensor(\n    block: AbstractBlock,\n    values: dict[str, TNumber | torch.Tensor] = {},\n    qubit_support: tuple | None = None,\n    use_full_support: bool = True,\n    tensor_type: TensorType = TensorType.DENSE,\n    endianness: Endianness = Endianness.BIG,\n    device: torch.device = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Convert a block into a torch tensor.\n\n    Arguments:\n        block (AbstractBlock): The block to convert.\n        values (dict): A optional dict with values for parameters.\n        qubit_support (tuple): The qubit_support of the block.\n        use_full_support (bool): True infers the total number of qubits.\n        tensor_type (TensorType): the target tensor type.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n\n    block = hea(2,2)\n    print(block_to_tensor(block))\n\n    # In case you have a diagonal observable, you can use\n    obs = hamiltonian_factory(2, detuning = Z)\n    print(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n    ```\n    \"\"\"\n\n    # FIXME: default use_full_support to False. In general, it would\n    # be more efficient to do that, and make sure that computations such\n    # as observables only do the matmul of the size of the qubit support.\n\n    if tensor_type == TensorType.DENSE:\n        from qadence.blocks import embedding\n\n        (ps, embed) = embedding(block)\n        return _block_to_tensor_embedded(\n            block,\n            embed(ps, values),\n            qubit_support,\n            use_full_support,\n            endianness=endianness,\n            device=device,\n        )\n\n    elif tensor_type == TensorType.SPARSEDIAGONAL:\n        t = block_to_diagonal(block, endianness=endianness)\n        indices, values, size = torch.nonzero(t), t[t != 0], len(t)\n        indices = torch.stack((indices.flatten(), indices.flatten()))\n        return torch.sparse_coo_tensor(indices, values, (size, size))\n</code></pre>"},{"location":"api/constructors/","title":"Constructors for common quantum circuits","text":""},{"location":"api/constructors/#qadence.constructors.feature_maps.exp_fourier_feature_map","title":"<code>exp_fourier_feature_map(n_qubits, support=None, param='x', feature_range=None)</code>","text":"<p>Exponential fourier feature map.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the feature</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>name of feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'x'</code> </p> <code>feature_range</code> <p>min and max value of the feature, as floats in a Tuple</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def exp_fourier_feature_map(\n    n_qubits: int,\n    support: tuple[int, ...] = None,\n    param: str = \"x\",\n    feature_range: tuple[float, float] = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Exponential fourier feature map.\n\n    Args:\n        n_qubits: number of qubits in the feature\n        support: qubit support\n        param: name of feature `Parameter`\n        feature_range: min and max value of the feature, as floats in a Tuple\n    \"\"\"\n\n    if feature_range is None:\n        feature_range = (0.0, 2.0**n_qubits)\n\n    support = tuple(range(n_qubits)) if support is None else support\n    hlayer = kron(H(qubit) for qubit in support)\n    rlayer = feature_map(\n        n_qubits,\n        support=support,\n        param=param,\n        op=RZ,\n        fm_type=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.EXP,\n        feature_range=feature_range,\n        target_range=(0.0, 2 * PI),\n    )\n    rlayer.tag = None\n    return tag(chain(hlayer, rlayer), f\"ExpFourierFM({param})\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.feature_maps.feature_map","title":"<code>feature_map(n_qubits, support=None, param='phi', op=RX, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multiplier=None, param_prefix=None)</code>","text":"<p>Construct a feature map of a given type.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Number of qubits the feature map covers. Results in <code>support=range(n_qubits)</code>.</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>Puts one feature-encoding rotation gate on every qubit in <code>support</code>. n_qubits in this case specifies the total overall qubits of the circuit, which may be wider than the support itself, but not narrower.</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>Parameter of the feature map; you can pass a string or Parameter; it will be set as non-trainable (FeatureParameter) regardless.</p> <p> TYPE: <code>Parameter | str</code> DEFAULT: <code>'phi'</code> </p> <code>op</code> <p>Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.</p> <p> TYPE: <code>RotationTypes</code> DEFAULT: <code>RX</code> </p> <code>fm_type</code> <p>Basis set for data encoding; choose from <code>BasisSet.FOURIER</code> for Fourier encoding, or <code>BasisSet.CHEBYSHEV</code> for Chebyshev polynomials of the first kind.</p> <p> TYPE: <code>BasisSet | Callable | str</code> DEFAULT: <code>FOURIER</code> </p> <code>reupload_scaling</code> <p>how the feature map scales the data that is re-uploaded for each qubit. choose from <code>ReuploadScaling</code> enumeration or provide your own function with a single int as input and int or float as output.</p> <p> TYPE: <code>ReuploadScaling | Callable | str</code> DEFAULT: <code>CONSTANT</code> </p> <code>feature_range</code> <p>range of data that the input data provided comes from. Used to map input data to the correct domain of the feature-encoding function.</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>target_range</code> <p>range of data the data encoder assumes as the natural range. For example, in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*PI). Used to map data to the correct domain of the feature-encoding function.</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>multiplier</code> <p>overall multiplier; this is useful for reuploading the feature map serially with different scalings; can be a number or parameter/expression.</p> <p> TYPE: <code>Parameter | TParameter | None</code> DEFAULT: <code>None</code> </p> <code>param_prefix</code> <p>string prefix to create trainable parameters multiplying the feature parameter inside the feature-encoding function. Note that currently this does not take into account the domain of the feature-encoding function.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <p>Example: <pre><code>from qadence import feature_map, BasisSet, ReuploadScaling\n\nfm = feature_map(3, fm_type=BasisSet.FOURIER)\nprint(f\"{fm = }\")\n\nfm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\nprint(f\"{fm = }\")\n\nfm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\nprint(f\"{fm = }\")\n</code></pre> <pre><code>fm = KronBlock(0,1,2) [tag: Constant Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nfm = KronBlock(0,1,2) [tag: Constant Chebyshev FM]\n\u251c\u2500\u2500 RX(0) [params: ['acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['acos(phi)']]\nfm = KronBlock(0,1,2) [tag: Tower Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['1_0*phi']]\n\u251c\u2500\u2500 RX(1) [params: ['2_0*phi']]\n\u2514\u2500\u2500 RX(2) [params: ['3_0*phi']]\n</code></pre> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def feature_map(\n    n_qubits: int,\n    support: tuple[int, ...] | None = None,\n    param: Parameter | str = \"phi\",\n    op: RotationTypes = RX,\n    fm_type: BasisSet | Callable | str = BasisSet.FOURIER,\n    reupload_scaling: ReuploadScaling | Callable | str = ReuploadScaling.CONSTANT,\n    feature_range: tuple[float, float] | None = None,\n    target_range: tuple[float, float] | None = None,\n    multiplier: Parameter | TParameter | None = None,\n    param_prefix: str | None = None,\n) -&gt; KronBlock:\n    \"\"\"Construct a feature map of a given type.\n\n    Arguments:\n        n_qubits: Number of qubits the feature map covers. Results in `support=range(n_qubits)`.\n        support: Puts one feature-encoding rotation gate on every qubit in `support`. n_qubits in\n            this case specifies the total overall qubits of the circuit, which may be wider than the\n            support itself, but not narrower.\n        param: Parameter of the feature map; you can pass a string or Parameter;\n            it will be set as non-trainable (FeatureParameter) regardless.\n        op: Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.\n        fm_type: Basis set for data encoding; choose from `BasisSet.FOURIER` for Fourier\n            encoding, or `BasisSet.CHEBYSHEV` for Chebyshev polynomials of the first kind.\n        reupload_scaling: how the feature map scales the data that is re-uploaded for each qubit.\n            choose from `ReuploadScaling` enumeration or provide your own function with a single\n            int as input and int or float as output.\n        feature_range: range of data that the input data provided comes from. Used to map input data\n            to the correct domain of the feature-encoding function.\n        target_range: range of data the data encoder assumes as the natural range. For example,\n            in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*PI).\n            Used to map data to the correct domain of the feature-encoding function.\n        multiplier: overall multiplier; this is useful for reuploading the feature map serially with\n            different scalings; can be a number or parameter/expression.\n        param_prefix: string prefix to create trainable parameters multiplying the feature parameter\n            inside the feature-encoding function. Note that currently this does not take into\n            account the domain of the feature-encoding function.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import feature_map, BasisSet, ReuploadScaling\n\n    fm = feature_map(3, fm_type=BasisSet.FOURIER)\n    print(f\"{fm = }\")\n\n    fm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\n    print(f\"{fm = }\")\n\n    fm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\n    print(f\"{fm = }\")\n    ```\n    \"\"\"\n\n    # Process input\n    if support is None:\n        support = tuple(range(n_qubits))\n    elif len(support) != n_qubits:\n        raise ValueError(\"Wrong qubit support supplied\")\n\n    if op not in ROTATIONS:\n        raise ValueError(\n            f\"Operation {op} not supported. \"\n            f\"Please provide one from {[rot.__name__ for rot in ROTATIONS]}.\"\n        )\n\n    scaled_fparam = fm_parameter_scaling(\n        fm_type, param, feature_range=feature_range, target_range=target_range\n    )\n\n    transform_func = fm_parameter_func(fm_type)\n\n    basis_tag = fm_type.value if isinstance(fm_type, BasisSet) else str(fm_type)\n    rs_func, rs_tag = fm_reupload_scaling_fn(reupload_scaling)\n\n    # Set overall multiplier\n    multiplier = 1 if multiplier is None else Parameter(multiplier)\n\n    # Build feature map\n    op_list = []\n    fparam = scaled_fparam\n    for i, qubit in enumerate(support):\n        if param_prefix is not None:\n            train_param = VariationalParameter(param_prefix + f\"_{i}\")\n            fparam = train_param * scaled_fparam\n        op_list.append(op(qubit, multiplier * rs_func(i) * transform_func(fparam)))\n    fm = kron(*op_list)\n\n    fm.tag = rs_tag + \" \" + basis_tag + \" FM\"\n\n    return fm\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.ansatze.hea","title":"<code>hea(n_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the Hardware Efficient Ansatz (HEA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.DigitalAnalog</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital and DigitalAnalog HEA.</p> <p> TYPE: <code>list</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c. Valid for only for Digital HEA.</p> <p> TYPE: <code>bool</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>DigitaAnalog | Analog: Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples: <pre><code>from qadence import RZ, RX\nfrom qadence import hea\n\n# create the circuit\nn_qubits, depth = 2, 4\nansatz = hea(\n    n_qubits=n_qubits,\n    depth=depth,\n    strategy=\"sDAQC\",\n    operations=[RZ,RX,RZ]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    support: tuple[int, ...] = None,\n    strategy: Strategy = Strategy.DIGITAL,\n    **strategy_args: Any,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Factory function for the Hardware Efficient Ansatz (HEA).\n\n    Args:\n        n_qubits: number of qubits in the block\n        depth: number of layers of the HEA\n        param_prefix: the base name of the variational parameters\n        support: qubit indexes where the HEA is applied\n        strategy: Strategy.Digital or Strategy.DigitalAnalog\n        **strategy_args: see below\n\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital and DigitalAnalog HEA.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c. Valid for only\n            for Digital HEA.\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - DigitaAnalog | Analog: Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import RZ, RX\n    from qadence import hea\n\n    # create the circuit\n    n_qubits, depth = 2, 4\n    ansatz = hea(\n        n_qubits=n_qubits,\n        depth=depth,\n        strategy=\"sDAQC\",\n        operations=[RZ,RX,RZ]\n    )\n    ```\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    hea_func_dict = {\n        Strategy.DIGITAL: hea_digital,\n        Strategy.SDAQC: hea_sDAQC,\n        Strategy.BDAQC: hea_bDAQC,\n        Strategy.ANALOG: hea_analog,\n    }\n\n    try:\n        hea_func = hea_func_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    hea_block: AbstractBlock = hea_func(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        **strategy_args,\n    )  # type: ignore\n\n    return hea_block\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.ansatze.hea_digital","title":"<code>hea_digital(n_qubits, depth=1, param_prefix='theta', periodic=False, operations=[RX, RY, RX], support=None, entangler=CNOT)</code>","text":"<p>Construct the Digital Hardware Efficient Ansatz (HEA).</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_digital(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    periodic: bool = False,\n    operations: list[type[AbstractBlock]] = [RX, RY, RX],\n    support: tuple[int, ...] = None,\n    entangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the Digital Hardware Efficient Ansatz (HEA).\n\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n    \"\"\"\n    try:\n        if entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\n            raise ValueError(\n                \"Please provide a valid two-qubit entangler operation for digital HEA.\"\n            )\n    except TypeError:\n        raise ValueError(\"Please provide a valid two-qubit entangler operation for digital HEA.\")\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        periodic=periodic,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n    return tag(chain(*layers), \"HEA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.ansatze.hea_sDAQC","title":"<code>hea_sDAQC(n_qubits, depth=1, param_prefix='theta', operations=[RX, RY, RX], support=None, entangler=None)</code>","text":"<p>Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers.</p> <p>It uses step-wise digital-analog computation.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_sDAQC(\n    n_qubits: int,\n    depth: int = 1,\n    param_prefix: str = \"theta\",\n    operations: list[type[AbstractBlock]] = [RX, RY, RX],\n    support: tuple[int, ...] = None,\n    entangler: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers.\n\n    It uses step-wise digital-analog computation.\n\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n    \"\"\"\n\n    # TODO: Add qubit support\n    if entangler is None:\n        entangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n    try:\n        if not block_is_qubit_hamiltonian(entangler):\n            raise ValueError(\n                \"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n            )\n    except NotImplementedError:\n        raise ValueError(\n            \"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n        )\n\n    rot_list = _rotations_digital(\n        n_qubits=n_qubits,\n        depth=depth,\n        param_prefix=param_prefix,\n        support=support,\n        operations=operations,\n    )\n\n    ent_list = _entanglers_analog(\n        depth=depth,\n        param_prefix=param_prefix,\n        entangler=entangler,\n    )\n\n    layers = []\n    for d in range(depth):\n        layers.append(rot_list[d])\n        layers.append(ent_list[d])\n    return tag(chain(*layers), \"HEA-sDA\")\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig","title":"<code>ObservableConfig(detuning, scale=1.0, shift=0.0, transformation_type=ObservableTransform.NONE, trainable_transform=None)</code>  <code>dataclass</code>","text":""},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.detuning","title":"<code>detuning: TDetuning</code>  <code>instance-attribute</code>","text":"<p>Single qubit detuning of the observable Hamiltonian.</p> <p>Accepts single-qubit operator N, X, Y, or Z.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.scale","title":"<code>scale: TParameter = 1.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The scale by which to multiply the output of the observable.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.shift","title":"<code>shift: TParameter = 0.0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The shift to add to the output of the observable.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.trainable_transform","title":"<code>trainable_transform: bool | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to have a trainable transformation on the output of the observable.</p> <p>If None, the scale and shift are numbers. If True, the scale and shift are VariationalParameter. If False, the scale and shift are FeatureParameter.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.ObservableConfig.transformation_type","title":"<code>transformation_type: ObservableTransform = ObservableTransform.NONE</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The type of transformation.</p>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.hamiltonian_factory","title":"<code>hamiltonian_factory(register, interaction=None, detuning=None, interaction_strength=None, detuning_strength=None, random_strength=False, use_all_node_pairs=False)</code>","text":"<p>General Hamiltonian creation function.</p> <p>Can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings, both with arbitrary strength or parameterized.</p> PARAMETER DESCRIPTION <code>register</code> <p>register of qubits with a specific graph topology, or number of qubits. When passing a number of qubits a register with all-to-all connectivity is created.</p> <p> TYPE: <code>Register | int</code> </p> <code>interaction</code> <p>Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.</p> <p> TYPE: <code>Interaction | Callable | None</code> DEFAULT: <code>None</code> </p> <code>detuning</code> <p>single-qubit operator N, X, Y, or Z.</p> <p> TYPE: <code>TDetuning | None</code> DEFAULT: <code>None</code> </p> <code>interaction_strength</code> <p>list of values to be used as the interaction strength for each pair of qubits. Should be ordered following the order of <code>Register(n_qubits).edges</code>. Alternatively, some string \"x\" can be passed, which will create a parameterized interactions for each pair of qubits, each labelled as <code>\"x_ij\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>detuning_strength</code> <p>list of values to be used as the detuning strength for each qubit. Alternatively, some string \"x\" can be passed, which will create a parameterized detuning for each qubit, each labelled as <code>\"x_i\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>random_strength</code> <p>set random interaction and detuning strengths between -1 and 1.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_all_node_pairs</code> <p>computes an interaction term for every pair of nodes in the graph, independent of the edge topology in the register. Useful for defining Hamiltonians where the interaction strength decays with the distance.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>from qadence import hamiltonian_factory, Interaction, Register, Z\n\nn_qubits = 3\n\n# Constant total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n\n# Parameterized total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n\n# Random all-to-all XY Hamiltonian generator:\ngenerator = hamiltonian_factory(\n    n_qubits,\n    interaction = Interaction.XY,\n    random_strength = True,\n    )\n\n# Parameterized NN Hamiltonian generator with a square grid interaction topology:\nregister = Register.square(qubits_side = n_qubits)\ngenerator = hamiltonian_factory(\n    register,\n    interaction = Interaction.NN,\n    interaction_strength = \"theta\"\n    )\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def hamiltonian_factory(\n    register: Register | int,\n    interaction: Interaction | Callable | None = None,\n    detuning: TDetuning | None = None,\n    interaction_strength: TArray | str | None = None,\n    detuning_strength: TArray | str | None = None,\n    random_strength: bool = False,\n    use_all_node_pairs: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    General Hamiltonian creation function.\n\n    Can be used to create Hamiltonians with 2-qubit\n    interactions and single-qubit detunings, both with arbitrary strength or parameterized.\n\n    Arguments:\n        register: register of qubits with a specific graph topology, or number of qubits.\n            When passing a number of qubits a register with all-to-all connectivity\n            is created.\n        interaction: Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.\n        detuning: single-qubit operator N, X, Y, or Z.\n        interaction_strength: list of values to be used as the interaction strength for each\n            pair of qubits. Should be ordered following the order of `Register(n_qubits).edges`.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            interactions for each pair of qubits, each labelled as `\"x_ij\"`.\n        detuning_strength: list of values to be used as the detuning strength for each qubit.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            detuning for each qubit, each labelled as `\"x_i\"`.\n        random_strength: set random interaction and detuning strengths between -1 and 1.\n        use_all_node_pairs: computes an interaction term for every pair of nodes in the graph,\n            independent of the edge topology in the register. Useful for defining Hamiltonians\n            where the interaction strength decays with the distance.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import hamiltonian_factory, Interaction, Register, Z\n\n        n_qubits = 3\n\n        # Constant total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z)\n\n        # Parameterized total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n\n        # Random all-to-all XY Hamiltonian generator:\n        generator = hamiltonian_factory(\n            n_qubits,\n            interaction = Interaction.XY,\n            random_strength = True,\n            )\n\n        # Parameterized NN Hamiltonian generator with a square grid interaction topology:\n        register = Register.square(qubits_side = n_qubits)\n        generator = hamiltonian_factory(\n            register,\n            interaction = Interaction.NN,\n            interaction_strength = \"theta\"\n            )\n        ```\n    \"\"\"\n\n    if interaction is None and detuning is None:\n        raise ValueError(\"Please provide an interaction and/or detuning for the Hamiltonian.\")\n\n    # If number of qubits is given, creates all-to-all register\n    register = Register(register) if isinstance(register, int) else register\n\n    # Get interaction function\n    if interaction is not None:\n        if callable(interaction):\n            int_fn = interaction\n            try:\n                if not block_is_qubit_hamiltonian(interaction(0, 1)):\n                    raise ValueError(\"Custom interactions must be composed of Pauli operators.\")\n            except TypeError:\n                raise TypeError(\n                    \"Please use a custom interaction function signed with two integer parameters.\"\n                )\n        else:\n            int_fn = INTERACTION_DICT.get(interaction, None)  # type: ignore [arg-type]\n            if int_fn is None:\n                raise KeyError(f\"Interaction {interaction} not supported.\")\n\n    # Check single-qubit detuning\n    if (detuning is not None) and (detuning not in DETUNINGS):\n        raise TypeError(f\"Detuning of type {type(detuning)} not supported.\")\n\n    # Pre-process detuning and interaction strengths and update register\n    detuning_strength_array = _preprocess_strengths(\n        register, detuning_strength, \"nodes\", random_strength\n    )\n\n    edge_str = \"all_node_pairs\" if use_all_node_pairs else \"edges\"\n    interaction_strength_array = _preprocess_strengths(\n        register, interaction_strength, edge_str, random_strength\n    )\n\n    # Create single-qubit detunings:\n    single_qubit_terms: List[AbstractBlock] = []\n    if detuning is not None:\n        for strength, node in zip(detuning_strength_array, register.nodes):\n            single_qubit_terms.append(strength * detuning(node))\n\n    # Create two-qubit interactions:\n    two_qubit_terms: List[AbstractBlock] = []\n    edge_data = register.all_node_pairs if use_all_node_pairs else register.edges\n    if interaction is not None and int_fn is not None:\n        for strength, edge in zip(interaction_strength_array, edge_data):\n            two_qubit_terms.append(strength * int_fn(*edge))\n\n    return add(*single_qubit_terms, *two_qubit_terms)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_nn","title":"<code>interaction_nn(i, j)</code>","text":"<p>Ising NN interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_nn(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Ising NN interaction.\"\"\"\n    return N(i) @ N(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_xy","title":"<code>interaction_xy(i, j)</code>","text":"<p>XY interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xy(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"XY interaction.\"\"\"\n    return X(i) @ X(j) + Y(i) @ Y(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_xyz","title":"<code>interaction_xyz(i, j)</code>","text":"<p>Heisenberg XYZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xyz(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Heisenberg XYZ interaction.\"\"\"\n    return X(i) @ X(j) + Y(i) @ Y(j) + Z(i) @ Z(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.hamiltonians.interaction_zz","title":"<code>interaction_zz(i, j)</code>","text":"<p>Ising ZZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_zz(i: int, j: int) -&gt; AbstractBlock:\n    \"\"\"Ising ZZ interaction.\"\"\"\n    return Z(i) @ Z(j)\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.qft.qft","title":"<code>qft(n_qubits, support=None, inverse=False, reverse_in=False, swaps_out=False, strategy=Strategy.DIGITAL, gen_build=None)</code>","text":"<p>The Quantum Fourier Transform.</p> <p>Depending on the application, user should be careful with qubit ordering in the input and output. This can be controlled with reverse_in and swaps_out arguments.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>number of qubits in the QFT</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support to use</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>inverse</code> <p>True performs the inverse QFT</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reverse_in</code> <p>Reverses the input qubits to account for endianness</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>swaps_out</code> <p>Performs swaps on the output qubits to match the \"textbook\" QFT.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.sDAQC</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>gen_build</code> <p>building block Ising Hamiltonian for the DAQC transform. Defaults to constant all-to-all Ising.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import qft\n\nn_qubits = 3\n\nqft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/qft.py</code> <pre><code>def qft(\n    n_qubits: int,\n    support: tuple[int, ...] = None,\n    inverse: bool = False,\n    reverse_in: bool = False,\n    swaps_out: bool = False,\n    strategy: Strategy = Strategy.DIGITAL,\n    gen_build: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n    \"\"\"\n    The Quantum Fourier Transform.\n\n    Depending on the application, user should be careful with qubit ordering\n    in the input and output. This can be controlled with reverse_in and swaps_out\n    arguments.\n\n    Args:\n        n_qubits: number of qubits in the QFT\n        support: qubit support to use\n        inverse: True performs the inverse QFT\n        reverse_in: Reverses the input qubits to account for endianness\n        swaps_out: Performs swaps on the output qubits to match the \"textbook\" QFT.\n        strategy: Strategy.Digital or Strategy.sDAQC\n        gen_build: building block Ising Hamiltonian for the DAQC transform.\n            Defaults to constant all-to-all Ising.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import qft\n\n        n_qubits = 3\n\n        qft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n        ```\n    \"\"\"\n\n    if support is None:\n        support = tuple(range(n_qubits))\n\n    assert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\n\n    if reverse_in:\n        support = support[::-1]\n\n    qft_layer_dict = {\n        Strategy.DIGITAL: _qft_layer_digital,\n        Strategy.SDAQC: _qft_layer_sDAQC,\n        Strategy.BDAQC: _qft_layer_bDAQC,\n        Strategy.ANALOG: _qft_layer_analog,\n    }\n\n    try:\n        layer_func = qft_layer_dict[strategy]\n    except KeyError:\n        raise KeyError(f\"Strategy {strategy} not recognized.\")\n\n    qft_layers = reversed(range(n_qubits)) if inverse else range(n_qubits)\n\n    qft_circ = chain(\n        layer_func(\n            n_qubits=n_qubits, support=support, layer=layer, inverse=inverse, gen_build=gen_build\n        )  # type: ignore\n        for layer in qft_layers\n    )\n\n    if swaps_out:\n        swap_ops = [SWAP(support[i], support[n_qubits - i - 1]) for i in range(n_qubits // 2)]\n        qft_circ = chain(*swap_ops, qft_circ) if inverse else chain(qft_circ, *swap_ops)\n\n    return tag(qft_circ, tag=\"iQFT\") if inverse else tag(qft_circ, tag=\"QFT\")\n</code></pre>"},{"location":"api/constructors/#hardware-efficient-ansatz-for-rydberg-atom-arrays","title":"Hardware efficient ansatz for Rydberg atom arrays","text":""},{"location":"api/constructors/#qadence.constructors.rydberg_hea.rydberg_hea","title":"<code>rydberg_hea(register, n_layers=1, addressable_detuning=True, addressable_drive=False, tunable_phase=False, additional_prefix=None)</code>","text":"<p>Hardware efficient ansatz for neutral atom (Rydberg) platforms.</p> <p>This constructor implements a variational ansatz which is very close to what is implementable on 2nd generation PASQAL quantum devices. In particular, it implements evolution over a specific Hamiltonian which can be realized on the device. This Hamiltonian contains:</p> <ul> <li> <p>an interaction term given by the standard NN interaction and determined starting     from the positions in the input register: H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c</p> </li> <li> <p>a detuning term which corresponding to a n_i = (1+sigma_i^z)/2 applied to     all the qubits. If the <code>addressable_detuning</code> flag is set to True, the routine     effectively a local n_i = (1+sigma_i^z)/2 term in the     evolved Hamiltonian with a different coefficient for each atom. These     coefficients determine a local addressing pattern for the detuning on a subset     of the qubits. In this routine, the coefficients are variational parameters     and they will therefore be optimized at each optimizer step</p> </li> <li> <p>a drive term which corresponding to a sigma^x evolution operation applied to     all the qubits. If the <code>addressable_drive</code> flag is set to True, the routine     effectively a local sigma_i^x term in the evolved Hamiltonian with a different     coefficient for each atom. These coefficients determine a local addressing pattern     for the drive on a subset of the qubits. In this routine, the coefficients are     variational parameters and they will therefore be optimized at each optimizer step</p> </li> <li> <p>if the <code>tunable_phase</code> flag is set to True, the drive term is modified in the following     way: drive = cos(phi) * sigma^x - sin(phi) * sigma^y     The addressable pattern above is maintained and the phase is considered just as an     additional variational parameter which is optimized with the rest</p> </li> </ul> <p>Notice that, on real devices, the coefficients assigned to each qubit in both the detuning and drive patterns should be non-negative and they should always sum to 1. This is not the case for the implementation in this routine since the coefficients (weights) do not have any constraint. Therefore, this HEA is not completely realizable on neutral atom devices.</p> PARAMETER DESCRIPTION <code>register</code> <p>the input atomic register with Cartesian coordinates.</p> <p> TYPE: <code>Register</code> </p> <code>n_layers</code> <p>number layers in the HEA, each layer includes a drive, detuning and pure interaction pulses whose is a variational parameter</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>addressable_detuning</code> <p>whether to turn on the trainable semi-local addressing pattern on the detuning (n_i terms in the Hamiltonian)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>addressable_drive</code> <p>whether to turn on the trainable semi-local addressing pattern on the drive (sigma_i^x terms in the Hamiltonian)</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tunable_phase</code> <p>whether to have a tunable phase to get both sigma^x and sigma^y rotations in the drive term. If False, only a sigma^x term will be included in the drive part of the Hamiltonian generator</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>additional_prefix</code> <p>an additional prefix to attach to the parameter names</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>The Rydberg HEA block</p> Source code in <code>qadence/constructors/rydberg_hea.py</code> <pre><code>def rydberg_hea(\n    register: qd.Register,\n    n_layers: int = 1,\n    addressable_detuning: bool = True,\n    addressable_drive: bool = False,\n    tunable_phase: bool = False,\n    additional_prefix: str = None,\n) -&gt; qd.blocks.ChainBlock:\n    \"\"\"Hardware efficient ansatz for neutral atom (Rydberg) platforms.\n\n    This constructor implements a variational ansatz which is very close to\n    what is implementable on 2nd generation PASQAL quantum devices. In particular,\n    it implements evolution over a specific Hamiltonian which can be realized on\n    the device. This Hamiltonian contains:\n\n    * an interaction term given by the standard NN interaction and determined starting\n        from the positions in the input register: H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n\n    * a detuning term which corresponding to a n_i = (1+sigma_i^z)/2 applied to\n        all the qubits. If the `addressable_detuning` flag is set to True, the routine\n        effectively a local n_i = (1+sigma_i^z)/2 term in the\n        evolved Hamiltonian with a different coefficient for each atom. These\n        coefficients determine a local addressing pattern for the detuning on a subset\n        of the qubits. In this routine, the coefficients are variational parameters\n        and they will therefore be optimized at each optimizer step\n\n    * a drive term which corresponding to a sigma^x evolution operation applied to\n        all the qubits. If the `addressable_drive` flag is set to True, the routine\n        effectively a local sigma_i^x term in the evolved Hamiltonian with a different\n        coefficient for each atom. These coefficients determine a local addressing pattern\n        for the drive on a subset of the qubits. In this routine, the coefficients are\n        variational parameters and they will therefore be optimized at each optimizer step\n\n    * if the `tunable_phase` flag is set to True, the drive term is modified in the following\n        way: drive = cos(phi) * sigma^x - sin(phi) * sigma^y\n        The addressable pattern above is maintained and the phase is considered just as an\n        additional variational parameter which is optimized with the rest\n\n    Notice that, on real devices, the coefficients assigned to each qubit in both the detuning\n    and drive patterns should be non-negative and they should always sum to 1. This is not the\n    case for the implementation in this routine since the coefficients (weights) do not have any\n    constraint. Therefore, this HEA is not completely realizable on neutral atom devices.\n\n    Args:\n        register: the input atomic register with Cartesian coordinates.\n        n_layers: number layers in the HEA, each layer includes a drive, detuning and\n            pure interaction pulses whose is a variational parameter\n        addressable_detuning: whether to turn on the trainable semi-local addressing pattern\n            on the detuning (n_i terms in the Hamiltonian)\n        addressable_drive: whether to turn on the trainable semi-local addressing pattern\n            on the drive (sigma_i^x terms in the Hamiltonian)\n        tunable_phase: whether to have a tunable phase to get both sigma^x and sigma^y rotations\n            in the drive term. If False, only a sigma^x term will be included in the drive part\n            of the Hamiltonian generator\n        additional_prefix: an additional prefix to attach to the parameter names\n\n    Returns:\n        The Rydberg HEA block\n    \"\"\"\n    n_qubits = register.n_qubits\n    prefix = \"\" if additional_prefix is None else \"_\" + additional_prefix\n\n    detunings = None\n    # add a detuning pattern locally addressing the atoms\n    if addressable_detuning:\n        detunings = [qd.VariationalParameter(f\"detmap_{j}\") for j in range(n_qubits)]\n\n    drives = None\n    # add a drive pattern locally addressing the atoms\n    if addressable_drive:\n        drives = [qd.VariationalParameter(f\"drivemap_{j}\") for j in range(n_qubits)]\n\n    phase = None\n    if tunable_phase:\n        phase = qd.VariationalParameter(\"phase\")\n\n    return chain(\n        rydberg_hea_layer(\n            register,\n            VariationalParameter(f\"At{prefix}_{layer}\"),\n            VariationalParameter(f\"Omega{prefix}_{layer}\"),\n            VariationalParameter(f\"wait{prefix}_{layer}\"),\n            detunings=detunings,\n            drives=drives,\n            phase=phase,\n        )\n        for layer in range(n_layers)\n    )\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.rydberg_hea.rydberg_hea_layer","title":"<code>rydberg_hea_layer(register, tevo_drive, tevo_det, tevo_wait, phase=None, detunings=None, drives=None, drive_scaling=1.0)</code>","text":"<p>A single layer of the Rydberg hardware efficient ansatz.</p> PARAMETER DESCRIPTION <code>register</code> <p>the input register with atomic coordinates needed to build the interaction.</p> <p> TYPE: <code>Register</code> </p> <code>tevo_drive</code> <p>a variational parameter for the duration of the drive term of the Hamiltonian generator, including optional semi-local addressing</p> <p> TYPE: <code>Parameter | float</code> </p> <code>tevo_det</code> <p>a variational parameter for the duration of the detuning term of the Hamiltonian generator, including optional semi-local addressing</p> <p> TYPE: <code>Parameter | float</code> </p> <code>tevo_wait</code> <p>a variational parameter for the duration of the waiting time with interaction only</p> <p> TYPE: <code>Parameter | float</code> </p> <code>phase</code> <p>a variational parameter representing the global phase. If None, the global phase is set to 0 which results in a drive term in sigma^x only. Otherwise both sigma^x and sigma^y terms will be present</p> <p> TYPE: <code>Parameter | float | None</code> DEFAULT: <code>None</code> </p> <code>detunings</code> <p>a list of parameters with the weights of the locally addressed detuning terms. These are variational parameters which are tuned by the optimizer</p> <p> TYPE: <code>list[Parameter] | list[float] | None</code> DEFAULT: <code>None</code> </p> <code>drives</code> <p>a list of parameters with the weights of the locally addressed drive terms. These are variational parameters which are tuned by the optimizer</p> <p> TYPE: <code>list[Parameter] | list[float] | None</code> DEFAULT: <code>None</code> </p> <code>drive_scaling</code> <p>a scaling term to be added to the drive Hamiltonian generator</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A block with a single layer of Rydberg HEA</p> Source code in <code>qadence/constructors/rydberg_hea.py</code> <pre><code>def rydberg_hea_layer(\n    register: qd.Register,\n    tevo_drive: Parameter | float,\n    tevo_det: Parameter | float,\n    tevo_wait: Parameter | float,\n    phase: Parameter | float | None = None,\n    detunings: list[Parameter] | list[float] | None = None,\n    drives: list[Parameter] | list[float] | None = None,\n    drive_scaling: float = 1.0,\n) -&gt; ChainBlock:\n    \"\"\"A single layer of the Rydberg hardware efficient ansatz.\n\n    Args:\n        register: the input register with atomic coordinates needed to build the interaction.\n        tevo_drive: a variational parameter for the duration of the drive term of\n            the Hamiltonian generator, including optional semi-local addressing\n        tevo_det: a variational parameter for the duration of the detuning term of the\n            Hamiltonian generator, including optional semi-local addressing\n        tevo_wait: a variational parameter for the duration of the waiting\n            time with interaction only\n        phase: a variational parameter representing the global phase. If None, the\n            global phase is set to 0 which results in a drive term in sigma^x only. Otherwise\n            both sigma^x and sigma^y terms will be present\n        detunings: a list of parameters with the weights of the locally addressed\n            detuning terms. These are variational parameters which are tuned by the optimizer\n        drives: a list of parameters with the weights of the locally addressed\n            drive terms. These are variational parameters which are tuned by the optimizer\n        drive_scaling: a scaling term to be added to the drive Hamiltonian generator\n\n    Returns:\n        A block with a single layer of Rydberg HEA\n    \"\"\"\n    n_qubits = register.n_qubits\n\n    drive_x = _amplitude_map(n_qubits, qd.X, weights=drives)\n    drive_y = _amplitude_map(n_qubits, qd.Y, weights=drives)\n    detuning = _amplitude_map(n_qubits, qd.N, weights=detunings)\n    interaction = hamiltonian_factory(register, qd.Interaction.NN)\n\n    # drive and interaction are not commuting thus they need to be\n    # added directly into the final Hamiltonian generator\n    if phase is not None:\n        generator = (\n            drive_scaling * sympy.cos(phase) * drive_x\n            - drive_scaling * sympy.sin(phase) * drive_y\n            + interaction\n        )\n    else:\n        generator = drive_scaling * drive_x + interaction\n\n    return chain(\n        qd.HamEvo(generator, tevo_drive),\n        # detuning and interaction are commuting, so they\n        # can be ordered arbitrarily and treated separately\n        qd.HamEvo(interaction, tevo_wait),\n        qd.HamEvo(detuning, tevo_det),\n    )\n</code></pre>"},{"location":"api/constructors/#the-daqc-transform","title":"The DAQC Transform","text":""},{"location":"api/constructors/#qadence.constructors.daqc.daqc.daqc_transform","title":"<code>daqc_transform(n_qubits, gen_target, t_f, gen_build=None, zero_tol=1e-08, strategy=Strategy.SDAQC, ignore_global_phases=False)</code>","text":"<p>Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian.</p> <p>The result is another fixed 2-body Hamiltonian.</p> <p>Reference for universality of 2-body Hamiltonians:</p> <p>-- https://arxiv.org/abs/quant-ph/0106064</p> <p>Based on the transformation for Ising (ZZ) interactions, as described in the paper</p> <p>-- https://arxiv.org/abs/1812.03637</p> <p>The transform translates a target weighted generator of the type:</p> <pre><code>`gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>To a circuit using analog evolutions with a fixed building block generator:</p> <pre><code>`gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>where <code>op = Z</code> or <code>op = N</code>.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>total number of qubits to use.</p> <p> TYPE: <code>int</code> </p> <code>gen_target</code> <p>target generator built with the structure above. The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>t_f</code> <p>total time for the gen_target evolution.</p> <p> TYPE: <code>float</code> </p> <code>gen_build</code> <p>fixed generator to act as a building block. Defaults to constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>zero_tol</code> <p>default \"zero\" for a missing interaction. Included for numerical reasons, see notes below.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>strategy</code> <p>sDAQC or bDAQC, following definitions in the reference paper.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>SDAQC</code> </p> <code>ignore_global_phases</code> <p>if <code>True</code> the transform does not correct the global phases coming from the mapping between ZZ and NN interactions.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Notes:</p> <pre><code>The paper follows an index convention of running from 1 to N. A few functions\nhere also use that convention to be consistent with the paper. However, for qadence\nrelated things the indices are converted to [0, N-1].\n\nThe case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\nThere is a workaround for this described in the paper, but it is currently not implemented.\n\nThe current implementation may result in evolution times that are both positive or\nnegative. In practice, both can be represented by simply changing the signs of the\ninteractions. However, for a real implementation where the interactions should remain\nfixed, the paper discusses a workaround that is not currently implemented.\n\nThe transformation works by representing each interaction in the target hamiltonian by\na set of evolutions using the build hamiltonian. As a consequence, some care must be\ntaken when choosing the build hamiltonian. Some cases:\n\n- The target hamiltonian can have any interaction, as long as it is sufficiently\nrepresented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\nis in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\nneeds to be in the build hamiltonian. This is checked when the generators are parsed.\n\n- The build hamiltonian can have any interaction, irrespectively of it being needed\nfor the target hamiltonian. This is especially useful for designing local operations\nthrough the repeated evolution of a \"global\" hamiltonian.\n\n- The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\nAny interaction strength smaller than `zero_tol` in the build hamiltonian will not be\nconsidered, and thus that interaction is missing.\n\n- The various ratios `g_jk / f_jk` will influence the time parameter for the various\nevolution slices, meaning that if there is a big discrepancy in the interaction strength\nfor a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\nevolutions with very large times.\n\n- A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\ntimes smaller than `zero_tol` will not be represented.\n</code></pre> <p>Examples:</p> <pre><code>from qadence import Z, N, daqc_transform\n\nn_qubits = 3\n\ngen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n\ngen_target = 0.1 * (Z(1)@Z(2))\n\nt_f = 2.0\n\ntransformed_circuit = daqc_transform(\n    n_qubits = n_qubits,\n    gen_target = gen_target,\n    t_f = t_f,\n    gen_build = gen_build,\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/daqc/daqc.py</code> <pre><code>def daqc_transform(\n    n_qubits: int,\n    gen_target: AbstractBlock,\n    t_f: float,\n    gen_build: AbstractBlock | None = None,\n    zero_tol: float = 1e-08,\n    strategy: Strategy = Strategy.SDAQC,\n    ignore_global_phases: bool = False,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian.\n\n    The result is another fixed 2-body Hamiltonian.\n\n    Reference for universality of 2-body Hamiltonians:\n\n    -- https://arxiv.org/abs/quant-ph/0106064\n\n    Based on the transformation for Ising (ZZ) interactions, as described in the paper\n\n    -- https://arxiv.org/abs/1812.03637\n\n    The transform translates a target weighted generator of the type:\n\n        `gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n\n    To a circuit using analog evolutions with a fixed building block generator:\n\n        `gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n\n    where `op = Z` or `op = N`.\n\n    Args:\n        n_qubits: total number of qubits to use.\n        gen_target: target generator built with the structure above. The type\n            of the generator will be automatically evaluated when parsing.\n        t_f (float): total time for the gen_target evolution.\n        gen_build: fixed generator to act as a building block. Defaults to\n            constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type\n            of the generator will be automatically evaluated when parsing.\n        zero_tol: default \"zero\" for a missing interaction. Included for\n            numerical reasons, see notes below.\n        strategy: sDAQC or bDAQC, following definitions in the reference paper.\n        ignore_global_phases: if `True` the transform does not correct the global\n            phases coming from the mapping between ZZ and NN interactions.\n\n    Notes:\n\n        The paper follows an index convention of running from 1 to N. A few functions\n        here also use that convention to be consistent with the paper. However, for qadence\n        related things the indices are converted to [0, N-1].\n\n        The case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\n        There is a workaround for this described in the paper, but it is currently not implemented.\n\n        The current implementation may result in evolution times that are both positive or\n        negative. In practice, both can be represented by simply changing the signs of the\n        interactions. However, for a real implementation where the interactions should remain\n        fixed, the paper discusses a workaround that is not currently implemented.\n\n        The transformation works by representing each interaction in the target hamiltonian by\n        a set of evolutions using the build hamiltonian. As a consequence, some care must be\n        taken when choosing the build hamiltonian. Some cases:\n\n        - The target hamiltonian can have any interaction, as long as it is sufficiently\n        represented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\n        is in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\n        needs to be in the build hamiltonian. This is checked when the generators are parsed.\n\n        - The build hamiltonian can have any interaction, irrespectively of it being needed\n        for the target hamiltonian. This is especially useful for designing local operations\n        through the repeated evolution of a \"global\" hamiltonian.\n\n        - The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\n        Any interaction strength smaller than `zero_tol` in the build hamiltonian will not be\n        considered, and thus that interaction is missing.\n\n        - The various ratios `g_jk / f_jk` will influence the time parameter for the various\n        evolution slices, meaning that if there is a big discrepancy in the interaction strength\n        for a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\n        evolutions with very large times.\n\n        - A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\n        times smaller than `zero_tol` will not be represented.\n\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import Z, N, daqc_transform\n\n        n_qubits = 3\n\n        gen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n\n        gen_target = 0.1 * (Z(1)@Z(2))\n\n        t_f = 2.0\n\n        transformed_circuit = daqc_transform(\n            n_qubits = n_qubits,\n            gen_target = gen_target,\n            t_f = t_f,\n            gen_build = gen_build,\n        )\n        ```\n    \"\"\"\n\n    ##################\n    # Input controls #\n    ##################\n\n    if strategy != Strategy.SDAQC:\n        raise NotImplementedError(\"Currently only the sDAQC transform is implemented.\")\n\n    if n_qubits == 4:\n        raise NotImplementedError(\"DAQC transform 4-qubit edge case not implemented.\")\n\n    if gen_build is None:\n        gen_build = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\n\n    try:\n        if (not block_is_qubit_hamiltonian(gen_target)) or (\n            not block_is_qubit_hamiltonian(gen_build)\n        ):\n            raise ValueError(\n                \"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n            )\n    except NotImplementedError:\n        # Happens when block_is_qubit_hamiltonian is called on something that is not a block.\n        raise TypeError(\n            \"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n        )\n\n    #####################\n    # Generator parsing #\n    #####################\n\n    g_jk_target, mat_jk_target, target_type = _parse_generator(n_qubits, gen_target, 0.0)\n    g_jk_build, mat_jk_build, build_type = _parse_generator(n_qubits, gen_build, zero_tol)\n\n    # Get the global phase hamiltonian and single-qubit detuning hamiltonian\n    if build_type == GenDAQC.NN:\n        h_phase_build, h_sq_build = _nn_phase_and_detunings(n_qubits, mat_jk_build)\n\n    if target_type == GenDAQC.NN:\n        h_phase_target, h_sq_target = _nn_phase_and_detunings(n_qubits, mat_jk_target)\n\n    # Time re-scalings\n    if build_type == GenDAQC.ZZ and target_type == GenDAQC.NN:\n        t_star = t_f / 4.0\n    elif build_type == GenDAQC.NN and target_type == GenDAQC.ZZ:\n        t_star = 4.0 * t_f\n    else:\n        t_star = t_f\n\n    # Check if target Hamiltonian can be mapped with the build Hamiltonian\n    assert _check_compatibility(g_jk_target, g_jk_build, zero_tol)\n\n    ##################\n    # DAQC Transform #\n    ##################\n\n    # Section III A of https://arxiv.org/abs/1812.03637:\n\n    # Matrix M for the linear system, exemplified in Table I:\n    matrix_M = _build_matrix_M(n_qubits)\n\n    # Linear system mapping interaction ratios -&gt; evolution times.\n    t_slices = torch.linalg.solve(matrix_M, g_jk_target / g_jk_build) * t_star\n\n    # ZZ-DAQC with ZZ or NN build Hamiltonian\n    daqc_slices = []\n    for m in range(2, n_qubits + 1):\n        for n in range(1, m):\n            alpha = _ix_map(n_qubits, n, m)\n            t = t_slices[alpha - 1]\n            if abs(t) &gt; zero_tol:\n                if abs(t) &gt; (1 / (zero_tol**0.5)):\n                    logger.warning(\n                        \"\"\"\nTransformed circuit with very long evolution time.\nMake sure your target interactions are sufficiently\nrepresented in the build Hamiltonian.\"\"\"\n                    )\n                x_gates = kron(X(n - 1), X(m - 1))\n                analog_evo = HamEvo(gen_build, t)\n                # TODO: Fix repeated X-gates\n                if build_type == GenDAQC.NN:\n                    # Local detuning at each DAQC layer for NN build Hamiltonian\n                    sq_detuning_build = HamEvo(h_sq_build, t)\n                    daqc_slices.append(chain(x_gates, sq_detuning_build, analog_evo, x_gates))\n                elif build_type == GenDAQC.ZZ:\n                    daqc_slices.append(chain(x_gates, analog_evo, x_gates))\n\n    daqc_circuit = chain(*daqc_slices)\n\n    ########################\n    # Phases and Detunings #\n    ########################\n\n    if target_type == GenDAQC.NN:\n        # Local detuning given a NN target Hamiltonian\n        sq_detuning_target = HamEvo(h_sq_target, t_f).dagger()\n        daqc_circuit = chain(sq_detuning_target, daqc_circuit)\n\n    if not ignore_global_phases:\n        if build_type == GenDAQC.NN:\n            # Constant global phase given a NN build Hamiltonian\n            global_phase_build = HamEvo(h_phase_build, t_slices.sum())\n            daqc_circuit = chain(global_phase_build, daqc_circuit)\n\n        if target_type == GenDAQC.NN:\n            # Constant global phase and given a NN target Hamiltonian\n            global_phase_target = HamEvo(h_phase_target, t_f).dagger()\n            daqc_circuit = chain(global_phase_target, daqc_circuit)\n\n    return daqc_circuit\n</code></pre>"},{"location":"api/constructors/#some-utility-functions","title":"Some utility functions","text":""},{"location":"api/constructors/#qadence.constructors.utils.build_idx_fms","title":"<code>build_idx_fms(basis, fm_pauli, multivariate_strategy, n_features, n_qubits, reupload_scaling)</code>","text":"<p>Builds the index feature maps based on the given parameters.</p> PARAMETER DESCRIPTION <code>basis</code> <p>Type of basis chosen for the feature map.</p> <p> TYPE: <code>BasisSet</code> </p> <code>fm_pauli</code> <p>The chosen Pauli rotation type.</p> <p> TYPE: <code>PrimitiveBlock type</code> </p> <code>multivariate_strategy</code> <p>The strategy used for encoding the multivariate feature map.</p> <p> TYPE: <code>MultivariateStrategy</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>reupload_scaling</code> <p>The chosen scaling for the reupload.</p> <p> TYPE: <code>ReuploadScaling</code> </p> RETURNS DESCRIPTION <code>list[KronBlock]</code> <p>List[KronBlock]: The list of index feature maps.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def build_idx_fms(\n    basis: BasisSet,\n    fm_pauli: Type[RY],\n    multivariate_strategy: MultivariateStrategy,\n    n_features: int,\n    n_qubits: int,\n    reupload_scaling: ReuploadScaling,\n) -&gt; list[KronBlock]:\n    \"\"\"Builds the index feature maps based on the given parameters.\n\n    Args:\n        basis (BasisSet): Type of basis chosen for the feature map.\n        fm_pauli (PrimitiveBlock type): The chosen Pauli rotation type.\n        multivariate_strategy (MultivariateStrategy): The strategy used for encoding\n            the multivariate feature map.\n        n_features (int): The number of features.\n        n_qubits (int): The number of qubits.\n        reupload_scaling (ReuploadScaling): The chosen scaling for the reupload.\n\n    Returns:\n        List[KronBlock]: The list of index feature maps.\n    \"\"\"\n    idx_fms = []\n    for i in range(n_features):\n        target_qubits = get_fm_qubits(multivariate_strategy, i, n_qubits, n_features)\n        param = FeatureParameter(f\"x{i}\")\n        block = kron(\n            *[\n                fm_pauli(qubit, generator_prefactor(reupload_scaling, j) * basis_func(basis, param))\n                for j, qubit in enumerate(target_qubits)\n            ]\n        )\n        idx_fm = block\n        idx_fms.append(idx_fm)\n    return idx_fms\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.utils.generator_prefactor","title":"<code>generator_prefactor(reupload_scaling, qubit_index)</code>","text":"<p>Converts a spectrum string, e.g. tower or exponential.</p> <p>The result is the correct generator prefactor.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def generator_prefactor(reupload_scaling: ReuploadScaling, qubit_index: int) -&gt; float | int:\n    \"\"\"Converts a spectrum string, e.g. tower or exponential.\n\n    The result is the correct generator prefactor.\n    \"\"\"\n    conversion_dict: dict[str, float | int] = {\n        ReuploadScaling.CONSTANT: 1,\n        ReuploadScaling.TOWER: qubit_index + 1,\n        ReuploadScaling.EXP: 2 * PI / (2 ** (qubit_index + 1)),\n    }\n    return conversion_dict[reupload_scaling]\n</code></pre>"},{"location":"api/constructors/#qadence.constructors.utils.get_fm_qubits","title":"<code>get_fm_qubits(multivariate_strategy, i, n_qubits, n_features)</code>","text":"<p>Returns the list of target qubits for the given feature map strategy and feature index.</p> PARAMETER DESCRIPTION <code>multivariate_strategy</code> <p>The strategy used for encoding the multivariate feature map.</p> <p> TYPE: <code>MultivariateStrategy</code> </p> <code>i</code> <p>The feature index.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Iterable</code> <p>List[int]: The list of target qubits.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the feature map strategy is not implemented.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def get_fm_qubits(\n    multivariate_strategy: MultivariateStrategy, i: int, n_qubits: int, n_features: int\n) -&gt; Iterable:\n    \"\"\"Returns the list of target qubits for the given feature map strategy and feature index.\n\n    Args:\n        multivariate_strategy (MultivariateStrategy): The strategy used for encoding\n            the multivariate feature map.\n        i (int): The feature index.\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of features.\n\n    Returns:\n        List[int]: The list of target qubits.\n\n    Raises:\n        ValueError: If the feature map strategy is not implemented.\n    \"\"\"\n    if multivariate_strategy == MultivariateStrategy.PARALLEL:\n        n_qubits_per_feature = int(n_qubits / n_features)\n        target_qubits = range(i * n_qubits_per_feature, (i + 1) * n_qubits_per_feature)\n    elif multivariate_strategy == MultivariateStrategy.SERIES:\n        target_qubits = range(0, n_qubits)\n    else:\n        raise ValueError(f\"Multivariate strategy {multivariate_strategy} not implemented.\")\n    return target_qubits\n</code></pre>"},{"location":"api/draw/","title":"Drawing","text":""},{"location":"api/draw/#drawing","title":"Drawing","text":""},{"location":"api/draw/#qadence.draw.display","title":"<code>display(x, qcd=None, layout='LR', theme='light', fill=True, **kwargs)</code>","text":"<p>Display a block, circuit, or quantum model.</p> <p>The <code>kwargs</code> are forwarded to the underlying <code>nx.Graph</code>, so you can e.g. specify the size of the resulting plot via <code>size=\"2,2\"</code> (see examples)</p> PARAMETER DESCRIPTION <code>x</code> <p><code>AbstractBlock</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <p> TYPE: <code>Any</code> </p> <code>qcd</code> <p>Circuit diagram to plot the block into.</p> <p> TYPE: <code>QuantumCircuitDiagram | Cluster | None</code> DEFAULT: <code>None</code> </p> <code>layout</code> <p>Can be either \"LR\" (left-right), or \"TB\" (top-bottom).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'LR'</code> </p> <code>theme</code> <p>Available themes are: [\"light\", \"dark\", \"black\", \"white\"].</p> <p> TYPE: <code>str</code> DEFAULT: <code>'light'</code> </p> <code>fill</code> <p>Whether to fill the passed <code>x</code> with identities.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>kwargs</code> <p>Passed on to <code>nx.Graph</code></p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples: <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\ndisplay(b, size=\"1,1\", theme=\"dark\")\n</code></pre> </p> Source code in <code>qadence/draw/__init__.py</code> <pre><code>def display(\n    x: Any,\n    qcd: QuantumCircuitDiagram | Cluster | None = None,\n    layout: str = \"LR\",\n    theme: str = \"light\",\n    fill: bool = True,\n    **kwargs: Any,\n) -&gt; Graph:\n    \"\"\"Display a block, circuit, or quantum model.\n\n    The `kwargs` are forwarded to\n    the underlying `nx.Graph`, so you can e.g. specify the size of the resulting plot via\n    `size=\"2,2\"` (see examples)\n\n    Arguments:\n        x: `AbstractBlock`, `QuantumCircuit`, or `QuantumModel`.\n        qcd: Circuit diagram to plot the block into.\n        layout: Can be either \"LR\" (left-right), or \"TB\" (top-bottom).\n        theme: Available themes are: [\"light\", \"dark\", \"black\", \"white\"].\n        fill: Whether to fill the passed `x` with identities.\n        kwargs: Passed on to `nx.Graph`\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from qadence import X, Y, kron\n    from qadence.draw import display\n\n    b = kron(X(0), Y(1))\n    def display(*args, **kwargs): return args # markdown-exec: hide\n    display(b, size=\"1,1\", theme=\"dark\")\n    ```\n    \"\"\"\n    return make_diagram(x, **kwargs).show()\n</code></pre>"},{"location":"api/draw/#qadence.draw.savefig","title":"<code>savefig(x, filename, *args, **kwargs)</code>","text":"<p>Save a block, circuit, or quantum model to file. Accepts the same args/kwargs as <code>display</code>.</p> PARAMETER DESCRIPTION <code>x</code> <p><code>AbstractBlock</code>, <code>QuantumCircuit</code>, or <code>QuantumModel</code>.</p> <p> TYPE: <code>Any</code> </p> <code>filename</code> <p>Should end in svg/png.</p> <p> TYPE: <code>str</code> </p> <code>args</code> <p>Same as in <code>display</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>kwargs</code> <p>Same as in <code>display</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Examples: <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\nsavefig(b, \"test.svg\", size=\"1,1\", theme=\"dark\")\n</code></pre> </p> Source code in <code>qadence/draw/__init__.py</code> <pre><code>def savefig(x: Any, filename: str, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Save a block, circuit, or quantum model to file. Accepts the same args/kwargs as `display`.\n\n    Arguments:\n        x: `AbstractBlock`, `QuantumCircuit`, or `QuantumModel`.\n        filename: Should end in svg/png.\n        args: Same as in `display`.\n        kwargs: Same as in `display`.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" html=\"1\"\n    from qadence import X, Y, kron\n    from qadence.draw import display\n\n    b = kron(X(0), Y(1))\n    def savefig(*args, **kwargs): return args # markdown-exec: hide\n    savefig(b, \"test.svg\", size=\"1,1\", theme=\"dark\")\n    ```\n    \"\"\"\n    make_diagram(x, *args, **kwargs).savefig(filename)\n</code></pre>"},{"location":"api/execution/","title":"Execution","text":""},{"location":"api/execution/#qadence.execution.expectation","title":"<code>expectation(x, observable, values={}, state=None, backend=BackendName.PYQTORCH, diff_mode=None, noise=None, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.expectation</code> method.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>observable</code> <p>Observable(s) w.r.t. which the expectation is computed.</p> <p> TYPE: <code>Union[list[AbstractBlock], AbstractBlock]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>Which differentiation mode to use.</p> <p> TYPE: <code>Union[DiffMode, str, None]</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> <pre><code>from qadence import RX, Z, Register, QuantumCircuit, expectation\n\nreg = Register(1)\nblock = RX(0, 0.5)\nobservable = Z(0)\ncirc = QuantumCircuit(reg, block)\n\n# You can compute the expectation for a\n# QuantumCircuit with a given observable.\nexpectation(circ, observable)\n\n# You can also use only a block.\n# In this case the register is constructed automatically to\n# Register.line(block.n_qubits)\nexpectation(block, observable)\n\n# Or a register and block\nexpectation(reg, block, observable)\n</code></pre> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef expectation(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    observable: Union[list[AbstractBlock], AbstractBlock],\n    values: dict = {},\n    state: Tensor = None,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: Union[DiffMode, str, None] = None,\n    noise: Union[Noise, None] = None,\n    endianness: Endianness = Endianness.BIG,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n    \"\"\"Convenience wrapper for the `QuantumModel.expectation` method.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        observable: Observable(s) w.r.t. which the expectation is computed.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        diff_mode: Which differentiation mode to use.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n\n    Returns:\n        A wavefunction\n\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import RX, Z, Register, QuantumCircuit, expectation\n\n    reg = Register(1)\n    block = RX(0, 0.5)\n    observable = Z(0)\n    circ = QuantumCircuit(reg, block)\n\n    # You can compute the expectation for a\n    # QuantumCircuit with a given observable.\n    expectation(circ, observable)\n\n    # You can also use only a block.\n    # In this case the register is constructed automatically to\n    # Register.line(block.n_qubits)\n    expectation(block, observable)\n\n    # Or a register and block\n    expectation(reg, block, observable)\n    ```\n    \"\"\"\n\n    raise ValueError(f\"Cannot execute {type(x)}\")\n</code></pre>"},{"location":"api/execution/#qadence.execution.run","title":"<code>run(x, *args, values={}, state=None, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.run</code> method.</p> <p>This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef run(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    *args: Any,\n    values: dict = {},\n    state: Tensor = None,\n    backend: BackendName = BackendName.PYQTORCH,\n    endianness: Endianness = Endianness.BIG,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n    \"\"\"Convenience wrapper for the `QuantumModel.run` method.\n\n     This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n\n    Returns:\n        A wavefunction\n    \"\"\"\n    raise ValueError(f\"Cannot run {type(x)}\")\n</code></pre>"},{"location":"api/execution/#qadence.execution.sample","title":"<code>sample(x, *args, values={}, state=None, n_shots=100, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, noise=None, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.sample</code> method.</p> PARAMETER DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Union[Tensor, None]</code> DEFAULT: <code>None</code> </p> <code>n_shots</code> <p>Number of shots per element in the batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>noise</code> <p>The noise model to use if any.</p> <p> TYPE: <code>Union[Noise, None]</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef sample(\n    x: Union[QuantumCircuit, AbstractBlock, Register, int],\n    *args: Any,\n    values: dict = {},\n    state: Union[Tensor, None] = None,\n    n_shots: int = 100,\n    backend: BackendName = BackendName.PYQTORCH,\n    endianness: Endianness = Endianness.BIG,\n    noise: Union[Noise, None] = None,\n    configuration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; list[Counter]:\n    \"\"\"Convenience wrapper for the `QuantumModel.sample` method.\n\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        n_shots: Number of shots per element in the batch.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        noise: The noise model to use if any.\n        configuration: The backend configuration.\n\n    Returns:\n        A list of Counter instances with the sample results\n    \"\"\"\n    raise ValueError(f\"Cannot sample from {type(x)}\")\n</code></pre>"},{"location":"api/ml_tools/","title":"QML tools","text":""},{"location":"api/ml_tools/#ml-tools","title":"ML Tools","text":"<p>This module implements gradient-free and gradient-based training loops for torch Modules and QuantumModel. It also implements the QNN class.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig","title":"<code>AnsatzConfig(depth=1, ansatz_type=AnsatzType.HEA, ansatz_strategy=Strategy.DIGITAL, strategy_args=dict(), param_prefix='theta', tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.ansatz_strategy","title":"<code>ansatz_strategy: Strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ansatz strategy.</p> <p><code>Strategy.DIGITAL</code> for fully digital ansatz. Required if <code>ansatz_type</code> is <code>AnsatzType.IIA</code>. <code>Strategy.SDAQC</code> for analog entangling block. <code>Strategy.RYDBERG</code> for fully rydberg hea ansatz.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.ansatz_type","title":"<code>ansatz_type: AnsatzType = AnsatzType.HEA</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>What type of ansatz.</p> <p><code>AnsatzType.HEA</code> for Hardware Efficient Ansatz. <code>AnsatzType.IIA</code> for Identity intialized Ansatz.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.depth","title":"<code>depth: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of layers of the ansatz.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.param_prefix","title":"<code>param_prefix: str = 'theta'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The base bame of the variational parameter.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.strategy_args","title":"<code>strategy_args: dict = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A dictionary containing keyword arguments to the function creating the ansatz.</p> <p>Details about each below.</p> <p>For <code>Strategy.DIGITAL</code> strategy, accepts the following:     periodic (bool): if the qubits should be linked periodically.         periodic=False is not supported in emu-c.     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): 2-qubit entangling operation.         Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlld rotations         will have variational parameters on the rotation angles.         Defaults to CNOT</p> <p>For <code>Strategy.SDAQC</code> strategy, accepts the following:     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): Hamiltonian generator for the         analog entangling layer. Time parameter is considered variational.         Defaults to NN interaction.</p> <p>For <code>Strategy.RYDBERG</code> strategy, accepts the following:     addressable_detuning: whether to turn on the trainable semi-local addressing pattern         on the detuning (n_i terms in the Hamiltonian).         Defaults to True.     addressable_drive: whether to turn on the trainable semi-local addressing pattern         on the drive (sigma_i^x terms in the Hamiltonian).         Defaults to False.     tunable_phase: whether to have a tunable phase to get both sigma^x and sigma^y rotations         in the drive term. If False, only a sigma^x term will be included in the drive part         of the Hamiltonian generator.         Defaults to False.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.AnsatzConfig.tag","title":"<code>tag: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the ansatz.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.Callback","title":"<code>Callback(callback, callback_condition=None, modify_optimize_result=None, called_every=1, call_before_opt=False, call_end_epoch=True, call_after_opt=False, call_during_eval=False)</code>","text":"<p>Callback functions are calling in train functions.</p> <p>Each callback function should take at least as first input an OptimizeResult instance.</p> <p>Note: when setting call_after_opt to True, we skip verifying iteration % called_every == 0.</p> ATTRIBUTE DESCRIPTION <code>callback</code> <p>Callback function accepting an OptimizeResult as first argument.</p> <p> TYPE: <code>CallbackFunction</code> </p> <code>callback_condition</code> <p>Function that conditions the call to callback. Defaults to None.</p> <p> TYPE: <code>CallbackConditionFunction | None</code> </p> <code>modify_optimize_result</code> <p>Function that modify the OptimizeResult before callback. For instance, one can change the <code>extra</code> (dict) argument to be used in callback. If a dict is provided, the <code>extra</code> field of OptimizeResult is updated with the dict.</p> <p> TYPE: <code>CallbackFunction | dict[str, Any] | None</code> </p> <code>called_every</code> <p>Callback to be called each <code>called_every</code> epoch. Defaults to 1. If callback_condition is None, we set callback_condition to returns True when iteration % called_every == 0.</p> <p> TYPE: <code>int</code> </p> <code>call_before_opt</code> <p>If true, callback is applied before training. Defaults to False.</p> <p> TYPE: <code>bool</code> </p> <code>call_end_epoch</code> <p>If true, callback is applied during training, after an epoch is performed. Defaults to True.</p> <p> TYPE: <code>bool</code> </p> <code>call_after_opt</code> <p>If true, callback is applied after training. Defaults to False.</p> <p> TYPE: <code>bool</code> </p> <code>call_during_eval</code> <p>If true, callback is applied during evaluation. Defaults to False.</p> <p> TYPE: <code>bool</code> </p> <p>Initialized Callback.</p> PARAMETER DESCRIPTION <code>callback</code> <p>Callback function accepting an OptimizeResult as ifrst argument.</p> <p> TYPE: <code>CallbackFunction</code> </p> <code>callback_condition</code> <p>Function that conditions the call to callback. Defaults to None.</p> <p> TYPE: <code>CallbackConditionFunction | None</code> DEFAULT: <code>None</code> </p> <code>modify_optimize_result</code> <p>Function that modify the OptimizeResult before callback. If a dict is provided, this updates the <code>extra</code> field of OptimizeResult.</p> <p> TYPE: <code>CallbackFunction | dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>called_every</code> <p>Callback to be called each <code>called_every</code> epoch. Defaults to 1. If callback_condition is None, we set callback_condition to returns True when iteration % called_every == 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>call_before_opt</code> <p>If true, callback is applied before training. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>call_end_epoch</code> <p>If true, callback is applied during training, after an epoch is performed. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>call_after_opt</code> <p>If true, callback is applied after training. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>call_during_eval</code> <p>If true, callback is applied during evaluation. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>qadence/ml_tools/config.py</code> <pre><code>def __init__(\n    self,\n    callback: CallbackFunction,\n    callback_condition: CallbackConditionFunction | None = None,\n    modify_optimize_result: CallbackFunction | dict[str, Any] | None = None,\n    called_every: int = 1,\n    call_before_opt: bool = False,\n    call_end_epoch: bool = True,\n    call_after_opt: bool = False,\n    call_during_eval: bool = False,\n) -&gt; None:\n    \"\"\"Initialized Callback.\n\n    Args:\n        callback (CallbackFunction): Callback function accepting an\n            OptimizeResult as ifrst argument.\n        callback_condition (CallbackConditionFunction | None, optional): Function that\n            conditions the call to callback. Defaults to None.\n        modify_optimize_result (CallbackFunction | dict[str, Any] | None , optional):\n            Function that modify the OptimizeResult before callback. If a dict\n            is provided, this updates the `extra` field of OptimizeResult.\n        called_every (int, optional): Callback to be called each `called_every` epoch.\n            Defaults to 1.\n            If callback_condition is None, we set\n            callback_condition to returns True when iteration % called_every == 0.\n        call_before_opt (bool, optional): If true, callback is applied before training.\n            Defaults to False.\n        call_end_epoch (bool, optional): If true, callback is applied during training,\n            after an epoch is performed. Defaults to True.\n        call_after_opt (bool, optional): If true, callback is applied after training.\n            Defaults to False.\n        call_during_eval (bool, optional): If true, callback is applied during evaluation.\n            Defaults to False.\n    \"\"\"\n    self.callback = callback\n    self.call_before_opt = call_before_opt\n    self.call_end_epoch = call_end_epoch\n    self.call_after_opt = call_after_opt\n    self.call_during_eval = call_during_eval\n\n    if called_every &lt;= 0:\n        raise ValueError(\"Please provide a strictly positive `called_every` argument.\")\n    self.called_every = called_every\n\n    if callback_condition is None:\n        self.callback_condition = lambda opt_result: True\n    else:\n        self.callback_condition = callback_condition\n\n    if modify_optimize_result is None:\n        self.modify_optimize_result = lambda opt_result: opt_result\n    elif isinstance(modify_optimize_result, dict):\n\n        def update_extra(opt_result: OptimizeResult) -&gt; OptimizeResult:\n            opt_result.extra.update(modify_optimize_result)\n            return opt_result\n\n        self.modify_optimize_result = update_extra\n    else:\n        self.modify_optimize_result = modify_optimize_result\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.config.Callback.__call__","title":"<code>__call__(opt_result, is_last_iteration=False)</code>","text":"<p>Apply callback if conditions are met.</p> <p>Note that the current result may be modified by specifying a function <code>modify_optimize_result</code> for instance to add inputs to the <code>extra</code> argument of the current OptimizeResult.</p> PARAMETER DESCRIPTION <code>opt_result</code> <p>Current result.</p> <p> TYPE: <code>OptimizeResult</code> </p> <code>is_last_iteration</code> <p>When True, avoid verifying modulo. Defaults to False. Useful when call_after_opt is True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The result of the callback.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/config.py</code> <pre><code>def __call__(self, opt_result: OptimizeResult, is_last_iteration: bool = False) -&gt; Any:\n    \"\"\"Apply callback if conditions are met.\n\n    Note that the current result may be modified by specifying a function\n    `modify_optimize_result` for instance to add inputs to the `extra` argument\n    of the current OptimizeResult.\n\n    Args:\n        opt_result (OptimizeResult): Current result.\n        is_last_iteration (bool, optional): When True,\n            avoid verifying modulo. Defaults to False.\n            Useful when call_after_opt is True.\n\n    Returns:\n        Any: The result of the callback.\n    \"\"\"\n    opt_result = self.modify_optimize_result(opt_result)\n    if opt_result.iteration % self.called_every == 0 and self.callback_condition(opt_result):\n        return self.callback(opt_result)\n    if is_last_iteration and self.callback_condition(opt_result):\n        return self.callback(opt_result)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig","title":"<code>FeatureMapConfig(num_features=0, basis_set=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multivariate_strategy=MultivariateStrategy.PARALLEL, feature_map_strategy=Strategy.DIGITAL, param_prefix=None, num_repeats=0, operation=None, inputs=None, tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.basis_set","title":"<code>basis_set: BasisSet | dict[str, BasisSet] = BasisSet.FOURIER</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basis set for feature encoding.</p> <p>Takes qadence.BasisSet. Give a single BasisSet to use the same for all features. Give a dict of (str, BasisSet) where the key is the name of the variable and the value is the BasisSet to use for encoding that feature. BasisSet.FOURIER for Fourier encoding. BasisSet.CHEBYSHEV for Chebyshev encoding.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.feature_map_strategy","title":"<code>feature_map_strategy: Strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Strategy for feature map.</p> <p>Accepts DIGITAL, ANALOG or RYDBERG. Defaults to DIGITAL. If the strategy is incompatible with the <code>operation</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.feature_range","title":"<code>feature_range: tuple[float, float] | dict[str, tuple[float, float]] | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data that the input data is assumed to come from.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the feature range to use for that feature.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.inputs","title":"<code>inputs: list[Basic | str] | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List that indicates the order of variables of the tensors that are passed.</p> <p>Optional if a single feature is being encoded, required otherwise. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.multivariate_strategy","title":"<code>multivariate_strategy: MultivariateStrategy = MultivariateStrategy.PARALLEL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The encoding strategy in case of multi-variate function.</p> <p>Takes qadence.MultivariateStrategy. If PARALLEL, the features are encoded in one block of rotation gates with the register being split in sub-registers for each feature. If SERIES, the features are encoded sequentially using the full register for each feature, with an ansatz block between them. PARALLEL is allowed only for DIGITAL <code>feature_map_strategy</code>.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.num_features","title":"<code>num_features: int = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature parameters to be encoded.</p> <p>Defaults to 0. Thus, no feature parameters are encoded.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.num_repeats","title":"<code>num_repeats: int | dict[str, int] = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature map layers repeated in the data reuploading step.</p> <p>If all features are to be repeated the same number of times, then can give a single <code>int</code>. For different number of repetitions for each feature, provide a dict of (str, int) where the key is the name of the variable and the value is the number of repetitions for that feature. This amounts to the number of additional reuploads. So if <code>num_repeats</code> is N, the data gets uploaded N+1 times. Defaults to no repetition.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.operation","title":"<code>operation: Callable[[Parameter | Basic], AnalogBlock] | Type[RX] | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of operation.</p> <p>Choose among the analog or digital rotations or a custom callable function returning an AnalogBlock instance. If the type of operation is incompatible with the <code>strategy</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.param_prefix","title":"<code>param_prefix: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String prefix to create trainable parameters in Feature Map.</p> <p>A string prefix to create trainable parameters multiplying the feature parameter inside the feature-encoding function. Note that currently this does not take into account the domain of the feature-encoding function. Defaults to <code>None</code> and thus, the feature map is not trainable. Note that this is separate from the name of the parameter. The user can provide a single prefix for all features, and it will be appended by appropriate feature name automatically.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.reupload_scaling","title":"<code>reupload_scaling: ReuploadScaling | dict[str, ReuploadScaling] = ReuploadScaling.CONSTANT</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Scaling for encoding the same feature on different qubits.</p> <p>Scaling used to encode the same feature on different qubits in the same layer of the feature maps. Takes qadence.ReuploadScaling. Give a single ReuploadScaling to use the same for all features. Give a dict of (str, ReuploadScaling) where the key is the name of the variable and the value is the ReuploadScaling to use for encoding that feature. ReuploadScaling.CONSTANT for constant scaling. ReuploadScaling.TOWER for linearly increasing scaling. ReuploadScaling.EXP for exponentially increasing scaling.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.tag","title":"<code>tag: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the feature map.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.FeatureMapConfig.target_range","title":"<code>target_range: tuple[float, float] | dict[str, tuple[float, float]] | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data the data encoder assumes as natural range.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the target range to use for that feature.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.MLFlowConfig","title":"<code>MLFlowConfig()</code>","text":"<p>Configuration for mlflow tracking.</p> <p>Example:</p> <pre><code>export MLFLOW_TRACKING_URI=tracking_uri\nexport MLFLOW_EXPERIMENT=experiment_name\nexport MLFLOW_RUN_NAME=run_name\n</code></pre> Source code in <code>qadence/ml_tools/config.py</code> <pre><code>def __init__(self) -&gt; None:\n    import mlflow\n\n    self.tracking_uri: str = os.getenv(\"MLFLOW_TRACKING_URI\", \"\")\n    \"\"\"The URI of the mlflow tracking server.\n\n    An empty string, or a local file path, prefixed with file:/.\n    Data is stored locally at the provided file (or ./mlruns if empty).\n    \"\"\"\n\n    self.experiment_name: str = os.getenv(\"MLFLOW_EXPERIMENT\", str(uuid4()))\n    \"\"\"The name of the experiment.\n\n    If None or empty, a new experiment is created with a random UUID.\n    \"\"\"\n\n    self.run_name: str = os.getenv(\"MLFLOW_RUN_NAME\", str(uuid4()))\n    \"\"\"The name of the run.\"\"\"\n\n    mlflow.set_tracking_uri(self.tracking_uri)\n\n    # activate existing or create experiment\n    exp_filter_string = f\"name = '{self.experiment_name}'\"\n    if not mlflow.search_experiments(filter_string=exp_filter_string):\n        mlflow.create_experiment(name=self.experiment_name)\n\n    self.experiment = mlflow.set_experiment(self.experiment_name)\n    self.run = mlflow.start_run(run_name=self.run_name, nested=False)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.config.MLFlowConfig.experiment_name","title":"<code>experiment_name: str = os.getenv('MLFLOW_EXPERIMENT', str(uuid4()))</code>  <code>instance-attribute</code>","text":"<p>The name of the experiment.</p> <p>If None or empty, a new experiment is created with a random UUID.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.MLFlowConfig.run_name","title":"<code>run_name: str = os.getenv('MLFLOW_RUN_NAME', str(uuid4()))</code>  <code>instance-attribute</code>","text":"<p>The name of the run.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.MLFlowConfig.tracking_uri","title":"<code>tracking_uri: str = os.getenv('MLFLOW_TRACKING_URI', '')</code>  <code>instance-attribute</code>","text":"<p>The URI of the mlflow tracking server.</p> <p>An empty string, or a local file path, prefixed with file:/. Data is stored locally at the provided file (or ./mlruns if empty).</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig","title":"<code>TrainConfig(max_iter=10000, print_every=1000, write_every=50, checkpoint_every=5000, plot_every=5000, callbacks=lambda: list()(), log_model=False, folder=None, create_subfolder_per_run=False, checkpoint_best_only=False, val_every=None, val_epsilon=1e-05, validation_criterion=None, trainstop_criterion=None, batch_size=1, verbose=True, tracking_tool=ExperimentTrackingTool.TENSORBOARD, hyperparams=dict(), plotting_functions=tuple())</code>  <code>dataclass</code>","text":"<p>Default config for the train function.</p> <p>The default value of each field can be customized with the constructor:</p> <pre><code>from qadence.ml_tools import TrainConfig\nc = TrainConfig(folder=\"/tmp/train\")\n</code></pre> <pre><code>TrainConfig(max_iter=10000, print_every=1000, write_every=50, checkpoint_every=5000, plot_every=5000, callbacks=[], log_model=False, folder=PosixPath('/tmp/train'), create_subfolder_per_run=False, checkpoint_best_only=False, val_every=None, val_epsilon=1e-05, validation_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7f4f3333f400&gt;, trainstop_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7f4f3333ecb0&gt;, batch_size=1, verbose=True, tracking_tool=&lt;ExperimentTrackingTool.TENSORBOARD: 'tensorboard'&gt;, hyperparams={}, plotting_functions=())\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.batch_size","title":"<code>batch_size: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The batch_size to use when passing a list/tuple of torch.Tensors.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.callbacks","title":"<code>callbacks: list[Callback] = field(default_factory=lambda: list())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of callbacks.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_best_only","title":"<code>checkpoint_best_only: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint only if a metric has improved.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_every","title":"<code>checkpoint_every: int = 5000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint.</p> <p>Set to 0 to disable</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.create_subfolder_per_run","title":"<code>create_subfolder_per_run: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs stored in subfolder with name <code>&lt;timestamp&gt;_&lt;PID&gt;</code>.</p> <p>Prevents continuing from previous checkpoint, useful for fast prototyping.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.folder","title":"<code>folder: Path | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs folder.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.hyperparams","title":"<code>hyperparams: dict = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hyperparameters to track.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.log_model","title":"<code>log_model: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Logs a serialised version of the model.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.max_iter","title":"<code>max_iter: int = 10000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of training iterations.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.plot_every","title":"<code>plot_every: int = 5000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write figures.</p> <p>Set to 0 to disable</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.plotting_functions","title":"<code>plotting_functions: tuple[LoggablePlotFunction, ...] = field(default_factory=tuple)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Functions for in-train plotting.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.print_every","title":"<code>print_every: int = 1000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Print loss/metrics.</p> <p>Set to 0 to disable</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.tracking_tool","title":"<code>tracking_tool: ExperimentTrackingTool = ExperimentTrackingTool.TENSORBOARD</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The tracking tool of choice.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.trainstop_criterion","title":"<code>trainstop_criterion: Callable | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given training stopping metric is satisfied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.val_epsilon","title":"<code>val_epsilon: float = 1e-05</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Safety margin to check if validation loss is smaller than the lowest.</p> <p>validation loss across previous iterations.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.val_every","title":"<code>val_every: int | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Calculate validation metric.</p> <p>If None, validation check is not performed.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.validation_criterion","title":"<code>validation_criterion: Callable | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given validation metric is satisfied.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.verbose","title":"<code>verbose: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether or not to print out metrics values during training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.TrainConfig.write_every","title":"<code>write_every: int = 50</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write loss and metrics with the tracking tool.</p> <p>Set to 0 to disable</p>"},{"location":"api/ml_tools/#qadence.ml_tools.config.run_callbacks","title":"<code>run_callbacks(callback_iterable, opt_res, is_last_iteration=False)</code>","text":"<p>Run a list of Callback given the current OptimizeResult.</p> <p>Used in train functions.</p> PARAMETER DESCRIPTION <code>callback_iterable</code> <p>Iterable of Callbacks</p> <p> TYPE: <code>list[Callback]</code> </p> <code>opt_res</code> <p>Current optimization result,</p> <p> TYPE: <code>OptimizeResult</code> </p> <code>is_last_iteration</code> <p>Whether we reached the last iteration or not. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>qadence/ml_tools/config.py</code> <pre><code>def run_callbacks(\n    callback_iterable: list[Callback], opt_res: OptimizeResult, is_last_iteration: bool = False\n) -&gt; None:\n    \"\"\"Run a list of Callback given the current OptimizeResult.\n\n    Used in train functions.\n\n    Args:\n        callback_iterable (list[Callback]): Iterable of Callbacks\n        opt_res (OptimizeResult): Current optimization result,\n        is_last_iteration (bool, optional): Whether we reached the last iteration or not.\n            Defaults to False.\n    \"\"\"\n    for callback in callback_iterable:\n        callback(opt_res, is_last_iteration)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.get_parameters","title":"<code>get_parameters(model)</code>","text":"<p>Retrieve all trainable model parameters in a single vector.</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a 1-dimensional tensor with the parameters</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def get_parameters(model: Module) -&gt; Tensor:\n    \"\"\"Retrieve all trainable model parameters in a single vector.\n\n    Args:\n        model (Module): the input PyTorch model\n\n    Returns:\n        Tensor: a 1-dimensional tensor with the parameters\n    \"\"\"\n    ps = [p.reshape(-1) for p in model.parameters() if p.requires_grad]\n    return torch.concat(ps)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.num_parameters","title":"<code>num_parameters(model)</code>","text":"<p>Return the total number of parameters of the given model.</p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def num_parameters(model: Module) -&gt; int:\n    \"\"\"Return the total number of parameters of the given model.\"\"\"\n    return len(get_parameters(model))\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.parameters.set_parameters","title":"<code>set_parameters(model, theta)</code>","text":"<p>Set all trainable parameters of a model from a single vector.</p> <p>Notice that this function assumes prior knowledge of right number of parameters in the model</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> <code>theta</code> <p>the parameters to assign</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def set_parameters(model: Module, theta: Tensor) -&gt; None:\n    \"\"\"Set all trainable parameters of a model from a single vector.\n\n    Notice that this function assumes prior knowledge of right number\n    of parameters in the model\n\n    Args:\n        model (Module): the input PyTorch model\n        theta (Tensor): the parameters to assign\n    \"\"\"\n\n    with torch.no_grad():\n        idx = 0\n        for ps in model.parameters():\n            if ps.requires_grad:\n                n = torch.numel(ps)\n                if ps.ndim == 0:\n                    ps[()] = theta[idx : idx + n]\n                else:\n                    ps[:] = theta[idx : idx + n].reshape(ps.size())\n                idx += n\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.optimize_step.optimize_step","title":"<code>optimize_step(model, optimizer, loss_fn, xs, device=None, dtype=None)</code>","text":"<p>Default Torch optimize step with closure.</p> <p>This is the default optimization step which should work for most of the standard use cases of optimization of Torch models</p> PARAMETER DESCRIPTION <code>model</code> <p>The input model</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The chosen Torch optimizer</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>the input data. If None it means that the given model does not require any input data</p> <p> TYPE: <code>dict | list | Tensor | None</code> </p> <code>device</code> <p>A target device to run computation on.</p> <p> TYPE: <code>device</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Data type for xs conversion.</p> <p> TYPE: <code>dtype</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>tuple containing the computed loss value, and a dictionary with the collected metrics.</p> <p> TYPE: <code>tuple[Tensor | float, dict | None]</code> </p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def optimize_step(\n    model: Module,\n    optimizer: Optimizer,\n    loss_fn: Callable,\n    xs: dict | list | torch.Tensor | None,\n    device: torch.device = None,\n    dtype: torch.dtype = None,\n) -&gt; tuple[torch.Tensor | float, dict | None]:\n    \"\"\"Default Torch optimize step with closure.\n\n    This is the default optimization step which should work for most\n    of the standard use cases of optimization of Torch models\n\n    Args:\n        model (Module): The input model\n        optimizer (Optimizer): The chosen Torch optimizer\n        loss_fn (Callable): A custom loss function\n        xs (dict | list | torch.Tensor | None): the input data. If None it means\n            that the given model does not require any input data\n        device (torch.device): A target device to run computation on.\n        dtype (torch.dtype): Data type for xs conversion.\n\n    Returns:\n        tuple: tuple containing the computed loss value, and a dictionary with\n            the collected metrics.\n    \"\"\"\n\n    loss, metrics = None, {}\n    xs_to_device = data_to_device(xs, device=device, dtype=dtype)\n\n    def closure() -&gt; Any:\n        # NOTE: We need the nonlocal as we can't return a metric dict and\n        # because e.g. LBFGS calls this closure multiple times but for some\n        # reason the returned loss is always the first one...\n        nonlocal metrics, loss\n        optimizer.zero_grad()\n        loss, metrics = loss_fn(model, xs_to_device)\n        loss.backward(retain_graph=True)\n        return loss.item()\n\n    optimizer.step(closure)\n    # return the loss/metrics that are being mutated inside the closure...\n    return loss, metrics\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn, device=None, optimize_step=optimize_step, dtype=None)</code>","text":"<p>Runs the training loop with gradient-based optimizer.</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to train.</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>dataloader of different types. If None, no data is required by the model</p> <p> TYPE: <code>Union[None, DataLoader, DictDataLoader]</code> </p> <code>optimizer</code> <p>The optimizer to use.</p> <p> TYPE: <code>Optimizer</code> </p> <code>config</code> <p><code>TrainConfig</code> with additional training options.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float], ...)</p> <p> TYPE: <code>Callable</code> </p> <code>device</code> <p>String defining device to train on, pass 'cuda' for GPU.</p> <p> TYPE: <code>device</code> DEFAULT: <code>None</code> </p> <code>optimize_step</code> <p>Customizable optimization callback which is called at every iteration.= The function must have the signature <code>optimize_step(model, optimizer, loss_fn, xs, device=\"cpu\")</code>.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>optimize_step</code> </p> <code>dtype</code> <p>The dtype to use for the data.</p> <p> TYPE: <code>dtype</code> DEFAULT: <code>None</code> </p> <p>Example: <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence import Parameter, QuantumCircuit, Z\nfrom qadence import hamiltonian_factory, hea, feature_map, chain\nfrom qadence import QNN\nfrom qadence.ml_tools import TrainConfig, train_with_grad, to_dataloader\n\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\n\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n\n## lets prepare the train routine\n\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    x, y = data[0], data[1]\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ntmp_path = Path(\"/tmp\")\nn_epochs = 5\nbatch_size = 25\nconfig = TrainConfig(\n    folder=tmp_path,\n    max_iter=n_epochs,\n    checkpoint_every=100,\n    write_every=100,\n)\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ndata = to_dataloader(x, y, batch_size=batch_size, infinite=True)\ntrain_with_grad(model, data, optimizer, config, loss_fn=loss_fn)\n</code></pre> </p> Source code in <code>qadence/ml_tools/train_grad.py</code> <pre><code>def train(\n    model: Module,\n    dataloader: Union[None, DataLoader, DictDataLoader],\n    optimizer: Optimizer,\n    config: TrainConfig,\n    loss_fn: Callable,\n    device: torch_device = None,\n    optimize_step: Callable = optimize_step,\n    dtype: torch_dtype = None,\n) -&gt; tuple[Module, Optimizer]:\n    \"\"\"Runs the training loop with gradient-based optimizer.\n\n    Assumes that `loss_fn` returns a tuple of (loss,\n    metrics: dict), where `metrics` is a dict of scalars. Loss and metrics are\n    written to tensorboard. Checkpoints are written every\n    `config.checkpoint_every` steps (and after the last training step).  If a\n    checkpoint is found at `config.folder` we resume training from there.  The\n    tensorboard logs can be viewed via `tensorboard --logdir /path/to/folder`.\n\n    Args:\n        model: The model to train.\n        dataloader: dataloader of different types. If None, no data is required by\n            the model\n        optimizer: The optimizer to use.\n        config: `TrainConfig` with additional training options.\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float], ...)\n        device: String defining device to train on, pass 'cuda' for GPU.\n        optimize_step: Customizable optimization callback which is called at every iteration.=\n            The function must have the signature `optimize_step(model,\n            optimizer, loss_fn, xs, device=\"cpu\")`.\n        dtype: The dtype to use for the data.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\"\n    from pathlib import Path\n    import torch\n    from itertools import count\n    from qadence import Parameter, QuantumCircuit, Z\n    from qadence import hamiltonian_factory, hea, feature_map, chain\n    from qadence import QNN\n    from qadence.ml_tools import TrainConfig, train_with_grad, to_dataloader\n\n    n_qubits = 2\n    fm = feature_map(n_qubits)\n    ansatz = hea(n_qubits=n_qubits, depth=3)\n    observable = hamiltonian_factory(n_qubits, detuning = Z)\n    circuit = QuantumCircuit(n_qubits, fm, ansatz)\n\n    model = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\n    batch_size = 1\n    input_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\n    pred = model(input_values)\n\n    ## lets prepare the train routine\n\n    cnt = count()\n    criterion = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\n    def loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n        next(cnt)\n        x, y = data[0], data[1]\n        out = model(x)\n        loss = criterion(out, y)\n        return loss, {}\n\n    tmp_path = Path(\"/tmp\")\n    n_epochs = 5\n    batch_size = 25\n    config = TrainConfig(\n        folder=tmp_path,\n        max_iter=n_epochs,\n        checkpoint_every=100,\n        write_every=100,\n    )\n    x = torch.linspace(0, 1, batch_size).reshape(-1, 1)\n    y = torch.sin(x)\n    data = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n    train_with_grad(model, data, optimizer, config, loss_fn=loss_fn)\n    ```\n    \"\"\"\n    # load available checkpoint\n    init_iter = 0\n    log_device = \"cpu\" if device is None else device\n    if config.folder:\n        model, optimizer, init_iter = load_checkpoint(\n            config.folder, model, optimizer, device=log_device\n        )\n        logger.debug(f\"Loaded model and optimizer from {config.folder}\")\n\n    # Move model to device before optimizer is loaded\n    if isinstance(model, DataParallel):\n        model = model.module.to(device=device, dtype=dtype)\n    else:\n        model = model.to(device=device, dtype=dtype)\n    # initialize tracking tool\n    if config.tracking_tool == ExperimentTrackingTool.TENSORBOARD:\n        writer = SummaryWriter(config.folder, purge_step=init_iter)\n    else:\n        writer = importlib.import_module(\"mlflow\")\n\n    perform_val = isinstance(config.val_every, int)\n    if perform_val:\n        if not isinstance(dataloader, DictDataLoader):\n            raise ValueError(\n                \"If `config.val_every` is provided as an integer, dataloader must\"\n                \"be an instance of `DictDataLoader`.\"\n            )\n        iter_keys = dataloader.dataloaders.keys()\n        if \"train\" not in iter_keys or \"val\" not in iter_keys:\n            raise ValueError(\n                \"If `config.val_every` is provided as an integer, the dictdataloader\"\n                \"must have `train` and `val` keys to access the respective dataloaders.\"\n            )\n        val_dataloader = dataloader.dataloaders[\"val\"]\n        dataloader = dataloader.dataloaders[\"train\"]\n\n    ## Training\n    progress = Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        BarColumn(),\n        TaskProgressColumn(),\n        TimeRemainingColumn(elapsed_when_finished=True),\n    )\n    data_dtype = None\n    if dtype:\n        data_dtype = float64 if dtype == complex128 else float32\n\n    best_val_loss = math.inf\n\n    if not ((dataloader is None) or isinstance(dataloader, (DictDataLoader, DataLoader))):\n        raise NotImplementedError(\n            f\"Unsupported dataloader type: {type(dataloader)}. \"\n            \"You can use e.g. `qadence.ml_tools.to_dataloader` to build a dataloader.\"\n        )\n\n    def next_loss_iter(dl_iter: Union[None, DataLoader, DictDataLoader]) -&gt; Any:\n        \"\"\"Get loss on the next batch of a dataloader.\n\n            loaded on device if not None.\n\n        Args:\n            dl_iter (Union[None, DataLoader, DictDataLoader]): Dataloader.\n\n        Returns:\n            Any: Loss value\n        \"\"\"\n        xs = next(dl_iter) if dl_iter is not None else None\n        xs_to_device = data_to_device(xs, device=device, dtype=data_dtype)\n        return loss_fn(model, xs_to_device)\n\n    # populate callbacks with already available internal functions\n    # printing, writing and plotting\n    callbacks = config.callbacks\n\n    # printing\n    if config.verbose and config.print_every &gt; 0:\n        # Note that the loss returned by optimize_step\n        # is the value before doing the training step\n        # which is printed accordingly by the previous iteration number\n        callbacks += [\n            Callback(\n                lambda opt_res: print_metrics(opt_res.loss, opt_res.metrics, opt_res.iteration - 1),\n                called_every=config.print_every,\n            )\n        ]\n\n    # plotting\n    callbacks += [\n        Callback(\n            lambda opt_res: plot_tracker(\n                writer,\n                opt_res.model,\n                opt_res.iteration,\n                config.plotting_functions,\n                tracking_tool=config.tracking_tool,\n            ),\n            called_every=config.plot_every,\n            call_before_opt=True,\n        )\n    ]\n\n    # writing metrics\n    # we specify two writers,\n    # to write at evaluation time and before evaluation\n    callbacks += [\n        Callback(\n            lambda opt_res: write_tracker(\n                writer,\n                opt_res.loss,\n                opt_res.metrics,\n                opt_res.iteration - 1,  # loss returned be optimized_step is at -1\n                tracking_tool=config.tracking_tool,\n            ),\n            called_every=config.write_every,\n            call_end_epoch=True,\n        ),\n        Callback(\n            lambda opt_res: write_tracker(\n                writer,\n                opt_res.loss,\n                opt_res.metrics,\n                opt_res.iteration,  # after_opt we match the right loss function\n                tracking_tool=config.tracking_tool,\n            ),\n            called_every=config.write_every,\n            call_end_epoch=False,\n            call_after_opt=True,\n        ),\n    ]\n    if perform_val:\n        callbacks += [\n            Callback(\n                lambda opt_res: write_tracker(\n                    writer,\n                    None,\n                    opt_res.metrics,\n                    opt_res.iteration,\n                    tracking_tool=config.tracking_tool,\n                ),\n                called_every=config.write_every,\n                call_before_opt=True,\n                call_during_eval=True,\n            )\n        ]\n\n    # checkpointing\n    if config.folder and config.checkpoint_every &gt; 0 and not config.checkpoint_best_only:\n        callbacks += [\n            Callback(\n                lambda opt_res: write_checkpoint(\n                    config.folder,  # type: ignore[arg-type]\n                    opt_res.model,\n                    opt_res.optimizer,\n                    opt_res.iteration,\n                ),\n                called_every=config.checkpoint_every,\n                call_before_opt=False,\n                call_after_opt=True,\n            )\n        ]\n\n    if config.folder and config.checkpoint_best_only:\n        callbacks += [\n            Callback(\n                lambda opt_res: write_checkpoint(\n                    config.folder,  # type: ignore[arg-type]\n                    opt_res.model,\n                    opt_res.optimizer,\n                    \"best\",\n                ),\n                called_every=config.checkpoint_every,\n                call_before_opt=True,\n                call_after_opt=True,\n                call_during_eval=True,\n            )\n        ]\n\n    callbacks_before_opt = [\n        callback\n        for callback in callbacks\n        if callback.call_before_opt and not callback.call_during_eval\n    ]\n    callbacks_before_opt_eval = [\n        callback for callback in callbacks if callback.call_before_opt and callback.call_during_eval\n    ]\n\n    with progress:\n        dl_iter = iter(dataloader) if dataloader is not None else None\n\n        # Initial validation evaluation\n        try:\n            opt_result = OptimizeResult(init_iter, model, optimizer)\n            if perform_val:\n                dl_iter_val = iter(val_dataloader) if val_dataloader is not None else None\n                best_val_loss, metrics, *_ = next_loss_iter(dl_iter_val)\n                metrics[\"val_loss\"] = best_val_loss\n                opt_result.metrics = metrics\n                run_callbacks(callbacks_before_opt_eval, opt_result)\n\n            run_callbacks(callbacks_before_opt, opt_result)\n\n        except KeyboardInterrupt:\n            logger.info(\"Terminating training gracefully after the current iteration.\")\n\n        # outer epoch loop\n        init_iter += 1\n        callbacks_end_epoch = [\n            callback\n            for callback in callbacks\n            if callback.call_end_epoch and not callback.call_during_eval\n        ]\n        callbacks_end_epoch_eval = [\n            callback\n            for callback in callbacks\n            if callback.call_end_epoch and callback.call_during_eval\n        ]\n        for iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\n            try:\n                # in case there is not data needed by the model\n                # this is the case, for example, of quantum models\n                # which do not have classical input data (e.g. chemistry)\n                loss, metrics = optimize_step(\n                    model=model,\n                    optimizer=optimizer,\n                    loss_fn=loss_fn,\n                    xs=None if dataloader is None else next(dl_iter),  # type: ignore[arg-type]\n                    device=device,\n                    dtype=data_dtype,\n                )\n                if isinstance(loss, Tensor):\n                    loss = loss.item()\n                opt_result = OptimizeResult(iteration, model, optimizer, loss, metrics)\n                run_callbacks(callbacks_end_epoch, opt_result)\n\n                if perform_val:\n                    if iteration % config.val_every == 0:\n                        val_loss, *_ = next_loss_iter(dl_iter_val)\n                        if config.validation_criterion(val_loss, best_val_loss, config.val_epsilon):  # type: ignore[misc]\n                            best_val_loss = val_loss\n                            metrics[\"val_loss\"] = val_loss\n                            opt_result.metrics = metrics\n\n                            run_callbacks(callbacks_end_epoch_eval, opt_result)\n\n            except KeyboardInterrupt:\n                logger.info(\"Terminating training gracefully after the current iteration.\")\n                break\n\n        # For handling printing/writing the last training loss\n        # as optimize_step does not give the loss value at the last iteration\n        try:\n            loss, metrics, *_ = next_loss_iter(dl_iter)\n            if isinstance(loss, Tensor):\n                loss = loss.item()\n            if perform_val:\n                # reputting val_loss as already evaluated before\n                metrics[\"val_loss\"] = val_loss\n            print_metrics(loss, metrics, iteration)\n\n        except KeyboardInterrupt:\n            logger.info(\"Terminating training gracefully after the current iteration.\")\n\n    # Final callbacks, by default checkpointing and writing\n    opt_result = OptimizeResult(iteration, model, optimizer, loss, metrics)\n    callbacks_after_opt = [callback for callback in callbacks if callback.call_after_opt]\n    run_callbacks(callbacks_after_opt, opt_result, is_last_iteration=True)\n\n    # writing hyperparameters\n    if config.hyperparams:\n        log_tracker(writer, config.hyperparams, metrics, tracking_tool=config.tracking_tool)\n\n    # logging the model\n    if config.log_model:\n        log_model_tracker(writer, model, dataloader, tracking_tool=config.tracking_tool)\n\n    # close tracker\n    if config.tracking_tool == ExperimentTrackingTool.TENSORBOARD:\n        writer.close()\n    elif config.tracking_tool == ExperimentTrackingTool.MLFLOW:\n        writer.end_run()\n\n    return model, optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.train_no_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn)</code>","text":"<p>Runs the training loop with a gradient-free optimizer.</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to train</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>Dataloader constructed via <code>dictdataloader</code></p> <p> TYPE: <code>DictDataLoader | DataLoader | None</code> </p> <code>optimizer</code> <p>The optimizer to use taken from the Nevergrad library. If this is not the case the function will raise an AssertionError</p> <p> TYPE: <code>Optimizer</code> </p> <code>config</code> <p><code>TrainConfig</code> with additional training options.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float])</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_no_grad.py</code> <pre><code>def train(\n    model: Module,\n    dataloader: DictDataLoader | DataLoader | None,\n    optimizer: NGOptimizer,\n    config: TrainConfig,\n    loss_fn: Callable,\n) -&gt; tuple[Module, NGOptimizer]:\n    \"\"\"Runs the training loop with a gradient-free optimizer.\n\n    Assumes that `loss_fn` returns a tuple of (loss, metrics: dict), where\n    `metrics` is a dict of scalars. Loss and metrics are written to\n    tensorboard. Checkpoints are written every `config.checkpoint_every` steps\n    (and after the last training step).  If a checkpoint is found at `config.folder`\n    we resume training from there.  The tensorboard logs can be viewed via\n    `tensorboard --logdir /path/to/folder`.\n\n    Args:\n        model: The model to train\n        dataloader: Dataloader constructed via `dictdataloader`\n        optimizer: The optimizer to use taken from the Nevergrad library. If this is not\n            the case the function will raise an AssertionError\n        config: `TrainConfig` with additional training options.\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float])\n    \"\"\"\n    init_iter = 0\n    if config.folder:\n        model, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\n        logger.debug(f\"Loaded model and optimizer from {config.folder}\")\n\n    def _update_parameters(\n        data: Tensor | None, ng_params: ng.p.Array\n    ) -&gt; tuple[float, dict, ng.p.Array]:\n        loss, metrics = loss_fn(model, data)  # type: ignore[misc]\n        optimizer.tell(ng_params, float(loss))\n        ng_params = optimizer.ask()  # type: ignore [assignment]\n        params = promote_to_tensor(ng_params.value, requires_grad=False)\n        set_parameters(model, params)\n        return loss, metrics, ng_params\n\n    assert loss_fn is not None, \"Provide a valid loss function\"\n    # TODO: support also Scipy optimizers\n    assert isinstance(optimizer, NGOptimizer), \"Use only optimizers from the Nevergrad library\"\n\n    # initialize tracking tool\n    if config.tracking_tool == ExperimentTrackingTool.TENSORBOARD:\n        writer = SummaryWriter(config.folder, purge_step=init_iter)\n    else:\n        writer = importlib.import_module(\"mlflow\")\n\n    # set optimizer configuration and initial parameters\n    optimizer.budget = config.max_iter\n    optimizer.enable_pickling()\n\n    # TODO: Make it GPU compatible if possible\n    params = get_parameters(model).detach().numpy()\n    ng_params = ng.p.Array(init=params)\n\n    if not ((dataloader is None) or isinstance(dataloader, (DictDataLoader, DataLoader))):\n        raise NotImplementedError(\n            f\"Unsupported dataloader type: {type(dataloader)}. \"\n            \"You can use e.g. `qadence.ml_tools.to_dataloader` to build a dataloader.\"\n        )\n\n    # serial training\n    # TODO: Add a parallelization using the num_workers argument in Nevergrad\n    progress = Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        BarColumn(),\n        TaskProgressColumn(),\n        TimeRemainingColumn(elapsed_when_finished=True),\n    )\n\n    # populate callbacks with already available internal functions\n    # printing, writing and plotting\n    callbacks = config.callbacks\n\n    # printing\n    if config.verbose and config.print_every &gt; 0:\n        callbacks += [\n            Callback(\n                lambda opt_res: print_metrics(opt_res.loss, opt_res.metrics, opt_res.iteration),\n                called_every=config.print_every,\n            )\n        ]\n\n    # writing metrics\n    if config.write_every &gt; 0:\n        callbacks += [\n            Callback(\n                lambda opt_res: write_tracker(\n                    writer,\n                    opt_res.loss,\n                    opt_res.metrics,\n                    opt_res.iteration,\n                    tracking_tool=config.tracking_tool,\n                ),\n                called_every=config.write_every,\n                call_after_opt=True,\n            )\n        ]\n\n    # plot tracker\n    if config.plot_every &gt; 0:\n        callbacks += [\n            Callback(\n                lambda opt_res: plot_tracker(\n                    writer,\n                    opt_res.model,\n                    opt_res.iteration,\n                    config.plotting_functions,\n                    tracking_tool=config.tracking_tool,\n                ),\n                called_every=config.plot_every,\n            )\n        ]\n\n    # checkpointing\n    if config.folder and config.checkpoint_every &gt; 0:\n        callbacks += [\n            Callback(\n                lambda opt_res: write_checkpoint(\n                    config.folder,  # type: ignore[arg-type]\n                    opt_res.model,\n                    opt_res.optimizer,\n                    opt_res.iteration,\n                ),\n                called_every=config.checkpoint_every,\n                call_after_opt=True,\n            )\n        ]\n\n    callbacks_end_opt = [\n        callback\n        for callback in callbacks\n        if callback.call_end_epoch and not callback.call_during_eval\n    ]\n\n    with progress:\n        dl_iter = iter(dataloader) if dataloader is not None else None\n\n        for iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\n            loss, metrics, ng_params = _update_parameters(\n                None if dataloader is None else next(dl_iter), ng_params  # type: ignore[arg-type]\n            )\n            opt_result = OptimizeResult(iteration, model, optimizer, loss, metrics)\n            run_callbacks(callbacks_end_opt, opt_result)\n\n            if iteration &gt;= init_iter + config.max_iter:\n                break\n\n    # writing hyperparameters\n    if config.hyperparams:\n        log_tracker(writer, config.hyperparams, metrics, tracking_tool=config.tracking_tool)\n\n    if config.log_model:\n        log_model_tracker(writer, model, dataloader, tracking_tool=config.tracking_tool)\n\n    # Final callbacks\n    callbacks_after_opt = [callback for callback in callbacks if callback.call_after_opt]\n    run_callbacks(callbacks_after_opt, opt_result, is_last_iteration=True)\n\n    # close tracker\n    if config.tracking_tool == ExperimentTrackingTool.TENSORBOARD:\n        writer.close()\n    elif config.tracking_tool == ExperimentTrackingTool.MLFLOW:\n        writer.end_run()\n\n    return model, optimizer\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.DictDataLoader","title":"<code>DictDataLoader(dataloaders)</code>  <code>dataclass</code>","text":"<p>This class only holds a dictionary of <code>DataLoader</code>s and samples from them.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.InfiniteTensorDataset","title":"<code>InfiniteTensorDataset(*tensors)</code>","text":"<p>               Bases: <code>IterableDataset</code></p> <p>Randomly sample points from the first dimension of the given tensors.</p> <p>Behaves like a normal torch <code>Dataset</code> just that we can sample from it as many times as we want.</p> <p>Examples: <pre><code>import torch\nfrom qadence.ml_tools.data import InfiniteTensorDataset\n\nx_data, y_data = torch.rand(5,2), torch.ones(5,1)\n# The dataset accepts any number of tensors with the same batch dimension\nds = InfiniteTensorDataset(x_data, y_data)\n\n# call `next` to get one sample from each tensor:\nxs = next(iter(ds))\n</code></pre> <pre><code>(tensor([0.6381, 0.8086]), tensor([1.]))\n</code></pre></p> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>def __init__(self, *tensors: Tensor):\n    \"\"\"Randomly sample points from the first dimension of the given tensors.\n\n    Behaves like a normal torch `Dataset` just that we can sample from it as\n    many times as we want.\n\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    import torch\n    from qadence.ml_tools.data import InfiniteTensorDataset\n\n    x_data, y_data = torch.rand(5,2), torch.ones(5,1)\n    # The dataset accepts any number of tensors with the same batch dimension\n    ds = InfiniteTensorDataset(x_data, y_data)\n\n    # call `next` to get one sample from each tensor:\n    xs = next(iter(ds))\n    print(str(xs)) # markdown-exec: hide\n    ```\n    \"\"\"\n    self.tensors = tensors\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult","title":"<code>OptimizeResult(iteration, model, optimizer, loss=None, metrics=lambda: dict()(), extra=lambda: dict()())</code>  <code>dataclass</code>","text":"<p>OptimizeResult stores many optimization intermediate values.</p> <p>We store at a current iteration, the model, optimizer, loss values, metrics. An extra dict can be used for saving other information to be used for callbacks.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.extra","title":"<code>extra: dict = field(default_factory=lambda: dict())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Extra dict for saving anything else to be used in callbacks.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.iteration","title":"<code>iteration: int</code>  <code>instance-attribute</code>","text":"<p>Current iteration number.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.loss","title":"<code>loss: Tensor | float | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Loss value.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.metrics","title":"<code>metrics: dict = field(default_factory=lambda: dict())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Metrics that can be saved during training.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.model","title":"<code>model: Module</code>  <code>instance-attribute</code>","text":"<p>Model at iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.OptimizeResult.optimizer","title":"<code>optimizer: Optimizer | NGOptimizer</code>  <code>instance-attribute</code>","text":"<p>Optimizer at iteration.</p>"},{"location":"api/ml_tools/#qadence.ml_tools.data.data_to_device","title":"<code>data_to_device(xs, *args, **kwargs)</code>","text":"<p>Utility method to move arbitrary data to 'device'.</p> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>@singledispatch\ndef data_to_device(xs: Any, *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"Utility method to move arbitrary data to 'device'.\"\"\"\n    raise ValueError(f\"Unable to move {type(xs)} with input args: {args} and kwargs: {kwargs}.\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.data.to_dataloader","title":"<code>to_dataloader(*tensors, batch_size=1, infinite=False)</code>","text":"<p>Convert torch tensors an (infinite) Dataloader.</p> PARAMETER DESCRIPTION <code>*tensors</code> <p>Torch tensors to use in the dataloader.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>()</code> </p> <code>batch_size</code> <p>batch size of sampled tensors</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>infinite</code> <p>if <code>True</code>, the dataloader will keep sampling indefinitely even after the whole dataset was sampled once</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>import torch\nfrom qadence.ml_tools import to_dataloader\n\n(x, y, z) = [torch.rand(10) for _ in range(3)]\nloader = iter(to_dataloader(x, y, z, batch_size=5, infinite=True))\nprint(next(loader))\nprint(next(loader))\nprint(next(loader))\n</code></pre> <pre><code>[tensor([0.0282, 0.9692, 0.2500, 0.5161, 0.5529]), tensor([0.1105, 0.6830, 0.0856, 0.2184, 0.2903]), tensor([0.3127, 0.0778, 0.3476, 0.7542, 0.1282])]\n[tensor([0.0402, 0.2835, 0.8745, 0.0816, 0.4890]), tensor([0.2680, 0.2680, 0.8276, 0.5022, 0.6830]), tensor([0.3039, 0.1653, 0.4049, 0.1604, 0.4612])]\n[tensor([0.0282, 0.9692, 0.2500, 0.5161, 0.5529]), tensor([0.1105, 0.6830, 0.0856, 0.2184, 0.2903]), tensor([0.3127, 0.0778, 0.3476, 0.7542, 0.1282])]\n</code></pre> Source code in <code>qadence/ml_tools/data.py</code> <pre><code>def to_dataloader(*tensors: Tensor, batch_size: int = 1, infinite: bool = False) -&gt; DataLoader:\n    \"\"\"Convert torch tensors an (infinite) Dataloader.\n\n    Arguments:\n        *tensors: Torch tensors to use in the dataloader.\n        batch_size: batch size of sampled tensors\n        infinite: if `True`, the dataloader will keep sampling indefinitely even after the whole\n            dataset was sampled once\n\n    Examples:\n\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    import torch\n    from qadence.ml_tools import to_dataloader\n\n    (x, y, z) = [torch.rand(10) for _ in range(3)]\n    loader = iter(to_dataloader(x, y, z, batch_size=5, infinite=True))\n    print(next(loader))\n    print(next(loader))\n    print(next(loader))\n    ```\n    \"\"\"\n    ds = InfiniteTensorDataset(*tensors) if infinite else TensorDataset(*tensors)\n    return DataLoader(ds, batch_size=batch_size)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN","title":"<code>QNN(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, inputs=None, input_diff_mode=InputDiffMode.AD)</code>","text":"<p>               Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs.</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN, Z\nfrom qadence import hea, feature_map, hamiltonian_factory, kron\n\n# create the circuit\nn_qubits, depth = 2, 4\nfm = kron(\n    feature_map(1, support=(0,), param=\"x\"),\n    feature_map(1, support=(1,), param=\"y\")\n)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning=Z)\n\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n\n# initialize and use the model\nqnn = QNN(circuit, obs, inputs=[\"x\", \"y\"])\ny = qnn(torch.rand(3, 2))\n</code></pre> <pre><code>tensor([[-0.7438, -1.4876],\n        [-1.0947, -2.1893],\n        [-0.5030, -1.0060]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN.</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>The observable.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>inputs</code> <p>List that indicates the order of variables of the tensors that are passed to the model. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p> <p> TYPE: <code>list[Basic | str] | None</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode | str</code> DEFAULT: <code>AD</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    inputs: list[sympy.Basic | str] | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n):\n    \"\"\"Initialize the QNN.\n\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        observable: The observable.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        configuration: optional configuration for the backend\n        inputs: List that indicates the order of variables of the tensors that are passed\n            to the model. Given input tensors `xs = torch.rand(batch_size, input_size:=2)` a QNN\n            with `inputs=[\"t\", \"x\"]` will assign `t, x = xs[:,0], xs[:,1]`.\n        input_diff_mode: The differentiation mode for the input tensor.\n    \"\"\"\n    super().__init__(\n        circuit,\n        observable=observable,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        configuration=configuration,\n        noise=noise,\n    )\n    if self._observable is None:\n        raise ValueError(\"You need to provide at least one observable in the QNN constructor\")\n    if (inputs is not None) and (len(self.inputs) == len(inputs)):\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in inputs]  # type: ignore[union-attr]\n    elif (inputs is None) and len(self.inputs) &lt;= 1:\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in self.inputs]  # type: ignore[union-attr]\n    else:\n        raise ValueError(\n            \"\"\"\n            Your QNN has more than one input. Please provide a list of inputs in the order of\n            your tensor domain. For example, if you want to pass\n            `xs = torch.rand(batch_size, input_size:=3)` to you QNN, where\n            ```\n            t = x[:,0]\n            x = x[:,1]\n            y = x[:,2]\n            ```\n            you have to specify\n            ```\n            QNN(circuit, observable, inputs=[\"t\", \"x\", \"y\"])\n            ```\n            You can also pass a list of sympy symbols.\n        \"\"\"\n        )\n    self.format_to_dict = format_to_dict_fn(self.inputs)  # type: ignore[arg-type]\n    self.input_diff_mode = InputDiffMode(input_diff_mode)\n    if self.input_diff_mode == InputDiffMode.FD:\n        from qadence.backends.utils import finitediff\n\n        self.__derivative = finitediff\n    elif self.input_diff_mode == InputDiffMode.AD:\n        self.__derivative = _torch_derivative  # type: ignore[assignment]\n    else:\n        raise ValueError(f\"Unkown forward diff mode: {self.input_diff_mode}\")\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.forward","title":"<code>forward(values=None, state=None, measurement=None, noise=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model.</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def forward(\n    self,\n    values: dict[str, Tensor] | Tensor = None,\n    state: Tensor | None = None,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    \"\"\"Forward pass of the model.\n\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n\n    Args:\n        values: the values of the feature parameters\n        state: Initial state.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\n    return self.expectation(\n        values, state=state, measurement=measurement, noise=noise, endianness=endianness\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.QNN.from_configs","title":"<code>from_configs(register, obs_config, fm_config=FeatureMapConfig(), ansatz_config=AnsatzConfig(), backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, input_diff_mode=InputDiffMode.AD)</code>  <code>classmethod</code>","text":"<p>Create a QNN from a set of configurations.</p> PARAMETER DESCRIPTION <code>register</code> <p>The number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>obs_config</code> <p>The configuration(s) for the observable(s).</p> <p> TYPE: <code>list[ObservableConfig] | ObservableConfig</code> </p> <code>fm_config</code> <p>The configuration for the feature map. Defaults to no feature encoding block.</p> <p> TYPE: <code>FeatureMapConfig</code> DEFAULT: <code>FeatureMapConfig()</code> </p> <code>ansatz_config</code> <p>The configuration for the ansatz. Defaults to a single layer of hardware efficient ansatz.</p> <p> TYPE: <code>AnsatzConfig</code> DEFAULT: <code>AnsatzConfig()</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices are 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Optional backend configuration.</p> <p> TYPE: <code>BackendConfiguration | dict</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode</code> DEFAULT: <code>AD</code> </p> RETURNS DESCRIPTION <code>QNN</code> <p>A QNN object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the observable configuration is not provided.</p> <p>Example: <pre><code>import torch\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools import QNN\nfrom qadence.constructors import ObservableConfig\nfrom qadence.operations import Z\nfrom qadence.types import (\n    AnsatzType, BackendName, BasisSet, ObservableTransform, ReuploadScaling, Strategy\n)\n\nregister = 4\nobs_config = ObservableConfig(\n    detuning=Z,\n    scale=5.0,\n    shift=0.0,\n    transformation_type=ObservableTransform.SCALE,\n    trainable_transform=None,\n)\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs=[\"x\", \"y\"],\n    basis_set=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.CONSTANT,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nqnn = QNN.from_configs(\n    register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n)\n\nx = torch.rand(2, 2)\ny = qnn(x)\n</code></pre> <pre><code>tensor([[-2.8395],\n        [ 1.0086]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>@classmethod\ndef from_configs(\n    cls,\n    register: int | Register,\n    obs_config: Any,\n    fm_config: Any = FeatureMapConfig(),\n    ansatz_config: Any = AnsatzConfig(),\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n) -&gt; QNN:\n    \"\"\"Create a QNN from a set of configurations.\n\n    Args:\n        register (int | Register): The number of qubits or a register object.\n        obs_config (list[ObservableConfig] | ObservableConfig): The configuration(s)\n            for the observable(s).\n        fm_config (FeatureMapConfig): The configuration for the feature map.\n            Defaults to no feature encoding block.\n        ansatz_config (AnsatzConfig): The configuration for the ansatz.\n            Defaults to a single layer of hardware efficient ansatz.\n        backend (BackendName): The chosen quantum backend.\n        diff_mode (DiffMode): The differentiation engine to use. Choices are\n            'gpsr' or 'ad'.\n        measurement (Measurements): Optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator.\n        noise (Noise): A noise model to use.\n        configuration (BackendConfiguration | dict): Optional backend configuration.\n        input_diff_mode (InputDiffMode): The differentiation mode for the input tensor.\n\n    Returns:\n        A QNN object.\n\n    Raises:\n        ValueError: If the observable configuration is not provided.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools import QNN\n    from qadence.constructors import ObservableConfig\n    from qadence.operations import Z\n    from qadence.types import (\n        AnsatzType, BackendName, BasisSet, ObservableTransform, ReuploadScaling, Strategy\n    )\n\n    register = 4\n    obs_config = ObservableConfig(\n        detuning=Z,\n        scale=5.0,\n        shift=0.0,\n        transformation_type=ObservableTransform.SCALE,\n        trainable_transform=None,\n    )\n    fm_config = FeatureMapConfig(\n        num_features=2,\n        inputs=[\"x\", \"y\"],\n        basis_set=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.CONSTANT,\n        feature_range={\n            \"x\": (-1.0, 1.0),\n            \"y\": (0.0, 1.0),\n        },\n    )\n    ansatz_config = AnsatzConfig(\n        depth=2,\n        ansatz_type=AnsatzType.HEA,\n        ansatz_strategy=Strategy.DIGITAL,\n    )\n\n    qnn = QNN.from_configs(\n        register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n    )\n\n    x = torch.rand(2, 2)\n    y = qnn(x)\n    print(str(y)) # markdown-exec: hide\n    ```\n    \"\"\"\n    from .constructors import build_qnn_from_configs\n\n    return build_qnn_from_configs(\n        register=register,\n        observable_config=obs_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        noise=noise,\n        configuration=configuration,\n        input_diff_mode=input_diff_mode,\n    )\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.derivative","title":"<code>derivative(ufa, x, derivative_indices)</code>","text":"<p>Compute derivatives w.r.t.</p> <p>inputs of a UFA with a single output. The <code>derivative_indices</code> specify which derivative(s) are computed.  E.g. <code>derivative_indices=(1,2)</code> would compute the a second order derivative w.r.t to the indices <code>1</code> and <code>2</code> of the input tensor.</p> PARAMETER DESCRIPTION <code>ufa</code> <p>The model for which we want to compute the derivative.</p> <p> TYPE: <code>Module</code> </p> <code>x</code> <p>(batch_size, input_size) input tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>derivative_indices</code> <p>Define which derivatives to compute.</p> <p> TYPE: <code>tuple</code> </p> <p>Examples: If we create a UFA with three inputs and denote the first, second, and third input with <code>x</code>, <code>y</code>, and <code>z</code> we can compute the following derivatives w.r.t to those inputs: <pre><code>import torch\nfrom qadence.ml_tools.models import derivative, QNN\nfrom qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\nfrom qadence.constructors.hamiltonians import ObservableConfig\nfrom qadence.operations import Z\n\nfm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\nansatz_config = AnsatzConfig()\nobs_config = ObservableConfig(detuning=Z)\n\nf = QNN.from_configs(\n    register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n)\ninputs = torch.rand(5,3,requires_grad=True)\n\n# df_dx\nderivative(f, inputs, (0,))\n\n# d2f_dydz\nderivative(f, inputs, (1,2))\n\n# d3fdy2dx\nderivative(f, inputs, (1,1,0))\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def derivative(ufa: torch.nn.Module, x: Tensor, derivative_indices: tuple[int, ...]) -&gt; Tensor:\n    \"\"\"Compute derivatives w.r.t.\n\n    inputs of a UFA with a single output. The\n    `derivative_indices` specify which derivative(s) are computed.  E.g.\n    `derivative_indices=(1,2)` would compute the a second order derivative w.r.t\n    to the indices `1` and `2` of the input tensor.\n\n    Arguments:\n        ufa: The model for which we want to compute the derivative.\n        x (Tensor): (batch_size, input_size) input tensor.\n        derivative_indices (tuple): Define which derivatives to compute.\n\n    Examples:\n    If we create a UFA with three inputs and denote the first, second, and third\n    input with `x`, `y`, and `z` we can compute the following derivatives w.r.t\n    to those inputs:\n    ```py exec=\"on\" source=\"material-block\"\n    import torch\n    from qadence.ml_tools.models import derivative, QNN\n    from qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\n    from qadence.constructors.hamiltonians import ObservableConfig\n    from qadence.operations import Z\n\n    fm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\n    ansatz_config = AnsatzConfig()\n    obs_config = ObservableConfig(detuning=Z)\n\n    f = QNN.from_configs(\n        register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n    )\n    inputs = torch.rand(5,3,requires_grad=True)\n\n    # df_dx\n    derivative(f, inputs, (0,))\n\n    # d2f_dydz\n    derivative(f, inputs, (1,2))\n\n    # d3fdy2dx\n    derivative(f, inputs, (1,1,0))\n    ```\n    \"\"\"\n    assert ufa.out_features == 1, \"Can only call `derivative` on models with 1D output.\"\n    return ufa._derivative(x, derivative_indices)\n</code></pre>"},{"location":"api/ml_tools/#qadence.ml_tools.models.format_to_dict_fn","title":"<code>format_to_dict_fn(inputs=[])</code>","text":"<p>Format an input tensor into the format required by the forward pass.</p> <p>The tensor is assumed to have dimensions: n_batches x in_features where in_features corresponds to the number of input features of the QNN</p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def format_to_dict_fn(\n    inputs: list[sympy.Symbol | str] = [],\n) -&gt; Callable[[Tensor | ParamDictType], ParamDictType]:\n    \"\"\"Format an input tensor into the format required by the forward pass.\n\n    The tensor is assumed to have dimensions: n_batches x in_features where in_features\n    corresponds to the number of input features of the QNN\n    \"\"\"\n    in_features = len(inputs)\n\n    def tensor_to_dict(values: Tensor | ParamDictType) -&gt; ParamDictType:\n        if isinstance(values, Tensor):\n            values = values.reshape(-1, 1) if len(values.size()) == 1 else values\n            if not values.shape[1] == in_features:\n                raise ValueError(\n                    f\"Model expects in_features={in_features} but got {values.shape[1]}.\"\n                )\n            values = {fparam.name: values[:, inputs.index(fparam)] for fparam in inputs}  # type: ignore[union-attr]\n        return values\n\n    return tensor_to_dict\n</code></pre>"},{"location":"api/models/","title":"Quantum models","text":"<p>               Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs.</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN, Z\nfrom qadence import hea, feature_map, hamiltonian_factory, kron\n\n# create the circuit\nn_qubits, depth = 2, 4\nfm = kron(\n    feature_map(1, support=(0,), param=\"x\"),\n    feature_map(1, support=(1,), param=\"y\")\n)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning=Z)\n\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n\n# initialize and use the model\nqnn = QNN(circuit, obs, inputs=[\"x\", \"y\"])\ny = qnn(torch.rand(3, 2))\n</code></pre> <pre><code>tensor([[-0.5038, -1.0075],\n        [-0.6993, -1.3986],\n        [-0.5410, -1.0820]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN.</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>The observable.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>inputs</code> <p>List that indicates the order of variables of the tensors that are passed to the model. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p> <p> TYPE: <code>list[Basic | str] | None</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode | str</code> DEFAULT: <code>AD</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    inputs: list[sympy.Basic | str] | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n):\n    \"\"\"Initialize the QNN.\n\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        observable: The observable.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        configuration: optional configuration for the backend\n        inputs: List that indicates the order of variables of the tensors that are passed\n            to the model. Given input tensors `xs = torch.rand(batch_size, input_size:=2)` a QNN\n            with `inputs=[\"t\", \"x\"]` will assign `t, x = xs[:,0], xs[:,1]`.\n        input_diff_mode: The differentiation mode for the input tensor.\n    \"\"\"\n    super().__init__(\n        circuit,\n        observable=observable,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        configuration=configuration,\n        noise=noise,\n    )\n    if self._observable is None:\n        raise ValueError(\"You need to provide at least one observable in the QNN constructor\")\n    if (inputs is not None) and (len(self.inputs) == len(inputs)):\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in inputs]  # type: ignore[union-attr]\n    elif (inputs is None) and len(self.inputs) &lt;= 1:\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in self.inputs]  # type: ignore[union-attr]\n    else:\n        raise ValueError(\n            \"\"\"\n            Your QNN has more than one input. Please provide a list of inputs in the order of\n            your tensor domain. For example, if you want to pass\n            `xs = torch.rand(batch_size, input_size:=3)` to you QNN, where\n            ```\n            t = x[:,0]\n            x = x[:,1]\n            y = x[:,2]\n            ```\n            you have to specify\n            ```\n            QNN(circuit, observable, inputs=[\"t\", \"x\", \"y\"])\n            ```\n            You can also pass a list of sympy symbols.\n        \"\"\"\n        )\n    self.format_to_dict = format_to_dict_fn(self.inputs)  # type: ignore[arg-type]\n    self.input_diff_mode = InputDiffMode(input_diff_mode)\n    if self.input_diff_mode == InputDiffMode.FD:\n        from qadence.backends.utils import finitediff\n\n        self.__derivative = finitediff\n    elif self.input_diff_mode == InputDiffMode.AD:\n        self.__derivative = _torch_derivative  # type: ignore[assignment]\n    else:\n        raise ValueError(f\"Unkown forward diff mode: {self.input_diff_mode}\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel","title":"<code>QuantumModel(circuit, observable=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, mitigation=None, configuration=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>The central class of qadence that executes <code>QuantumCircuit</code>s and make them differentiable.</p> <p>This class should be used as base class for any new quantum model supported in the qadence framework for information on the implementation of custom models see here.</p> <p>Example: <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit, RX, RY, Z, PI, chain, kron\nfrom qadence import FeatureParameter, VariationalParameter\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, theta), RY(1, theta)),\n    kron(RX(0, phi), RY(1, phi)),\n)\n\ncircuit = QuantumCircuit(2, block)\n\nobservable = Z(0) + Z(1)\n\nmodel = QuantumModel(circuit, observable)\nvalues = {\"phi\": torch.tensor([PI, PI/2]), \"theta\": torch.tensor([PI, PI/2])}\n\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\nprint(wf)\nprint(xs)\nprint(ex)\n</code></pre> <pre><code>tensor([[ 1.0000e+00+0.0000e+00j, -1.2246e-16+0.0000e+00j,\n          0.0000e+00+1.2246e-16j,  0.0000e+00-1.4998e-32j],\n        [ 4.9304e-32+0.0000e+00j,  2.2204e-16+0.0000e+00j,\n          0.0000e+00-2.2204e-16j,  0.0000e+00-1.0000e+00j]])\n[Counter({'00': 100}), Counter({'11': 100})]\ntensor([[ 2.],\n        [-2.]], requires_grad=True)\n</code></pre>  ```</p> <p>Initialize a generic QuantumModel instance.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>Optional observable(s) that are used only in the <code>expectation</code> method. You can also provide observables on the fly to the expectation call directly.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>A backend for circuit execution.</p> <p> TYPE: <code>BackendName | str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>A differentiability mode. Parameter shift based modes work on all backends. AD based modes only on PyTorch based backends.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Configuration for the backend.</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if the <code>diff_mode</code> argument is set to None</p> Source code in <code>qadence/model.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock | None = None,\n    backend: BackendName | str = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    mitigation: Mitigations | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n):\n    \"\"\"Initialize a generic QuantumModel instance.\n\n    Arguments:\n        circuit: The circuit that is executed.\n        observable: Optional observable(s) that are used only in the `expectation` method. You\n            can also provide observables on the fly to the expectation call directly.\n        backend: A backend for circuit execution.\n        diff_mode: A differentiability mode. Parameter shift based modes work on all backends.\n            AD based modes only on PyTorch based backends.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        configuration: Configuration for the backend.\n        noise: A noise model to use.\n\n    Raises:\n        ValueError: if the `diff_mode` argument is set to None\n    \"\"\"\n    super().__init__()\n\n    if not isinstance(circuit, QuantumCircuit):\n        TypeError(\n            f\"The circuit should be of type '&lt;class QuantumCircuit&gt;'. Got {type(circuit)}.\"\n        )\n\n    if diff_mode is None:\n        raise ValueError(\"`diff_mode` cannot be `None` in a `QuantumModel`.\")\n\n    self.backend = backend_factory(\n        backend=backend, diff_mode=diff_mode, configuration=configuration\n    )\n\n    if isinstance(observable, list) or observable is None:\n        observable = observable\n    else:\n        observable = [observable]\n\n    def _is_feature_param(p: Parameter) -&gt; bool:\n        return not p.trainable and not p.is_number\n\n    if observable is None:\n        self.inputs = list(filter(_is_feature_param, circuit.unique_parameters))\n    else:\n        uparams = unique_parameters(chain(circuit.block, *observable))\n        self.inputs = list(filter(_is_feature_param, uparams))\n\n    conv = self.backend.convert(circuit, observable)\n    self.embedding_fn = conv.embedding_fn\n    self._circuit = conv.circuit\n    self._observable = conv.observable\n    self._backend_name = backend\n    self._diff_mode = diff_mode\n    self._measurement = measurement\n    self._noise = noise\n    self._mitigation = mitigation\n    self._params = nn.ParameterDict(\n        {\n            str(key): nn.Parameter(val, requires_grad=val.requires_grad)\n            for key, val in conv.params.items()\n        }\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.device","title":"<code>device: torch.device</code>  <code>property</code>","text":"<p>Get device.</p> RETURNS DESCRIPTION <code>device</code> <p>torch.device</p>"},{"location":"api/models/#qadence.model.QuantumModel.in_features","title":"<code>in_features: int</code>  <code>property</code>","text":"<p>Number of inputs.</p>"},{"location":"api/models/#qadence.model.QuantumModel.num_vparams","title":"<code>num_vparams: int</code>  <code>property</code>","text":"<p>The number of variational parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.out_features","title":"<code>out_features: int | None</code>  <code>property</code>","text":"<p>Number of outputs.</p>"},{"location":"api/models/#qadence.model.QuantumModel.vals_vparams","title":"<code>vals_vparams: Tensor</code>  <code>property</code>","text":"<p>Dictionary with parameters which are actually updated during optimization.</p>"},{"location":"api/models/#qadence.model.QuantumModel.vparams","title":"<code>vparams: OrderedDict</code>  <code>property</code>","text":"<p>Variational parameters.</p>"},{"location":"api/models/#qadence.model.QuantumModel.assign_parameters","title":"<code>assign_parameters(values)</code>","text":"<p>Return the final, assigned circuit that is used in e.g. <code>backend.run</code>.</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Final, assigned circuit that is used in e.g. <code>backend.run</code></p> Source code in <code>qadence/model.py</code> <pre><code>def assign_parameters(self, values: dict[str, Tensor]) -&gt; Any:\n    \"\"\"Return the final, assigned circuit that is used in e.g. `backend.run`.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n\n    Returns:\n        Final, assigned circuit that is used in e.g. `backend.run`\n    \"\"\"\n    params = self.embedding_fn(self._params, values)\n    return self.backend.assign_parameters(self._circuit, params)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.circuit","title":"<code>circuit(circuit)</code>","text":"<p>Get backend-converted circuit.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>QuantumCircuit instance.</p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>Backend circuit.</p> Source code in <code>qadence/model.py</code> <pre><code>def circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Get backend-converted circuit.\n\n    Args:\n        circuit: QuantumCircuit instance.\n\n    Returns:\n        Backend circuit.\n    \"\"\"\n    return self.backend.circuit(circuit)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.expectation","title":"<code>expectation(values={}, observable=None, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute expectation using the given backend.</p> <p>Given an input state \\(|\\psi_0 \\rangle\\), a set of variational parameters \\(\\vec{\\theta}\\) and the unitary representation of the model \\(U(\\vec{\\theta})\\) we return \\(\\langle \\psi_0 | U(\\vec{\\theta}) | \\psi_0 \\rangle\\).</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>observable</code> <p>Observable part of the expectation.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable | None</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional input state.</p> <p> TYPE: <code>Optional[Tensor]</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>A mitigation protocol to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>when no observable is set.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor of shape n_batches x n_obs</p> Source code in <code>qadence/model.py</code> <pre><code>def expectation(\n    self,\n    values: dict[str, Tensor] = {},\n    observable: list[ConvertedObservable] | ConvertedObservable | None = None,\n    state: Optional[Tensor] = None,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    r\"\"\"Compute expectation using the given backend.\n\n\n\n    Given an input state $|\\psi_0 \\rangle$,\n    a set of variational parameters $\\vec{\\theta}$\n    and the unitary representation of the model $U(\\vec{\\theta})$\n    we return $\\langle \\psi_0 | U(\\vec{\\theta}) | \\psi_0 \\rangle$.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        observable: Observable part of the expectation.\n        state: Optional input state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: A mitigation protocol to use.\n        endianness: Storage convention for binary information.\n\n    Raises:\n        ValueError: when no observable is set.\n\n    Returns:\n        A torch.Tensor of shape n_batches x n_obs\n    \"\"\"\n    if observable is None:\n        if self._observable is None:\n            raise ValueError(\n                \"Provide an AbstractBlock as the observable to compute expectation.\"\n                \"Either pass a 'native_observable' directly to 'QuantumModel.expectation'\"\n                \"or pass a (non-native) '&lt;class AbstractBlock&gt;' to the 'QuantumModel.__init__'.\"\n            )\n        observable = self._observable\n\n    params = self.embedding_fn(self._params, values)\n    if measurement is None:\n        measurement = self._measurement\n    if noise is None:\n        noise = self._noise\n    else:\n        self._noise = noise\n    if mitigation is None:\n        mitigation = self._mitigation\n    return self.backend.expectation(\n        circuit=self._circuit,\n        observable=observable,\n        param_values=params,\n        state=state,\n        measurement=measurement,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Calls run method with arguments.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor representing output.</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def forward(self, *args: Any, **kwargs: Any) -&gt; Tensor:\n    \"\"\"Calls run method with arguments.\n\n    Returns:\n        Tensor: A torch.Tensor representing output.\n    \"\"\"\n    return self.run(*args, **kwargs)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.load","title":"<code>load(file_path, as_torch=False, map_location='cpu')</code>  <code>classmethod</code>","text":"<p>Load QuantumModel.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>File path to load model from.</p> <p> TYPE: <code>str | Path</code> </p> <code>as_torch</code> <p>Load parameters as torch tensor. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>map_location</code> <p>Location for loading. Defaults to \"cpu\".</p> <p> TYPE: <code>str | device</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>QuantumModel</code> <p>QuantumModel from file_path.</p> Source code in <code>qadence/model.py</code> <pre><code>@classmethod\ndef load(\n    cls, file_path: str | Path, as_torch: bool = False, map_location: str | torch.device = \"cpu\"\n) -&gt; QuantumModel:\n    \"\"\"Load QuantumModel.\n\n    Arguments:\n        file_path: File path to load model from.\n        as_torch: Load parameters as torch tensor. Defaults to False.\n        map_location (str | torch.device, optional): Location for loading. Defaults to \"cpu\".\n\n    Returns:\n        QuantumModel from file_path.\n    \"\"\"\n    qm_pt = {}\n    if isinstance(file_path, str):\n        file_path = Path(file_path)\n    if os.path.isdir(file_path):\n        from qadence.ml_tools.saveload import get_latest_checkpoint_name\n\n        file_path = file_path / get_latest_checkpoint_name(file_path, \"model\")\n\n    try:\n        qm_pt = torch.load(file_path, map_location=map_location)\n    except Exception as e:\n        logger.error(f\"Unable to load QuantumModel due to {e}\")\n    return cls._from_dict(qm_pt, as_torch)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.load_params_from_dict","title":"<code>load_params_from_dict(d, strict=True)</code>","text":"<p>Copy parameters from dictionary into this QuantumModel.</p> <p>Unlike :meth:<code>~qadence.QuantumModel.from_dict</code>, this method does not create a new QuantumModel instance, but rather loads the parameters into the same QuantumModel. The behaviour of this method is similar to :meth:<code>~torch.nn.Module.load_state_dict</code>.</p> <p>The dictionary is assumed to have the format as saved via :meth:<code>~qadence.QuantumModel.to_dict</code></p> PARAMETER DESCRIPTION <code>d</code> <p>The dictionary</p> <p> TYPE: <code>dict</code> </p> <code>strict</code> <p>Whether to strictly enforce that the parameter keys in the dictionary and in the model match exactly. Default: <code>True</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>qadence/model.py</code> <pre><code>def load_params_from_dict(self, d: dict, strict: bool = True) -&gt; None:\n    \"\"\"Copy parameters from dictionary into this QuantumModel.\n\n    Unlike :meth:`~qadence.QuantumModel.from_dict`, this method does not create a new\n    QuantumModel instance, but rather loads the parameters into the same QuantumModel.\n    The behaviour of this method is similar to :meth:`~torch.nn.Module.load_state_dict`.\n\n    The dictionary is assumed to have the format as saved via\n    :meth:`~qadence.QuantumModel.to_dict`\n\n    Args:\n        d (dict): The dictionary\n        strict (bool, optional):\n            Whether to strictly enforce that the parameter keys in the dictionary and\n            in the model match exactly. Default: ``True``.\n    \"\"\"\n    param_dict = d[\"param_dict\"]\n    missing_keys = set(self._params.keys()) - set(param_dict.keys())\n    unexpected_keys = set(param_dict.keys()) - set(self._params.keys())\n\n    if strict:\n        error_msgs = []\n        if len(unexpected_keys) &gt; 0:\n            error_msgs.append(f\"Unexpected key(s) in dictionary: {unexpected_keys}\")\n        if len(missing_keys) &gt; 0:\n            error_msgs.append(f\"Missing key(s) in dictionary: {missing_keys}\")\n        if len(error_msgs) &gt; 0:\n            errors_string = \"\\n\\t\".join(error_msgs)\n            raise RuntimeError(\n                f\"Error(s) loading the parameter dictionary due to: \\n\\t{errors_string}\\n\"\n                \"This error was thrown because the `strict` argument is set `True`.\"\n                \"If you don't need the parameter keys of the dictionary to exactly match \"\n                \"the model parameters, set `strict=False`.\"\n            )\n\n    for n, param in param_dict.items():\n        try:\n            with torch.no_grad():\n                self._params[n].copy_(\n                    torch.nn.Parameter(param, requires_grad=param.requires_grad)\n                )\n        except Exception as e:\n            logger.warning(f\"Unable to load parameter {n} from dictionary due to {e}.\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.observable","title":"<code>observable(observable, n_qubits)</code>","text":"<p>Get backend observable.</p> PARAMETER DESCRIPTION <code>observable</code> <p>Observable block.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Backend observable.</p> Source code in <code>qadence/model.py</code> <pre><code>def observable(self, observable: AbstractBlock, n_qubits: int) -&gt; Any:\n    \"\"\"Get backend observable.\n\n    Args:\n        observable: Observable block.\n        n_qubits: Number of qubits\n\n    Returns:\n        Backend observable.\n    \"\"\"\n    return self.backend.observable(observable, n_qubits)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.overlap","title":"<code>overlap()</code>","text":"<p>Overlap of model.</p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>The overlap method is not implemented for this model.</p> Source code in <code>qadence/model.py</code> <pre><code>def overlap(self) -&gt; Tensor:\n    \"\"\"Overlap of model.\n\n    Raises:\n        NotImplementedError: The overlap method is not implemented for this model.\n    \"\"\"\n    raise NotImplementedError(\"The overlap method is not implemented for this model.\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.reset_vparams","title":"<code>reset_vparams(values)</code>","text":"<p>Reset all the variational parameters with a given list of values.</p> Source code in <code>qadence/model.py</code> <pre><code>def reset_vparams(self, values: Sequence) -&gt; None:\n    \"\"\"Reset all the variational parameters with a given list of values.\"\"\"\n    current_vparams = OrderedDict({k: v for k, v in self._params.items() if v.requires_grad})\n\n    assert (\n        len(values) == self.num_vparams\n    ), \"Pass an iterable with the values of all variational parameters\"\n    for i, k in enumerate(current_vparams.keys()):\n        current_vparams[k].data = torch.tensor([values[i]])\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.run","title":"<code>run(values=None, state=None, endianness=Endianness.BIG)</code>","text":"<p>Run model.</p> <p>Given an input state \\(| \\psi_0 \\rangle\\), a set of variational parameters \\(\\vec{\\theta}\\) and the unitary representation of the model \\(U(\\vec{\\theta})\\) we return \\(U(\\vec{\\theta}) | \\psi_0 \\rangle\\).</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Optional input state to apply model on.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor representing output.</p> Source code in <code>qadence/model.py</code> <pre><code>def run(\n    self,\n    values: dict[str, Tensor] = None,\n    state: Tensor | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    r\"\"\"Run model.\n\n    Given an input state $| \\psi_0 \\rangle$,\n    a set of variational parameters $\\vec{\\theta}$\n    and the unitary representation of the model $U(\\vec{\\theta})$\n    we return $U(\\vec{\\theta}) | \\psi_0 \\rangle$.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        state: Optional input state to apply model on.\n        endianness: Storage convention for binary information.\n\n    Returns:\n        A torch.Tensor representing output.\n    \"\"\"\n    if values is None:\n        values = {}\n\n    params = self.embedding_fn(self._params, values)\n\n    return self.backend.run(self._circuit, params, state=state, endianness=endianness)\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.sample","title":"<code>sample(values={}, n_shots=1000, state=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Obtain samples from model.</p> PARAMETER DESCRIPTION <code>values</code> <p>Values dict which contains values for the parameters.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Observable part of the expectation.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Optional input state to apply model on.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>A mitigation protocol to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Storage convention for binary information.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results.</p> Source code in <code>qadence/model.py</code> <pre><code>def sample(\n    self,\n    values: dict[str, torch.Tensor] = {},\n    n_shots: int = 1000,\n    state: torch.Tensor | None = None,\n    noise: Noise | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n    \"\"\"Obtain samples from model.\n\n    Arguments:\n        values: Values dict which contains values for the parameters.\n        n_shots: Observable part of the expectation.\n        state: Optional input state to apply model on.\n        noise: A noise model to use.\n        mitigation: A mitigation protocol to use.\n        endianness: Storage convention for binary information.\n\n    Returns:\n        A list of Counter instances with the sample results.\n    \"\"\"\n    params = self.embedding_fn(self._params, values)\n    if noise is None:\n        noise = self._noise\n    if mitigation is None:\n        mitigation = self._mitigation\n    return self.backend.sample(\n        self._circuit,\n        params,\n        n_shots=n_shots,\n        state=state,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.save","title":"<code>save(folder, file_name='quantum_model.pt', save_params=True)</code>","text":"<p>Save model.</p> PARAMETER DESCRIPTION <code>folder</code> <p>Folder where model is saved.</p> <p> TYPE: <code>str | Path</code> </p> <code>file_name</code> <p>File name for saving model. Defaults to \"quantum_model.pt\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'quantum_model.pt'</code> </p> <code>save_params</code> <p>Save parameters if True. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If folder is not a directory.</p> Source code in <code>qadence/model.py</code> <pre><code>def save(\n    self, folder: str | Path, file_name: str = \"quantum_model.pt\", save_params: bool = True\n) -&gt; None:\n    \"\"\"Save model.\n\n    Arguments:\n        folder: Folder where model is saved.\n        file_name: File name for saving model. Defaults to \"quantum_model.pt\".\n        save_params: Save parameters if True. Defaults to True.\n\n    Raises:\n        FileNotFoundError: If folder is not a directory.\n    \"\"\"\n    if not os.path.isdir(folder):\n        raise FileNotFoundError\n    try:\n        torch.save(self._to_dict(save_params), folder / Path(file_name))\n    except Exception as e:\n        logger.error(f\"Unable to write QuantumModel to disk due to {e}\")\n</code></pre>"},{"location":"api/models/#qadence.model.QuantumModel.to","title":"<code>to(*args, **kwargs)</code>","text":"<p>Conversion method for device or types.</p> RETURNS DESCRIPTION <code>QuantumModel</code> <p>QuantumModel with conversions.</p> Source code in <code>qadence/model.py</code> <pre><code>def to(self, *args: Any, **kwargs: Any) -&gt; QuantumModel:\n    \"\"\"Conversion method for device or types.\n\n    Returns:\n        QuantumModel with conversions.\n    \"\"\"\n    from pyqtorch import QuantumCircuit as PyQCircuit\n\n    try:\n        if isinstance(self._circuit.native, PyQCircuit):\n            self._circuit.native = self._circuit.native.to(*args, **kwargs)\n            if self._observable is not None:\n                if isinstance(self._observable, ConvertedObservable):\n                    self._observable.native = self._observable.native.to(*args, **kwargs)\n                elif isinstance(self._observable, list):\n                    for obs in self._observable:\n                        obs.native = obs.native.to(*args, **kwargs)\n            self._params = self._params.to(\n                device=self._circuit.native.device,\n                dtype=(\n                    torch.float64\n                    if self._circuit.native.dtype == torch.cdouble\n                    else torch.float32\n                ),\n            )\n            logger.debug(f\"Moved {self} to {args}, {kwargs}.\")\n        else:\n            logger.debug(\"QuantumModel.to only supports pyqtorch.QuantumCircuits.\")\n    except Exception as e:\n        logger.warning(f\"Unable to move {self} to {args}, {kwargs} due to {e}.\")\n    return self\n</code></pre>"},{"location":"api/models/#qadence.ml_tools.models.QNN.forward","title":"<code>forward(values=None, state=None, measurement=None, noise=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model.</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>def forward(\n    self,\n    values: dict[str, Tensor] | Tensor = None,\n    state: Tensor | None = None,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    \"\"\"Forward pass of the model.\n\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n\n    Args:\n        values: the values of the feature parameters\n        state: Initial state.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\n    return self.expectation(\n        values, state=state, measurement=measurement, noise=noise, endianness=endianness\n    )\n</code></pre>"},{"location":"api/models/#qadence.ml_tools.models.QNN.from_configs","title":"<code>from_configs(register, obs_config, fm_config=FeatureMapConfig(), ansatz_config=AnsatzConfig(), backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, input_diff_mode=InputDiffMode.AD)</code>  <code>classmethod</code>","text":"<p>Create a QNN from a set of configurations.</p> PARAMETER DESCRIPTION <code>register</code> <p>The number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>obs_config</code> <p>The configuration(s) for the observable(s).</p> <p> TYPE: <code>list[ObservableConfig] | ObservableConfig</code> </p> <code>fm_config</code> <p>The configuration for the feature map. Defaults to no feature encoding block.</p> <p> TYPE: <code>FeatureMapConfig</code> DEFAULT: <code>FeatureMapConfig()</code> </p> <code>ansatz_config</code> <p>The configuration for the ansatz. Defaults to a single layer of hardware efficient ansatz.</p> <p> TYPE: <code>AnsatzConfig</code> DEFAULT: <code>AnsatzConfig()</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices are 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Optional backend configuration.</p> <p> TYPE: <code>BackendConfiguration | dict</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode</code> DEFAULT: <code>AD</code> </p> RETURNS DESCRIPTION <code>QNN</code> <p>A QNN object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the observable configuration is not provided.</p> <p>Example: <pre><code>import torch\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools import QNN\nfrom qadence.constructors import ObservableConfig\nfrom qadence.operations import Z\nfrom qadence.types import (\n    AnsatzType, BackendName, BasisSet, ObservableTransform, ReuploadScaling, Strategy\n)\n\nregister = 4\nobs_config = ObservableConfig(\n    detuning=Z,\n    scale=5.0,\n    shift=0.0,\n    transformation_type=ObservableTransform.SCALE,\n    trainable_transform=None,\n)\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs=[\"x\", \"y\"],\n    basis_set=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.CONSTANT,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nqnn = QNN.from_configs(\n    register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n)\n\nx = torch.rand(2, 2)\ny = qnn(x)\n</code></pre> <pre><code>tensor([[3.5351],\n        [1.2724]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> Source code in <code>qadence/ml_tools/models.py</code> <pre><code>@classmethod\ndef from_configs(\n    cls,\n    register: int | Register,\n    obs_config: Any,\n    fm_config: Any = FeatureMapConfig(),\n    ansatz_config: Any = AnsatzConfig(),\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n) -&gt; QNN:\n    \"\"\"Create a QNN from a set of configurations.\n\n    Args:\n        register (int | Register): The number of qubits or a register object.\n        obs_config (list[ObservableConfig] | ObservableConfig): The configuration(s)\n            for the observable(s).\n        fm_config (FeatureMapConfig): The configuration for the feature map.\n            Defaults to no feature encoding block.\n        ansatz_config (AnsatzConfig): The configuration for the ansatz.\n            Defaults to a single layer of hardware efficient ansatz.\n        backend (BackendName): The chosen quantum backend.\n        diff_mode (DiffMode): The differentiation engine to use. Choices are\n            'gpsr' or 'ad'.\n        measurement (Measurements): Optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator.\n        noise (Noise): A noise model to use.\n        configuration (BackendConfiguration | dict): Optional backend configuration.\n        input_diff_mode (InputDiffMode): The differentiation mode for the input tensor.\n\n    Returns:\n        A QNN object.\n\n    Raises:\n        ValueError: If the observable configuration is not provided.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools import QNN\n    from qadence.constructors import ObservableConfig\n    from qadence.operations import Z\n    from qadence.types import (\n        AnsatzType, BackendName, BasisSet, ObservableTransform, ReuploadScaling, Strategy\n    )\n\n    register = 4\n    obs_config = ObservableConfig(\n        detuning=Z,\n        scale=5.0,\n        shift=0.0,\n        transformation_type=ObservableTransform.SCALE,\n        trainable_transform=None,\n    )\n    fm_config = FeatureMapConfig(\n        num_features=2,\n        inputs=[\"x\", \"y\"],\n        basis_set=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.CONSTANT,\n        feature_range={\n            \"x\": (-1.0, 1.0),\n            \"y\": (0.0, 1.0),\n        },\n    )\n    ansatz_config = AnsatzConfig(\n        depth=2,\n        ansatz_type=AnsatzType.HEA,\n        ansatz_strategy=Strategy.DIGITAL,\n    )\n\n    qnn = QNN.from_configs(\n        register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n    )\n\n    x = torch.rand(2, 2)\n    y = qnn(x)\n    print(str(y)) # markdown-exec: hide\n    ```\n    \"\"\"\n    from .constructors import build_qnn_from_configs\n\n    return build_qnn_from_configs(\n        register=register,\n        observable_config=obs_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        noise=noise,\n        configuration=configuration,\n        input_diff_mode=input_diff_mode,\n    )\n</code></pre>"},{"location":"api/operations/","title":"Operations","text":"<p>Operations are common <code>PrimitiveBlocks</code>, these are often called gates elsewhere.</p>"},{"location":"api/operations/#constant-blocks","title":"Constant blocks","text":"<p>CY gate not implemented</p>"},{"location":"api/operations/#qadence.operations.X","title":"<code>X(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The X gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.Y","title":"<code>Y(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Y gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.Z","title":"<code>Z(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Z gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.I","title":"<code>I(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The identity gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.H","title":"<code>H(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hadamard or H gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    self.generator = (1 / np.sqrt(2)) * (X(target) + Z(target) - np.sqrt(2) * I(target))\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.S","title":"<code>S(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The S / Phase gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    self.generator = I(target) - Z(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.SDagger","title":"<code>SDagger(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the S / Phase gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    self.generator = I(target) - Z(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.SWAP","title":"<code>SWAP(control, target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The SWAP gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\n    a11 = 0.5 * (Z(control) - I(control))\n    a22 = -0.5 * (Z(target) + I(target))\n    a12 = 0.5 * (chain(X(control), Z(control)) + X(control))\n    a21 = 0.5 * (chain(Z(target), X(target)) + X(target))\n    self.generator = (\n        kron(-1.0 * a22, a11) + kron(-1.0 * a11, a22) + kron(a12, a21) + kron(a21, a12)\n    )\n    super().__init__((control, target))\n</code></pre>"},{"location":"api/operations/#qadence.operations.T","title":"<code>T(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The T gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    self.generator = I(target) - Z(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.TDagger","title":"<code>TDagger(target)</code>","text":"<p>               Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the T gate.</p> Source code in <code>qadence/operations/primitive.py</code> <pre><code>def __init__(self, target: int):\n    self.generator = I(target) - Z(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.CNOT","title":"<code>CNOT(control, target)</code>","text":"<p>               Bases: <code>ControlBlock</code></p> <p>The CNot, or CX, gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\n    self.generator = kron(N(control), X(target) - I(target))\n    super().__init__((control,), X(target))\n</code></pre>"},{"location":"api/operations/#qadence.operations.CZ","title":"<code>CZ(control, target)</code>","text":"<p>               Bases: <code>MCZ</code></p> <p>The CZ gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\n    super().__init__((control,), target)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CPHASE","title":"<code>CPHASE(control, target, parameter)</code>","text":"<p>               Bases: <code>MCPHASE</code></p> <p>The CPHASE gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n):\n    super().__init__((control,), target, parameter)\n</code></pre>"},{"location":"api/operations/#parametrized-blocks","title":"Parametrized blocks","text":""},{"location":"api/operations/#qadence.operations.RX","title":"<code>RX(target, parameter)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Rx gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\n    # TODO: should we give them more meaningful names? like 'angle'?\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = X(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.RY","title":"<code>RY(target, parameter)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Ry gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = Y(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.RZ","title":"<code>RZ(target, parameter)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Rz gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\n    self.parameters = (\n        parameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n    )\n    self.generator = Z(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRX","title":"<code>CRX(control, target, parameter)</code>","text":"<p>               Bases: <code>MCRX</code></p> <p>The CRX gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n):\n    super().__init__((control,), target, parameter)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRY","title":"<code>CRY(control, target, parameter)</code>","text":"<p>               Bases: <code>MCRY</code></p> <p>The CRY gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: TParameter,\n):\n    super().__init__((control,), target, parameter)\n</code></pre>"},{"location":"api/operations/#qadence.operations.CRZ","title":"<code>CRZ(control, target, parameter)</code>","text":"<p>               Bases: <code>MCRZ</code></p> <p>The CRZ gate.</p> Source code in <code>qadence/operations/control_ops.py</code> <pre><code>def __init__(\n    self,\n    control: int,\n    target: int,\n    parameter: Parameter | TNumber | sympy.Expr | str,\n):\n    super().__init__((control,), target, parameter)\n</code></pre>"},{"location":"api/operations/#qadence.operations.PHASE","title":"<code>PHASE(target, parameter)</code>","text":"<p>               Bases: <code>ParametricBlock</code></p> <p>The Parametric Phase / S gate.</p> Source code in <code>qadence/operations/parametric.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TNumber | sympy.Expr | str):\n    self.parameters = ParamMap(parameter=parameter)\n    self.generator = I(target) - Z(target)\n    super().__init__((target,))\n</code></pre>"},{"location":"api/operations/#hamiltonian-evolution","title":"Hamiltonian Evolution","text":"<p>AnalogSWAP should be turned into a proper analog block</p>"},{"location":"api/operations/#qadence.operations.HamEvo","title":"<code>HamEvo(generator, parameter, qubit_support=None, duration=None)</code>","text":"<p>               Bases: <code>TimeEvolutionBlock</code></p> <p>A block implementing the Hamiltonian evolution operation H where:</p> <pre><code>H = exp(-iG, t)\n</code></pre> <p>where G represents a square generator and t represents the time parameter which can be parametrized.</p> PARAMETER DESCRIPTION <code>generator</code> <p>Either a AbstractBlock, torch.Tensor or numpy.ndarray.</p> <p> TYPE: <code>Union[TGenerator, AbstractBlock]</code> </p> <code>parameter</code> <p>A scalar or vector of numeric or torch.Tensor type.</p> <p> TYPE: <code>TParameter</code> </p> <code>qubit_support</code> <p>The qubits on which the evolution will be performed on.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>duration</code> <p>duration of evolution in case of time-dependent generator</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import RX, HamEvo, run, PI\nimport torch\nhevo = HamEvo(generator=RX(0, PI), parameter=torch.rand(2))\nprint(run(hevo))\n# Now lets use a torch.Tensor as a generator, Now we have to pass the support\ngen = torch.rand(2,2, dtype=torch.complex128)\nhevo = HamEvo(generator=gen, parameter=torch.rand(2), qubit_support=(0,))\nprint(run(hevo))\n</code></pre> <pre><code>tensor([[ 1.4529-8.1759e-17j, -1.0540+5.9310e-17j],\n        [ 1.1190-3.3099e-17j, -0.5021+1.4852e-17j]])\ntensor([[1.3743-0.2001j, 0.5196-0.4704j],\n        [1.0508-0.0081j, 0.0726-0.0491j]])\n</code></pre> Source code in <code>qadence/operations/ham_evo.py</code> <pre><code>def __init__(\n    self,\n    generator: Union[TGenerator, AbstractBlock],\n    parameter: TParameter,\n    qubit_support: tuple[int, ...] = None,\n    duration: float | None = None,\n):\n    gen_exprs = {}\n    if qubit_support is None and not isinstance(generator, AbstractBlock):\n        raise ValueError(\"You have to supply a qubit support for non-block generators.\")\n    super().__init__(qubit_support if qubit_support else generator.qubit_support)\n    if isinstance(generator, AbstractBlock):\n        qubit_support = generator.qubit_support\n        if generator.is_parametric:\n            gen_exprs = {str(e): e for e in expressions(generator)}\n\n            if generator.is_time_dependent and duration is None:\n                raise ValueError(\"For time-dependent generators, a duration must be specified.\")\n\n    elif isinstance(generator, torch.Tensor):\n        msg = \"Please provide a square generator.\"\n        if len(generator.shape) == 2:\n            assert generator.shape[0] == generator.shape[1], msg\n        elif len(generator.shape) == 3:\n            assert generator.shape[1] == generator.shape[2], msg\n            assert generator.shape[0] == 1, \"Qadence doesnt support batched generators.\"\n        else:\n            raise TypeError(\n                \"Only 2D or 3D generators are supported.\\\n                            In case of a 3D generator, the batch dim\\\n                            is expected to be at dim 0.\"\n            )\n        gen_exprs = {str(generator.__hash__()): generator}\n    elif isinstance(generator, (sympy.Basic, sympy.Array)):\n        gen_exprs = {str(generator): generator}\n    else:\n        raise TypeError(\n            f\"Generator of type {type(generator)} not supported.\\\n                        If you're using a numpy.ndarray, please cast it to a torch tensor.\"\n        )\n    ps = {\"parameter\": Parameter(parameter), **gen_exprs}\n    self.parameters = ParamMap(**ps)\n    self.generator = generator\n    self.duration = duration\n</code></pre>"},{"location":"api/operations/#qadence.operations.HamEvo.digital_decomposition","title":"<code>digital_decomposition(approximation=LTSOrder.ST4)</code>","text":"<p>Decompose the Hamiltonian evolution into digital gates.</p> PARAMETER DESCRIPTION <code>approximation</code> <p>Choose the type of decomposition. Defaults to \"st4\". Available types are: * 'basic' = apply first-order Trotter formula and decompose each term of     the exponential into digital gates. It is exact only if applied to an     operator whose terms are mutually commuting. * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting     Hamiltonians. * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting     Hamiltonians.</p> <p> TYPE: <code>str</code> DEFAULT: <code>ST4</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>a block with the digital decomposition</p> <p> TYPE: <code>AbstractBlock</code> </p> Source code in <code>qadence/operations/ham_evo.py</code> <pre><code>def digital_decomposition(self, approximation: LTSOrder = LTSOrder.ST4) -&gt; AbstractBlock:\n    \"\"\"Decompose the Hamiltonian evolution into digital gates.\n\n    Args:\n        approximation (str, optional): Choose the type of decomposition. Defaults to \"st4\".\n            Available types are:\n            * 'basic' = apply first-order Trotter formula and decompose each term of\n                the exponential into digital gates. It is exact only if applied to an\n                operator whose terms are mutually commuting.\n            * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting\n                Hamiltonians.\n            * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting\n                Hamiltonians.\n\n    Returns:\n        AbstractBlock: a block with the digital decomposition\n    \"\"\"\n\n    # psi(t) = exp(-i * H * t * psi0)\n    # psi(t) = exp(-i * lambda * t * psi0)\n    # H = sum(Paulin) + sum(Pauli1*Pauli2)\n    logger.info(\"Quantum simulation of the time-independent Schr\u00f6dinger equation.\")\n\n    blocks = []\n\n    # how to change the type/dict to enum effectively\n\n    # when there is a term including non-commuting matrices use st2 or st4\n\n    # 1) should check that the given generator respects the constraints\n    # single-qubit gates\n\n    assert isinstance(\n        self.generator, AbstractBlock\n    ), \"Only a generator represented as a block can be decomposed\"\n\n    if block_is_qubit_hamiltonian(self.generator):\n        try:\n            block_is_commuting_hamiltonian(self.generator)\n            approximation = LTSOrder.BASIC  # use the simpler approach if the H is commuting\n        except TypeError:\n            logger.warning(\n                \"\"\"Non-commuting terms in the Pauli operator.\n                The Suzuki-Trotter approximation is applied.\"\"\"\n            )\n\n        blocks.extend(\n            lie_trotter_suzuki(\n                block=self.generator,\n                parameter=self.parameters.parameter,\n                order=LTSOrder[approximation],\n            )\n        )\n\n        # 2) return an AbstractBlock instance with the set of gates\n        # resulting from the decomposition\n\n        return chain(*blocks)\n    else:\n        raise NotImplementedError(\n            \"The current digital decomposition can be applied only to Pauli Hamiltonians.\"\n        )\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogSWAP","title":"<code>AnalogSWAP(control, target, parameter=3 * PI / 4)</code>","text":"<p>               Bases: <code>HamEvo</code></p> <p>Single time-independent Hamiltonian evolution over a Rydberg Ising.</p> <p>hamiltonian yielding a SWAP (up to global phase).</p> <p>Derived from Bapat et al. where it is applied to XX-type Hamiltonian</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def __init__(self, control: int, target: int, parameter: TParameter = 3 * PI / 4):\n    rydberg_ising_hamiltonian_generator = (\n        4.0 * kron((I(control) - Z(control)) / 2.0, (I(target) - Z(target)) / 2.0)\n        + (2.0 / 3.0) * np.sqrt(2.0) * X(control)\n        + (2.0 / 3.0) * np.sqrt(2.0) * X(target)\n        + (1.0 + np.sqrt(5.0) / 3) * Z(control)\n        + (1.0 + np.sqrt(5.0) / 3) * Z(target)\n    )\n    super().__init__(rydberg_ising_hamiltonian_generator, parameter, (control, target))\n</code></pre>"},{"location":"api/operations/#analog-blocks","title":"Analog blocks","text":""},{"location":"api/operations/#qadence.operations.AnalogRX","title":"<code>AnalogRX(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog X rotation.</p> <p>Shorthand for <code>AnalogRot</code>:</p> <pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9)\n</code></pre> PARAMETER DESCRIPTION <code>angle</code> <p>Rotation angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRX(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog X rotation.\n\n    Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9)\n    ```\n\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n    return _analog_rot(angle, qubit_support, phase=0, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRY","title":"<code>AnalogRY(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog Y rotation.</p> <p>Shorthand for <code>AnalogRot</code>:</p> <p><pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n</code></pre> Arguments:     angle: Rotation angle [rad]     qubit_support: Defines the (local/global) qubit support</p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRY(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog Y rotation.\n\n    Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n    return _analog_rot(angle, qubit_support, phase=-PI / 2, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRZ","title":"<code>AnalogRZ(angle, qubit_support='global', add_pattern=True)</code>","text":"<p>Analog Z rotation. Shorthand for <code>AnalogRot</code>: <pre><code>\u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\nAnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n</code></pre></p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRZ(\n    angle: float | str | Parameter,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"Analog Z rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```\n    \u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\n    AnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n    ```\n    \"\"\"\n    q = _cast(QubitSupport, qubit_support)\n    alpha = _cast(Parameter, angle)\n    delta = PI\n    omega = 0\n    duration = alpha / delta * 1000\n    h_norm = sympy.sqrt(omega**2 + delta**2)\n    ps = ParamMap(\n        alpha=alpha, duration=duration, omega=omega, delta=delta, phase=0.0, h_norm=h_norm\n    )\n    return ConstantAnalogRotation(qubit_support=q, parameters=ps, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogRot","title":"<code>AnalogRot(duration, omega=0, delta=0, phase=0, qubit_support='global', add_pattern=True)</code>","text":"<p>General analog rotation operation.</p> PARAMETER DESCRIPTION <code>duration</code> <p>Duration of the rotation [ns].</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>omega</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>delta</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>phase</code> <p>Phase angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> <code>add_pattern</code> <p>False disables the semi-local addressing pattern for the execution of this specific block.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogRot(\n    duration: float | str | Parameter,\n    omega: float | str | Parameter = 0,\n    delta: float | str | Parameter = 0,\n    phase: float | str | Parameter = 0,\n    qubit_support: str | QubitSupport | Tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; ConstantAnalogRotation:\n    \"\"\"General analog rotation operation.\n\n    Arguments:\n        duration: Duration of the rotation [ns].\n        omega: Rotation frequency [rad/\u03bcs]\n        delta: Rotation frequency [rad/\u03bcs]\n        phase: Phase angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n        add_pattern: False disables the semi-local addressing pattern\n            for the execution of this specific block.\n\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\n\n    if omega == 0 and delta == 0:\n        raise ValueError(\"Parameters omega and delta cannot both be 0.\")\n\n    q = _cast(QubitSupport, qubit_support)\n    duration = Parameter(duration)\n    omega = Parameter(omega)\n    delta = Parameter(delta)\n    phase = Parameter(phase)\n    h_norm = sympy.sqrt(omega**2 + delta**2)\n    alpha = duration * h_norm / 1000\n    ps = ParamMap(\n        alpha=alpha, duration=duration, omega=omega, delta=delta, phase=phase, h_norm=h_norm\n    )\n    return ConstantAnalogRotation(parameters=ps, qubit_support=q, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/operations/#qadence.operations.AnalogInteraction","title":"<code>AnalogInteraction(duration, qubit_support='global', add_pattern=True)</code>","text":"<p>Evolution of the interaction term for a register of qubits.</p> <p>Constructs a <code>InteractionBlock</code>.</p> PARAMETER DESCRIPTION <code>duration</code> <p>Time to evolve the interaction for in nanoseconds.</p> <p> TYPE: <code>TNumber | Basic</code> </p> <code>qubit_support</code> <p>Qubits the <code>InteractionBlock</code> is applied to. Can be either <code>\"global\"</code> to evolve the interaction block to all qubits or a tuple of integers.</p> <p> TYPE: <code>str | QubitSupport | tuple</code> DEFAULT: <code>'global'</code> </p> <code>add_pattern</code> <p>False disables the semi-local addressing pattern for the execution of this specific block.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>InteractionBlock</code> <p>a <code>InteractionBlock</code></p> Source code in <code>qadence/operations/analog.py</code> <pre><code>def AnalogInteraction(\n    duration: TNumber | sympy.Basic,\n    qubit_support: str | QubitSupport | tuple = \"global\",\n    add_pattern: bool = True,\n) -&gt; InteractionBlock:\n    \"\"\"Evolution of the interaction term for a register of qubits.\n\n    Constructs a [`InteractionBlock`][qadence.blocks.analog.InteractionBlock].\n\n    Arguments:\n        duration: Time to evolve the interaction for in nanoseconds.\n        qubit_support: Qubits the `InteractionBlock` is applied to. Can be either\n            `\"global\"` to evolve the interaction block to all qubits or a tuple of integers.\n        add_pattern: False disables the semi-local addressing pattern\n            for the execution of this specific block.\n\n    Returns:\n        a `InteractionBlock`\n    \"\"\"\n    q = _cast(QubitSupport, qubit_support)\n    ps = ParamMap(duration=duration)\n    return InteractionBlock(parameters=ps, qubit_support=q, add_pattern=add_pattern)\n</code></pre>"},{"location":"api/parameters/","title":"Parameters","text":""},{"location":"api/parameters/#parameters","title":"Parameters","text":""},{"location":"api/parameters/#qadence.parameters.ParamMap","title":"<code>ParamMap(**kwargs)</code>","text":"<p>Connects UUIDs of parameters to their expressions and names.</p> <p>This class is not user-facing and only needed for more complex block definitions. It provides convenient access to expressions/UUIDs/names needed in different backends.</p> PARAMETER DESCRIPTION <code>kwargs</code> <p>Parameters.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>import sympy\nfrom qadence.parameters import ParamMap\n\n(x,y) = sympy.symbols(\"x y\")\nps = ParamMap(omega=2.0, duration=x+y)\n\nprint(f\"{ps.names() = }\")\nprint(f\"{ps.expressions() = }\")\nprint(f\"{ps.uuids() = }\")\n</code></pre> <pre><code>ps.names() = dict_keys(['omega', 'duration'])\nps.expressions() = dict_values([2.00000000000000, x + y])\nps.uuids() = dict_keys(['5e46187a-e8a5-44ee-a509-8e2180c96ce4', '74c89bd3-2615-4baa-893d-40225ea99afc'])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __init__(self, **kwargs: str | TNumber | Tensor | Basic | Parameter):\n    self._name_dict: dict[str, tuple[str, Basic]] = {}\n    self._uuid_dict: dict[str, str] = {}\n    for name, v in kwargs.items():\n        param = v if isinstance(v, sympy.Basic) else Parameter(v)\n        uuid = str(uuid4())\n        self._name_dict[name] = (uuid, param)\n        self._uuid_dict[uuid] = param\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.Parameter","title":"<code>Parameter</code>","text":"<p>               Bases: <code>Symbol</code></p> <p>A wrapper on top of <code>sympy.Symbol</code>.</p> <p>Includes two additional keywords: <code>trainable</code> and <code>value</code>. This class is to define both feature parameter and variational parameters.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.trainable","title":"<code>trainable: bool</code>  <code>instance-attribute</code>","text":"<p>Trainable parameters are variational parameters.</p> <p>Non-trainable parameters are feature parameters.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.value","title":"<code>value: TNumber</code>  <code>instance-attribute</code>","text":"<p>(Initial) value of the parameter.</p>"},{"location":"api/parameters/#qadence.parameters.Parameter.__new__","title":"<code>__new__(name, **assumptions)</code>","text":"<p>Arguments:</p> <pre><code>name: When given a string only, the class\n    constructs a trainable Parameter with a a randomly initialized value.\n**assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n    kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n</code></pre> <p>Example: <pre><code>from qadence.parameters import Parameter, VariationalParameter\n\ntheta = Parameter(\"theta\")\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\nassert not theta.is_number\n\n# you can specify both trainable/value in the constructor\ntheta = Parameter(\"theta\", trainable=True, value=2.0)\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n\n# VariationalParameter/FeatureParameter are constructing\n# trainable/untrainable Parameters\ntheta = VariationalParameter(\"theta\", value=2.0)\nassert theta == Parameter(\"theta\", trainable=True, value=2.0)\n\n# When provided with a numeric type, Parameter constructs a sympy numeric type\":\nconstant_zero = Parameter(0)\nassert constant_zero.is_number\n\n# When passed a Parameter or a sympy expression, it just returns it.\nexpr = Parameter(\"x\") * Parameter(\"y\")\nprint(f\"{expr=} : {expr.free_symbols}\")\n</code></pre> <pre><code>theta: trainable=True value=0.42707459177605245\ntheta: trainable=True value=2.0\nexpr=x*y : {y, x}\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __new__(\n    cls, name: str | TNumber | Tensor | Basic | Parameter, **assumptions: Any\n) -&gt; Parameter | Basic | Expr | Array:\n    \"\"\"\n    Arguments:\n\n        name: When given a string only, the class\n            constructs a trainable Parameter with a a randomly initialized value.\n        **assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n            kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, VariationalParameter\n\n    theta = Parameter(\"theta\")\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    assert not theta.is_number\n\n    # you can specify both trainable/value in the constructor\n    theta = Parameter(\"theta\", trainable=True, value=2.0)\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n\n    # VariationalParameter/FeatureParameter are constructing\n    # trainable/untrainable Parameters\n    theta = VariationalParameter(\"theta\", value=2.0)\n    assert theta == Parameter(\"theta\", trainable=True, value=2.0)\n\n    # When provided with a numeric type, Parameter constructs a sympy numeric type\":\n    constant_zero = Parameter(0)\n    assert constant_zero.is_number\n\n    # When passed a Parameter or a sympy expression, it just returns it.\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    print(f\"{expr=} : {expr.free_symbols}\")\n    ```\n    \"\"\"\n    p: Parameter\n    if isinstance(name, get_args(TNumber)):\n        return sympify(name)\n    elif isinstance(name, Tensor):\n        if name.numel() == 1:\n            return sympify(name)\n        else:\n            return Array(name.detach().numpy())\n    elif isinstance(name, Parameter):\n        p = super().__new__(cls, name.name, **assumptions)\n        p.name = name.name\n        p.trainable = name.trainable\n        p.value = name.value\n        p.is_time = name.is_time\n        return p\n    elif isinstance(name, (Basic, Expr)):\n        if name.is_number:\n            return sympify(evaluate(name))\n        return name\n    elif isinstance(name, str):\n        p = super().__new__(cls, name, **assumptions)\n        p.trainable = assumptions.get(\"trainable\", True)\n        p.value = assumptions.get(\"value\", None)\n        p.is_time = assumptions.get(\"is_time\", False)\n        if p.value is None:\n            p.value = rand(1).item()\n        return p\n    else:\n        raise TypeError(f\"Parameter does not support type {type(name)}\")\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.FeatureParameter","title":"<code>FeatureParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def FeatureParameter(name: str, **kwargs: Any) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=False)`.\"\"\"\n    return Parameter(name, trainable=False, **kwargs)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.TimeParameter","title":"<code>TimeParameter(name)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False, is_time=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def TimeParameter(name: str) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=False, is_time=True)`.\"\"\"\n    return Parameter(name, trainable=False, is_time=True)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.VariationalParameter","title":"<code>VariationalParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def VariationalParameter(name: str, **kwargs: Any) -&gt; Parameter:\n    \"\"\"Shorthand for `Parameter(..., trainable=True)`.\"\"\"\n    return Parameter(name, trainable=True, **kwargs)\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.evaluate","title":"<code>evaluate(expr, values={}, as_torch=False)</code>","text":"<p>Arguments:</p> <pre><code>expr: An expression consisting of Parameters.\nvalues: values dict which contains values for the Parameters,\n    if empty, Parameter.value will be used.\nas_torch: Whether to retrieve a torch-differentiable expression result.\n</code></pre> <p>Example: <pre><code>from qadence.parameters import Parameter, evaluate\n\nexpr = Parameter(\"x\") * Parameter(\"y\")\n\n# Unless specified, Parameter initialized random values\n# Lets evaluate this expression and see what the result is\nres = evaluate(expr)\nprint(res)\n\n# We can also evaluate the expr using a custom dict\nd = {\"x\": 1, \"y\":2}\nres = evaluate(expr, d)\nprint(res)\n\n# Lastly, if we want a differentiable result, lets put the as_torch flag\nres = evaluate(expr, d, as_torch=True)\nprint(res)\n</code></pre> <pre><code>0.062059532907797296\n2.0\ntensor([2])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def evaluate(expr: Expr, values: dict = {}, as_torch: bool = False) -&gt; TNumber | Tensor:\n    \"\"\"\n    Arguments:\n\n        expr: An expression consisting of Parameters.\n        values: values dict which contains values for the Parameters,\n            if empty, Parameter.value will be used.\n        as_torch: Whether to retrieve a torch-differentiable expression result.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, evaluate\n\n    expr = Parameter(\"x\") * Parameter(\"y\")\n\n    # Unless specified, Parameter initialized random values\n    # Lets evaluate this expression and see what the result is\n    res = evaluate(expr)\n    print(res)\n\n    # We can also evaluate the expr using a custom dict\n    d = {\"x\": 1, \"y\":2}\n    res = evaluate(expr, d)\n    print(res)\n\n    # Lastly, if we want a differentiable result, lets put the as_torch flag\n    res = evaluate(expr, d, as_torch=True)\n    print(res)\n    ```\n    \"\"\"\n    res: Basic\n    res_value: TNumber | Tensor\n    query: dict[Parameter, TNumber | Tensor] = {}\n    if isinstance(expr, Array):\n        return Tensor(expr.tolist())\n    else:\n        if not expr.is_number:\n            for s in expr.free_symbols:\n                if s.name in values.keys():\n                    query[s] = values[s.name]\n                elif hasattr(s, \"value\"):\n                    query[s] = s.value\n                else:\n                    raise ValueError(f\"No value provided for symbol {s.name}\")\n        if as_torch:\n            res_value = make_differentiable(expr)(**{s.name: tensor(v) for s, v in query.items()})\n        else:\n            res = expr.subs(query)\n            res_value = sympy_to_numeric(res)\n        return res_value\n</code></pre>"},{"location":"api/parameters/#qadence.parameters.extract_original_param_entry","title":"<code>extract_original_param_entry(param)</code>","text":"<p>Given an Expression, what was the original \"param\" given by the user? It is either.</p> <p>going to be a numeric value, or a sympy Expression (in case a string was given, it was converted via Parameter(\"string\").</p> Source code in <code>qadence/parameters.py</code> <pre><code>def extract_original_param_entry(\n    param: Expr,\n) -&gt; TNumber | Tensor | Expr:\n    \"\"\"\n    Given an Expression, what was the original \"param\" given by the user? It is either.\n\n    going to be a numeric value, or a sympy Expression (in case a string was given,\n    it was converted via Parameter(\"string\").\n    \"\"\"\n    return param if not param.is_number else evaluate(param)\n</code></pre>"},{"location":"api/parameters/#parameter-embedding","title":"Parameter embedding","text":""},{"location":"api/parameters/#qadence.blocks.embedding.embedding","title":"<code>embedding(block, to_gate_params=False, engine=Engine.TORCH)</code>","text":"<p>Construct embedding function which maps user-facing parameters to either expression-level.</p> <p>parameters or gate-level parameters. The constructed embedding function has the signature:</p> <pre><code> embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n</code></pre> <p>which means that it maps the variational parameter dict <code>params</code> and the feature parameter dict <code>inputs</code> to one new parameter dict <code>embedded_dict</code> which holds all parameters that are needed to execute a circuit on a given backend. There are two different modes for this mapping:</p> <ul> <li>Expression-level parameters: For AD-based optimization. For every unique expression we end   up with one entry in the embedded dict:   <code>len(embedded_dict) == len(unique_parameter_expressions)</code>.</li> <li>Gate-level parameters: For PSR-based optimization or real devices. One parameter for each   gate parameter, regardless if they are based on the same expression. <code>len(embedded_dict) ==   len(parametric_gates)</code>. This is needed because PSR requires to shift the angles of every   gate where the same parameter appears.</li> </ul> PARAMETER DESCRIPTION <code>block</code> <p>parametrized block into which we want to embed parameters.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>to_gate_params</code> <p>A boolean flag whether to generate gate-level parameters or expression-level parameters.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>tuple[ParamDictType, Callable[[ParamDictType, ParamDictType], ParamDictType]]</code> <p>A tuple with variational parameter dict and the embedding function.</p> Source code in <code>qadence/blocks/embedding.py</code> <pre><code>def embedding(\n    block: AbstractBlock, to_gate_params: bool = False, engine: Engine = Engine.TORCH\n) -&gt; tuple[ParamDictType, Callable[[ParamDictType, ParamDictType], ParamDictType],]:\n    \"\"\"Construct embedding function which maps user-facing parameters to either *expression-level*.\n\n    parameters or *gate-level* parameters. The constructed embedding function has the signature:\n\n         embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n\n    which means that it maps the *variational* parameter dict `params` and the *feature* parameter\n    dict `inputs` to one new parameter dict `embedded_dict` which holds all parameters that are\n    needed to execute a circuit on a given backend. There are two different *modes* for this\n    mapping:\n\n    - *Expression-level* parameters: For AD-based optimization. For every unique expression we end\n      up with one entry in the embedded dict:\n      `len(embedded_dict) == len(unique_parameter_expressions)`.\n    - *Gate-level* parameters: For PSR-based optimization or real devices. One parameter for each\n      gate parameter, regardless if they are based on the same expression. `len(embedded_dict) ==\n      len(parametric_gates)`. This is needed because PSR requires to shift the angles of **every**\n      gate where the same parameter appears.\n\n    Arguments:\n        block: parametrized block into which we want to embed parameters.\n        to_gate_params: A boolean flag whether to generate gate-level parameters or\n            expression-level parameters.\n\n    Returns:\n        A tuple with variational parameter dict and the embedding function.\n    \"\"\"\n    concretize_parameter = _concretize_parameter(engine)\n    if engine == Engine.TORCH:\n        cast_dtype = tensor\n    else:\n        from jax.numpy import array\n\n        cast_dtype = array\n\n    unique_expressions = unique(expressions(block))\n    unique_symbols = [p for p in unique(parameters(block)) if not isinstance(p, sympy.Array)]\n    unique_const_matrices = [e for e in unique_expressions if isinstance(e, sympy.Array)]\n    unique_expressions = [e for e in unique_expressions if not isinstance(e, sympy.Array)]\n\n    # NOTE\n    # there are 3 kinds of parameters in qadence\n    # - non-trainable which are considered as inputs for classical data\n    # - trainable which are the variational parameters to be optimized\n    # - fixed: which are non-trainable parameters with fixed value (e.g. pi/2)\n    #\n    # both non-trainable and trainable parameters can have the same element applied\n    # to different operations in the quantum circuit, e.g. assigning the same parameter\n    # to multiple gates.\n    non_numeric_symbols = [p for p in unique_symbols if not p.is_number]\n    trainable_symbols = [p for p in non_numeric_symbols if p.trainable]\n    constant_expressions = [expr for expr in unique_expressions if expr.is_number]\n    # we dont need to care about constant symbols if they are contained in an symbolic expression\n    # we only care about gate params which are ONLY a constant\n\n    embeddings: dict[sympy.Expr, DifferentiableExpression] = {\n        expr: make_differentiable(expr=expr, engine=engine)\n        for expr in unique_expressions\n        if not expr.is_number\n    }\n\n    uuid_to_expr = uuid_to_expression(block)\n\n    def embedding_fn(params: ParamDictType, inputs: ParamDictType) -&gt; ParamDictType:\n        embedded_params: dict[sympy.Expr, ArrayLike] = {}\n        for expr, fn in embeddings.items():\n            angle: ArrayLike\n            values = {}\n            for symbol in expr.free_symbols:\n                if not symbol.is_time:\n                    if symbol.name in inputs:\n                        value = inputs[symbol.name]\n                    elif symbol.name in params:\n                        value = params[symbol.name]\n                    else:\n                        msg_trainable = \"Trainable\" if symbol.trainable else \"Non-trainable\"\n                        raise KeyError(\n                            f\"{msg_trainable} parameter '{symbol.name}' not found in the \"\n                            f\"inputs list: {list(inputs.keys())} nor the \"\n                            f\"params list: {list(params.keys())}.\"\n                        )\n                    values[symbol.name] = value\n                else:\n                    values[symbol.name] = tensor(1.0)\n            angle = fn(**values)\n            # do not reshape parameters which are multi-dimensional\n            # tensors, such as for example generator matrices\n            if not len(angle.squeeze().shape) &gt; 1:\n                angle = angle.reshape(-1)\n            embedded_params[expr] = angle\n\n        for e in constant_expressions + unique_const_matrices:\n            embedded_params[e] = params[stringify(e)]\n\n        if to_gate_params:\n            gate_lvl_params: ParamDictType = {}\n            for uuid, e in uuid_to_expr.items():\n                gate_lvl_params[uuid] = embedded_params[e]\n            return gate_lvl_params\n        else:\n            out = {stringify(k): v for k, v in embedded_params.items()}\n            out.update({\"orig_param_values\": inputs})\n            return out\n\n    params: ParamDictType\n    params = {\n        p.name: concretize_parameter(value=p.value, trainable=True) for p in trainable_symbols\n    }\n    params.update(\n        {\n            stringify(expr): concretize_parameter(value=evaluate(expr), trainable=False)\n            for expr in constant_expressions\n        }\n    )\n    params.update(\n        {\n            stringify(expr): cast_dtype(nparray(expr.tolist(), dtype=npcdouble))\n            for expr in unique_const_matrices\n        }\n    )\n    return params, embedding_fn\n</code></pre>"},{"location":"api/quantumcircuit/","title":"QuantumCircuit","text":""},{"location":"api/quantumcircuit/#quantumcircuit","title":"QuantumCircuit","text":"<p>The abstract <code>QuantumCircuit</code> is the key object in Qadence, as it is what can be executed.</p>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit","title":"<code>QuantumCircuit(support, *blocks)</code>  <code>dataclass</code>","text":"<p>Am abstract QuantumCircuit instance.</p> <p>It needs to be passed to a quantum backend for execution.</p> <p>Arguments:</p> <pre><code>support: `Register` or number of qubits. If an integer is provided, a register is\n    constructed with `Register.all_to_all(x)`\n*blocks: (Possibly multiple) blocks to construct the circuit from.\n</code></pre> Source code in <code>qadence/circuit.py</code> <pre><code>def __init__(self, support: int | Register, *blocks: AbstractBlock):\n    \"\"\"\n    Arguments:\n\n        support: `Register` or number of qubits. If an integer is provided, a register is\n            constructed with `Register.all_to_all(x)`\n        *blocks: (Possibly multiple) blocks to construct the circuit from.\n    \"\"\"\n    self.block = chain(*blocks) if len(blocks) != 1 else blocks[0]\n    self.register = Register(support) if isinstance(support, int) else support\n\n    global_block = isinstance(self.block, AnalogBlock) and self.block.qubit_support.is_global\n    if not global_block and len(self.block) and self.block.n_qubits &gt; self.register.n_qubits:\n        raise ValueError(\n            f\"Register with {self.register.n_qubits} qubits is too small for the \"\n            f\"given block with {self.block.n_qubits} qubits\"\n        )\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.unique_parameters","title":"<code>unique_parameters: list[Parameter]</code>  <code>property</code>","text":"<p>Return the unique parameters in the circuit.</p> <p>These parameters are the actual user-facing parameters which can be assigned by the user. Multiple gates can contain the same unique parameter</p> RETURNS DESCRIPTION <code>list[Parameter]</code> <p>list[Parameter]: List of unique parameters in the circuit</p>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.dagger","title":"<code>dagger()</code>","text":"<p>Reverse the QuantumCircuit by calling dagger on the block.</p> Source code in <code>qadence/circuit.py</code> <pre><code>def dagger(self) -&gt; QuantumCircuit:\n    \"\"\"Reverse the QuantumCircuit by calling dagger on the block.\"\"\"\n    return QuantumCircuit(self.n_qubits, self.block.dagger())\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.get_blocks_by_tag","title":"<code>get_blocks_by_tag(tag)</code>","text":"<p>Extract one or more blocks using the human-readable tag.</p> <p>This function recursively explores all composite blocks to find all the occurrences of a certain tag in the blocks.</p> PARAMETER DESCRIPTION <code>tag</code> <p>the tag to look for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>list[AbstractBlock]: The block(s) corresponding to the given tag</p> Source code in <code>qadence/circuit.py</code> <pre><code>def get_blocks_by_tag(self, tag: str) -&gt; list[AbstractBlock]:\n    \"\"\"Extract one or more blocks using the human-readable tag.\n\n    This function recursively explores all composite blocks to find\n    all the occurrences of a certain tag in the blocks.\n\n    Args:\n        tag (str): the tag to look for\n\n    Returns:\n        list[AbstractBlock]: The block(s) corresponding to the given tag\n    \"\"\"\n\n    def _get_block(block: AbstractBlock) -&gt; list[AbstractBlock]:\n        blocks = []\n        if block.tag == tag:\n            blocks += [block]\n        if isinstance(block, CompositeBlock):\n            blocks += flatten(*[_get_block(b) for b in block.blocks])\n        return blocks\n\n    return _get_block(self.block)\n</code></pre>"},{"location":"api/quantumcircuit/#qadence.circuit.QuantumCircuit.parameters","title":"<code>parameters()</code>","text":"<p>Extract all parameters for primitive blocks in the circuit.</p> <p>Notice that this function returns all the unique Parameters used in the quantum circuit. These can correspond to constants too.</p> RETURNS DESCRIPTION <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>List[tuple[Parameter]]: A list of tuples containing the Parameter</p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>instance of each of the primitive blocks in the circuit or, if the <code>flatten</code></p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>flag is set to True, a flattened list of all circuit parameters</p> Source code in <code>qadence/circuit.py</code> <pre><code>def parameters(self) -&gt; list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]:\n    \"\"\"Extract all parameters for primitive blocks in the circuit.\n\n    Notice that this function returns all the unique Parameters used\n    in the quantum circuit. These can correspond to constants too.\n\n    Returns:\n        List[tuple[Parameter]]: A list of tuples containing the Parameter\n        instance of each of the primitive blocks in the circuit or, if the `flatten`\n        flag is set to True, a flattened list of all circuit parameters\n    \"\"\"\n    return parameters(self.block)\n</code></pre>"},{"location":"api/register/","title":"Register","text":""},{"location":"api/register/#quantum-registers","title":"Quantum Registers","text":""},{"location":"api/register/#qadence.register.Register","title":"<code>Register(support, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>","text":"<p>A register of qubits including 2D coordinates.</p> <p>Instantiating the Register class directly is only recommended for building custom registers. For most uses where a predefined lattice is desired it is recommended to use the various class methods available, e.g. <code>Register.triangular_lattice</code>.</p> PARAMETER DESCRIPTION <code>support</code> <p>A NetworkX graph or number of qubits. Nodes can include a <code>\"pos\"</code> attribute such that e.g.: <code>graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}</code> which will be used in backends that need qubit coordinates. Passing a number of qubits calls <code>Register.all_to_all(n_qubits)</code>.</p> <p> TYPE: <code>Graph | int</code> </p> <code>spacing</code> <p>Value set as the distance between the two closest qubits. The spacing argument is also available for all the class method constructors.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>1.0</code> </p> <p>Examples: <pre><code>from qadence import Register\n\nreg_all = Register.all_to_all(n_qubits = 4)\nreg_line = Register.line(n_qubits = 4)\nreg_circle = Register.circle(n_qubits = 4)\nreg_squre = Register.square(qubits_side = 2)\nreg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\nreg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\nreg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n</code></pre> </p> Source code in <code>qadence/register.py</code> <pre><code>def __init__(\n    self,\n    support: nx.Graph | int,\n    spacing: float | None = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n):\n    \"\"\"\n    A register of qubits including 2D coordinates.\n\n    Instantiating the Register class directly is only recommended for building custom registers.\n    For most uses where a predefined lattice is desired it is recommended to use the various\n    class methods available, e.g. `Register.triangular_lattice`.\n\n    Arguments:\n        support: A NetworkX graph or number of qubits. Nodes can include a `\"pos\"` attribute\n            such that e.g.: `graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}` which\n            will be used in backends that need qubit coordinates. Passing a number of qubits\n            calls `Register.all_to_all(n_qubits)`.\n        spacing: Value set as the distance between the two closest qubits. The spacing\n            argument is also available for all the class method constructors.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import Register\n\n    reg_all = Register.all_to_all(n_qubits = 4)\n    reg_line = Register.line(n_qubits = 4)\n    reg_circle = Register.circle(n_qubits = 4)\n    reg_squre = Register.square(qubits_side = 2)\n    reg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\n    reg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\n    reg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n    ```\n    \"\"\"\n    if device_specs is not None and not isinstance(device_specs, RydbergDevice):\n        raise ValueError(\"Device specs are not valid. Please pass a `RydbergDevice` instance.\")\n\n    self.device_specs = device_specs\n\n    self.graph = support if isinstance(support, nx.Graph) else alltoall_graph(support)\n\n    if spacing is not None and self.min_distance != 0.0:\n        _scale_node_positions(self.graph, self.min_distance, spacing)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.all_node_pairs","title":"<code>all_node_pairs: EdgeView</code>  <code>property</code>","text":"<p>Return a list of all possible qubit pairs in the register.</p>"},{"location":"api/register/#qadence.register.Register.coords","title":"<code>coords: dict</code>  <code>property</code>","text":"<p>Return the dictionary of qubit coordinates.</p>"},{"location":"api/register/#qadence.register.Register.distances","title":"<code>distances: dict</code>  <code>property</code>","text":"<p>Return a dictionary of distances for all qubit pairs in the register.</p>"},{"location":"api/register/#qadence.register.Register.edge_distances","title":"<code>edge_distances: dict</code>  <code>property</code>","text":"<p>Return a dictionary of distances for the qubit pairs that are.</p> <p>connected by an edge in the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.edges","title":"<code>edges: EdgeView</code>  <code>property</code>","text":"<p>Return the EdgeView of the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.min_distance","title":"<code>min_distance: float</code>  <code>property</code>","text":"<p>Return the minimum distance between two qubts in the register.</p>"},{"location":"api/register/#qadence.register.Register.n_qubits","title":"<code>n_qubits: int</code>  <code>property</code>","text":"<p>Total number of qubits in the register.</p>"},{"location":"api/register/#qadence.register.Register.nodes","title":"<code>nodes: NodeView</code>  <code>property</code>","text":"<p>Return the NodeView of the underlying NetworkX graph.</p>"},{"location":"api/register/#qadence.register.Register.support","title":"<code>support: set</code>  <code>property</code>","text":"<p>Return the set of qubits in the register.</p>"},{"location":"api/register/#qadence.register.Register.all_to_all","title":"<code>all_to_all(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a register with an all-to-all connectivity graph.</p> <p>The graph is projected onto a 2D space and the qubit coordinates are set using a spring layout algorithm.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef all_to_all(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a register with an all-to-all connectivity graph.\n\n    The graph is projected\n    onto a 2D space and the qubit coordinates are set using a spring layout algorithm.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    return cls(alltoall_graph(n_qubits), spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.circle","title":"<code>circle(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a circle register.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef circle(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a circle register.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    graph = nx.grid_2d_graph(n_qubits, 1, periodic=True)\n    graph = nx.relabel_nodes(graph, {(i, 0): i for i in range(n_qubits)})\n    coords = nx.circular_layout(graph)\n    values = {i: {\"pos\": pos} for i, pos in coords.items()}\n    nx.set_node_attributes(graph, values)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.draw","title":"<code>draw(show=True)</code>","text":"<p>Draw the underlying NetworkX graph representing the register.</p> Source code in <code>qadence/register.py</code> <pre><code>def draw(self, show: bool = True) -&gt; None:\n    \"\"\"Draw the underlying NetworkX graph representing the register.\"\"\"\n    coords = {i: n[\"pos\"] for i, n in self.graph.nodes.items()}\n    nx.draw(self.graph, with_labels=True, pos=coords)\n    if show:\n        plt.gcf().show()\n</code></pre>"},{"location":"api/register/#qadence.register.Register.from_coordinates","title":"<code>from_coordinates(coords, lattice=LatticeTopology.ARBITRARY, spacing=None, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a register from a list of qubit coordinates.</p> <p>Each node is added to the underlying graph with the respective coordinates, but the edges are left empty.</p> PARAMETER DESCRIPTION <code>coords</code> <p>List of qubit coordinate tuples.</p> <p> TYPE: <code>list[tuple]</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef from_coordinates(\n    cls,\n    coords: list[tuple],\n    lattice: LatticeTopology | str = LatticeTopology.ARBITRARY,\n    spacing: float | None = None,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a register from a list of qubit coordinates.\n\n    Each node is added to the underlying\n    graph with the respective coordinates, but the edges are left empty.\n\n    Arguments:\n        coords: List of qubit coordinate tuples.\n    \"\"\"\n    graph = nx.Graph()\n    for i, pos in enumerate(coords):\n        graph.add_node(i, pos=pos)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.honeycomb_lattice","title":"<code>honeycomb_lattice(n_cells_row, n_cells_col, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a honeycomb lattice register.</p> <p>Each cell is an hexagon made up of six qubits.</p> PARAMETER DESCRIPTION <code>n_cells_row</code> <p>Number of cells in each row.</p> <p> TYPE: <code>int</code> </p> <code>n_cells_col</code> <p>Number of cells in each column.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef honeycomb_lattice(\n    cls,\n    n_cells_row: int,\n    n_cells_col: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a honeycomb lattice register.\n\n    Each cell is an hexagon made up of six qubits.\n\n    Arguments:\n        n_cells_row: Number of cells in each row.\n        n_cells_col: Number of cells in each column.\n    \"\"\"\n    graph = nx.hexagonal_lattice_graph(n_cells_row, n_cells_col)\n    graph = nx.relabel_nodes(graph, {(i, j): k for k, (i, j) in enumerate(graph.nodes)})\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.line","title":"<code>line(n_qubits, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a line register.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef line(\n    cls,\n    n_qubits: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a line register.\n\n    Arguments:\n        n_qubits: Total number of qubits.\n    \"\"\"\n    return cls(line_graph(n_qubits), spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.rescale_coords","title":"<code>rescale_coords(scaling)</code>","text":"<p>Rescale the coordinates of all qubits in the register.</p> PARAMETER DESCRIPTION <code>scaling</code> <p>Scaling value.</p> <p> TYPE: <code>float</code> </p> Source code in <code>qadence/register.py</code> <pre><code>def rescale_coords(self, scaling: float) -&gt; Register:\n    \"\"\"\n    Rescale the coordinates of all qubits in the register.\n\n    Arguments:\n        scaling: Scaling value.\n    \"\"\"\n    g = deepcopy(self.graph)\n    _scale_node_positions(g, min_distance=1.0, spacing=scaling)\n    return Register(g, spacing=None, device_specs=self.device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.square","title":"<code>square(qubits_side, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a square register.</p> PARAMETER DESCRIPTION <code>qubits_side</code> <p>Number of qubits on one side of the square.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef square(\n    cls,\n    qubits_side: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a square register.\n\n    Arguments:\n        qubits_side: Number of qubits on one side of the square.\n    \"\"\"\n    n_points = 4 * (qubits_side - 1)\n\n    def gen_points() -&gt; np.ndarray:\n        rotate_left = np.array([[0.0, -1.0], [1.0, 0.0]])\n        increment = np.array([0.0, 1.0])\n\n        points = [np.array([0.0, 0.0])]\n        counter = 1\n        while len(points) &lt; n_points:\n            points.append(points[-1] + increment)\n\n            counter = (counter + 1) % qubits_side\n            if counter == 0:\n                increment = rotate_left.dot(increment)\n                counter = 1\n        points = np.array(points)  # type: ignore[assignment]\n        points -= np.mean(points, axis=0)\n\n        return points  # type: ignore[return-value]\n\n    graph = nx.grid_2d_graph(n_points, 1, periodic=True)\n    graph = nx.relabel_nodes(graph, {(i, 0): i for i in range(n_points)})\n    values = {i: {\"pos\": point} for i, point in zip(graph.nodes, gen_points())}\n    nx.set_node_attributes(graph, values)\n    return cls(graph, spacing, device_specs)\n</code></pre>"},{"location":"api/register/#qadence.register.Register.triangular_lattice","title":"<code>triangular_lattice(n_cells_row, n_cells_col, spacing=1.0, device_specs=DEFAULT_DEVICE)</code>  <code>classmethod</code>","text":"<p>Build a triangular lattice register.</p> <p>Each cell is a triangle made up of three qubits.</p> PARAMETER DESCRIPTION <code>n_cells_row</code> <p>Number of cells in each row.</p> <p> TYPE: <code>int</code> </p> <code>n_cells_col</code> <p>Number of cells in each column.</p> <p> TYPE: <code>int</code> </p> Source code in <code>qadence/register.py</code> <pre><code>@classmethod\ndef triangular_lattice(\n    cls,\n    n_cells_row: int,\n    n_cells_col: int,\n    spacing: float = 1.0,\n    device_specs: RydbergDevice = DEFAULT_DEVICE,\n) -&gt; Register:\n    \"\"\"\n    Build a triangular lattice register.\n\n    Each cell is a triangle made up of three qubits.\n\n    Arguments:\n        n_cells_row: Number of cells in each row.\n        n_cells_col: Number of cells in each column.\n    \"\"\"\n    return cls(triangular_lattice_graph(n_cells_row, n_cells_col), spacing, device_specs)\n</code></pre>"},{"location":"api/serialization/","title":"Serialization","text":""},{"location":"api/serialization/#serialization","title":"Serialization","text":""},{"location":"api/serialization/#qadence.serialization.SerializationModel","title":"<code>SerializationModel(d=dict())</code>  <code>dataclass</code>","text":"<p>A serialization model class to serialize data from <code>QuantumModel</code>s,.</p> <p><code>torch.nn.Module</code> and similar structures. The data included in the serialization logic includes: the <code>AbstractBlock</code> and its children classes, <code>QuantumCircuit</code>, <code>Register</code>, and <code>sympy</code> expressions (including <code>Parameter</code> class from <code>qadence.parameters</code>).</p> <p>A children class must define the <code>value</code> attribute type and how to handle it, since it is the main property for the class to be used by the serialization process. For instance:</p> <pre><code>@dataclass\nclass QuantumCircuitSerialization(SerializationModel):\n    value: QuantumCircuit = dataclass_field(init=False)\n\n    def __post_init__(self) -&gt; None:\n        self.value = (\n            QuantumCircuit._from_dict(self.d)\n            if isinstance(self.d, dict)\n            else self.d\n        )\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.deserialize","title":"<code>deserialize(d, as_torch=False)</code>","text":"<p>Supported Types:</p> <p>AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module Deserializes a dict to one of the supported types.</p> PARAMETER DESCRIPTION <code>d</code> <p>A dict containing a serialized object.</p> <p> TYPE: <code>dict</code> </p> <code>as_torch</code> <p>Whether to transform to torch for the deserialized object.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Returns:     AbstractBlock, QuantumCircuit, QuantumModel, Register, torch.nn.Module.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n\n## Lets use myblock in a QuantumCircuit and serialize it.\n\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('dda7aea3-68c4-4316-b2fb-003d999b22bc', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.015641083829560976'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('6ed0f7c6-55c4-48d2-8dc2-bcdc0cb05205', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.6797649437144105'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('2e96f899-cab3-477e-ab89-62aeaf31cd2d', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.5725923484359651'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('027fffb8-c20a-400a-b0eb-c30d91ccf1bb', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.9543310831254966'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('21f03c9a-0af4-440d-b2b9-e230885f41b6', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.4698570477778493'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('2a1910ae-1c17-4e55-8768-71c7a6933356', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.9290576462924997'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def deserialize(d: dict, as_torch: bool = False) -&gt; SUPPORTED_TYPES:\n    \"\"\"\n    Supported Types:\n\n    AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module\n    Deserializes a dict to one of the supported types.\n\n    Arguments:\n        d (dict): A dict containing a serialized object.\n        as_torch (bool): Whether to transform to torch for the deserialized object.\n    Returns:\n        AbstractBlock, QuantumCircuit, QuantumModel, Register, torch.nn.Module.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\n    obj: SerializationModel\n    if d.get(\"expression\"):\n        obj = ExpressionSerialization(d)\n    elif d.get(\"block\") and d.get(\"register\"):\n        obj = QuantumCircuitSerialization(d)\n    elif d.get(\"graph\"):\n        obj = RegisterSerialization(d)\n    elif d.get(\"type\"):\n        obj = BlockTypeSerialization(d)\n    else:\n        obj = ModelSerialization(d, as_torch=as_torch)\n    return obj.value\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.load","title":"<code>load(file_path, map_location='cpu')</code>","text":"<p>Same as serialize/deserialize but for storing/loading files.</p> <p>Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register Loads a .json or .pt file to one of the supported types.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> </p> <code>map_location</code> <p>In case of a .pt file, on which device to load the object (cpu,cuda).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <p>Returns:     A object of type AbstractBlock, QuantumCircuit, QuantumModel, Register.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\n\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def load(file_path: str | Path, map_location: str = \"cpu\") -&gt; SUPPORTED_TYPES:\n    \"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n\n    Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register\n    Loads a .json or .pt file to one of the supported types.\n\n    Arguments:\n        file_path (str): The name of the file.\n        map_location (str): In case of a .pt file, on which device to load the object (cpu,cuda).\n    Returns:\n        A object of type AbstractBlock, QuantumCircuit, QuantumModel, Register.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\n    d = {}\n    if isinstance(file_path, str):\n        file_path = Path(file_path)\n    if not os.path.exists(file_path):\n        logger.error(f\"File {file_path} not found.\")\n        raise FileNotFoundError\n    FORMAT = file_extension(file_path)\n    _, _, load_fn, _ = FORMAT_DICT[FORMAT]  # type: ignore[index]\n    try:\n        d = load_fn(file_path, map_location)\n        logger.debug(f\"Successfully loaded {d} from {file_path}.\")\n    except Exception as e:\n        logger.error(f\"Unable to load Object from {file_path} due to {e}\")\n    return deserialize(d)\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.parse_expr_fn","title":"<code>parse_expr_fn(code)</code>","text":"<p>A parsing expressions function that checks whether a given code is valid on.</p> <p>the parsing grammar. The grammar is defined to be compatible with <code>sympy</code> expressions, such as <code>Float('-0.33261030434342942', precision=53)</code>, while avoiding code injection such as <code>2*3</code> or <code>__import__('os').system('ls -la')</code>.</p> PARAMETER DESCRIPTION <code>code</code> <p>code to be parsed and checked.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Boolean indicating whether the code matches the defined grammar or not.</p> Source code in <code>qadence/serialization.py</code> <pre><code>def parse_expr_fn(code: str) -&gt; bool:\n    \"\"\"\n    A parsing expressions function that checks whether a given code is valid on.\n\n    the parsing grammar. The grammar is defined to be compatible with `sympy`\n    expressions, such as `Float('-0.33261030434342942', precision=53)`, while\n    avoiding code injection such as `2*3` or `__import__('os').system('ls -la')`.\n\n    Args:\n        code (str): code to be parsed and checked.\n\n    Returns:\n        Boolean indicating whether the code matches the defined grammar or not.\n    \"\"\"\n\n    parser = _parsing_serialize_expr\n    try:\n        parser.parse(code)\n    except NoMatch:\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.save","title":"<code>save(obj, folder, file_name='', format=SerializationFormat.JSON)</code>","text":"<p>Same as serialize/deserialize but for storing/loading files.</p> <p>Supported types: AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module Saves a qadence object to a json/.pt.</p> PARAMETER DESCRIPTION <code>obj</code> <pre><code>Either AbstractBlock, QuantumCircuit, QuantumModel, Register.\n</code></pre> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register</code> </p> <code>file_name</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>format</code> <p>The type of file to save.</p> <p> TYPE: <code>str</code> DEFAULT: <code>JSON</code> </p> <p>Returns:     None.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\n\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def save(\n    obj: SUPPORTED_TYPES,\n    folder: str | Path,\n    file_name: str = \"\",\n    format: SerializationFormat = SerializationFormat.JSON,\n) -&gt; None:\n    \"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n\n    Supported types:\n    AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module\n    Saves a qadence object to a json/.pt.\n\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register):\n                Either AbstractBlock, QuantumCircuit, QuantumModel, Register.\n        file_name (str): The name of the file.\n        format (str): The type of file to save.\n    Returns:\n        None.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\n    if not isinstance(obj, get_args(SUPPORTED_TYPES)):\n        logger.error(f\"Serialization of object type {type(obj)} not supported.\")\n    folder = Path(folder)\n    if not folder.is_dir():\n        logger.error(NotADirectoryError)\n    if file_name == \"\":\n        file_name = type(obj).__name__\n    try:\n        suffix, save_fn, _, save_params = FORMAT_DICT[format]\n        d = serialize(obj, save_params)\n        file_path = folder / Path(file_name + suffix)\n        save_fn(d, file_path)\n        logger.debug(f\"Successfully saved {obj} from to {folder}.\")\n    except Exception as e:\n        logger.error(f\"Unable to write {type(obj)} to disk due to {e}\")\n</code></pre>"},{"location":"api/serialization/#qadence.serialization.serialize","title":"<code>serialize(obj, save_params=False)</code>","text":"<p>Supported Types:</p> <p>AbstractBlock | QuantumCircuit | QuantumModel | torch.nn.Module | Register | Module Serializes a qadence object to a dictionary.</p> PARAMETER DESCRIPTION <code>obj</code> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register | Module</code> </p> <p>Returns:     A dict.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\n\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n\n## Lets use myblock in a QuantumCircuit and serialize it.\n\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('1d9ffa32-1f2d-4a20-a7e7-a3bd0291acb9', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.32630052032995993'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('7c336bf8-d3b9-4cac-b788-084f7bd0860e', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.5523669439577359'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('97cca6c6-04ce-4ab6-bc49-1c33df22d826', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.7306854608406383'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('34a0b282-92fc-4123-92b8-99d64255517b', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.31168165302168105'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('a375e2a8-29a4-4a51-a681-4ef40e0f230b', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.8155787667451212'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('4a298f7f-09c9-43cf-b4e4-64a3a4d86be4', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.1026851782629501'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def serialize(obj: SUPPORTED_TYPES, save_params: bool = False) -&gt; dict:\n    \"\"\"\n    Supported Types:\n\n    AbstractBlock | QuantumCircuit | QuantumModel | torch.nn.Module | Register | Module\n    Serializes a qadence object to a dictionary.\n\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register | torch.nn.Module):\n    Returns:\n        A dict.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\n    if not isinstance(obj, get_args(SUPPORTED_TYPES)):\n        logger.error(TypeError(f\"Serialization of object type {type(obj)} not supported.\"))\n\n    d: dict = dict()\n    try:\n        if isinstance(obj, core.Expr):\n            symb_dict = dict()\n            expr_dict = {\"name\": str(obj), \"expression\": srepr(obj)}\n            symbs: set[Parameter | core.Basic] = obj.free_symbols\n            if symbs:\n                symb_dict = {\"symbols\": {str(s): s._to_dict() for s in symbs}}\n            d = {**expr_dict, **symb_dict}\n        else:\n            if hasattr(obj, \"_to_dict\"):\n                model_to_dict: Callable = obj._to_dict\n                d = (\n                    model_to_dict(save_params)\n                    if isinstance(obj, torch.nn.Module)\n                    else model_to_dict()\n                )\n            elif hasattr(obj, \"state_dict\"):\n                d = {type(obj).__name__: obj.state_dict()}\n            else:\n                raise ValueError(f\"Cannot serialize object {obj}.\")\n    except Exception as e:\n        logger.error(f\"Serialization of object {obj} failed due to {e}\")\n    return d\n</code></pre>"},{"location":"api/states/","title":"State preparation","text":""},{"location":"api/states/#state-preparation-routines","title":"State Preparation Routines","text":""},{"location":"api/states/#qadence.states.ghz_block","title":"<code>ghz_block(n_qubits)</code>","text":"<p>Generates the abstract ghz state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A ChainBlock representing the GHZ state.</p> <p>Examples: <pre><code>from qadence.states import ghz_block\n\nblock = ghz_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 CNOT(0, 1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_block(n_qubits: int) -&gt; ChainBlock:\n    \"\"\"\n    Generates the abstract ghz state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A ChainBlock representing the GHZ state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_block\n\n    block = ghz_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    cnots = chain(CNOT(i - 1, i) for i in range(1, n_qubits))\n    return chain(H(0), cnots)\n</code></pre>"},{"location":"api/states/#qadence.states.ghz_state","title":"<code>ghz_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a GHZ state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import ghz_state\n\nprint(ghz_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j],\n        [0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Creates a GHZ state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_state\n\n    print(ghz_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\n    norm = 1 / torch.sqrt(torch.tensor(2))\n    return norm * (zero_state(n_qubits, batch_size) + one_state(n_qubits, batch_size))\n</code></pre>"},{"location":"api/states/#qadence.states.is_normalized","title":"<code>is_normalized(wf, atol=NORMALIZATION_ATOL)</code>","text":"<p>Checks if a wave function is normalized.</p> PARAMETER DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>atol</code> <p>The tolerance.</p> <p> TYPE: <code>float) </code> DEFAULT: <code>NORMALIZATION_ATOL</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A bool.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, is_normalized\n\nprint(is_normalized(uniform_state(2)))\n</code></pre> <pre><code>True\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def is_normalized(wf: Tensor, atol: float = NORMALIZATION_ATOL) -&gt; bool:\n    \"\"\"\n    Checks if a wave function is normalized.\n\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n        atol (float) : The tolerance.\n\n    Returns:\n        A bool.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, is_normalized\n\n    print(is_normalized(uniform_state(2)))\n    ```\n    \"\"\"\n    if wf.dim() == 1:\n        wf = wf.unsqueeze(0)\n    sum_probs: Tensor = (wf.abs() ** 2).sum(dim=1)\n    ones = torch.ones_like(sum_probs)\n    return torch.allclose(sum_probs, ones, rtol=0.0, atol=atol)  # type: ignore[no-any-return]\n</code></pre>"},{"location":"api/states/#qadence.states.normalize","title":"<code>normalize(wf)</code>","text":"<p>Normalizes a wavefunction or batch of wave functions.</p> PARAMETER DESCRIPTION <code>wf</code> <p>Normalized wavefunctions.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, normalize\n\nprint(normalize(uniform_state(2, 2)))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j],\n        [0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def normalize(wf: Tensor) -&gt; Tensor:\n    \"\"\"\n    Normalizes a wavefunction or batch of wave functions.\n\n    Arguments:\n        wf (torch.Tensor): Normalized wavefunctions.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, normalize\n\n    print(normalize(uniform_state(2, 2)))\n    ```\n    \"\"\"\n    if wf.dim() == 1:\n        return wf / torch.sqrt((wf.abs() ** 2).sum())\n    else:\n        return wf / torch.sqrt((wf.abs() ** 2).sum(1)).unsqueeze(1)\n</code></pre>"},{"location":"api/states/#qadence.states.one_block","title":"<code>one_block(n_qubits)</code>","text":"<p>Generates the abstract one state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the one state.</p> <p>Examples: <pre><code>from qadence.states import one_block\n\nblock = one_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract one state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the one state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_block\n\n    block = one_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(X, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.one_state","title":"<code>one_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the one state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import one_state\n\nstate = one_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the one state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_state\n\n    state = one_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    bitstring = \"1\" * n_qubits\n    return _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"api/states/#qadence.states.pmf","title":"<code>pmf(wf)</code>","text":"<p>Converts a wave function into a torch Distribution.</p> PARAMETER DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Distribution</code> <p>A torch.distributions.Distribution.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, pmf\n\nprint(pmf(uniform_state(2)).probs)\n</code></pre> <pre><code>tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def pmf(wf: Tensor) -&gt; Distribution:\n    \"\"\"\n    Converts a wave function into a torch Distribution.\n\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n\n    Returns:\n        A torch.distributions.Distribution.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, pmf\n\n    print(pmf(uniform_state(2)).probs)\n    ```\n    \"\"\"\n    return Categorical(torch.abs(torch.pow(wf, 2)))\n</code></pre>"},{"location":"api/states/#qadence.states.product_block","title":"<code>product_block(bitstring)</code>","text":"<p>Creates an abstract product state from a bitstring.</p> PARAMETER DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import product_block\n\nprint(product_block(\"1100\"))\n</code></pre> <pre><code>KronBlock(0,1,2,3)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u251c\u2500\u2500 I(2)\n\u2514\u2500\u2500 I(3)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def product_block(bitstring: str) -&gt; KronBlock:\n    \"\"\"\n    Creates an abstract product state from a bitstring.\n\n    Arguments:\n        bitstring (str): A bitstring.\n\n    Returns:\n        A KronBlock representing the product state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_block\n\n    print(product_block(\"1100\"))\n    ```\n    \"\"\"\n    return _block_from_bitstring(bitstring)\n</code></pre>"},{"location":"api/states/#qadence.states.product_state","title":"<code>product_state(bitstring, batch_size=1, endianness=Endianness.BIG, backend=BackendName.PYQTORCH)</code>","text":"<p>Creates a product state from a bitstring.</p> PARAMETER DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size.</p> <p> TYPE: <code>int) </code> DEFAULT: <code>1</code> </p> <code>backend</code> <p>The backend to use. Default is \"pyqtorch\".</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> RETURNS DESCRIPTION <code>ArrayLike</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import product_state\n\nprint(product_state(\"1100\", backend=\"pyqtorch\"))\nprint(product_state(\"1100\", backend=\"horqrux\"))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n         1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n 0.+0.j 0.+0.j 1.+0.j 0.+0.j 0.+0.j 0.+0.j]\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>@singledispatch\ndef product_state(\n    bitstring: str,\n    batch_size: int = 1,\n    endianness: Endianness = Endianness.BIG,\n    backend: BackendName = BackendName.PYQTORCH,\n) -&gt; ArrayLike:\n    \"\"\"\n    Creates a product state from a bitstring.\n\n    Arguments:\n        bitstring (str): A bitstring.\n        batch_size (int) : Batch size.\n        backend (BackendName): The backend to use. Default is \"pyqtorch\".\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_state\n\n    print(product_state(\"1100\", backend=\"pyqtorch\"))\n    print(product_state(\"1100\", backend=\"horqrux\"))\n    ```\n    \"\"\"\n    if batch_size:\n        logger.debug(\n            \"The input `batch_size` is going to be deprecated. \"\n            \"For now, default batch_size is set to 1.\"\n        )\n    return run(product_block(bitstring), backend=backend, endianness=endianness)\n</code></pre>"},{"location":"api/states/#qadence.states.rand_bitstring","title":"<code>rand_bitstring(N)</code>","text":"<p>Creates a random bistring.</p> PARAMETER DESCRIPTION <code>N</code> <p>The length of the bitstring.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\n\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>00110111\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_bitstring(N: int) -&gt; str:\n    \"\"\"\n    Creates a random bistring.\n\n    Arguments:\n        N (int): The length of the bitstring.\n\n    Returns:\n        A string.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\n    return \"\".join(str(random.randint(0, 1)) for _ in range(N))\n</code></pre>"},{"location":"api/states/#qadence.states.rand_product_block","title":"<code>rand_product_block(n_qubits)</code>","text":"<p>Creates a block representing a random abstract product state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import rand_product_block\n\nprint(rand_product_block(n_qubits=2))\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Creates a block representing a random abstract product state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the product state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_block\n\n    print(rand_product_block(n_qubits=2))\n    ```\n    \"\"\"\n    return product_block(rand_bitstring(n_qubits))\n</code></pre>"},{"location":"api/states/#qadence.states.rand_product_state","title":"<code>rand_product_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a random product state.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import rand_product_state\n\nprint(rand_product_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Creates a random product state.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_state\n\n    print(rand_product_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\n    wf_batch = torch.zeros(batch_size, 2**n_qubits, dtype=DTYPE)\n    rand_pos = torch.randint(0, 2**n_qubits, (batch_size,))\n    wf_batch[torch.arange(batch_size), rand_pos] = torch.tensor(1.0 + 0j, dtype=DTYPE)\n    return wf_batch\n</code></pre>"},{"location":"api/states/#qadence.states.random_state","title":"<code>random_state(n_qubits, batch_size=1, backend=BackendName.PYQTORCH, type=StateGeneratorType.HAAR_MEASURE_FAST)</code>","text":"<p>Generates a random state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>backend</code> <p>The backend to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>type</code> <p>StateGeneratorType.</p> <p> DEFAULT: <code>HAAR_MEASURE_FAST</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import random_state, StateGeneratorType\nfrom qadence.states import random_state, is_normalized, pmf\nfrom qadence.types import BackendName\nfrom torch.distributions import Distribution\n\n### We have the following options:\nprint([g.value for g in StateGeneratorType])\n\nn_qubits = 2\n# The default is StateGeneratorType.HAAR_MEASURE_FAST\nstate = random_state(n_qubits=n_qubits)\nprint(state)\n\n### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\nrandom = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\nprint(random)\n</code></pre> <pre><code>['RandomRotations', 'HaarMeasureFast', 'HaarMeasureSlow']\ntensor([[-0.1079-0.5672j, -0.1319-0.3223j, -0.1497+0.4839j, -0.0080+0.5374j]])\ntensor([[0.8728+0.0000j, 0.0000+0.0448j, 0.0000-0.4853j, 0.0249+0.0000j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def random_state(\n    n_qubits: int,\n    batch_size: int = 1,\n    backend: str = BackendName.PYQTORCH,\n    type: StateGeneratorType = StateGeneratorType.HAAR_MEASURE_FAST,\n) -&gt; Tensor:\n    \"\"\"\n    Generates a random state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        backend (str): The backend to use.\n        batch_size (int): The batch size.\n        type : StateGeneratorType.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import random_state, StateGeneratorType\n    from qadence.states import random_state, is_normalized, pmf\n    from qadence.types import BackendName\n    from torch.distributions import Distribution\n\n    ### We have the following options:\n    print([g.value for g in StateGeneratorType])\n\n    n_qubits = 2\n    # The default is StateGeneratorType.HAAR_MEASURE_FAST\n    state = random_state(n_qubits=n_qubits)\n    print(state)\n\n    ### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\n    random = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\n    print(random)\n    ```\n    \"\"\"\n\n    if type == StateGeneratorType.HAAR_MEASURE_FAST:\n        state = concat(tuple(_rand_haar_fast(n_qubits) for _ in range(batch_size)), dim=0)\n    elif type == StateGeneratorType.HAAR_MEASURE_SLOW:\n        state = concat(tuple(_rand_haar_slow(n_qubits) for _ in range(batch_size)), dim=0)\n    elif type == StateGeneratorType.RANDOM_ROTATIONS:\n        state = run(_abstract_random_state(n_qubits, batch_size))  # type: ignore\n    assert all(list(map(is_normalized, state)))\n    return state\n</code></pre>"},{"location":"api/states/#qadence.states.uniform_block","title":"<code>uniform_block(n_qubits)</code>","text":"<p>Generates the abstract uniform state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the uniform state.</p> <p>Examples: <pre><code>from qadence.states import uniform_block\n\nblock = uniform_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract uniform state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the uniform state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_block\n\n    block = uniform_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(H, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.uniform_state","title":"<code>uniform_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the uniform state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state\n\nstate = uniform_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the uniform state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state\n\n    state = uniform_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    norm = 1 / torch.sqrt(torch.tensor(2**n_qubits))\n    return norm * torch.ones(batch_size, 2**n_qubits, dtype=DTYPE)\n</code></pre>"},{"location":"api/states/#qadence.states.zero_block","title":"<code>zero_block(n_qubits)</code>","text":"<p>Generates the abstract zero state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the zero state.</p> <p>Examples: <pre><code>from qadence.states import zero_block\n\nblock = zero_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_block(n_qubits: int) -&gt; KronBlock:\n    \"\"\"\n    Generates the abstract zero state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits.\n\n    Returns:\n        A KronBlock representing the zero state.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_block\n\n    block = zero_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\n    return _from_op(I, n_qubits=n_qubits)\n</code></pre>"},{"location":"api/states/#qadence.states.zero_state","title":"<code>zero_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the zero state for a specified number of qubits.</p> PARAMETER DESCRIPTION <code>n_qubits</code> <p>The number of qubits for which the zero state is to be generated.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size for the zero state.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import zero_state\n\nstate = zero_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n    \"\"\"\n    Generates the zero state for a specified number of qubits.\n\n    Arguments:\n        n_qubits (int): The number of qubits for which the zero state is to be generated.\n        batch_size (int): The batch size for the zero state.\n\n    Returns:\n        A torch.Tensor.\n\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_state\n\n    state = zero_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\n    bitstring = \"0\" * n_qubits\n    return _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"api/transpile/","title":"Transpilation","text":"<p>Contains functions that operate on blocks and circuits to <code>transpile</code> them to new blocks/circuits.</p>"},{"location":"api/transpile/#qadence.transpile.transpile.transpile","title":"<code>transpile(*fs)</code>","text":"<p><code>AbstractBlock</code> or <code>QuantumCircuit</code> transpilation.</p> <p>Compose functions that accept a circuit/block and returns a circuit/block.</p> PARAMETER DESCRIPTION <code>*fs</code> <p>composable functions that either map blocks to blocks (<code>Callable[[AbstractBlock], AbstractBlock]</code>) or circuits to circuits (<code>Callable[[QuantumCircuit], QuantumCircuit]</code>).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Composed function.</p> <p>Examples:</p> <p>Flatten a block of nested chains and krons: <pre><code>from qadence import *\nfrom qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n\nb = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\nprint(b)\n\n# both flatten and scale_primitive_blocks_only are functions that accept and\n# return a block\nt = transpile(flatten, scale_primitive_blocks_only)(b)\nprint(t)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 ChainBlock(0)\n\u2502           \u251c\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u251c\u2500\u2500 X(0)\n        \u2514\u2500\u2500 X(1)\n\nChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 X(1)\n</code></pre> </p> <p>We also proved a decorator to easily turn a function <code>Callable[[AbstractBlock], AbstractBlock]</code> into a <code>Callable[[QuantumCircuit], QuantumCircuit]</code> to be used in circuit transpilation. <pre><code>from qadence import *\nfrom qadence.transpile import transpile, blockfn_to_circfn, flatten\n\n# We want to pass this circuit to `transpile` instead of a block,\n# so we need functions that map from a circuit to a circuit.\ncirc = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n\n@blockfn_to_circfn\ndef fn(block):\n    # un-decorated function accepts a block and returns a block\n    return block * block\n\ntransp = transpile(\n    # the decorated function accepts a circuit and returns a circuit\n    fn,\n    # already existing functions can also be decorated\n    blockfn_to_circfn(flatten)\n)\nprint(transp(circ))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/transpile/transpile.py</code> <pre><code>def transpile(*fs: Callable) -&gt; Callable:\n    \"\"\"`AbstractBlock` or `QuantumCircuit` transpilation.\n\n    Compose functions that\n    accept a circuit/block and returns a circuit/block.\n\n    Arguments:\n        *fs: composable functions that either map blocks to blocks\n            (`Callable[[AbstractBlock], AbstractBlock]`)\n            or circuits to circuits (`Callable[[QuantumCircuit], QuantumCircuit]`).\n\n    Returns:\n        Composed function.\n\n    Examples:\n\n    Flatten a block of nested chains and krons:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n\n    b = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\n    print(b)\n    print() # markdown-exec: hide\n\n    # both flatten and scale_primitive_blocks_only are functions that accept and\n    # return a block\n    t = transpile(flatten, scale_primitive_blocks_only)(b)\n    print(t)\n    ```\n\n    We also proved a decorator to easily turn a function `Callable[[AbstractBlock], AbstractBlock]`\n    into a `Callable[[QuantumCircuit], QuantumCircuit]` to be used in circuit transpilation.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, blockfn_to_circfn, flatten\n\n    # We want to pass this circuit to `transpile` instead of a block,\n    # so we need functions that map from a circuit to a circuit.\n    circ = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n\n    @blockfn_to_circfn\n    def fn(block):\n        # un-decorated function accepts a block and returns a block\n        return block * block\n\n    transp = transpile(\n        # the decorated function accepts a circuit and returns a circuit\n        fn,\n        # already existing functions can also be decorated\n        blockfn_to_circfn(flatten)\n    )\n    print(transp(circ))\n    ```\n    \"\"\"\n    return lambda x: reduce(lambda acc, f: f(acc), reversed(fs), x)\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.chain_single_qubit_ops","title":"<code>chain_single_qubit_ops(block)</code>","text":"<p>Transpile a chain of krons into a kron of chains of single qubit operations.</p> <p>Examples: <pre><code>from qadence import hea\nfrom qadence.transpile.block import chain_single_qubit_ops\n\n# Consider a single HEA layer\nblock = hea(2,1)\nprint(block)\n\n# After applying chain_single_qubit_ops, we get:\nprint(chain_single_qubit_ops(block))\n</code></pre> <pre><code>ChainBlock(0,1) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u2514\u2500\u2500 CNOT(0, 1)\nChainBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502   \u2514\u2500\u2500 ChainBlock(1)\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502       \u251c\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n    \u2514\u2500\u2500 KronBlock(0,1)\n        \u2514\u2500\u2500 CNOT(0, 1)\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def chain_single_qubit_ops(block: AbstractBlock) -&gt; AbstractBlock:\n    \"\"\"Transpile a chain of krons into a kron of chains of single qubit operations.\n\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import hea\n    from qadence.transpile.block import chain_single_qubit_ops\n\n    # Consider a single HEA layer\n    block = hea(2,1)\n    print(block)\n\n    # After applying chain_single_qubit_ops, we get:\n    print(chain_single_qubit_ops(block))\n    ```\n    \"\"\"\n    if is_chain_of_primitivekrons(block):\n        try:\n            return kron(*map(lambda bs: chain(*bs), zip(*block)))  # type: ignore[misc]\n        except Exception as e:\n            logger.debug(\n                f\"Unable to transpile {block} using chain_single_qubit_ops\\\n                         due to {e}. Returning original circuit.\"\n            )\n            return block\n\n    elif isinstance(block, CompositeBlock):\n        return _construct(type(block), tuple(chain_single_qubit_ops(b) for b in block.blocks))\n    else:\n        return block\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.scale_primitive_blocks_only","title":"<code>scale_primitive_blocks_only(block, scale=None)</code>","text":"<p>Push the scale all the way down into the leaves of the block tree.</p> <p>When given a scaled CompositeBlock consisting of several PrimitiveBlocks.</p> PARAMETER DESCRIPTION <code>block</code> <p>The block to be transpiled.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>scale</code> <p>An optional scale parameter. Only to be used for recursive calls internally.</p> <p> TYPE: <code>Basic</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>A block of the same type where the scales have been moved into the subblocks.</p> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples:</p> <p>There are two different cases: <code>ChainBlock</code>s/<code>KronBlock</code>s: Only the first subblock needs to be scaled because chains/krons represent multiplications. <pre><code>from qadence import chain, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * chain(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 ChainBlock(0)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\nChainBlock(0)\n\u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> <p><code>AddBlock</code>s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")). <pre><code>from qadence import add, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * add(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \n\u2514\u2500\u2500 AddBlock(0)\n    \u251c\u2500\u2500 X(0)\n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\nAddBlock(0)\n\u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 [mul: 2.000] \n    \u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>@singledispatch\ndef scale_primitive_blocks_only(block: AbstractBlock, scale: sympy.Basic = None) -&gt; AbstractBlock:\n    \"\"\"Push the scale all the way down into the leaves of the block tree.\n\n    When given a scaled CompositeBlock consisting of several PrimitiveBlocks.\n\n    Arguments:\n        block: The block to be transpiled.\n        scale: An optional scale parameter. Only to be used for recursive calls internally.\n\n    Returns:\n        AbstractBlock: A block of the same type where the scales have been moved into the subblocks.\n\n    Examples:\n\n    There are two different cases:\n    `ChainBlock`s/`KronBlock`s: Only the first subblock needs to be scaled because chains/krons\n    represent multiplications.\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import chain, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * chain(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n\n    `AddBlock`s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all\n    subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")).\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import add, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * add(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    \"\"\"\n    raise NotImplementedError(f\"scale_primitive_blocks_only is not implemented for {type(block)}\")\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.set_trainable","title":"<code>set_trainable(blocks, value=True, inplace=True)</code>","text":"<p>Set the trainability of all parameters in a block to a given value.</p> PARAMETER DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>value</code> <p>The value of the trainable attribute to assign to the input blocks</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to the given value</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_trainable(\n    blocks: AbstractBlock | list[AbstractBlock], value: bool = True, inplace: bool = True\n) -&gt; AbstractBlock | list[AbstractBlock]:\n    \"\"\"Set the trainability of all parameters in a block to a given value.\n\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        value (bool, optional): The value of the trainable attribute to assign to the input blocks\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to the given value\n    \"\"\"\n\n    if isinstance(blocks, AbstractBlock):\n        blocks = [blocks]\n\n    if inplace:\n        for block in blocks:\n            params: list[sympy.Basic] = parameters(block)\n            for p in params:\n                if not p.is_number:\n                    p.trainable = value\n    else:\n        raise NotImplementedError(\"Not inplace set_trainable is not yet available\")\n\n    return blocks if len(blocks) &gt; 1 else blocks[0]\n</code></pre>"},{"location":"api/transpile/#qadence.transpile.block.validate","title":"<code>validate(block)</code>","text":"<p>Moves a block from global to local qubit numbers by adding PutBlocks.</p> <p>Reassigns qubit locations appropriately.</p>"},{"location":"api/transpile/#qadence.transpile.block.validate--example","title":"Example","text":"<pre><code>from qadence.blocks import chain\nfrom qadence.operations import X\nfrom qadence.transpile import validate\n\nx = chain(chain(X(0)), chain(X(1)))\nprint(x)\nprint(validate(x))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 ChainBlock(1)\n    \u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 put on (0)\n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 put on (0)\n\u2502           \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 put on (1)\n    \u2514\u2500\u2500 ChainBlock(0)\n        \u2514\u2500\u2500 put on (0)\n            \u2514\u2500\u2500 X(0)\n</code></pre> Source code in <code>qadence/transpile/block.py</code> <pre><code>def validate(block: AbstractBlock) -&gt; AbstractBlock:\n    \"\"\"Moves a block from global to local qubit numbers by adding PutBlocks.\n\n    Reassigns qubit locations appropriately.\n\n    # Example\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence.blocks import chain\n    from qadence.operations import X\n    from qadence.transpile import validate\n\n    x = chain(chain(X(0)), chain(X(1)))\n    print(x)\n    print(validate(x))\n    ```\n    \"\"\"\n    vblock: AbstractBlock\n    from qadence.transpile import reassign\n\n    if isinstance(block, ControlBlock):\n        vblock = deepcopy(block)\n        b: AbstractBlock\n        (b,) = block.blocks\n        b = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\n        b = validate(b)\n        vblock.blocks = (b,)  # type: ignore[assignment]\n\n    elif isinstance(block, CompositeBlock):\n        blocks = []\n        for b in block.blocks:\n            mi, ma = min(b.qubit_support), max(b.qubit_support)\n            nb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\n            nb = validate(nb)\n            nb = PutBlock(nb, tuple(range(mi, ma + 1)))\n            blocks.append(nb)\n        try:\n            vblock = _construct(type(block), tuple(blocks))\n        except AssertionError as e:\n            if str(e) == \"Make sure blocks act on distinct qubits!\":\n                vblock = chain(*blocks)\n            else:\n                raise e\n\n    elif isinstance(block, PrimitiveBlock):\n        vblock = deepcopy(block)\n\n    else:\n        raise NotImplementedError\n\n    vblock.tag = block.tag\n    return vblock\n</code></pre>"},{"location":"api/types/","title":"Types","text":""},{"location":"api/types/#qadence-types","title":"Qadence Types","text":""},{"location":"api/types/#qadence.types.TArray","title":"<code>TArray = Union[Iterable, Tensor, np.ndarray]</code>  <code>module-attribute</code>","text":"<p>Union of common array types.</p>"},{"location":"api/types/#qadence.types.TGenerator","title":"<code>TGenerator = Union[Tensor, sympy.Array, sympy.Basic]</code>  <code>module-attribute</code>","text":"<p>Union of torch tensors and numpy arrays.</p>"},{"location":"api/types/#qadence.types.TNumber","title":"<code>TNumber = Union[int, float, complex, np.int64, np.float64]</code>  <code>module-attribute</code>","text":"<p>Union of python and numpy numeric types.</p>"},{"location":"api/types/#qadence.types.TParameter","title":"<code>TParameter = Union[TNumber, Tensor, sympy.Basic, str]</code>  <code>module-attribute</code>","text":"<p>Union of numbers, tensors, and parameter types.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo","title":"<code>AlgoHEvo</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Hamiltonian Evolution algorithms that can be used by the backend.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.EIG","title":"<code>EIG = 'EIG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using Hamiltonian diagonalization.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.EXP","title":"<code>EXP = 'EXP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using torch.matrix_exp on the generator matrix.</p>"},{"location":"api/types/#qadence.types.AlgoHEvo.RK4","title":"<code>RK4 = 'RK4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>4th order Runge-Kutta approximation.</p>"},{"location":"api/types/#qadence.types.AnsatzType","title":"<code>AnsatzType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Ansatz types for variational circuits.</p>"},{"location":"api/types/#qadence.types.AnsatzType.HEA","title":"<code>HEA = 'hea'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hardware-efficient ansatz.</p>"},{"location":"api/types/#qadence.types.AnsatzType.IIA","title":"<code>IIA = 'iia'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Identity-Initialised Ansatz.</p>"},{"location":"api/types/#qadence.types.BasisSet","title":"<code>BasisSet</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Basis set for feature maps.</p>"},{"location":"api/types/#qadence.types.BasisSet.CHEBYSHEV","title":"<code>CHEBYSHEV = 'Chebyshev'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Chebyshev polynomials of the first kind.</p>"},{"location":"api/types/#qadence.types.BasisSet.FOURIER","title":"<code>FOURIER = 'Fourier'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fourier basis set.</p>"},{"location":"api/types/#qadence.types.DeviceType","title":"<code>DeviceType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Supported types of devices for Pulser backend.</p>"},{"location":"api/types/#qadence.types.DeviceType.IDEALIZED","title":"<code>IDEALIZED = 'IdealDevice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Idealized device, least realistic.</p>"},{"location":"api/types/#qadence.types.DeviceType.REALISTIC","title":"<code>REALISTIC = 'RealisticDevice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Device with realistic specs.</p>"},{"location":"api/types/#qadence.types.Endianness","title":"<code>Endianness</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The endianness convention to use.</p>"},{"location":"api/types/#qadence.types.Endianness.BIG","title":"<code>BIG = 'Big'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use Big endianness.</p>"},{"location":"api/types/#qadence.types.Endianness.LITTLE","title":"<code>LITTLE = 'Little'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use little endianness.</p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool","title":"<code>ExperimentTrackingTool</code>","text":"<p>               Bases: <code>StrEnum</code></p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool.MLFLOW","title":"<code>MLFLOW = 'mlflow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the ml-flow experiment tracker.</p>"},{"location":"api/types/#qadence.types.ExperimentTrackingTool.TENSORBOARD","title":"<code>TENSORBOARD = 'tensorboard'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the tensorboard experiment tracker.</p>"},{"location":"api/types/#qadence.types.FigFormat","title":"<code>FigFormat</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available output formats for exporting visualized circuits to a file.</p>"},{"location":"api/types/#qadence.types.FigFormat.PDF","title":"<code>PDF = 'PDF'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PDF format.</p>"},{"location":"api/types/#qadence.types.FigFormat.PNG","title":"<code>PNG = 'PNG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PNG format.</p>"},{"location":"api/types/#qadence.types.FigFormat.SVG","title":"<code>SVG = 'SVG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>SVG format.</p>"},{"location":"api/types/#qadence.types.GenDAQC","title":"<code>GenDAQC</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>The type of interaction for the DAQC transform.</p>"},{"location":"api/types/#qadence.types.GenDAQC.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN</p>"},{"location":"api/types/#qadence.types.GenDAQC.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ</p>"},{"location":"api/types/#qadence.types.InputDiffMode","title":"<code>InputDiffMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Derivative modes w.r.t inputs of UFAs.</p>"},{"location":"api/types/#qadence.types.InputDiffMode.AD","title":"<code>AD = 'ad'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Reverse automatic differentiation.</p>"},{"location":"api/types/#qadence.types.InputDiffMode.FD","title":"<code>FD = 'fd'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Central finite differencing.</p>"},{"location":"api/types/#qadence.types.Interaction","title":"<code>Interaction</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Interaction types used in.</p> <ul> <li><code>RydbergDevice</code>.</li> <li><code>hamiltonian_factory</code>.</li> </ul>"},{"location":"api/types/#qadence.types.Interaction.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN-Ising Interaction, N=(I-Z)/2.</p>"},{"location":"api/types/#qadence.types.Interaction.XY","title":"<code>XY = 'XY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XY Interaction.</p>"},{"location":"api/types/#qadence.types.Interaction.XYZ","title":"<code>XYZ = 'XYZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XYZ Interaction.</p>"},{"location":"api/types/#qadence.types.Interaction.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ-Ising Interaction.</p>"},{"location":"api/types/#qadence.types.LTSOrder","title":"<code>LTSOrder</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Lie-Trotter-Suzuki approximation order.</p>"},{"location":"api/types/#qadence.types.LTSOrder.BASIC","title":"<code>BASIC = 'BASIC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic.</p>"},{"location":"api/types/#qadence.types.LTSOrder.ST2","title":"<code>ST2 = 'ST2'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST2.</p>"},{"location":"api/types/#qadence.types.LTSOrder.ST4","title":"<code>ST4 = 'ST4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST4.</p>"},{"location":"api/types/#qadence.types.LatticeTopology","title":"<code>LatticeTopology</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Lattice topologies to choose from for the register.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.ALL_TO_ALL","title":"<code>ALL_TO_ALL = 'all_to_all'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>All to all- connected lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.ARBITRARY","title":"<code>ARBITRARY = 'arbitrary'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Arbitrarily-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.CIRCLE","title":"<code>CIRCLE = 'circle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Circular lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.HONEYCOMB_LATTICE","title":"<code>HONEYCOMB_LATTICE = 'honeycomb_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Honeycomb-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.LINE","title":"<code>LINE = 'line'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Line-format lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.RECTANGULAR_LATTICE","title":"<code>RECTANGULAR_LATTICE = 'rectangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rectangular-shaped lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.SQUARE","title":"<code>SQUARE = 'square'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Square lattice.</p>"},{"location":"api/types/#qadence.types.LatticeTopology.TRIANGULAR_LATTICE","title":"<code>TRIANGULAR_LATTICE = 'triangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Triangular-shaped shape.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy","title":"<code>MultivariateStrategy</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Multivariate strategy for feature maps.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy.PARALLEL","title":"<code>PARALLEL = 'Parallel'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Parallel strategy.</p>"},{"location":"api/types/#qadence.types.MultivariateStrategy.SERIES","title":"<code>SERIES = 'Series'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Serial strategy.</p>"},{"location":"api/types/#qadence.types.ObservableTransform","title":"<code>ObservableTransform</code>","text":"<p>Observable transformation type.</p>"},{"location":"api/types/#qadence.types.ObservableTransform.NONE","title":"<code>NONE = 'none'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>No transformation.</p>"},{"location":"api/types/#qadence.types.ObservableTransform.RANGE","title":"<code>RANGE = 'range'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the given values as min and max.</p>"},{"location":"api/types/#qadence.types.ObservableTransform.SCALE","title":"<code>SCALE = 'scale'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the given values as scale and shift.</p>"},{"location":"api/types/#qadence.types.OpName","title":"<code>OpName</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>A list of all available of digital-analog operations.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGENTANG","title":"<code>ANALOGENTANG = 'AnalogEntanglement'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog entanglement operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGINTERACTION","title":"<code>ANALOGINTERACTION = 'AnalogInteraction'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog interaction operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRX","title":"<code>ANALOGRX = 'AnalogRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RX operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRY","title":"<code>ANALOGRY = 'AnalogRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RY operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGRZ","title":"<code>ANALOGRZ = 'AnalogRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RZ operation.</p>"},{"location":"api/types/#qadence.types.OpName.ANALOGSWAP","title":"<code>ANALOGSWAP = 'AnalogSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog SWAP operation.</p>"},{"location":"api/types/#qadence.types.OpName.CNOT","title":"<code>CNOT = 'CNOT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CNOT gate.</p>"},{"location":"api/types/#qadence.types.OpName.CPHASE","title":"<code>CPHASE = 'CPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The controlled PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRX","title":"<code>CRX = 'CRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRY","title":"<code>CRY = 'CRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Controlled RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.CRZ","title":"<code>CRZ = 'CRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.CSWAP","title":"<code>CSWAP = 'CSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control SWAP gate.</p>"},{"location":"api/types/#qadence.types.OpName.CZ","title":"<code>CZ = 'CZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.ENTANGLE","title":"<code>ENTANGLE = 'entangle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The entanglement operation.</p>"},{"location":"api/types/#qadence.types.OpName.H","title":"<code>H = 'H'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hadamard gate.</p>"},{"location":"api/types/#qadence.types.OpName.HAMEVO","title":"<code>HAMEVO = 'HamEvo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hamiltonian Evolution operation.</p>"},{"location":"api/types/#qadence.types.OpName.I","title":"<code>I = 'I'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Identity gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCPHASE","title":"<code>MCPHASE = 'MCPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRX","title":"<code>MCRX = 'MCRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRY","title":"<code>MCRY = 'MCRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCRZ","title":"<code>MCRZ = 'MCRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.MCZ","title":"<code>MCZ = 'MCZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol CZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.N","title":"<code>N = 'N'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The N = (1/2)(I-Z) operator.</p>"},{"location":"api/types/#qadence.types.OpName.PHASE","title":"<code>PHASE = 'PHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PHASE gate.</p>"},{"location":"api/types/#qadence.types.OpName.PROJ","title":"<code>PROJ = 'Projector'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The projector operation.</p>"},{"location":"api/types/#qadence.types.OpName.RX","title":"<code>RX = 'RX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RX gate.</p>"},{"location":"api/types/#qadence.types.OpName.RY","title":"<code>RY = 'RY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RY gate.</p>"},{"location":"api/types/#qadence.types.OpName.RZ","title":"<code>RZ = 'RZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RZ gate.</p>"},{"location":"api/types/#qadence.types.OpName.S","title":"<code>S = 'S'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S gate.</p>"},{"location":"api/types/#qadence.types.OpName.SDAGGER","title":"<code>SDAGGER = 'SDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S dagger gate.</p>"},{"location":"api/types/#qadence.types.OpName.SWAP","title":"<code>SWAP = 'SWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The SWAP gate.</p>"},{"location":"api/types/#qadence.types.OpName.T","title":"<code>T = 'T'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T gate.</p>"},{"location":"api/types/#qadence.types.OpName.TDAGGER","title":"<code>TDAGGER = 'TDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T dagger gate.</p>"},{"location":"api/types/#qadence.types.OpName.TOFFOLI","title":"<code>TOFFOLI = 'Toffoli'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Toffoli gate.</p>"},{"location":"api/types/#qadence.types.OpName.U","title":"<code>U = 'U'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The U gate.</p>"},{"location":"api/types/#qadence.types.OpName.X","title":"<code>X = 'X'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The X gate.</p>"},{"location":"api/types/#qadence.types.OpName.Y","title":"<code>Y = 'Y'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Y gate.</p>"},{"location":"api/types/#qadence.types.OpName.Z","title":"<code>Z = 'Z'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Z gate.</p>"},{"location":"api/types/#qadence.types.OpName.ZERO","title":"<code>ZERO = 'Zero'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The zero gate.</p>"},{"location":"api/types/#qadence.types.OverlapMethod","title":"<code>OverlapMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Overlap Methods to choose from.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.COMPUTE_UNCOMPUTE","title":"<code>COMPUTE_UNCOMPUTE = 'compute_uncompute'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute-uncompute.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.EXACT","title":"<code>EXACT = 'exact'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exact.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.HADAMARD_TEST","title":"<code>HADAMARD_TEST = 'hadamard_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hadamard-test.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.JENSEN_SHANNON","title":"<code>JENSEN_SHANNON = 'jensen_shannon'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Jensen-shannon.</p>"},{"location":"api/types/#qadence.types.OverlapMethod.SWAP_TEST","title":"<code>SWAP_TEST = 'swap_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Swap-test.</p>"},{"location":"api/types/#qadence.types.ParameterType","title":"<code>ParameterType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Parameter types available in qadence.</p>"},{"location":"api/types/#qadence.types.ParameterType.FEATURE","title":"<code>FEATURE = 'Feature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>FeatureParameters act as input and are not trainable.</p>"},{"location":"api/types/#qadence.types.ParameterType.FIXED","title":"<code>FIXED = 'Fixed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fixed/ constant parameters are neither trainable nor act as input.</p>"},{"location":"api/types/#qadence.types.ParameterType.VARIATIONAL","title":"<code>VARIATIONAL = 'Variational'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>VariationalParameters are trainable.</p>"},{"location":"api/types/#qadence.types.QubitSupportType","title":"<code>QubitSupportType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Qubit support types.</p>"},{"location":"api/types/#qadence.types.QubitSupportType.GLOBAL","title":"<code>GLOBAL = 'global'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use global qubit support.</p>"},{"location":"api/types/#qadence.types.ResultType","title":"<code>ResultType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available data types for generating certain results.</p>"},{"location":"api/types/#qadence.types.ResultType.NUMPY","title":"<code>NUMPY = 'Numpy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Numpy Array Type.</p>"},{"location":"api/types/#qadence.types.ResultType.STRING","title":"<code>STRING = 'String'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String Type.</p>"},{"location":"api/types/#qadence.types.ResultType.TORCH","title":"<code>TORCH = 'Torch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torch Tensor Type.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling","title":"<code>ReuploadScaling</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Scaling for data reuploads in feature maps.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.CONSTANT","title":"<code>CONSTANT = 'Constant'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Constant scaling.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.EXP","title":"<code>EXP = 'Exponential'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exponentially increasing scaling.</p>"},{"location":"api/types/#qadence.types.ReuploadScaling.TOWER","title":"<code>TOWER = 'Tower'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Linearly increasing scaling.</p>"},{"location":"api/types/#qadence.types.SerializationFormat","title":"<code>SerializationFormat</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Available serialization formats for circuits.</p>"},{"location":"api/types/#qadence.types.SerializationFormat.JSON","title":"<code>JSON = 'JSON'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Json format.</p>"},{"location":"api/types/#qadence.types.SerializationFormat.PT","title":"<code>PT = 'PT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PT format used by Torch.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType","title":"<code>StateGeneratorType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Methods to generate random states.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_FAST","title":"<code>HAAR_MEASURE_FAST = 'HaarMeasureFast'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_SLOW","title":"<code>HAAR_MEASURE_SLOW = 'HaarMeasureSlow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure non-optimized version.</p>"},{"location":"api/types/#qadence.types.StateGeneratorType.RANDOM_ROTATIONS","title":"<code>RANDOM_ROTATIONS = 'RandomRotations'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Random Rotations.</p>"},{"location":"api/types/#qadence.types.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"api/types/#qadence.types.StrEnum.__str__","title":"<code>__str__()</code>","text":"<p>Used when dumping enum fields in a schema.</p> Source code in <code>qadence/types.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Used when dumping enum fields in a schema.\"\"\"\n    ret: str = self.value\n    return ret\n</code></pre>"},{"location":"api/types/#qadence.types.Strategy","title":"<code>Strategy</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Computing paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.ANALOG","title":"<code>ANALOG = 'Analog'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the analog paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.BDAQC","title":"<code>BDAQC = 'bDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the banged digital-analog QC paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.DIGITAL","title":"<code>DIGITAL = 'Digital'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the digital paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.RYDBERG","title":"<code>RYDBERG = 'Rydberg'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the Rydberg QC paradigm.</p>"},{"location":"api/types/#qadence.types.Strategy.SDAQC","title":"<code>SDAQC = 'sDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the step-wise digital-analog QC paradigm.</p>"},{"location":"api/types/#qadence.types.TensorType","title":"<code>TensorType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Tensor Types for converting blocks to tensors.</p>"},{"location":"api/types/#qadence.types.TensorType.DENSE","title":"<code>DENSE = 'Dense'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a block to a dense tensor.</p>"},{"location":"api/types/#qadence.types.TensorType.SPARSE","title":"<code>SPARSE = 'Sparse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a observable block to a sparse tensor.</p>"},{"location":"api/types/#qadence.types.TensorType.SPARSEDIAGONAL","title":"<code>SPARSEDIAGONAL = 'SparseDiagonal'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a diagonal observable block to a sparse diagonal if possible.</p>"},{"location":"api/backends/backend/","title":"Abstract backend","text":""},{"location":"api/backends/backend/#qadence.backend.Backend","title":"<code>Backend(name, supports_ad, support_bp, supports_adjoint, is_remote, with_measurements, native_endianness, engine, with_noise, config)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The abstract class that defines the interface for the backends.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>backend unique string identifier</p> <p> TYPE: <code>BackendName</code> </p> <code>supports_ad</code> <p>whether or not the backend has a native autograd</p> <p> TYPE: <code>bool</code> </p> <code>supports_bp</code> <p>whether or not the backend has a native backprop</p> <p> TYPE: <code>bool</code> </p> <code>supports_adjoint</code> <p>Does the backend support native adjoint differentation.</p> <p> TYPE: <code>bool</code> </p> <code>is_remote</code> <p>whether computations are executed locally or remotely on this backend, useful when using cloud platforms where credentials are needed for example.</p> <p> TYPE: <code>bool</code> </p> <code>with_measurements</code> <p>whether it supports counts or not</p> <p> TYPE: <code>bool</code> </p> <code>with_noise</code> <p>whether to add realistic noise or not</p> <p> TYPE: <code>bool</code> </p> <code>native_endianness</code> <p>The native endianness of the backend</p> <p> TYPE: <code>Endianness</code> </p> <code>engine</code> <p>The underlying (native) automatic differentiation engine of the backend.</p> <p> TYPE: <code>Engine</code> </p>"},{"location":"api/backends/backend/#qadence.backend.Backend.circuit","title":"<code>circuit(circuit)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract <code>QuantumCircuit</code> to the native backend representation.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A circuit, for example: <code>QuantumCircuit(2, X(0))</code></p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>A converted circuit <code>c</code>. You can access the original, arbstract circuit via <code>c.abstract</code></p> <code>ConvertedCircuit</code> <p>and the converted (or backend native) circuit via <code>c.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n    \"\"\"Converts an abstract `QuantumCircuit` to the native backend representation.\n\n    Arguments:\n        circuit: A circuit, for example: `QuantumCircuit(2, X(0))`\n\n    Returns:\n        A converted circuit `c`. You can access the original, arbstract circuit via `c.abstract`\n        and the converted (or backend *native*) circuit via `c.native`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit and an optional observable to their native representation.</p> <p>Additionally, this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\n    self, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n    \"\"\"Convert an abstract circuit and an optional observable to their native representation.\n\n    Additionally, this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\n\n    def check_observable(obs_obj: Any) -&gt; AbstractBlock:\n        if isinstance(obs_obj, QubitOperator):\n            from qadence.blocks.manipulate import from_openfermion\n\n            assert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\n\n            return from_openfermion(obs_obj)\n\n        elif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\n            from qadence.blocks.utils import block_is_qubit_hamiltonian\n\n            assert block_is_qubit_hamiltonian(\n                obs_obj\n            ), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\n            return obs_obj\n        raise TypeError(\n            \"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n        )\n\n    conv_circ = self.circuit(circuit)\n    circ_params, circ_embedding_fn = embedding(\n        conv_circ.abstract.block, self.config._use_gate_params, self.engine\n    )\n    params = circ_params\n    if observable is not None:\n        observable = observable if isinstance(observable, list) else [observable]\n        conv_obs = []\n        obs_embedding_fn_list = []\n\n        for obs in observable:\n            obs = check_observable(obs)\n            c_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\n            obs_params, obs_embedding_fn = embedding(\n                c_obs.abstract, self.config._use_gate_params, self.engine\n            )\n            params.update(obs_params)\n            obs_embedding_fn_list.append(obs_embedding_fn)\n            conv_obs.append(c_obs)\n\n        def embedding_fn_dict(a: dict, b: dict) -&gt; dict:\n            embedding_dict = circ_embedding_fn(a, b)\n            for o in obs_embedding_fn_list:\n                embedding_dict.update(o(a, b))\n            return embedding_dict\n\n        return Converted(conv_circ, conv_obs, embedding_fn_dict, params)\n\n    def embedding_fn(a: dict, b: dict) -&gt; dict:\n        return circ_embedding_fn(a, b)\n\n    return Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.observable","title":"<code>observable(observable, n_qubits)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract observable (which is just an <code>AbstractBlock</code>) to the native backend.</p> <p>representation.</p> PARAMETER DESCRIPTION <code>observable</code> <p>An observable.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits the observable covers. This is typically <code>circuit.n_qubits</code>.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ConvertedObservable</code> <p>A converted observable <code>o</code>. You can access the original, arbstract observable via</p> <code>ConvertedObservable</code> <p><code>o.abstract</code> and the converted (or backend native) observable via <code>o.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef observable(self, observable: AbstractBlock, n_qubits: int) -&gt; ConvertedObservable:\n    \"\"\"Converts an abstract observable (which is just an `AbstractBlock`) to the native backend.\n\n    representation.\n\n    Arguments:\n        observable: An observable.\n        n_qubits: Number of qubits the observable covers. This is typically `circuit.n_qubits`.\n\n    Returns:\n        A converted observable `o`. You can access the original, arbstract observable via\n        `o.abstract` and the converted (or backend *native*) observable via `o.native`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG, *args, **kwargs)</code>","text":"<p>Run a circuit and return the resulting wave function.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, ArrayLike]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting wavefunction.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>ArrayLike</code> <p>A list of Counter objects where each key represents a bitstring</p> <code>ArrayLike</code> <p>and its value the number of times it has been sampled from the given wave function.</p> Source code in <code>qadence/backend.py</code> <pre><code>def run(\n    self,\n    circuit: ConvertedCircuit,\n    param_values: dict[str, ArrayLike] = {},\n    state: Tensor | None = None,\n    endianness: Endianness = Endianness.BIG,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; ArrayLike:\n    \"\"\"Run a circuit and return the resulting wave function.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting wavefunction.\n\n    Returns:\n        A list of Counter objects where each key represents a bitstring\n        and its value the number of times it has been sampled from the given wave function.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1000, state=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Sample bit strings.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Number of shots to sample.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>An error mitigation protocol to apply.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef sample(\n    self,\n    circuit: ConvertedCircuit,\n    param_values: dict[str, Tensor] = {},\n    n_shots: int = 1000,\n    state: ArrayLike | None = None,\n    noise: Noise | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n    \"\"\"Sample bit strings.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        n_shots: Number of shots to sample.\n        state: Initial state.\n        noise: A noise model to use.\n        mitigation: An error mitigation protocol to apply.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration","title":"<code>BackendConfiguration(_use_gate_params=True, use_sparse_observable=False, use_gradient_checkpointing=False, use_single_qubit_composition=False, transpilation_passes=None)</code>  <code>dataclass</code>","text":""},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.available_options","title":"<code>available_options()</code>","text":"<p>Return as a string the available fields with types of the configuration.</p> RETURNS DESCRIPTION <code>str</code> <p>a string with all the available fields, one per line</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>def available_options(self) -&gt; str:\n    \"\"\"Return as a string the available fields with types of the configuration.\n\n    Returns:\n        str: a string with all the available fields, one per line\n    \"\"\"\n    conf_msg = \"\"\n    for _field in fields(self):\n        if not _field.name.startswith(\"_\"):\n            conf_msg += (\n                f\"Name: {_field.name} - Type: {_field.type} - Default value: {_field.default}\\n\"\n            )\n    return conf_msg\n</code></pre>"},{"location":"api/backends/backend/#qadence.backend.BackendConfiguration.get_param_name","title":"<code>get_param_name(blk)</code>","text":"<p>Return parameter names for the current backend.</p> <p>Depending on which backend is in use this function returns either UUIDs or expressions of parameters.</p> Source code in <code>qadence/backend.py</code> <pre><code>def get_param_name(self, blk: AbstractBlock) -&gt; Tuple[str, ...]:\n    \"\"\"Return parameter names for the current backend.\n\n    Depending on which backend is in use this\n    function returns either UUIDs or expressions of parameters.\n    \"\"\"\n    param_ids: Tuple\n    # FIXME: better type hiearchy?\n    types = (TimeEvolutionBlock, ParametricBlock, ConstantAnalogRotation, InteractionBlock)\n    if not isinstance(blk, types):\n        raise TypeError(f\"Can not infer param name from {type(blk)}\")\n    else:\n        if self._use_gate_params:\n            param_ids = tuple(blk.parameters.uuids())\n        else:\n            param_ids = tuple(map(stringify, blk.parameters.expressions()))\n    return param_ids\n</code></pre>"},{"location":"api/backends/differentiable/","title":"DifferentiableBackend","text":""},{"location":"api/backends/differentiable/#qadence.engines.torch.differentiable_backend.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>               Bases: <code>DifferentiableBackend</code></p> <p>A class which wraps a QuantumBackend with the automatic differentation engine TORCH.</p> PARAMETER DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/engines/torch/differentiable_backend.py</code> <pre><code>def __init__(\n    self,\n    backend: QuantumBackend,\n    diff_mode: DiffMode = DiffMode.AD,\n    **psr_args: int | float | None,\n) -&gt; None:\n    super().__init__(backend=backend, engine=Engine.TORCH, diff_mode=diff_mode)\n    self.psr_args = psr_args\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.torch.differentiable_backend.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A converted observable as returned by <code>backend.observable</code>.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>The error mitigation to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/engines/torch/differentiable_backend.py</code> <pre><code>def expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        observable: A converted observable as returned by `backend.observable`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: The error mitigation to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    observable = observable if isinstance(observable, list) else [observable]\n    differentiable_expectation = DifferentiableExpectation(\n        backend=self.backend,\n        circuit=circuit,\n        observable=observable,\n        param_values=param_values,\n        state=state,\n        measurement=measurement,\n        noise=noise,\n        mitigation=mitigation,\n        endianness=endianness,\n    )\n\n    if self.diff_mode == DiffMode.AD:\n        expectation = differentiable_expectation.ad\n    elif self.diff_mode == DiffMode.ADJOINT:\n        expectation = differentiable_expectation.adjoint\n    else:\n        try:\n            fns = get_gpsr_fns()\n            psr_fn = fns[self.diff_mode]\n        except KeyError:\n            raise ValueError(f\"{self.diff_mode} differentiation mode is not supported\")\n        expectation = partial(differentiable_expectation.psr, psr_fn=psr_fn, **self.psr_args)\n    return expectation()\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.jax.differentiable_backend.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>               Bases: <code>DifferentiableBackend</code></p> <p>A class which wraps a QuantumBackend with the automatic differentation engine JAX.</p> PARAMETER DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/engines/jax/differentiable_backend.py</code> <pre><code>def __init__(\n    self,\n    backend: Backend,\n    diff_mode: DiffMode = DiffMode.AD,\n    **psr_args: int | float | None,\n) -&gt; None:\n    super().__init__(backend=backend, engine=Engine.JAX, diff_mode=diff_mode)\n    self.psr_args = psr_args\n</code></pre>"},{"location":"api/backends/differentiable/#qadence.engines.jax.differentiable_backend.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, measurement=None, noise=None, mitigation=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A converted observable as returned by <code>backend.observable</code>.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>ParamDictType</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise | None</code> DEFAULT: <code>None</code> </p> <code>mitigation</code> <p>The error mitigation to use.</p> <p> TYPE: <code>Mitigations | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/engines/jax/differentiable_backend.py</code> <pre><code>def expectation(\n    self,\n    circuit: ConvertedCircuit,\n    observable: list[ConvertedObservable] | ConvertedObservable,\n    param_values: ParamDictType = {},\n    state: ArrayLike | None = None,\n    measurement: Measurements | None = None,\n    noise: Noise | None = None,\n    mitigation: Mitigations | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; ArrayLike:\n    \"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        observable: A converted observable as returned by `backend.observable`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        measurement: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        noise: A noise model to use.\n        mitigation: The error mitigation to use.\n        endianness: Endianness of the resulting bit strings.\n    \"\"\"\n    observable = observable if isinstance(observable, list) else [observable]\n\n    if self.diff_mode == DiffMode.AD:\n        expectation = self.backend.expectation(circuit, observable, param_values, state)\n    else:\n        expectation = DifferentiableExpectation(\n            backend=self.backend,\n            circuit=circuit,\n            observable=observable,\n            param_values=param_values,\n            state=state,\n            measurement=measurement,\n            noise=noise,\n            mitigation=mitigation,\n            endianness=endianness,\n        ).psr()\n    return expectation\n</code></pre>"},{"location":"api/backends/pulser/","title":"Pulser","text":"<p>The Pulser backend features a basic integration with the pulse-level programming interface Pulser. This backend offers for now few simple operations which are translated into a valid, non time-dependent pulse sequence. In particular, one has access to:</p> <ul> <li>analog rotations: <code>AnalogRx</code> and <code>AnalogRy</code> blocks</li> <li>free evolution blocks (basically no pulse, just interaction): <code>AnalogWait</code> block</li> <li>a block for creating entangled states: <code>AnalogEntanglement</code></li> <li>digital rotation <code>Rx</code> and <code>Ry</code></li> </ul>"},{"location":"api/backends/pulser/#qadence.backends.pulser.backend.Backend","title":"<code>Backend(name=BackendName.PULSER, supports_ad=False, support_bp=False, supports_adjoint=False, is_remote=False, with_measurements=True, native_endianness=Endianness.BIG, engine=Engine.TORCH, with_noise=False, config=Configuration())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Backend</code></p> <p>The Pulser backend.</p>"},{"location":"api/backends/pulser/#qadence.backends.pulser.backend.create_register","title":"<code>create_register(register)</code>","text":"<p>Convert Qadence Register to Pulser Register.</p> Source code in <code>qadence/backends/pulser/backend.py</code> <pre><code>def create_register(register: Register) -&gt; PulserRegister:\n    \"\"\"Convert Qadence Register to Pulser Register.\"\"\"\n    coords = np.array(list(register.coords.values()))\n    return PulserRegister.from_coordinates(coords)\n</code></pre>"},{"location":"api/backends/pyqtorch/","title":"PyQTorch","text":"<p>Fast differentiable statevector emulator based on PyTorch. The code is open source, hosted on Github and maintained by Pasqal.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend","title":"<code>Backend(name=BackendName.PYQTORCH, supports_ad=True, support_bp=True, supports_adjoint=True, is_remote=False, with_measurements=True, native_endianness=Endianness.BIG, engine=Engine.TORCH, with_noise=False, config=Configuration())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Backend</code></p> <p>PyQTorch backend.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit and an optional observable to their native representation.</p> <p>Additionally, this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\n    self, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n    \"\"\"Convert an abstract circuit and an optional observable to their native representation.\n\n    Additionally, this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\n\n    def check_observable(obs_obj: Any) -&gt; AbstractBlock:\n        if isinstance(obs_obj, QubitOperator):\n            from qadence.blocks.manipulate import from_openfermion\n\n            assert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\n\n            return from_openfermion(obs_obj)\n\n        elif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\n            from qadence.blocks.utils import block_is_qubit_hamiltonian\n\n            assert block_is_qubit_hamiltonian(\n                obs_obj\n            ), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\n            return obs_obj\n        raise TypeError(\n            \"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n        )\n\n    conv_circ = self.circuit(circuit)\n    circ_params, circ_embedding_fn = embedding(\n        conv_circ.abstract.block, self.config._use_gate_params, self.engine\n    )\n    params = circ_params\n    if observable is not None:\n        observable = observable if isinstance(observable, list) else [observable]\n        conv_obs = []\n        obs_embedding_fn_list = []\n\n        for obs in observable:\n            obs = check_observable(obs)\n            c_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\n            obs_params, obs_embedding_fn = embedding(\n                c_obs.abstract, self.config._use_gate_params, self.engine\n            )\n            params.update(obs_params)\n            obs_embedding_fn_list.append(obs_embedding_fn)\n            conv_obs.append(c_obs)\n\n        def embedding_fn_dict(a: dict, b: dict) -&gt; dict:\n            embedding_dict = circ_embedding_fn(a, b)\n            for o in obs_embedding_fn_list:\n                embedding_dict.update(o(a, b))\n            return embedding_dict\n\n        return Converted(conv_circ, conv_obs, embedding_fn_dict, params)\n\n    def embedding_fn(a: dict, b: dict) -&gt; dict:\n        return circ_embedding_fn(a, b)\n\n    return Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration","title":"<code>Configuration(_use_gate_params=True, use_sparse_observable=False, use_gradient_checkpointing=False, use_single_qubit_composition=False, transpilation_passes=None, algo_hevo=AlgoHEvo.EXP, ode_solver=SolverType.DP5_SE, n_steps_hevo=100, loop_expectation=False)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BackendConfiguration</code></p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.algo_hevo","title":"<code>algo_hevo: AlgoHEvo = AlgoHEvo.EXP</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Determine which kind of Hamiltonian evolution algorithm to use.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.loop_expectation","title":"<code>loop_expectation: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>When computing batches of expectation values, only allocate one wavefunction.</p> <p>Loop over the batch of parameters to only allocate a single wavefunction at any given time.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.n_steps_hevo","title":"<code>n_steps_hevo: int = 100</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default number of steps for the Hamiltonian evolution.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.ode_solver","title":"<code>ode_solver: SolverType = SolverType.DP5_SE</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Determine which ODE solver to use for time-dependent blocks.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_gradient_checkpointing","title":"<code>use_gradient_checkpointing: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use gradient checkpointing.</p> <p>Recommended for higher-order optimization tasks.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_single_qubit_composition","title":"<code>use_single_qubit_composition: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Composes chains of single qubit gates into a single matmul if possible.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.supported_gates","title":"<code>supported_gates = list(set(OpName.list()) - set([OpName.TDAGGER]))</code>  <code>module-attribute</code>","text":"<p>The set of supported gates.</p> <p>Tdagger is currently not supported.</p>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQTimeDependentEvolution","title":"<code>PyQTimeDependentEvolution(qubit_support, n_qubits, block, config)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def __init__(\n    self,\n    qubit_support: Tuple[int, ...],\n    n_qubits: int,\n    block: TimeEvolutionBlock,\n    config: Configuration,\n):\n    super().__init__()\n    self.qubit_support = qubit_support\n    self.n_qubits = n_qubits\n    self.param_names = config.get_param_name(block)\n    self.block = block\n    self.hmat: Tensor\n    self.config = config\n\n    def _hamiltonian(self: PyQTimeDependentEvolution, values: dict[str, Tensor]) -&gt; Tensor:\n        hmat = _block_to_tensor_embedded(\n            block.generator,  # type: ignore[arg-type]\n            values=values,\n            qubit_support=self.qubit_support,\n            use_full_support=False,\n            device=self.device,\n        )\n        return hmat.permute(1, 2, 0)\n\n    self._hamiltonian = _hamiltonian\n\n    self._time_evolution = lambda values: values[self.param_names[0]]\n    self._device: torch_device = (\n        self.hmat.device if hasattr(self, \"hmat\") else torch_device(\"cpu\")\n    )\n    self._dtype: torch_dtype = self.hmat.dtype if hasattr(self, \"hmat\") else cdouble\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQTimeDependentEvolution.dagger","title":"<code>dagger(values)</code>","text":"<p>Dagger of the evolved operator given the current parameter values.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def dagger(self, values: dict[str, Tensor]) -&gt; Tensor:\n    \"\"\"Dagger of the evolved operator given the current parameter values.\"\"\"\n    return _dagger(self.unitary(values))\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQTimeDependentEvolution.jacobian_generator","title":"<code>jacobian_generator(values)</code>","text":"<p>Approximate jacobian of the evolved operator with respect to generator parameter(s).</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def jacobian_generator(self, values: dict[str, Tensor]) -&gt; Tensor:\n    \"\"\"Approximate jacobian of the evolved operator with respect to generator parameter(s).\"\"\"\n    if len(self.param_names) &gt; 2:\n        raise NotImplementedError(\n            \"jacobian_generator does not support generators\\\n                                    with more than 1 parameter.\"\n        )\n\n    def _generator(val: Tensor) -&gt; Tensor:\n        val_copy = values.copy()\n        val_copy[self.param_names[1]] = val\n        hmat = _block_to_tensor_embedded(\n            self.block.generator,  # type: ignore[arg-type]\n            values=val_copy,\n            qubit_support=self.qubit_support,\n            use_full_support=False,\n            device=self.device,\n        )\n        return hmat.permute(1, 2, 0)\n\n    return finitediff(\n        lambda v: self._unitary(\n            time_evolution=self._time_evolution(values), hamiltonian=_generator(v)\n        ),\n        values[self.param_names[1]].reshape(-1, 1),\n        (0,),\n    )\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQTimeDependentEvolution.jacobian_time","title":"<code>jacobian_time(values)</code>","text":"<p>Approximate jacobian of the evolved operator with respect to time evolution.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def jacobian_time(self, values: dict[str, Tensor]) -&gt; Tensor:\n    \"\"\"Approximate jacobian of the evolved operator with respect to time evolution.\"\"\"\n    return finitediff(\n        lambda t: self._unitary(time_evolution=t, hamiltonian=self._hamiltonian(self, values)),\n        values[self.param_names[0]].reshape(-1, 1),\n        (0,),\n    )\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQTimeDependentEvolution.unitary","title":"<code>unitary(values)</code>","text":"<p>The evolved operator given current parameter values for generator and time evolution.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def unitary(self, values: dict[str, Tensor]) -&gt; Tensor:\n    \"\"\"The evolved operator given current parameter values for generator and time evolution.\"\"\"\n    return self._unitary(self._hamiltonian(self, values), self._time_evolution(values))\n</code></pre>"},{"location":"api/backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.extract_parameter","title":"<code>extract_parameter(block, config)</code>","text":"<p>Extract the parameter as string or its tensor value.</p> PARAMETER DESCRIPTION <code>block</code> <p>Block to extract parameter from.</p> <p> TYPE: <code>ScaleBlock | ParametricBlock</code> </p> <code>config</code> <p>Configuration instance.</p> <p> TYPE: <code>Configuration</code> </p> RETURNS DESCRIPTION <code>str | Tensor</code> <p>str | Tensor: Parameter value or symbol.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def extract_parameter(block: ScaleBlock | ParametricBlock, config: Configuration) -&gt; str | Tensor:\n    \"\"\"Extract the parameter as string or its tensor value.\n\n    Args:\n        block (ScaleBlock | ParametricBlock): Block to extract parameter from.\n        config (Configuration): Configuration instance.\n\n    Returns:\n        str | Tensor: Parameter value or symbol.\n    \"\"\"\n    if not block.is_parametric:\n        tensor_val = tensor([block.parameters.parameter], dtype=complex64)\n        return (\n            tensor([block.parameters.parameter], dtype=float64)\n            if torch.all(tensor_val.imag == 0)\n            else tensor_val\n        )\n\n    return config.get_param_name(block)[0]\n</code></pre>"},{"location":"content/backends/","title":"Backends","text":"<p>Backends allow execution of Qadence abstract quantum circuits. They could be chosen from a variety of simulators, emulators and hardware and can enable circuit differentiability. The primary way to interact and configure a backend is via the high-level API <code>QuantumModel</code>.</p> <p>Not all backends are equivalent</p> <p>Not all backends support the same set of operations, especially while executing analog blocks. Qadence will throw descriptive errors in such cases.</p>"},{"location":"content/backends/#execution-backends","title":"Execution backends","text":"<p>PyQTorch: An efficient, large-scale simulator designed for quantum machine learning, seamlessly integrated with the popular PyTorch deep learning framework for automatic differentiability. It also offers analog computing for time-independent pulses. See <code>PyQTorchBackend</code>.</p> <p>Pulser: A Python library for pulse-level/analog control of neutral atom devices. Execution via QuTiP. See <code>PulserBackend</code>.</p> <p>More: Proprietary Qadence extensions provide more high-performance backends based on tensor networks or differentiation engines. For more enquiries, please contact: <code>info@pasqal.com</code>.</p>"},{"location":"content/backends/#differentiation-backend","title":"Differentiation backend","text":"<p>The <code>DifferentiableBackend</code> class enables different differentiation modes for the given backend. This can be chosen from two types:</p> <ul> <li>Automatic differentiation (AD): available for PyTorch based backends (PyQTorch).</li> <li>Parameter Shift Rules (PSR): available for all backends. See this section for more information on differentiability and PSR.</li> </ul> <p>In practice, only a <code>diff_mode</code> should be provided in the <code>QuantumModel</code>. Please note that <code>diff_mode</code> defaults to <code>None</code>:</p> <pre><code>import sympy\nimport torch\nfrom qadence import Parameter, RX, RZ, Z, CNOT, QuantumCircuit, QuantumModel, chain, BackendName, DiffMode\n\nx = Parameter(\"x\", trainable=False)\ny = Parameter(\"y\", trainable=False)\nfm = chain(\n    RX(0, 3 * x),\n    RX(0, x),\n    RZ(1, sympy.exp(y)),\n    RX(0, 3.14),\n    RZ(1, \"theta\")\n)\n\nansatz = CNOT(0, 1)\nblock = chain(fm, ansatz)\n\ncircuit = QuantumCircuit(2, block)\n\nobservable = Z(0)\n\n# DiffMode.GPSR is available for any backend.\n# DiffMode.AD is only available for natively differentiable backends.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.GPSR)\n\n# Get some values for the feature parameters.\nvalues = {\"x\": (x := torch.tensor([0.5], requires_grad=True)), \"y\": torch.tensor([0.1])}\n\n# Compute expectation.\nexp = model.expectation(values)\n\n# Differentiate the expectation wrt x.\ndexp_dx = torch.autograd.grad(exp, x, torch.ones_like(exp))\n</code></pre> <pre><code>dexp_dx = (tensor([3.6398]),)\n</code></pre>"},{"location":"content/backends/#low-level-backend_factory-interface","title":"Low-level <code>backend_factory</code> interface","text":"<p>Every backend in Qadence inherits from the abstract <code>Backend</code> class: <code>Backend</code> and implement the following methods:</p> <ul> <li><code>run</code>: propagate the initial state according to the quantum circuit and return the final wavefunction object.</li> <li><code>sample</code>: sample from a circuit.</li> <li><code>expectation</code>: computes the expectation of a circuit given an observable.</li> <li><code>convert</code>: convert the abstract <code>QuantumCircuit</code> object to its backend-native representation including a backend specific parameter embedding function.</li> </ul> <p>Backends are purely functional objects which take as input the values for the circuit parameters and return the desired output from a call to a method. In order to use a backend directly, embedded parameters must be supplied as they are returned by the backend specific embedding function.</p> <p>Here is a simple demonstration of the use of the Braket backend to execute a circuit in non-differentiable mode:</p> <pre><code>from qadence import QuantumCircuit, FeatureParameter, RX, RZ, CNOT, hea, chain\n\n# Construct a feature map.\nx = FeatureParameter(\"x\")\nz = FeatureParameter(\"y\")\nfm = chain(RX(0, 3 * x), RZ(1, z), CNOT(0, 1))\n\n# Construct a circuit with an hardware-efficient ansatz.\ncircuit = QuantumCircuit(3, fm, hea(3,1))\n</code></pre> <p>The abstract <code>QuantumCircuit</code> can now be converted to its native representation via the Braket backend.</p> <pre><code>from qadence import backend_factory\n\n# Use only Braket in non-differentiable mode:\nbackend = backend_factory(\"braket\")\n\n# The `Converted` object\n# (contains a `ConvertedCircuit` with the original and native representation)\nconv = backend.convert(circuit)\n</code></pre> <pre><code>conv.circuit.original = ChainBlock(0,1,2)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 RX(0) [params: ['3*x']]\n\u2502   \u251c\u2500\u2500 RZ(1) [params: ['y']]\n\u2502   \u2514\u2500\u2500 CNOT(0, 1)\n\u2514\u2500\u2500 ChainBlock(0,1,2) [tag: HEA]\n    \u251c\u2500\u2500 ChainBlock(0,1,2)\n    \u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n    \u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n    \u2502   \u2502   \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n    \u2502   \u2502   \u2514\u2500\u2500 RX(2) [params: ['theta_2']]\n    \u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n    \u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_3']]\n    \u2502   \u2502   \u251c\u2500\u2500 RY(1) [params: ['theta_4']]\n    \u2502   \u2502   \u2514\u2500\u2500 RY(2) [params: ['theta_5']]\n    \u2502   \u2514\u2500\u2500 KronBlock(0,1,2)\n    \u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_6']]\n    \u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_7']]\n    \u2502       \u2514\u2500\u2500 RX(2) [params: ['theta_8']]\n    \u2514\u2500\u2500 ChainBlock(0,1,2)\n        \u251c\u2500\u2500 KronBlock(0,1)\n        \u2502   \u2514\u2500\u2500 CNOT(0, 1)\n        \u2514\u2500\u2500 KronBlock(1,2)\n            \u2514\u2500\u2500 CNOT(1, 2)\nconv.circuit.native = Circuit('instructions': [Instruction('operator': Rx('angle': 74bccc23-dc5e-4b1c-8dc0-be9bb9c96fa9, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rz('angle': 69b5c438-3989-44a7-ae4c-7966bd831fe9, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': a8099928-f62d-42ea-8aef-716687fd566d, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 0049b169-1019-45ca-b924-ceaf2e032b50, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 77b3ec9a-6a82-4683-8b06-4072cc6d34ad, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': b0b64cfd-e7f0-46d3-9b6a-03fb638ceca7, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 67f6189d-6d2f-41da-b2b6-557156e1deee, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': b1f8563a-df70-4e27-a436-93c4d977147e, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 06bd83e6-70b0-46f6-bf84-fa931ad436c1, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 4e1c663d-67dd-423c-9d07-22fcf4d125fd, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 319e4698-b37e-4005-a052-d1d3a03ce6d7, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(1), Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)])\n</code></pre> <p>Additionally, <code>Converted</code> contains all fixed and variational parameters, as well as an embedding function which accepts feature parameters to construct a dictionary of circuit native parameters. These are needed as each backend uses a different representation of the circuit parameters:</p> <pre><code>import torch\n\n# Contains fixed parameters and variational (from the HEA)\nconv.params\n\ninputs = {\"x\": torch.tensor([1., 1.]), \"y\":torch.tensor([2., 2.])}\n\n# get all circuit parameters (including feature params)\nembedded = conv.embedding_fn(conv.params, inputs)\n</code></pre> <pre><code>conv.params = {\n  theta_1: tensor([0.9870], requires_grad=True)\n  theta_3: tensor([0.6987], requires_grad=True)\n  theta_0: tensor([0.7831], requires_grad=True)\n  theta_2: tensor([0.3415], requires_grad=True)\n  theta_5: tensor([0.5376], requires_grad=True)\n  theta_4: tensor([0.0173], requires_grad=True)\n  theta_7: tensor([0.3505], requires_grad=True)\n  theta_6: tensor([0.9344], requires_grad=True)\n  theta_8: tensor([0.9638], requires_grad=True)\n}\nembedded = {\n  74bccc23-dc5e-4b1c-8dc0-be9bb9c96fa9: tensor([3., 3.], grad_fn=&lt;ViewBackward0&gt;)\n  69b5c438-3989-44a7-ae4c-7966bd831fe9: tensor([2., 2.])\n  a8099928-f62d-42ea-8aef-716687fd566d: tensor([0.7831], grad_fn=&lt;ViewBackward0&gt;)\n  0049b169-1019-45ca-b924-ceaf2e032b50: tensor([0.9870], grad_fn=&lt;ViewBackward0&gt;)\n  77b3ec9a-6a82-4683-8b06-4072cc6d34ad: tensor([0.3415], grad_fn=&lt;ViewBackward0&gt;)\n  b0b64cfd-e7f0-46d3-9b6a-03fb638ceca7: tensor([0.6987], grad_fn=&lt;ViewBackward0&gt;)\n  67f6189d-6d2f-41da-b2b6-557156e1deee: tensor([0.0173], grad_fn=&lt;ViewBackward0&gt;)\n  b1f8563a-df70-4e27-a436-93c4d977147e: tensor([0.5376], grad_fn=&lt;ViewBackward0&gt;)\n  06bd83e6-70b0-46f6-bf84-fa931ad436c1: tensor([0.9344], grad_fn=&lt;ViewBackward0&gt;)\n  4e1c663d-67dd-423c-9d07-22fcf4d125fd: tensor([0.3505], grad_fn=&lt;ViewBackward0&gt;)\n  319e4698-b37e-4005-a052-d1d3a03ce6d7: tensor([0.9638], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>Note that above the parameters keys have changed as they now address the keys on the Braket device. A more readable embedding is provided by the PyQTorch backend:</p> <pre><code>from qadence import BackendName, DiffMode\npyq_backend = backend_factory(backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\n\n# the `Converted` object\n# (contains a `ConvertedCircuit` wiht the original and native representation)\npyq_conv = pyq_backend.convert(circuit)\nembedded = pyq_conv.embedding_fn(pyq_conv.params, inputs)\n</code></pre> <pre><code>embedded = {\n  theta_1: tensor([0.9870], grad_fn=&lt;ViewBackward0&gt;)\n  theta_3: tensor([0.6987], grad_fn=&lt;ViewBackward0&gt;)\n  theta_0: tensor([0.7831], grad_fn=&lt;ViewBackward0&gt;)\n  theta_2: tensor([0.3415], grad_fn=&lt;ViewBackward0&gt;)\n  theta_5: tensor([0.5376], grad_fn=&lt;ViewBackward0&gt;)\n  3*x: tensor([3., 3.], grad_fn=&lt;ViewBackward0&gt;)\n  y: tensor([2., 2.])\n  theta_4: tensor([0.0173], grad_fn=&lt;ViewBackward0&gt;)\n  theta_7: tensor([0.3505], grad_fn=&lt;ViewBackward0&gt;)\n  theta_6: tensor([0.9344], grad_fn=&lt;ViewBackward0&gt;)\n  theta_8: tensor([0.9638], grad_fn=&lt;ViewBackward0&gt;)\n  orig_param_values: {'x': tensor([1., 1.]), 'y': tensor([2., 2.])}\n}\n</code></pre> <p>With the embedded parameters, <code>QuantumModel</code> methods are accessible:</p> <pre><code>embedded = conv.embedding_fn(conv.params, inputs)\nsamples = backend.run(conv.circuit, embedded)\nprint(f\"{samples = }\")\n</code></pre> <pre><code>samples = tensor([[ 0.3867-0.0223j,  0.1412-0.2880j,  0.3262+0.2082j, -0.0256+0.4668j,\n         -0.3457-0.1628j, -0.2580+0.1831j,  0.1018+0.2088j, -0.1593+0.2310j],\n        [ 0.3867-0.0223j,  0.1412-0.2880j,  0.3262+0.2082j, -0.0256+0.4668j,\n         -0.3457-0.1628j, -0.2580+0.1831j,  0.1018+0.2088j, -0.1593+0.2310j]])\n</code></pre>"},{"location":"content/backends/#lower-level-the-backend-representation","title":"Lower-level: the <code>Backend</code> representation","text":"<p>If there is a requirement to work with a specific backend, it is possible to access directly the native circuit. For example, Braket noise features can be imported which are not exposed directly by Qadence.</p> <pre><code>from braket.circuits import Noise\n\n# Get the native Braket circuit with the given parameters\ninputs = {\"x\": torch.rand(1), \"y\":torch.rand(1)}\nembedded = conv.embedding_fn(conv.params, inputs)\nnative = backend.assign_parameters(conv.circuit, embedded)\n\n# Define a noise channel\nnoise = Noise.Depolarizing(probability=0.1)\n\n# Add noise to every gate in the circuit\nnative.apply_gate_noise(noise)\n</code></pre> <p>In order to run this noisy circuit, the density matrix simulator is needed in Braket:</p> <p><pre><code>from braket.devices import LocalSimulator\n\ndevice = LocalSimulator(\"braket_dm\")\nresult = device.run(native, shots=1000).result().measurement_counts\nprint(result)\n</code></pre> <pre><code>Counter({'010': 152, '011': 140, '000': 140, '001': 129, '100': 123, '111': 120, '101': 116, '110': 80})\n</code></pre> <pre><code>print(conv.circuit.native.diagram())\n</code></pre> <pre><code>T  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\n\nq0 : -Rx(74bccc23-dc5e-4b1c-8dc0-be9bb9c96fa9)-C----------------------------------------Rx(a8099928-f62d-42ea-8aef-716687fd566d)-Ry(b0b64cfd-e7f0-46d3-9b6a-03fb638ceca7)-Rx(06bd83e6-70b0-46f6-bf84-fa931ad436c1)-C---\n                                               |                                                                                                                                                                   |   \nq1 : -Rz(69b5c438-3989-44a7-ae4c-7966bd831fe9)-X----------------------------------------Rx(0049b169-1019-45ca-b924-ceaf2e032b50)-Ry(67f6189d-6d2f-41da-b2b6-557156e1deee)-Rx(4e1c663d-67dd-423c-9d07-22fcf4d125fd)-X-C-\n                                                                                                                                                                                                                     | \nq2 : -Rx(77b3ec9a-6a82-4683-8b06-4072cc6d34ad)-Ry(b1f8563a-df70-4e27-a436-93c4d977147e)-Rx(319e4698-b37e-4005-a052-d1d3a03ce6d7)-------------------------------------------------------------------------------------X-\n\nT  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\n\nUnassigned parameters: [0049b169-1019-45ca-b924-ceaf2e032b50, 06bd83e6-70b0-46f6-bf84-fa931ad436c1, 319e4698-b37e-4005-a052-d1d3a03ce6d7, 4e1c663d-67dd-423c-9d07-22fcf4d125fd, 67f6189d-6d2f-41da-b2b6-557156e1deee, 69b5c438-3989-44a7-ae4c-7966bd831fe9, 74bccc23-dc5e-4b1c-8dc0-be9bb9c96fa9, 77b3ec9a-6a82-4683-8b06-4072cc6d34ad, a8099928-f62d-42ea-8aef-716687fd566d, b0b64cfd-e7f0-46d3-9b6a-03fb638ceca7, b1f8563a-df70-4e27-a436-93c4d977147e].\n</code></pre> <pre><code>print(native.diagram())\n</code></pre> <pre><code>T  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\n\nq0 : -Rx(2.35)-DEPO(0.1)-C--------DEPO(0.1)-Rx(0.78)-DEPO(0.1)-Ry(0.70)-DEPO(0.1)-Rx(0.93)-DEPO(0.1)-C-DEPO(0.1)-------------\n                         |                                                                           |                       \nq1 : -Rz(0.03)-DEPO(0.1)-X--------DEPO(0.1)-Rx(0.99)-DEPO(0.1)-Ry(0.02)-DEPO(0.1)-Rx(0.35)-DEPO(0.1)-X-DEPO(0.1)-C-DEPO(0.1)-\n                                                                                                                 |           \nq2 : -Rx(0.34)-DEPO(0.1)-Ry(0.54)-DEPO(0.1)-Rx(0.96)-DEPO(0.1)---------------------------------------------------X-DEPO(0.1)-\n\nT  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\n</code></pre> </p>"},{"location":"content/block_system/","title":"Block system","text":"<p>Quantum programs in Qadence are constructed using a block-system, with an emphasis on composability of primitive blocks to obtain larger, composite blocks. This functional approach is different from other frameworks which follow a more object-oriented way to construct circuits and express programs.</p>"},{"location":"content/block_system/#primitive-blocks","title":"Primitive blocks","text":"<p>A <code>PrimitiveBlock</code> represents a digital or an analog time-evolution quantum operation applied to a qubit support. Programs can always be decomposed down into a sequence of <code>PrimitiveBlock</code> elements.</p> <p>Two canonical examples of digital primitive blocks are the parametrized <code>RX</code> and the <code>CNOT</code> gates:</p> <pre><code>from qadence import chain, RX, CNOT\n\nrx = RX(0, 0.5)\ncnot = CNOT(0, 1)\n\nblock = chain(rx, cnot)\n</code></pre> %3 7326b18cd2684cfda8f4bec31603b8a2 0 93d133867d754e5cb7f6d7911d652977 RX(0.5) 7326b18cd2684cfda8f4bec31603b8a2--93d133867d754e5cb7f6d7911d652977 ea1e53ef9b6b4be1abe8f211c513f380 1 9165959359bd4dadb6a774e8923e37d1 93d133867d754e5cb7f6d7911d652977--9165959359bd4dadb6a774e8923e37d1 8a38ee05db4c4495aedaf87c68be6905 9165959359bd4dadb6a774e8923e37d1--8a38ee05db4c4495aedaf87c68be6905 c4006229e773402e8be5545c614cb3af 3613ce771b0446e0a5ebcaa8f4e87589 ea1e53ef9b6b4be1abe8f211c513f380--3613ce771b0446e0a5ebcaa8f4e87589 95f9ee7470644867b5e6d872e12441b7 X 3613ce771b0446e0a5ebcaa8f4e87589--95f9ee7470644867b5e6d872e12441b7 95f9ee7470644867b5e6d872e12441b7--9165959359bd4dadb6a774e8923e37d1 95f9ee7470644867b5e6d872e12441b7--c4006229e773402e8be5545c614cb3af <p>A list of all available primitive operations can be found here.</p> How to visualize blocks <p>There are two ways to display blocks in a Python interpreter: either as a tree in ASCII format using <code>print</code>:</p> <pre><code>from qadence import X, Y, kron\n\nkron_block = kron(X(0), Y(1))\nprint(kron_block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> <p>Or using the visualization package:</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nkron_block = kron(X(0), Y(1))\n# display(kron_block)\n</code></pre> %3 40c7a2f742cc4b8789c2c8c41a53d399 0 3d78bed7b222431d9d4463576d8041c2 X 40c7a2f742cc4b8789c2c8c41a53d399--3d78bed7b222431d9d4463576d8041c2 7c24ed9e885c4e94a0a99f9f58d21319 1 39601ca53c914887b1024481cf0787dd 3d78bed7b222431d9d4463576d8041c2--39601ca53c914887b1024481cf0787dd c6b2b28787a14efc9efc56d4c49da83e b99a97d7f7a345ea929228381bfb5556 Y 7c24ed9e885c4e94a0a99f9f58d21319--b99a97d7f7a345ea929228381bfb5556 b99a97d7f7a345ea929228381bfb5556--c6b2b28787a14efc9efc56d4c49da83e"},{"location":"content/block_system/#composite-blocks","title":"Composite Blocks","text":"<p>Programs can be expressed by composing blocks to result in a larger <code>CompositeBlock</code> using three fundamental operations: chain, kron, and add.</p> <ul> <li>chain applies a set of blocks in sequence, which can have overlapping qubit supports, and results in a <code>ChainBlock</code> type. It is akin to applying a matrix product of the sub-blocks, and can also be used with the <code>*</code> operator.</li> <li>kron applies a set of blocks in parallel, requiring disjoint qubit support, and results in a <code>KronBlock</code> type. This is akin to applying a tensor product of the sub-blocks, and can also be used with the <code>@</code> operator.</li> <li>add performs a direct sum of the operators, and results in an <code>AddBlock</code> type. Blocks constructed this way are typically non-unitary, as is the case for Hamiltonians which can be constructed through sums of Pauli strings. Addition can also be performed directly with the <code>+</code> operator.</li> </ul> <pre><code>from qadence import X, Y, chain, kron\n\nchain_0 = chain(X(0), Y(0))\nchain_1 = chain(X(1), Y(1))\n\nkron_block = kron(chain_0, chain_1)\n</code></pre> %3 34bb1744786c49bcb72b45c0fc098d0b 0 b2dde868d222497795e590efcb1676e4 X 34bb1744786c49bcb72b45c0fc098d0b--b2dde868d222497795e590efcb1676e4 d20082a78fea47f8ba18100783b71ca3 1 638b468ed1c3495fb684fadfbddf354f Y b2dde868d222497795e590efcb1676e4--638b468ed1c3495fb684fadfbddf354f 93fb8c3aefef499496ad158b346fd842 638b468ed1c3495fb684fadfbddf354f--93fb8c3aefef499496ad158b346fd842 817264cdf772419799a9cfa077834f18 44146076b1f84effa8e8acbeb4de6e64 X d20082a78fea47f8ba18100783b71ca3--44146076b1f84effa8e8acbeb4de6e64 4b229b18d997487aa9bda76163adbbba Y 44146076b1f84effa8e8acbeb4de6e64--4b229b18d997487aa9bda76163adbbba 4b229b18d997487aa9bda76163adbbba--817264cdf772419799a9cfa077834f18 <p>All composition functions support list comprehension syntax. Below we exemplify the creation of an XY Hamiltonian for qubits laid out on a line.</p> <pre><code>from qadence import X, Y, add\n\ndef xy_int(i: int, j: int):\n    return (1/2) * (X(i)@X(j) + Y(i)@Y(j))\n\nn_qubits = 3\n\nxy_ham = add(xy_int(i, i+1) for i in range(n_qubits-1))\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u251c\u2500\u2500 KronBlock(0,1)\n\u2502       \u2502   \u251c\u2500\u2500 X(0)\n\u2502       \u2502   \u2514\u2500\u2500 X(1)\n\u2502       \u2514\u2500\u2500 KronBlock(0,1)\n\u2502           \u251c\u2500\u2500 Y(0)\n\u2502           \u2514\u2500\u2500 Y(1)\n\u2514\u2500\u2500 [mul: 0.500] \n    \u2514\u2500\u2500 AddBlock(1,2)\n        \u251c\u2500\u2500 KronBlock(1,2)\n        \u2502   \u251c\u2500\u2500 X(1)\n        \u2502   \u2514\u2500\u2500 X(2)\n        \u2514\u2500\u2500 KronBlock(1,2)\n            \u251c\u2500\u2500 Y(1)\n            \u2514\u2500\u2500 Y(2)\n</code></pre> <p>Qadence blocks can be directly translated to matrix form by calling <code>block.tensor()</code>. Note that first dimension is the batch dimension, following PyTorch conventions. This becomes relevant if the block are parameterized and batched input values are passed, as we will see later.</p> <pre><code>from qadence import X, Y\n\nxy = (1/2) * (X(0)@X(1) + Y(0)@Y(1))\n\nprint(xy.tensor().real)\n</code></pre> <pre><code>tensor([[[0., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [0., 1., 0., 0.],\n         [0., 0., 0., 0.]]])\n</code></pre> <p>For a final example of the flexibility of functional block composition, below is an implementation of the Quantum Fourier Transform on an arbitrary qubit support.</p> <pre><code>from qadence import H, CPHASE, PI, chain, kron\n\ndef qft_layer(qs: tuple, l: int):\n    cphases = chain(CPHASE(qs[j], qs[l], PI/2**(j-l)) for j in range(l+1, len(qs)))\n    return H(qs[l]) * cphases\n\ndef qft(qs: tuple):\n    return chain(qft_layer(qs, l) for l in range(len(qs)))\n</code></pre> %3 ca391b8ca85544ba912aa75282ac49b7 0 8c4e31bc0f5b4ffb8131a2cd26d62bbe H ca391b8ca85544ba912aa75282ac49b7--8c4e31bc0f5b4ffb8131a2cd26d62bbe aa465cbecdfa4b848bf591d6b56df674 1 7f51b1be1de646c4a96735026a0d7c2c PHASE(1.571) 8c4e31bc0f5b4ffb8131a2cd26d62bbe--7f51b1be1de646c4a96735026a0d7c2c 305127914532453eaf71799566993148 PHASE(0.785) 7f51b1be1de646c4a96735026a0d7c2c--305127914532453eaf71799566993148 dac8613ce49a436997e9b28b5a989390 7f51b1be1de646c4a96735026a0d7c2c--dac8613ce49a436997e9b28b5a989390 c7cf172bd4c149e1931d8f7e54b58ce2 305127914532453eaf71799566993148--c7cf172bd4c149e1931d8f7e54b58ce2 3955d7eac6954df7ba6a255152859a53 305127914532453eaf71799566993148--3955d7eac6954df7ba6a255152859a53 f33c9c14d4ad412d82c79f8d9fa57bfa c7cf172bd4c149e1931d8f7e54b58ce2--f33c9c14d4ad412d82c79f8d9fa57bfa e29c3245a4c6404d9d6964149cb3a428 f33c9c14d4ad412d82c79f8d9fa57bfa--e29c3245a4c6404d9d6964149cb3a428 4869e0e6edc2407890fad0ac4d3b6f70 e29c3245a4c6404d9d6964149cb3a428--4869e0e6edc2407890fad0ac4d3b6f70 af3edb6f26fa4774ad67e7466126d540 97e67d10da304117bac29e5e0ea040f2 aa465cbecdfa4b848bf591d6b56df674--97e67d10da304117bac29e5e0ea040f2 197c98b703a445f3828afa11dcc01891 2 97e67d10da304117bac29e5e0ea040f2--dac8613ce49a436997e9b28b5a989390 8d5b6d43f4494fb08ed92d25cc90a677 dac8613ce49a436997e9b28b5a989390--8d5b6d43f4494fb08ed92d25cc90a677 0816d2695eb048de8cbd10bcbf802c42 H 8d5b6d43f4494fb08ed92d25cc90a677--0816d2695eb048de8cbd10bcbf802c42 2cc3691b6a634381a111bd87737a54a5 PHASE(1.571) 0816d2695eb048de8cbd10bcbf802c42--2cc3691b6a634381a111bd87737a54a5 5fdd91f218c24864b299db41cd49250b 2cc3691b6a634381a111bd87737a54a5--5fdd91f218c24864b299db41cd49250b 925a02e6663b41aabcdbd622e8e27ece 2cc3691b6a634381a111bd87737a54a5--925a02e6663b41aabcdbd622e8e27ece 5fdd91f218c24864b299db41cd49250b--af3edb6f26fa4774ad67e7466126d540 a6afea8a73714492b7f35a7c43bd2b82 fc9110985ba74dada571651f5756d68b 197c98b703a445f3828afa11dcc01891--fc9110985ba74dada571651f5756d68b 645527422ad64e4a9931274722773e65 fc9110985ba74dada571651f5756d68b--645527422ad64e4a9931274722773e65 645527422ad64e4a9931274722773e65--3955d7eac6954df7ba6a255152859a53 2e50798570c344dd9710105e5b80c38e 3955d7eac6954df7ba6a255152859a53--2e50798570c344dd9710105e5b80c38e 2e50798570c344dd9710105e5b80c38e--925a02e6663b41aabcdbd622e8e27ece c3fe3279f04245ea92c07def798d1d7f H 925a02e6663b41aabcdbd622e8e27ece--c3fe3279f04245ea92c07def798d1d7f c3fe3279f04245ea92c07def798d1d7f--a6afea8a73714492b7f35a7c43bd2b82 <p>Other functionalities are directly built in the block system. For example, the inverse operation can be created with the <code>dagger()</code> method.</p> <pre><code>qft_inv = qft((0, 1, 2)).dagger()\n</code></pre> %3 a93523f5552b4ffeb87cd8d02315254c 0 cec29d7f13484ea490a3dfcc92ae09d2 a93523f5552b4ffeb87cd8d02315254c--cec29d7f13484ea490a3dfcc92ae09d2 28112857066542c8a6394f6f84a4d8d1 1 00b3be6c952044db9a461293688f7568 cec29d7f13484ea490a3dfcc92ae09d2--00b3be6c952044db9a461293688f7568 f824ccb5f7fb404a942d63b709388441 00b3be6c952044db9a461293688f7568--f824ccb5f7fb404a942d63b709388441 835e8af90fd94218b0828f49cd208100 PHASE(-0.785) f824ccb5f7fb404a942d63b709388441--835e8af90fd94218b0828f49cd208100 b55d07e1a8e14cdeb4ccee0636a4a13a PHASE(-1.571) 835e8af90fd94218b0828f49cd208100--b55d07e1a8e14cdeb4ccee0636a4a13a 0f69a17bdde040f88a574022c63478b9 835e8af90fd94218b0828f49cd208100--0f69a17bdde040f88a574022c63478b9 530afb450d594cc0b88afe6e2e14b1fd H b55d07e1a8e14cdeb4ccee0636a4a13a--530afb450d594cc0b88afe6e2e14b1fd aa3240b406b34eaf9d9ee30271412f54 b55d07e1a8e14cdeb4ccee0636a4a13a--aa3240b406b34eaf9d9ee30271412f54 b7709de419c3437688c84d6425f178ce 530afb450d594cc0b88afe6e2e14b1fd--b7709de419c3437688c84d6425f178ce 2ea5c9a68135449e851eaadb004e076b a434a88d4d4a4a8999c9d89200c0d439 28112857066542c8a6394f6f84a4d8d1--a434a88d4d4a4a8999c9d89200c0d439 f0eb697d71284d96bc003d9ccdb1c27b 2 a651a8f411d64685a2b5e91fe13c785d PHASE(-1.571) a434a88d4d4a4a8999c9d89200c0d439--a651a8f411d64685a2b5e91fe13c785d 9a57d8f8f0a14328b6c7006f26c5c6b2 H a651a8f411d64685a2b5e91fe13c785d--9a57d8f8f0a14328b6c7006f26c5c6b2 c035bc5fc835421ba94a36ffee04815b a651a8f411d64685a2b5e91fe13c785d--c035bc5fc835421ba94a36ffee04815b 2a046e0937d6457bb02d5fa6df4dd7f0 9a57d8f8f0a14328b6c7006f26c5c6b2--2a046e0937d6457bb02d5fa6df4dd7f0 2a046e0937d6457bb02d5fa6df4dd7f0--aa3240b406b34eaf9d9ee30271412f54 252f07f0648f4d8e802bf67dc45f14c6 aa3240b406b34eaf9d9ee30271412f54--252f07f0648f4d8e802bf67dc45f14c6 252f07f0648f4d8e802bf67dc45f14c6--2ea5c9a68135449e851eaadb004e076b d7876e1424c7472fb68c844da9011ab0 011e17836766432fa3a023699c978d3d H f0eb697d71284d96bc003d9ccdb1c27b--011e17836766432fa3a023699c978d3d 011e17836766432fa3a023699c978d3d--c035bc5fc835421ba94a36ffee04815b e33c4d9e8c5f49dd9c9734b802b3ec63 c035bc5fc835421ba94a36ffee04815b--e33c4d9e8c5f49dd9c9734b802b3ec63 e33c4d9e8c5f49dd9c9734b802b3ec63--0f69a17bdde040f88a574022c63478b9 45d6c386dfbe4ce6b91e06235b9842a1 0f69a17bdde040f88a574022c63478b9--45d6c386dfbe4ce6b91e06235b9842a1 04da6e6d619847e8bf6cf5b3432be352 45d6c386dfbe4ce6b91e06235b9842a1--04da6e6d619847e8bf6cf5b3432be352 04da6e6d619847e8bf6cf5b3432be352--d7876e1424c7472fb68c844da9011ab0"},{"location":"content/block_system/#digital-analog-composition","title":"Digital-analog composition","text":"<p>In Qadence, analog operations are first-class citizens. An analog operation is one whose unitary is best described by the evolution of some hermitian generator, or Hamiltonian, acting on an arbitrary number of qubits. Qadence provides the <code>HamEvo</code> class to initialize analog operations. For a time-independent generator \\(\\mathcal{H}\\) and some time variable \\(t\\), <code>HamEvo(H, t)</code> represents the evolution operator \\(\\exp(-i\\mathcal{H}t)\\).</p> <p>Analog operations constitute a generalization of digital operations, and all digital operations can also be represented as the evolution of some hermitian generator. For example, the <code>RX</code> gate is the evolution of <code>X</code>.</p> <pre><code>from qadence import X, RX, HamEvo, PI\nfrom torch import allclose\n\nangle = PI/2\n\nblock_digital = RX(0, angle)\n\nblock_analog = HamEvo(0.5*X(0), angle)\n\nprint(allclose(block_digital.tensor(), block_analog.tensor()))\n</code></pre> <pre><code>True\n</code></pre> <p>As seen in the previous section, arbitrary Hamiltonians can be constructed using Pauli operators. Their evolution can be combined with other arbitrary digital operations and incorporated into any quantum program.</p> <pre><code>from qadence import X, Y, RX, HamEvo\nfrom qadence import add, kron, PI\n\ndef xy_int(i: int, j: int):\n    return (1/2) * (X(i)@X(j) + Y(i)@Y(j))\n\nn_qubits = 3\n\nxy_ham = add(xy_int(i, i+1) for i in range(n_qubits-1))\n\nanalog_evo = HamEvo(xy_ham, 1.0)\n\ndigital_block = kron(RX(i, i*PI/2) for i in range(n_qubits))\n\nprogram = digital_block * analog_evo * digital_block\n</code></pre> %3 cluster_4f4a7a038fa64ac7902a9d75b719fe3f 74709420eb674533826c86122d428847 0 8e10a1d7a5ef4028aeb7d283591929cc RX(0.0) 74709420eb674533826c86122d428847--8e10a1d7a5ef4028aeb7d283591929cc 7aa50619ce3d459b8b8027dca3dfbb21 1 eabe877b5b714e69806a4c60785c492c HamEvo 8e10a1d7a5ef4028aeb7d283591929cc--eabe877b5b714e69806a4c60785c492c 90f870612b734620b26b655807a9e005 RX(0.0) eabe877b5b714e69806a4c60785c492c--90f870612b734620b26b655807a9e005 f20f6dce53a4470a90295865e7a4270c 90f870612b734620b26b655807a9e005--f20f6dce53a4470a90295865e7a4270c 3b6a528c3a5e4fb49dc4a1699a553c85 07efce246e854d54b4653006319d091c RX(1.571) 7aa50619ce3d459b8b8027dca3dfbb21--07efce246e854d54b4653006319d091c 9492995ff65a46dbb9fa46632c233a79 2 afd6f0fdc11549bcbc1d3191b11be931 t = 1.000 07efce246e854d54b4653006319d091c--afd6f0fdc11549bcbc1d3191b11be931 2b3bedbd26de47deac7e0b9039721d06 RX(1.571) afd6f0fdc11549bcbc1d3191b11be931--2b3bedbd26de47deac7e0b9039721d06 2b3bedbd26de47deac7e0b9039721d06--3b6a528c3a5e4fb49dc4a1699a553c85 fced84817e364b6d9b55fbeca1db19dc aa5bd483f50d41b1a6be78cb5e89c39e RX(3.142) 9492995ff65a46dbb9fa46632c233a79--aa5bd483f50d41b1a6be78cb5e89c39e 021c919c8ea2415db6872d3b96740c9c aa5bd483f50d41b1a6be78cb5e89c39e--021c919c8ea2415db6872d3b96740c9c 3445054be39749f1ab1109cffb4c5605 RX(3.142) 021c919c8ea2415db6872d3b96740c9c--3445054be39749f1ab1109cffb4c5605 3445054be39749f1ab1109cffb4c5605--fced84817e364b6d9b55fbeca1db19dc"},{"location":"content/block_system/#block-execution","title":"Block execution","text":"<p>To quickly run block operations and access wavefunctions, samples or expectation values of observables, one can use the convenience functions <code>run</code>, <code>sample</code> and <code>expectation</code>.</p> <pre><code>from qadence import kron, add, H, Z, run, sample, expectation\n\nn_qubits = 2\n\n# Prepares a uniform state\nh_block = kron(H(i) for i in range(n_qubits))\n\nwf = run(h_block)\n\nxs = sample(h_block, n_shots=1000)\n\nobs = add(Z(i) for i in range(n_qubits))\nex = expectation(h_block, obs)\n</code></pre> <pre><code>wf = tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\nxs = [Counter({'00': 261, '01': 252, '11': 247, '10': 240})]\nex = tensor([[0.]], requires_grad=True)\n</code></pre>"},{"location":"content/block_system/#execution-via-quantumcircuit-and-quantummodel","title":"Execution via <code>QuantumCircuit</code> and <code>QuantumModel</code>","text":"<p>More fine-grained control and better performance is provided via the high-level <code>QuantumModel</code> abstraction. Quantum programs in Qadence are constructed in two steps:</p> <ol> <li>Build a <code>QuantumCircuit</code> which ties together a composite block and a register.</li> <li>Define a <code>QuantumModel</code> which differentiates, compiles and executes the circuit.</li> </ol> <p>Execution of more complex Qadence programs will be explored in the next tutorials.</p>"},{"location":"content/hamiltonians/","title":"Constructing arbitrary Hamiltonians","text":"<p>At the heart of digital-analog quantum computing is the description and execution of analog blocks, which represent a set of interacting qubits under some interaction Hamiltonian. For this purpose, Qadence relies on the <code>hamiltonian_factory</code> function to create arbitrary Hamiltonian blocks to be used as generators of <code>HamEvo</code> or as observables to be measured.</p>"},{"location":"content/hamiltonians/#arbitrary-all-to-all-hamiltonians","title":"Arbitrary all-to-all Hamiltonians","text":"<p>Arbitrary all-to-all interaction Hamiltonians can be easily created by passing the number of qubits in the first argument. The type of <code>interaction</code> can be chosen from the available ones in the <code>Interaction</code> enum type.</p> <pre><code>from qadence import hamiltonian_factory\nfrom qadence import N, X, Y, Z\nfrom qadence import Interaction\n\nn_qubits = 3\n\nhamilt = hamiltonian_factory(n_qubits, interaction=Interaction.ZZ)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 Z(1)\n        \u2514\u2500\u2500 Z(2)\n</code></pre> <p>Alternatively, a custom interaction function can also be defined. The input should be two integer indices \\(i\\) and \\(j\\) and it should return a composition of pauli terms representing the interaction between qubits \\(i\\) and \\(j\\):</p> <pre><code>def custom_int(i: int, j: int):\n    return X(i) @ X(j) + Y(i) @ Y(j)\n\nn_qubits = 2\n\nhamilt = hamiltonian_factory(n_qubits, interaction=custom_int)\n</code></pre> <pre><code>AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 AddBlock(0,1)\n        \u251c\u2500\u2500 KronBlock(0,1)\n        \u2502   \u251c\u2500\u2500 X(0)\n        \u2502   \u2514\u2500\u2500 X(1)\n        \u2514\u2500\u2500 KronBlock(0,1)\n            \u251c\u2500\u2500 Y(0)\n            \u2514\u2500\u2500 Y(1)\n</code></pre> <p>Single-qubit terms can also be added by passing the respective operator directly to the <code>detuning</code> argument. For example, the total magnetization is commonly used as an observable to be measured:</p> <pre><code>total_mag = hamiltonian_factory(n_qubits, detuning = Z)\n</code></pre> <pre><code>AddBlock(0,1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 Z(0)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 Z(1)\n</code></pre> <p>For further customization, arbitrary coefficients can be passed as arrays to the <code>interaction_strength</code> and <code>detuning_strength</code> arguments for the two-qubits and single-qubit terms respectively.</p> <pre><code>n_qubits = 3\n\nhamilt = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.ZZ,\n    detuning=Z,\n    interaction_strength=[0.5, 0.2, 0.1],\n    detuning_strength=[0.1, 0.5, -0.3]\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.100] \n\u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: -0.30] \n\u2502   \u2514\u2500\u2500 Z(2)\n\u251c\u2500\u2500 [mul: 0.500] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 0.200] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 0.100] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 Z(1)\n        \u2514\u2500\u2500 Z(2)\n</code></pre> <p>Ordering interaction strengths matters</p> <p>When passing interaction strengths as an array, the ordering must be identical to the one obtained from the <code>edges</code> property of a Qadence <code>Register</code>:</p> <pre><code>from qadence import Register\n\nprint(Register(n_qubits).edges)\n</code></pre> <pre><code>[(0, 1), (0, 2), (1, 2)]\n</code></pre> <p>For one more example, let's create a transverse-field Ising model,</p> <pre><code>n_qubits = 4\nn_edges = int(0.5 * n_qubits * (n_qubits - 1))\n\nz_terms = [1.0] * n_qubits\nzz_terms = [2.0] * n_edges\n\nzz_ham = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.ZZ,\n    detuning=Z,\n    interaction_strength=zz_terms,\n    detuning_strength=z_terms\n)\n\nx_terms = [-1.0] * n_qubits\nx_ham = hamiltonian_factory(n_qubits, detuning = X, detuning_strength = x_terms)\n\ntransverse_ising = zz_ham + x_ham\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 AddBlock(0,1,2,3)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(0)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2502   \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.000] \n\u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u2514\u2500\u2500 [mul: 2.000] \n\u2502       \u2514\u2500\u2500 KronBlock(2,3)\n\u2502           \u251c\u2500\u2500 Z(2)\n\u2502           \u2514\u2500\u2500 Z(3)\n\u2514\u2500\u2500 AddBlock(0,1,2,3)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(0)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(1)\n    \u251c\u2500\u2500 [mul: -1.00] \n    \u2502   \u2514\u2500\u2500 X(2)\n    \u2514\u2500\u2500 [mul: -1.00] \n        \u2514\u2500\u2500 X(3)\n</code></pre> <p>Random interaction coefficients</p> <p>Random interaction coefficients can be chosen between -1 and 1 by simply passing <code>random_strength = True</code> instead of <code>detuning_strength</code> and <code>interaction_strength</code>.</p>"},{"location":"content/hamiltonians/#arbitrary-hamiltonian-topologies","title":"Arbitrary Hamiltonian topologies","text":"<p>Arbitrary interaction topologies can be created using the Qadence <code>Register</code>. Simply pass the register with the desired topology as the first argument to the <code>hamiltonian_factory</code>:</p> <pre><code>from qadence import Register\n\nreg = Register.square(qubits_side=2)\n\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(2,3)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(3)\n</code></pre>"},{"location":"content/hamiltonians/#adding-variational-parameters","title":"Adding variational parameters","text":"<p>Finally, fully parameterized Hamiltonians can be created by passing a string to the strength arguments, and used to prefix the name of the variational parameters.</p> <pre><code>n_qubits = 3\n\nnn_ham = hamiltonian_factory(\n    n_qubits,\n    interaction=Interaction.NN,\n    detuning=N,\n    interaction_strength=\"c\",\n    detuning_strength=\"d\"\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: d_0] \n\u2502   \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: d_1] \n\u2502   \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: d_2] \n\u2502   \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: c_01] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: c_02] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: c_12] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 N(1)\n        \u2514\u2500\u2500 N(2)\n</code></pre> <p>Alternatively, fully customizable sympy functions can be passed in an array using the Qadence parameters. Furthermore, the <code>use_all_node_pairs = True</code> option can be passed so that interactions are created for every single node pair in the register, irrespectively of the topology of the edges. This is useful for creating Hamiltonians that depend on qubit distance.</p> <pre><code>from qadence import VariationalParameter, Register\n\n# Square register of 4 qubits with a dimensionless distance of 8.0\nreg = Register.square(2, spacing = 8.0)\n\n# Get the distances between all pairs of qubits\ndistance_dict = reg.distances\n\n# Create interaction strength with variational parameter and 1/r term\nstrength_list = []\nfor node_pair in reg.all_node_pairs:\n    param = VariationalParameter(\"x\" + f\"_{node_pair[0]}{node_pair[1]}\")\n    dist_factor = reg.distances[node_pair]\n    strength_list.append(param / dist_factor)\n\nnn_ham = hamiltonian_factory(\n    reg,\n    interaction=Interaction.NN,\n    interaction_strength=strength_list,\n    use_all_node_pairs=True,\n)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 0.125*x_01] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 0.088*x_02] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: 0.125*x_03] \n\u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 0.125*x_12] \n\u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: 0.088*x_13] \n\u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(3)\n\u2514\u2500\u2500 [mul: 0.125*x_23] \n    \u2514\u2500\u2500 KronBlock(2,3)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(3)\n</code></pre>"},{"location":"content/overlap/","title":"Wavefunction overlaps","text":"<p>Qadence offers convenience functions for computing the overlap between the wavefunctions generated by two quantum circuits \\(U\\) and \\(W\\) as:</p> \\[ S = |\\langle \\psi_U | \\psi_W \\rangle|^2 \\quad \\textrm{where} \\quad \\psi_U = U|\\psi_0\\rangle \\] <p>Here is an example on how to compute the overlap between two very simple parametric circuits consisting of a single <code>RX</code> rotation on different qubits. The overlap is expected to be non-zero only when the rotation angle is different from \\(\\pi \\; \\textrm{mod}\\; 2\\pi\\) for both rotations:</p> <pre><code>import numpy as np\nfrom torch import tensor\nfrom qadence import Overlap, OverlapMethod, QuantumCircuit, H, RX, X, FeatureParameter, hea, PI\n\n\n# Create two quantum circuits\n# with a single qubit rotation on two random qubits\nn_qubits = 4\nqubits = np.random.choice(n_qubits, n_qubits, replace=False)\n\nphi = FeatureParameter(\"phi\")\ncircuit_bra = QuantumCircuit(n_qubits, RX(qubits[0], phi))\n\npsi = FeatureParameter(\"psi\")\ncircuit_ket = QuantumCircuit(n_qubits, RX(qubits[1], psi))\n\n# Values for the feature parameters\nvalues_bra = {\"phi\": tensor([PI / 2, PI])}\nvalues_ket = {\"psi\": tensor([PI / 2, PI])}\n\n# Calculate overlap by assigning values to the given bra and ket circuits\novrlp = Overlap(circuit_bra, circuit_ket)\novrlp = ovrlp(bra_param_values=values_bra, ket_param_values=values_ket)\n</code></pre> <pre><code>Overlap with exact method:\n tensor([[2.5000e-01, 1.8747e-33],\n        [1.8747e-33, 1.4058e-65]])\n</code></pre> <p>The <code>Overlap</code> class above inherits from <code>QuantumModel</code> and is executed through its inherited forward method for the given input parameter values. By default, the overlap is computed exactly by performing the dot product of the wavefunction propagated from bra and ket circuits.</p> <p>However, it is possible to choose a different method from the <code>OverlapMethod</code> enumeration to be passed via the <code>overlap_method</code> argument in the <code>Overlap</code> initializer. Currently, one can choose from:</p> <ul> <li><code>EXACT</code>: exact computation using the wavefunction matrix representation. Does not work with real devices since it assumes access to the complete qubit system wavefunction.</li> <li><code>COMPUTE_UNCOMPUTE</code>: exact or sampling-based computation using bra \\(U\\) and ket \\(W^{\\dagger}\\) unitaries.</li> <li><code>SWAP_TEST</code>: exact or sampling-based computation using the SWAP test method.</li> <li><code>HADAMARD_TEST</code>: exact or sampling-based computation using the Hadamard test method.</li> <li><code>JENSEN_SHANNON</code>: compute the overlap using the Jensen-Shannon divergence of the two probability distributions obtained by sampling the propagated circuits. This will yield a different result than the other methods.</li> </ul> <p>All methods (except for the <code>EXACT</code> method) take an optional <code>n_shots</code> argument which can be used to perform shot-based calculations.</p> <p>Warning</p> <p>If you select a finite number of shots, the overlap is not differentiable. Therefore, it cannot be used as output of a quantum model if gradients are required.</p> <pre><code># Calculate overlap with SWAP test\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket)\n\n# Calculate overlap with SWAP test\n# using a finite number of shots\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket, n_shots=10_000)\n</code></pre> <pre><code>Overlap with SWAP test:\n tensor([[ 2.5000e-01, -3.3307e-16],\n        [-3.3307e-16, -4.4409e-16]])\nOverlap with SWAP test with finite number of shots:\n tensor([[ 0.2326, -0.0144],\n        [ 0.0026,  0.0094]])\n</code></pre>"},{"location":"content/parameters/","title":"Parametric programs","text":"<p>Qadence provides a flexible parameter system built on top of Sympy. Parameters can be of different types:</p> <ul> <li>Fixed parameter: a constant with a fixed, non-trainable value (e.g. \\(\\dfrac{\\pi}{2}\\)).</li> <li>Variational parameter: a trainable parameter which will be automatically picked up by the optimizer.</li> <li>Feature parameter: a non-trainable parameter which can be used to pass input values.</li> </ul>"},{"location":"content/parameters/#fixed-parameters","title":"Fixed parameters","text":"<p>Passing fixed parameters to blocks can be done by simply passing a Python numeric type or a <code>torch.Tensor</code>.</p> <pre><code>import torch\nfrom qadence import RX, run, PI\n\nwf = run(RX(0, torch.tensor(PI)))\n\nwf = run(RX(0, PI))\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\nwf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\n</code></pre>"},{"location":"content/parameters/#variational-parameters","title":"Variational parameters","text":"<p>To parametrize a block a <code>VariationalParameter</code> instance is required. In most cases Qadence also accepts a Python string, which will be used to automatically initialize a <code>VariationalParameter</code>:</p> <pre><code>from qadence import RX, run, VariationalParameter\n\nblock = RX(0, VariationalParameter(\"theta\"))\nblock = RX(0, \"theta\")  # Equivalent\n\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[0.9983+0.0000j, 0.0000-0.0577j]])\n</code></pre> <p>By calling <code>run</code>, a random value for <code>\"theta\"</code> is initialized at execution. In a <code>QuantumModel</code>, variational parameters are stored in the underlying model parameter dictionary.</p>"},{"location":"content/parameters/#feature-parameters","title":"Feature parameters","text":"<p>A <code>FeatureParameter</code> type can also be used. It requires an input value or a batch of values. In most cases, Qadence accepts a <code>values</code> dictionary to set the input of feature parameters.</p> <pre><code>from torch import tensor\nfrom qadence import RX, PI, run, FeatureParameter\n\nblock = RX(0, FeatureParameter(\"phi\"))\n\nwf = run(block, values = {\"phi\": tensor([PI, PI/2])})\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.0000j, 0.0000e+00-1.0000j],\n        [7.0711e-01+0.0000j, 0.0000e+00-0.7071j]])\n</code></pre> <p>Since a batch of input values was passed, the <code>run</code> function returns a batch of output states. Note that <code>FeatureParameter(\"x\")</code> and <code>VariationalParameter(\"x\")</code> are simply aliases for <code>Parameter(\"x\", trainable = False)</code> and <code>Parameter(\"x\", trainable = True)</code>.</p>"},{"location":"content/parameters/#multiparameter-expressions-and-analog-integration","title":"Multiparameter expressions and analog integration","text":"<p>The integration with Sympy becomes useful when one wishes to write arbitrary parameter compositions. Parameters can also be used as scaling coefficients in the block system, which is essential when defining arbitrary analog operations.</p> <pre><code>from torch import tensor\nfrom qadence import RX, Z, HamEvo, PI\nfrom qadence import VariationalParameter, FeatureParameter, run\nfrom sympy import sin\n\ntheta, phi = VariationalParameter(\"theta\"), FeatureParameter(\"phi\")\n\n# Arbitrary parameter composition\nexpr = PI * sin(theta + phi)\n\n# Use as unitary gate arguments\ngate = RX(0, expr)\n\n# Or as scaling coefficients for Hermitian operators\nh_op = expr * (Z(0) @ Z(1))\n\nwf = run(gate * HamEvo(h_op, phi), values = {\"phi\": tensor(PI)})\n</code></pre> <pre><code>wf = tensor([[-0.1917+0.9412j,  0.0000+0.0000j,  0.2727-0.0555j,  0.0000+0.0000j]])\n</code></pre>"},{"location":"content/parameters/#parameter-redundancy","title":"Parameter redundancy","text":"<p>Parameters are uniquely defined by their name and redundancy is allowed in composite blocks to assign the same value to different blocks. This is useful, for example, when defining layers of rotation gates typically used as feature maps.</p> <pre><code>from torch import tensor\nfrom qadence import RY, PI, run, kron, FeatureParameter\n\nn_qubits = 3\n\nparam = FeatureParameter(\"phi\")\n\nblock = kron(RY(i, (i+1) * param) for i in range(n_qubits))\n\nwf = run(block, values = {\"phi\": tensor(PI)})\n</code></pre> <pre><code>wf = tensor([[ 1.1248e-32+0.j,  6.1232e-17+0.j, -1.3775e-48+0.j, -7.4988e-33+0.j,\n          1.8370e-16+0.j,  1.0000e+00+0.j, -2.2496e-32+0.j, -1.2246e-16+0.j]])\n</code></pre>"},{"location":"content/parameters/#parametrized-circuits","title":"Parametrized circuits","text":"<p>Let's look at a final example of an arbitrary composition of digital and analog parameterized blocks:</p> <pre><code>import sympy\nfrom qadence import RX, RY, RZ, CNOT, CPHASE, Z, HamEvo\nfrom qadence import run, chain, add, kron, FeatureParameter, VariationalParameter, PI\n\nn_qubits = 3\n\nphi = FeatureParameter(\"\u03a6\")\ntheta = VariationalParameter(\"\u03b8\")\n\nrotation_block = kron(\n    RX(0, phi/theta),\n    RY(1, theta*2),\n    RZ(2, sympy.cos(phi))\n)\ndigital_entangler = CNOT(0, 1) * CPHASE(1, 2, PI)\n\nhamiltonian = add(theta * (Z(i) @ Z(i+1)) for i in range(n_qubits-1))\n\nanalog_evo = HamEvo(hamiltonian, phi)\n\nprogram = chain(rotation_block, digital_entangler, analog_evo)\n</code></pre> %3 cluster_848bb54ce12e4a2998df835c62b06c9e a5004b4a500c451fbfe9016138bba6bb 0 2c26ae4002684274a46a2844cd706f9d RX(\u03a6/\u03b8) a5004b4a500c451fbfe9016138bba6bb--2c26ae4002684274a46a2844cd706f9d ff8ef7272a524bbc93050669e948205f 1 e7ab64db31554996af62a575d4752d52 2c26ae4002684274a46a2844cd706f9d--e7ab64db31554996af62a575d4752d52 e4ab8bfc06f541e38be2b3ee538a72fa e7ab64db31554996af62a575d4752d52--e4ab8bfc06f541e38be2b3ee538a72fa bcb56f6cfbc24958a861d52718035516 HamEvo e4ab8bfc06f541e38be2b3ee538a72fa--bcb56f6cfbc24958a861d52718035516 39353d2ec6c8461d9bbe3e0287d43e1b bcb56f6cfbc24958a861d52718035516--39353d2ec6c8461d9bbe3e0287d43e1b cc0cd6c4504b49089000ea3a41108982 a8bcb739092f42ff87bc3cf0342d6e49 RY(2*\u03b8) ff8ef7272a524bbc93050669e948205f--a8bcb739092f42ff87bc3cf0342d6e49 7a56448e05ef410e8e9dab6b3deb5809 2 dadaf61440914e4ba93b61f8ef669118 X a8bcb739092f42ff87bc3cf0342d6e49--dadaf61440914e4ba93b61f8ef669118 dadaf61440914e4ba93b61f8ef669118--e7ab64db31554996af62a575d4752d52 61ca0bf5f35f4bd0bd6b64ef380d9e49 dadaf61440914e4ba93b61f8ef669118--61ca0bf5f35f4bd0bd6b64ef380d9e49 3af60921888f4fff92a39f8f4978f614 t = \u03a6 61ca0bf5f35f4bd0bd6b64ef380d9e49--3af60921888f4fff92a39f8f4978f614 3af60921888f4fff92a39f8f4978f614--cc0cd6c4504b49089000ea3a41108982 ea35408db38c4f579eb8b384ce66b9bf fde6070337ed4dc3b463db18c6f980bf RZ(cos(\u03a6)) 7a56448e05ef410e8e9dab6b3deb5809--fde6070337ed4dc3b463db18c6f980bf 23055569f0354c61a8d6a029532b05e0 fde6070337ed4dc3b463db18c6f980bf--23055569f0354c61a8d6a029532b05e0 c8b3ae1f78e1498a8128aa173f52b50e PHASE(3.142) 23055569f0354c61a8d6a029532b05e0--c8b3ae1f78e1498a8128aa173f52b50e c8b3ae1f78e1498a8128aa173f52b50e--61ca0bf5f35f4bd0bd6b64ef380d9e49 0a0053932e2d4b2aa10e47b3a166898a c8b3ae1f78e1498a8128aa173f52b50e--0a0053932e2d4b2aa10e47b3a166898a 0a0053932e2d4b2aa10e47b3a166898a--ea35408db38c4f579eb8b384ce66b9bf <p>Please note the different colors for the parametrization with different types. The default palette assigns blue for <code>VariationalParameter</code>, green for <code>FeatureParameter</code>, orange for numeric values, and shaded red for non-parametric gates.</p>"},{"location":"content/qml_constructors/","title":"Quantum machine learning constructors","text":"<p>Besides the arbitrary Hamiltonian constructors, Qadence also provides a complete set of program constructors useful for digital-analog quantum machine learning programs.</p>"},{"location":"content/qml_constructors/#feature-maps","title":"Feature maps","text":"<p>The <code>feature_map</code> function can easily create several types of data-encoding blocks. The two main types of feature maps use a Fourier basis or a Chebyshev basis.</p> <pre><code>from qadence import feature_map, BasisSet, chain\nfrom qadence.draw import display\n\nn_qubits = 3\n\nfourier_fm = feature_map(n_qubits, fm_type=BasisSet.FOURIER)\n\nchebyshev_fm = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV)\n\nblock = chain(fourier_fm, chebyshev_fm)\n</code></pre> %3 cluster_034ea06a73d44984a70b45ca828e3783 Constant Chebyshev FM cluster_ca011a0c06d948e281cc8a85fde00666 Constant Fourier FM 07f3659b2cc54893b925951c372ee960 0 f812f6f491684ead922d0835e01c3275 RX(phi) 07f3659b2cc54893b925951c372ee960--f812f6f491684ead922d0835e01c3275 a108dd05a9c74704a47cf24e22794a4a 1 2c1342f9d9664d2eafd902a5a98f6ba4 RX(acos(phi)) f812f6f491684ead922d0835e01c3275--2c1342f9d9664d2eafd902a5a98f6ba4 92449e418ed04872a7e530c743b7b6bb 2c1342f9d9664d2eafd902a5a98f6ba4--92449e418ed04872a7e530c743b7b6bb b82744f780d544c1851b92e0b8c11a75 c25599980c3642cbabbbe789f156c3aa RX(phi) a108dd05a9c74704a47cf24e22794a4a--c25599980c3642cbabbbe789f156c3aa 49e3a892c0664f4aa5fef4de420e008a 2 a328db6a8e264ddfb377057bfe083d4a RX(acos(phi)) c25599980c3642cbabbbe789f156c3aa--a328db6a8e264ddfb377057bfe083d4a a328db6a8e264ddfb377057bfe083d4a--b82744f780d544c1851b92e0b8c11a75 24f3d111198e49f281150e8fe0b7bb70 0ebf8925a60b45c5aeb061ec2ea83325 RX(phi) 49e3a892c0664f4aa5fef4de420e008a--0ebf8925a60b45c5aeb061ec2ea83325 51724cc8f6384793b01ea9a6d4d9bc3c RX(acos(phi)) 0ebf8925a60b45c5aeb061ec2ea83325--51724cc8f6384793b01ea9a6d4d9bc3c 51724cc8f6384793b01ea9a6d4d9bc3c--24f3d111198e49f281150e8fe0b7bb70 <p>A custom encoding function can also be passed with <code>sympy</code></p> <pre><code>from sympy import asin, Function\n\nn_qubits = 3\n\n# Using a pre-defined sympy Function\ncustom_fm_0 = feature_map(n_qubits, fm_type=asin)\n\n# Creating a custom function\ndef custom_fn(x):\n    return asin(x) + x**2\n\ncustom_fm_1 = feature_map(n_qubits, fm_type=custom_fn)\n\nblock = chain(custom_fm_0, custom_fm_1)\n</code></pre> %3 cluster_9a8dfa96f50449c490e1250ad0d884a4 Constant &lt;function custom_fn at 0x7f4f0c695e10&gt; FM cluster_2e9e8e9c033644108b363db6c5ea821e Constant asin FM 689a11c7a58a4de8b401172aca031949 0 62b47fb056aa49a8a385c4104d2458da RX(asin(phi)) 689a11c7a58a4de8b401172aca031949--62b47fb056aa49a8a385c4104d2458da 4a3ae45c59cc45328cde54f7147973f3 1 157bbf612f354e9aa91bc07a4a0fb718 RX(phi**2 + asin(phi)) 62b47fb056aa49a8a385c4104d2458da--157bbf612f354e9aa91bc07a4a0fb718 cfedc97dc55d43699ef3b4e3f5b3f1fe 157bbf612f354e9aa91bc07a4a0fb718--cfedc97dc55d43699ef3b4e3f5b3f1fe 528042fd44f14423873ab318de081f5f d29422b6f2d7463d8ef3a2830c5396ec RX(asin(phi)) 4a3ae45c59cc45328cde54f7147973f3--d29422b6f2d7463d8ef3a2830c5396ec d383ad75ea5a4fb6833f89e57713acff 2 ee793d649c9242b39fa89ee8ab41efb3 RX(phi**2 + asin(phi)) d29422b6f2d7463d8ef3a2830c5396ec--ee793d649c9242b39fa89ee8ab41efb3 ee793d649c9242b39fa89ee8ab41efb3--528042fd44f14423873ab318de081f5f 60d897e131e0414f8c34fa38b1b42ef6 f9ca023f9b254ad2b9d3e7fbaebdd8c9 RX(asin(phi)) d383ad75ea5a4fb6833f89e57713acff--f9ca023f9b254ad2b9d3e7fbaebdd8c9 434dc626eec24e07b96bd15555bd7a0e RX(phi**2 + asin(phi)) f9ca023f9b254ad2b9d3e7fbaebdd8c9--434dc626eec24e07b96bd15555bd7a0e 434dc626eec24e07b96bd15555bd7a0e--60d897e131e0414f8c34fa38b1b42ef6 <p>Furthermore, the <code>reupload_scaling</code> argument can be used to change the scaling applied to each qubit in the support of the feature map. The default scalings can be chosen from the <code>ReuploadScaling</code> enumeration.</p> <pre><code>from qadence import ReuploadScaling\nfrom qadence.draw import display\n\nn_qubits = 5\n\n# Default constant value\nfm_constant = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT)\n\n# Linearly increasing scaling\nfm_tower = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.TOWER)\n\n# Exponentially increasing scaling\nfm_exp = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.EXP)\n\nblock = chain(fm_constant, fm_tower, fm_exp)\n</code></pre> %3 cluster_69dcc7aee35d48cbb7047a27fbad1fd6 Exponential Fourier FM cluster_b34926d454f04e83893529d1f25bfadf Constant Fourier FM cluster_beabc8102d0449158d57deb301f8f2d3 Tower Fourier FM b48003e62ded4a8283a502c7b7cc6a4d 0 cb90370f1ca447b39a1615fe3396244f RX(phi) b48003e62ded4a8283a502c7b7cc6a4d--cb90370f1ca447b39a1615fe3396244f e131f4293f9d453a93c51a8b997cc174 1 022e43810d7e40d3a10415dec1faa860 RX(1.0*phi) cb90370f1ca447b39a1615fe3396244f--022e43810d7e40d3a10415dec1faa860 a96d015dd839486eb237f35819eecba2 RX(1.0*phi) 022e43810d7e40d3a10415dec1faa860--a96d015dd839486eb237f35819eecba2 9432bbb36f3d49c5b9c0b9cd1f73e7f2 a96d015dd839486eb237f35819eecba2--9432bbb36f3d49c5b9c0b9cd1f73e7f2 14ce147a089a4a28804b74b5a2abd6bb 8348fec00d4a4533b41ebe7b9831e562 RX(phi) e131f4293f9d453a93c51a8b997cc174--8348fec00d4a4533b41ebe7b9831e562 08dccbb305c840f387294342a6d29948 2 c75ad15ab1454663a085207e4582c102 RX(2.0*phi) 8348fec00d4a4533b41ebe7b9831e562--c75ad15ab1454663a085207e4582c102 c9f367a9220b4cbbad7f7b334e9109db RX(2.0*phi) c75ad15ab1454663a085207e4582c102--c9f367a9220b4cbbad7f7b334e9109db c9f367a9220b4cbbad7f7b334e9109db--14ce147a089a4a28804b74b5a2abd6bb c8e17873bc694a279c9c2f6240e21ac4 0ed1053c92e34f1a82ac72919f7d10aa RX(phi) 08dccbb305c840f387294342a6d29948--0ed1053c92e34f1a82ac72919f7d10aa 40d2e122da2148468d458b7a1e88cc52 3 039cfb109adb48afa305c58369fbcc9a RX(3.0*phi) 0ed1053c92e34f1a82ac72919f7d10aa--039cfb109adb48afa305c58369fbcc9a a8cb76157d8841f587a1c593e1f7889c RX(4.0*phi) 039cfb109adb48afa305c58369fbcc9a--a8cb76157d8841f587a1c593e1f7889c a8cb76157d8841f587a1c593e1f7889c--c8e17873bc694a279c9c2f6240e21ac4 671a4074508443769ba80231e14534de e3fef88603da42bba8dc04dce79f1dc3 RX(phi) 40d2e122da2148468d458b7a1e88cc52--e3fef88603da42bba8dc04dce79f1dc3 8386b3c6ab474c86b0c8058d79e407d1 4 54aac8414f8546178b50e1553326fee2 RX(4.0*phi) e3fef88603da42bba8dc04dce79f1dc3--54aac8414f8546178b50e1553326fee2 2f40e88297894510b6f75780277e812c RX(8.0*phi) 54aac8414f8546178b50e1553326fee2--2f40e88297894510b6f75780277e812c 2f40e88297894510b6f75780277e812c--671a4074508443769ba80231e14534de 757b0ae4777549208f17e4b1668c9bfd 5a8fd4416c6a4fad9cf5a1d463e074c5 RX(phi) 8386b3c6ab474c86b0c8058d79e407d1--5a8fd4416c6a4fad9cf5a1d463e074c5 0311ae715f574ccea9adc3ccf0c8dced RX(5.0*phi) 5a8fd4416c6a4fad9cf5a1d463e074c5--0311ae715f574ccea9adc3ccf0c8dced cddf4c4243cc49d784aa6af5cad49f9a RX(16.0*phi) 0311ae715f574ccea9adc3ccf0c8dced--cddf4c4243cc49d784aa6af5cad49f9a cddf4c4243cc49d784aa6af5cad49f9a--757b0ae4777549208f17e4b1668c9bfd <p>A custom scaling can also be defined with a function with an <code>int</code> input and <code>int</code> or <code>float</code> output.</p> <pre><code>n_qubits = 5\n\ndef custom_scaling(i: int) -&gt; int | float:\n    \"\"\"Sqrt(i+1)\"\"\"\n    return (i+1) ** (0.5)\n\n# Custom scaling function\nfm_custom = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV, reupload_scaling=custom_scaling)\n</code></pre> %3 91637b41462a43bfaa1064e71d140d4a 0 770b517435e849368b39ed345a64e7d1 RX(1.0*acos(phi)) 91637b41462a43bfaa1064e71d140d4a--770b517435e849368b39ed345a64e7d1 44975b0f983349d8828ec38cd0340ec5 1 e125c1261a4a4b2eb693d60fbf3d6270 770b517435e849368b39ed345a64e7d1--e125c1261a4a4b2eb693d60fbf3d6270 2865eaea8f0d4b57b3d6037ba6a3976e 3ef929a3a89e4773abb4c973e4f25663 RX(1.414*acos(phi)) 44975b0f983349d8828ec38cd0340ec5--3ef929a3a89e4773abb4c973e4f25663 6c3962df93c34a3fbb3364d6acc0eeb9 2 3ef929a3a89e4773abb4c973e4f25663--2865eaea8f0d4b57b3d6037ba6a3976e e9ed116beb8f4778a91880dd393aadd7 d440b50dc1174c4abaddde11ba33db5e RX(1.732*acos(phi)) 6c3962df93c34a3fbb3364d6acc0eeb9--d440b50dc1174c4abaddde11ba33db5e e0b9d11c01a34bb7883ca2a2c3c5331e 3 d440b50dc1174c4abaddde11ba33db5e--e9ed116beb8f4778a91880dd393aadd7 3667d3d78f5c4d298beb1171a2ba8eaf 28585997bb5a4b83b783bfb050588127 RX(2.0*acos(phi)) e0b9d11c01a34bb7883ca2a2c3c5331e--28585997bb5a4b83b783bfb050588127 230e3bd8ca814d2599929887d0e6a989 4 28585997bb5a4b83b783bfb050588127--3667d3d78f5c4d298beb1171a2ba8eaf 6318feb1aef74e629edc0a5eb0e8b2e0 ac578538ab704fcf9ff4a0a28f88c120 RX(2.236*acos(phi)) 230e3bd8ca814d2599929887d0e6a989--ac578538ab704fcf9ff4a0a28f88c120 ac578538ab704fcf9ff4a0a28f88c120--6318feb1aef74e629edc0a5eb0e8b2e0 <p>To add a trainable parameter that multiplies the feature parameter inside the encoding function, simply pass a <code>param_prefix</code> string:</p> <pre><code>n_qubits = 5\n\nfm_trainable = feature_map(\n    n_qubits,\n    fm_type=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.EXP,\n    param_prefix = \"w\",\n)\n</code></pre> %3 afa2c0b762ad4cc585ca1e2f4de55b9d 0 4a733435aa7240cb9868b7e1da0249f9 RX(1.0*phi*w\u2080) afa2c0b762ad4cc585ca1e2f4de55b9d--4a733435aa7240cb9868b7e1da0249f9 0f29b141ba8e4cdcaf34aae8feba5f75 1 d4e2a8a8a8074d26930021c09fcdd1d4 4a733435aa7240cb9868b7e1da0249f9--d4e2a8a8a8074d26930021c09fcdd1d4 50856e92672545138cc8993fdd77609e d635883dca094e9693d558618a06212d RX(2.0*phi*w\u2081) 0f29b141ba8e4cdcaf34aae8feba5f75--d635883dca094e9693d558618a06212d 613c8f013a5943e7b89619735568dac4 2 d635883dca094e9693d558618a06212d--50856e92672545138cc8993fdd77609e a308ff00ad7843b08a67ad9c853930e7 c169502a917047ffb29758f65b1b4667 RX(4.0*phi*w\u2082) 613c8f013a5943e7b89619735568dac4--c169502a917047ffb29758f65b1b4667 b2af88e47e5e44acbbdb6fe17b971530 3 c169502a917047ffb29758f65b1b4667--a308ff00ad7843b08a67ad9c853930e7 e9ac1c6e966149f5b457e056bba58cf5 4a14a8c1e7b1447fbda5fd7eb2eba5bb RX(8.0*phi*w\u2083) b2af88e47e5e44acbbdb6fe17b971530--4a14a8c1e7b1447fbda5fd7eb2eba5bb eed4f7fcd3cf4c1487d9364a58c2437f 4 4a14a8c1e7b1447fbda5fd7eb2eba5bb--e9ac1c6e966149f5b457e056bba58cf5 23aa9a39cae7498abdc4e86b68d3883f 9c0989a30cea4da89957d168e19d1a1a RX(16.0*phi*w\u2084) eed4f7fcd3cf4c1487d9364a58c2437f--9c0989a30cea4da89957d168e19d1a1a 9c0989a30cea4da89957d168e19d1a1a--23aa9a39cae7498abdc4e86b68d3883f <p>Note that for the Fourier feature map, the encoding function is simply \\(f(x)=x\\). For other cases, like the Chebyshev <code>acos()</code> encoding, the trainable parameter may cause the feature value to be outside the domain of the encoding function. This will eventually be fixed by adding range constraints to trainable parameters in Qadence.</p> <p>A full description of the remaining arguments can be found in the <code>feature_map</code> API reference. We provide an example below.</p> <pre><code>from qadence import RY\n\nn_qubits = 5\n\n# Custom scaling function\nfm_full = feature_map(\n    n_qubits = n_qubits,\n    support = tuple(reversed(range(n_qubits))), # Reverse the qubit support to run the scaling from bottom to top\n    param = \"x\", # Change the name of the parameter\n    op = RY, # Change the rotation gate between RX, RY, RZ or PHASE\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.EXP,\n    feature_range = (-1.0, 2.0), # Range from which the input data comes from\n    target_range = (1.0, 3.0), # Range the encoder assumes as the natural range\n    multiplier = 5.0, # Extra multiplier, which can also be a Parameter\n    param_prefix = \"w\", # Add trainable parameters\n)\n</code></pre> %3 1eb5c844ed1f4f409c196d5857143f10 0 ca82320a41a04e9388a7b1ece5a60b22 RY(80.0*acos(w\u2084*(0.667*x + 1.667))) 1eb5c844ed1f4f409c196d5857143f10--ca82320a41a04e9388a7b1ece5a60b22 949098f8b44946fca0e6ad48e8bbbbea 1 85d4d4ae46974a2badce33833ae173bb ca82320a41a04e9388a7b1ece5a60b22--85d4d4ae46974a2badce33833ae173bb baa46a87a8164ff69db62f7eeb10d873 8fb82491c44f4d62ad50be637c437474 RY(40.0*acos(w\u2083*(0.667*x + 1.667))) 949098f8b44946fca0e6ad48e8bbbbea--8fb82491c44f4d62ad50be637c437474 87c05ba7bcc84b6bacffe1ebf3161423 2 8fb82491c44f4d62ad50be637c437474--baa46a87a8164ff69db62f7eeb10d873 ba1efe46360c4746ab4debba5df71171 f6e05f55e1f14266ba8a4a5d71656b87 RY(20.0*acos(w\u2082*(0.667*x + 1.667))) 87c05ba7bcc84b6bacffe1ebf3161423--f6e05f55e1f14266ba8a4a5d71656b87 93a97f0207554b2d85a30fad76dfd299 3 f6e05f55e1f14266ba8a4a5d71656b87--ba1efe46360c4746ab4debba5df71171 68e1bdcb52cc49af9f7ac7456725345e 23ebf90c75b7431586eac753295a18a9 RY(10.0*acos(w\u2081*(0.667*x + 1.667))) 93a97f0207554b2d85a30fad76dfd299--23ebf90c75b7431586eac753295a18a9 86c6cd658195459597c9dce3a11d282c 4 23ebf90c75b7431586eac753295a18a9--68e1bdcb52cc49af9f7ac7456725345e a7634264a1ca4f1f83e76920583afb96 883c2f4878d04d379c5211911223fedb RY(5.0*acos(w\u2080*(0.667*x + 1.667))) 86c6cd658195459597c9dce3a11d282c--883c2f4878d04d379c5211911223fedb 883c2f4878d04d379c5211911223fedb--a7634264a1ca4f1f83e76920583afb96"},{"location":"content/qml_constructors/#hardware-efficient-ansatz","title":"Hardware-efficient ansatz","text":"<p>Ansatze blocks for quantum machine-learning are typically built following the Hardware-Efficient Ansatz formalism (HEA). Both fully digital and digital-analog HEAs can easily be built with the <code>hea</code> function. By default, the digital version is returned:</p> <pre><code>from qadence import hea\nfrom qadence.draw import display\n\nn_qubits = 3\ndepth = 2\n\nansatz = hea(n_qubits, depth)\n</code></pre> %3 50476719b9bc4460bc95e0f5405f7c7b 0 05ebdf4394b34ebcb462ac2455e1880a RX(theta\u2080) 50476719b9bc4460bc95e0f5405f7c7b--05ebdf4394b34ebcb462ac2455e1880a 2a812a8ebfc44066aea438775c2fdb3d 1 8cea17b5ebfe481ebd7ab9490097b6f1 RY(theta\u2083) 05ebdf4394b34ebcb462ac2455e1880a--8cea17b5ebfe481ebd7ab9490097b6f1 ca458c2c556d459bb28a7c938947e301 RX(theta\u2086) 8cea17b5ebfe481ebd7ab9490097b6f1--ca458c2c556d459bb28a7c938947e301 18a12bed611548fc82b8a5fc6426cc47 ca458c2c556d459bb28a7c938947e301--18a12bed611548fc82b8a5fc6426cc47 71d04c56b1c2437584df141bf526da47 18a12bed611548fc82b8a5fc6426cc47--71d04c56b1c2437584df141bf526da47 62709b77682b42eb92b1d03ffbcfc5e6 RX(theta\u2089) 71d04c56b1c2437584df141bf526da47--62709b77682b42eb92b1d03ffbcfc5e6 23a673b8006f4f1e9c7b9db3ed289dd2 RY(theta\u2081\u2082) 62709b77682b42eb92b1d03ffbcfc5e6--23a673b8006f4f1e9c7b9db3ed289dd2 0a538fdf9c4646198333d8601174d687 RX(theta\u2081\u2085) 23a673b8006f4f1e9c7b9db3ed289dd2--0a538fdf9c4646198333d8601174d687 ea3b9aebade84581908627eb8ca460fe 0a538fdf9c4646198333d8601174d687--ea3b9aebade84581908627eb8ca460fe 63b44a6d752241b0817d89edbfc74584 ea3b9aebade84581908627eb8ca460fe--63b44a6d752241b0817d89edbfc74584 5b5c8e71616b4e05ae86abf22d5a0726 63b44a6d752241b0817d89edbfc74584--5b5c8e71616b4e05ae86abf22d5a0726 dd5649c6be8244528a6ce88bff548734 74092972a23740098836176ae367b248 RX(theta\u2081) 2a812a8ebfc44066aea438775c2fdb3d--74092972a23740098836176ae367b248 57d9dc4781fb4de6b1e5dd0d687a8b78 2 0eb16cff87954c55b5b683d920d133f9 RY(theta\u2084) 74092972a23740098836176ae367b248--0eb16cff87954c55b5b683d920d133f9 b5ad4505629049c7a944cb793721e281 RX(theta\u2087) 0eb16cff87954c55b5b683d920d133f9--b5ad4505629049c7a944cb793721e281 5812fb97300849edac8b09258395254e X b5ad4505629049c7a944cb793721e281--5812fb97300849edac8b09258395254e 5812fb97300849edac8b09258395254e--18a12bed611548fc82b8a5fc6426cc47 72966174c47d401eaea697fd22ab8b19 5812fb97300849edac8b09258395254e--72966174c47d401eaea697fd22ab8b19 c300245be64a4ce2ac41328f7bef3a4c RX(theta\u2081\u2080) 72966174c47d401eaea697fd22ab8b19--c300245be64a4ce2ac41328f7bef3a4c 31b9510f6e054d878a5d49c83e7aee3b RY(theta\u2081\u2083) c300245be64a4ce2ac41328f7bef3a4c--31b9510f6e054d878a5d49c83e7aee3b 804c33010889467683308474faea978d RX(theta\u2081\u2086) 31b9510f6e054d878a5d49c83e7aee3b--804c33010889467683308474faea978d 5afbdeff020b4620b9af1a438a746974 X 804c33010889467683308474faea978d--5afbdeff020b4620b9af1a438a746974 5afbdeff020b4620b9af1a438a746974--ea3b9aebade84581908627eb8ca460fe 27d8749a94b74a338a954653062510cf 5afbdeff020b4620b9af1a438a746974--27d8749a94b74a338a954653062510cf 27d8749a94b74a338a954653062510cf--dd5649c6be8244528a6ce88bff548734 fa931ecbe36d4b9e9f6e3994fab9f3ed 73f852532fe846a4b11e0e8ed6e6558d RX(theta\u2082) 57d9dc4781fb4de6b1e5dd0d687a8b78--73f852532fe846a4b11e0e8ed6e6558d abf42bb0fec9491dbc26a6b28106d84c RY(theta\u2085) 73f852532fe846a4b11e0e8ed6e6558d--abf42bb0fec9491dbc26a6b28106d84c 3060af5f295c48459007349af4dcfe3b RX(theta\u2088) abf42bb0fec9491dbc26a6b28106d84c--3060af5f295c48459007349af4dcfe3b 1962b4a1ff5e471e90668d779fac708c 3060af5f295c48459007349af4dcfe3b--1962b4a1ff5e471e90668d779fac708c 0b475dc7f550482bb2964b9ea17210b1 X 1962b4a1ff5e471e90668d779fac708c--0b475dc7f550482bb2964b9ea17210b1 0b475dc7f550482bb2964b9ea17210b1--72966174c47d401eaea697fd22ab8b19 3484c7a89f63459fa3c4df0750b470c9 RX(theta\u2081\u2081) 0b475dc7f550482bb2964b9ea17210b1--3484c7a89f63459fa3c4df0750b470c9 083a1cd76c6943519b798f05ec59086e RY(theta\u2081\u2084) 3484c7a89f63459fa3c4df0750b470c9--083a1cd76c6943519b798f05ec59086e b280b689333a418b96b7c80b1be981af RX(theta\u2081\u2087) 083a1cd76c6943519b798f05ec59086e--b280b689333a418b96b7c80b1be981af ba14966bcb9447598a668db28f14349a b280b689333a418b96b7c80b1be981af--ba14966bcb9447598a668db28f14349a 4373d0d46ead498bb3efe27db2c3ae05 X ba14966bcb9447598a668db28f14349a--4373d0d46ead498bb3efe27db2c3ae05 4373d0d46ead498bb3efe27db2c3ae05--27d8749a94b74a338a954653062510cf 4373d0d46ead498bb3efe27db2c3ae05--fa931ecbe36d4b9e9f6e3994fab9f3ed <p>As seen above, the rotation layers are automatically parameterized, and the prefix <code>\"theta\"</code> can be changed with the <code>param_prefix</code> argument.</p> <p>Furthermore, both the single-qubit rotations and the two-qubit entangler can be customized with the <code>operations</code> and <code>entangler</code> argument. The operations can be passed as a list of single-qubit rotations, while the entangler should be either <code>CNOT</code>, <code>CZ</code>, <code>CRX</code>, <code>CRY</code>, <code>CRZ</code> or <code>CPHASE</code>.</p> <pre><code>from qadence import RX, RY, CPHASE\n\nansatz = hea(\n    n_qubits=n_qubits,\n    depth=depth,\n    param_prefix=\"phi\",\n    operations=[RX, RY, RX],\n    entangler=CPHASE\n)\n</code></pre> %3 79f3c0ccaa78442d8c52873faa110c8d 0 329e8e8705a44a6a9240d16eaad0ca02 RX(phi\u2080) 79f3c0ccaa78442d8c52873faa110c8d--329e8e8705a44a6a9240d16eaad0ca02 35a97c0ed2ee4291b6dd2e2fa3ec8422 1 499655cf234d47ada6f5c88d2583ce1a RY(phi\u2083) 329e8e8705a44a6a9240d16eaad0ca02--499655cf234d47ada6f5c88d2583ce1a 9983cf61501a46c480dfe217a123e2da RX(phi\u2086) 499655cf234d47ada6f5c88d2583ce1a--9983cf61501a46c480dfe217a123e2da a04b311666a444a5928fe271dca37ab3 9983cf61501a46c480dfe217a123e2da--a04b311666a444a5928fe271dca37ab3 b40e20b58a7a41e4966c051356743081 a04b311666a444a5928fe271dca37ab3--b40e20b58a7a41e4966c051356743081 2fa42d424a10411aad0792fd065c3145 RX(phi\u2089) b40e20b58a7a41e4966c051356743081--2fa42d424a10411aad0792fd065c3145 dc8af393bc9647bc817e0f88848b0e41 RY(phi\u2081\u2082) 2fa42d424a10411aad0792fd065c3145--dc8af393bc9647bc817e0f88848b0e41 196ddab0d5084df1b746280f10ffb7b6 RX(phi\u2081\u2085) dc8af393bc9647bc817e0f88848b0e41--196ddab0d5084df1b746280f10ffb7b6 8506109226724275b2c44963872e4df4 196ddab0d5084df1b746280f10ffb7b6--8506109226724275b2c44963872e4df4 138099aec7b04af9b040d7b7f9598d4c 8506109226724275b2c44963872e4df4--138099aec7b04af9b040d7b7f9598d4c 256d337613cc4d1fa701ee596a742fc9 138099aec7b04af9b040d7b7f9598d4c--256d337613cc4d1fa701ee596a742fc9 234115a5ee214167a98cdb18d4576763 3f8951d025004dc7afe589debe0fb0f1 RX(phi\u2081) 35a97c0ed2ee4291b6dd2e2fa3ec8422--3f8951d025004dc7afe589debe0fb0f1 12319a0416b34c6ebfd9d2d0831f3203 2 8a2be3d184c04708a4cb666ee5819ad0 RY(phi\u2084) 3f8951d025004dc7afe589debe0fb0f1--8a2be3d184c04708a4cb666ee5819ad0 d065b289672d4749960d25e68bb1c8bc RX(phi\u2087) 8a2be3d184c04708a4cb666ee5819ad0--d065b289672d4749960d25e68bb1c8bc 6f0cfe004a384d8d8f154a8cee93f5fd PHASE(phi_ent\u2080) d065b289672d4749960d25e68bb1c8bc--6f0cfe004a384d8d8f154a8cee93f5fd 6f0cfe004a384d8d8f154a8cee93f5fd--a04b311666a444a5928fe271dca37ab3 9d92d7c2744a4a498a06827f5f4ac4db 6f0cfe004a384d8d8f154a8cee93f5fd--9d92d7c2744a4a498a06827f5f4ac4db 244550c304714f0cb24c184479c0864d RX(phi\u2081\u2080) 9d92d7c2744a4a498a06827f5f4ac4db--244550c304714f0cb24c184479c0864d 0e32bbfee38242b690fc962a42d6bbd7 RY(phi\u2081\u2083) 244550c304714f0cb24c184479c0864d--0e32bbfee38242b690fc962a42d6bbd7 0b0d0b68b01d4124b8301889b854b7c5 RX(phi\u2081\u2086) 0e32bbfee38242b690fc962a42d6bbd7--0b0d0b68b01d4124b8301889b854b7c5 90203bfaa154402b8632a78856075fe6 PHASE(phi_ent\u2082) 0b0d0b68b01d4124b8301889b854b7c5--90203bfaa154402b8632a78856075fe6 90203bfaa154402b8632a78856075fe6--8506109226724275b2c44963872e4df4 c6db30a9132d4dc08ff850607a8eaf02 90203bfaa154402b8632a78856075fe6--c6db30a9132d4dc08ff850607a8eaf02 c6db30a9132d4dc08ff850607a8eaf02--234115a5ee214167a98cdb18d4576763 c88b366dd0d74f2db7b079d91403f717 34cf9678340c4789a67eb65f9ed6d58f RX(phi\u2082) 12319a0416b34c6ebfd9d2d0831f3203--34cf9678340c4789a67eb65f9ed6d58f e907395dc53e4854a89ab65678bdbeec RY(phi\u2085) 34cf9678340c4789a67eb65f9ed6d58f--e907395dc53e4854a89ab65678bdbeec e0feec8912e34aab94855091cec98ff2 RX(phi\u2088) e907395dc53e4854a89ab65678bdbeec--e0feec8912e34aab94855091cec98ff2 084a7b518bae41e3aa4ef6fdbb6eebd4 e0feec8912e34aab94855091cec98ff2--084a7b518bae41e3aa4ef6fdbb6eebd4 e0b8744765074e9f883c954340fd8782 PHASE(phi_ent\u2081) 084a7b518bae41e3aa4ef6fdbb6eebd4--e0b8744765074e9f883c954340fd8782 e0b8744765074e9f883c954340fd8782--9d92d7c2744a4a498a06827f5f4ac4db 36ba9f3c024b4f029c07f6d71ddcc15f RX(phi\u2081\u2081) e0b8744765074e9f883c954340fd8782--36ba9f3c024b4f029c07f6d71ddcc15f 6ed0eccc27684934ac31979e437ed052 RY(phi\u2081\u2084) 36ba9f3c024b4f029c07f6d71ddcc15f--6ed0eccc27684934ac31979e437ed052 af5fc6e2873946839bc66b398d820386 RX(phi\u2081\u2087) 6ed0eccc27684934ac31979e437ed052--af5fc6e2873946839bc66b398d820386 b121b01673bf47d7a1f7734cf6d0fd1d af5fc6e2873946839bc66b398d820386--b121b01673bf47d7a1f7734cf6d0fd1d 07e1a8aa64cc413ea3fda1ad7ff030a9 PHASE(phi_ent\u2083) b121b01673bf47d7a1f7734cf6d0fd1d--07e1a8aa64cc413ea3fda1ad7ff030a9 07e1a8aa64cc413ea3fda1ad7ff030a9--c6db30a9132d4dc08ff850607a8eaf02 07e1a8aa64cc413ea3fda1ad7ff030a9--c88b366dd0d74f2db7b079d91403f717 <p>Having a truly hardware-efficient ansatz means that the entangling operation can be chosen according to each device's native interactions. Besides digital operations, in Qadence it is also possible to build digital-analog HEAs with the entanglement produced by the natural evolution of a set of interacting qubits, as natively implemented in neutral atom devices. As with other digital-analog functions, this can be controlled with the <code>strategy</code> argument which can be chosen from the <code>Strategy</code> enum type. Currently, only <code>Strategy.DIGITAL</code> and <code>Strategy.SDAQC</code> are available. By default, calling <code>strategy = Strategy.SDAQC</code> will use a global entangling Hamiltonian with Ising-like \\(NN\\) interactions and constant interaction strength,</p> <pre><code>from qadence import Strategy\n\nansatz = hea(\n    n_qubits,\n    depth=depth,\n    strategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_4dfba951b85d4a18943ca3321531ad15 cluster_afe23695d9e64f5086bf98e4d86a2991 58667e61d92742a79a783cab6a223113 0 8aa61308400b48e29bb41679b396f7b4 RX(theta\u2080) 58667e61d92742a79a783cab6a223113--8aa61308400b48e29bb41679b396f7b4 0211bd5d82db45fe97033b8831063861 1 d30e820677c845f6ac47ac1cbd153b68 RY(theta\u2083) 8aa61308400b48e29bb41679b396f7b4--d30e820677c845f6ac47ac1cbd153b68 ad54ad089b1c4499a6ef55ebc2d33123 RX(theta\u2086) d30e820677c845f6ac47ac1cbd153b68--ad54ad089b1c4499a6ef55ebc2d33123 ecd336e495d94c07b403407364b2f324 HamEvo ad54ad089b1c4499a6ef55ebc2d33123--ecd336e495d94c07b403407364b2f324 76adc4e307e64de08b411112ade50a53 RX(theta\u2089) ecd336e495d94c07b403407364b2f324--76adc4e307e64de08b411112ade50a53 2366e23dddc34f94b174e8952a4a064b RY(theta\u2081\u2082) 76adc4e307e64de08b411112ade50a53--2366e23dddc34f94b174e8952a4a064b daa77e1ad9444d81a90790f053b7e218 RX(theta\u2081\u2085) 2366e23dddc34f94b174e8952a4a064b--daa77e1ad9444d81a90790f053b7e218 62ef348fc850407e9d3b709ca7bbdab8 HamEvo daa77e1ad9444d81a90790f053b7e218--62ef348fc850407e9d3b709ca7bbdab8 3ce88939aef24446997152fb6412d177 62ef348fc850407e9d3b709ca7bbdab8--3ce88939aef24446997152fb6412d177 510d5aa1ded140499b4766acd09fcc12 0bcce0b786584a3281f87f087e630add RX(theta\u2081) 0211bd5d82db45fe97033b8831063861--0bcce0b786584a3281f87f087e630add 2f74d2cfb8b248808a13899c286fbec2 2 3f1cae81d4a84e40ae4629fa2462dec5 RY(theta\u2084) 0bcce0b786584a3281f87f087e630add--3f1cae81d4a84e40ae4629fa2462dec5 bff5d240719a4f24b2c9239611723853 RX(theta\u2087) 3f1cae81d4a84e40ae4629fa2462dec5--bff5d240719a4f24b2c9239611723853 985841c51a4c4318b4aff7b2fd6d262a t = theta_t\u2080 bff5d240719a4f24b2c9239611723853--985841c51a4c4318b4aff7b2fd6d262a 41356851f35f4da4bdc73588b131f0b3 RX(theta\u2081\u2080) 985841c51a4c4318b4aff7b2fd6d262a--41356851f35f4da4bdc73588b131f0b3 983a9fa3e4c540bca06638f29c94941f RY(theta\u2081\u2083) 41356851f35f4da4bdc73588b131f0b3--983a9fa3e4c540bca06638f29c94941f 64d9312b41554c9a9870af9e901f7ab1 RX(theta\u2081\u2086) 983a9fa3e4c540bca06638f29c94941f--64d9312b41554c9a9870af9e901f7ab1 ca307dbb98244f52a873e4c65391317e t = theta_t\u2081 64d9312b41554c9a9870af9e901f7ab1--ca307dbb98244f52a873e4c65391317e ca307dbb98244f52a873e4c65391317e--510d5aa1ded140499b4766acd09fcc12 1c7a680987d64092ba91af5c3b2fc2dc aacffe7527cb4f378214e0f8f2a1bf67 RX(theta\u2082) 2f74d2cfb8b248808a13899c286fbec2--aacffe7527cb4f378214e0f8f2a1bf67 32ecfb8ecc80418a8c31495af201dd09 RY(theta\u2085) aacffe7527cb4f378214e0f8f2a1bf67--32ecfb8ecc80418a8c31495af201dd09 1512c1ee3a114f6ca6ce1f0520c65d3f RX(theta\u2088) 32ecfb8ecc80418a8c31495af201dd09--1512c1ee3a114f6ca6ce1f0520c65d3f 3c4883cd5cdc448a829aa2d6118d2243 1512c1ee3a114f6ca6ce1f0520c65d3f--3c4883cd5cdc448a829aa2d6118d2243 cc41a9593ef347209c0f8c2cc90619c3 RX(theta\u2081\u2081) 3c4883cd5cdc448a829aa2d6118d2243--cc41a9593ef347209c0f8c2cc90619c3 7e6daf9f97d84d20830a861d41e959d6 RY(theta\u2081\u2084) cc41a9593ef347209c0f8c2cc90619c3--7e6daf9f97d84d20830a861d41e959d6 1c6677702521457a90904e060a088a50 RX(theta\u2081\u2087) 7e6daf9f97d84d20830a861d41e959d6--1c6677702521457a90904e060a088a50 0f8109a022824b1eb17fea229f75f2aa 1c6677702521457a90904e060a088a50--0f8109a022824b1eb17fea229f75f2aa 0f8109a022824b1eb17fea229f75f2aa--1c7a680987d64092ba91af5c3b2fc2dc <p>Note that, by default, only the time-parameter is automatically parameterized when building a digital-analog HEA. However, as described in the Hamiltonians tutorial, arbitrary interaction Hamiltonians can be easily built with the <code>hamiltonian_factory</code> function, with both customized or fully parameterized interactions, and these can be directly passed as the <code>entangler</code> for a customizable digital-analog HEA.</p> <pre><code>from qadence import hamiltonian_factory, Interaction, N, Register, hea\n\n# Build a parameterized neutral-atom Hamiltonian following a honeycomb_lattice:\nregister = Register.honeycomb_lattice(1, 1)\n\nentangler = hamiltonian_factory(\n    register,\n    interaction=Interaction.NN,\n    detuning=N,\n    interaction_strength=\"e\",\n    detuning_strength=\"n\"\n)\n\n# Build a fully parameterized Digital-Analog HEA:\nn_qubits = register.n_qubits\ndepth = 2\n\nansatz = hea(\n    n_qubits=register.n_qubits,\n    depth=depth,\n    operations=[RX, RY, RX],\n    entangler=entangler,\n    strategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_885b0ee8ecee44a79e7c850e511b831a cluster_5069aacf79224211a00703e5e1b95cdb 0377128be36a4d74bee160dc5f9e60ce 0 37344accd4ab436bb08ea398608decb1 RX(theta\u2080) 0377128be36a4d74bee160dc5f9e60ce--37344accd4ab436bb08ea398608decb1 d15c241d34524aecb7dddf581997c9de 1 31d40b6444b54b49829ab0d4e90a6308 RY(theta\u2086) 37344accd4ab436bb08ea398608decb1--31d40b6444b54b49829ab0d4e90a6308 7a19d1a7bbed4485879ad72fd3862d50 RX(theta\u2081\u2082) 31d40b6444b54b49829ab0d4e90a6308--7a19d1a7bbed4485879ad72fd3862d50 62a987bbc40a4782a6553a7a617e302d 7a19d1a7bbed4485879ad72fd3862d50--62a987bbc40a4782a6553a7a617e302d 95192ead56e64941b6da56832d4f3e07 RX(theta\u2081\u2088) 62a987bbc40a4782a6553a7a617e302d--95192ead56e64941b6da56832d4f3e07 007869a661c84a54a0c7bb897d6df1ef RY(theta\u2082\u2084) 95192ead56e64941b6da56832d4f3e07--007869a661c84a54a0c7bb897d6df1ef 9b0b9a2d84874be0afb1913dc98ea3b4 RX(theta\u2083\u2080) 007869a661c84a54a0c7bb897d6df1ef--9b0b9a2d84874be0afb1913dc98ea3b4 0551512be9ac4c44ae0ac3c2bd285f45 9b0b9a2d84874be0afb1913dc98ea3b4--0551512be9ac4c44ae0ac3c2bd285f45 045dcd82f95c4a648dad4359b2e693d2 0551512be9ac4c44ae0ac3c2bd285f45--045dcd82f95c4a648dad4359b2e693d2 b001ef83ae3e40bdb9a7961f1922e613 2e36953d7e6c474eae7022f324cafed3 RX(theta\u2081) d15c241d34524aecb7dddf581997c9de--2e36953d7e6c474eae7022f324cafed3 4ea6c01d72f74dd6b4d0ba36e98bfb05 2 a9e8d175965341439855de25294b9e07 RY(theta\u2087) 2e36953d7e6c474eae7022f324cafed3--a9e8d175965341439855de25294b9e07 f0c4538d400f46ecb66e1123eebd30a0 RX(theta\u2081\u2083) a9e8d175965341439855de25294b9e07--f0c4538d400f46ecb66e1123eebd30a0 679644abf4d1464089a7f9b33d3d5187 f0c4538d400f46ecb66e1123eebd30a0--679644abf4d1464089a7f9b33d3d5187 93a8a7478b824e158f8b40b4208ef0e2 RX(theta\u2081\u2089) 679644abf4d1464089a7f9b33d3d5187--93a8a7478b824e158f8b40b4208ef0e2 b70e7756f7b24d98b9e99f2a938a851a RY(theta\u2082\u2085) 93a8a7478b824e158f8b40b4208ef0e2--b70e7756f7b24d98b9e99f2a938a851a a26a4875308b4e8ba44901f8eca5e0a1 RX(theta\u2083\u2081) b70e7756f7b24d98b9e99f2a938a851a--a26a4875308b4e8ba44901f8eca5e0a1 312a2fb9cd824c0dbe5ad25fd9d30089 a26a4875308b4e8ba44901f8eca5e0a1--312a2fb9cd824c0dbe5ad25fd9d30089 312a2fb9cd824c0dbe5ad25fd9d30089--b001ef83ae3e40bdb9a7961f1922e613 06710c0d334846b3a221aa5a2039b94c d26fcaa336e943e08d4996874cb529a0 RX(theta\u2082) 4ea6c01d72f74dd6b4d0ba36e98bfb05--d26fcaa336e943e08d4996874cb529a0 0d7c174994ef43b9b4dd19c6fe35d6b8 3 82c659c547bf46a59b5e848974f5931b RY(theta\u2088) d26fcaa336e943e08d4996874cb529a0--82c659c547bf46a59b5e848974f5931b 8b5c836b38734af1955469a3ee643bfc RX(theta\u2081\u2084) 82c659c547bf46a59b5e848974f5931b--8b5c836b38734af1955469a3ee643bfc b80a850fc94245608607f7d91b30c388 HamEvo 8b5c836b38734af1955469a3ee643bfc--b80a850fc94245608607f7d91b30c388 a7391082cd964e2dbe2fd722a09f154e RX(theta\u2082\u2080) b80a850fc94245608607f7d91b30c388--a7391082cd964e2dbe2fd722a09f154e 5162943cb43746a0b2536b58b7a3c4be RY(theta\u2082\u2086) a7391082cd964e2dbe2fd722a09f154e--5162943cb43746a0b2536b58b7a3c4be 9632d18f00da4b2e9c530b2a236ed2e3 RX(theta\u2083\u2082) 5162943cb43746a0b2536b58b7a3c4be--9632d18f00da4b2e9c530b2a236ed2e3 66ce33a5b7ab4674a7ec1219bcd007af HamEvo 9632d18f00da4b2e9c530b2a236ed2e3--66ce33a5b7ab4674a7ec1219bcd007af 66ce33a5b7ab4674a7ec1219bcd007af--06710c0d334846b3a221aa5a2039b94c 8359527e19984ee68a2cc57e09a253d3 2aa2dd70270f48798fc25c1e1f161bd5 RX(theta\u2083) 0d7c174994ef43b9b4dd19c6fe35d6b8--2aa2dd70270f48798fc25c1e1f161bd5 ba5783319c32455e92701ea938f18e1f 4 4457774fafea4a79b8cb32bdfc5c4e05 RY(theta\u2089) 2aa2dd70270f48798fc25c1e1f161bd5--4457774fafea4a79b8cb32bdfc5c4e05 b01a1794f18b4861ab3755431cb38d37 RX(theta\u2081\u2085) 4457774fafea4a79b8cb32bdfc5c4e05--b01a1794f18b4861ab3755431cb38d37 052b9e530cc54a698baa4d2622d5d5c7 t = theta_t\u2080 b01a1794f18b4861ab3755431cb38d37--052b9e530cc54a698baa4d2622d5d5c7 ec6f51c22c684195a9d6270c59da8bae RX(theta\u2082\u2081) 052b9e530cc54a698baa4d2622d5d5c7--ec6f51c22c684195a9d6270c59da8bae 52109197ee094d3d8b86965cb16b2f14 RY(theta\u2082\u2087) ec6f51c22c684195a9d6270c59da8bae--52109197ee094d3d8b86965cb16b2f14 9f3d23b7cadb4bcd997f1d0ca85aee3f RX(theta\u2083\u2083) 52109197ee094d3d8b86965cb16b2f14--9f3d23b7cadb4bcd997f1d0ca85aee3f 5adc08e5b68847ac9798673ee462e7a6 t = theta_t\u2081 9f3d23b7cadb4bcd997f1d0ca85aee3f--5adc08e5b68847ac9798673ee462e7a6 5adc08e5b68847ac9798673ee462e7a6--8359527e19984ee68a2cc57e09a253d3 2bd9fb3741bc4095bd333758dbedf3e5 c809d665de1d459882b712405253ac83 RX(theta\u2084) ba5783319c32455e92701ea938f18e1f--c809d665de1d459882b712405253ac83 6ee72a52e35f4d46a175efcbbc2977ef 5 d3addc3c31e24128ae682fb794969435 RY(theta\u2081\u2080) c809d665de1d459882b712405253ac83--d3addc3c31e24128ae682fb794969435 b6fb8814df284c818683c52a097cc2ff RX(theta\u2081\u2086) d3addc3c31e24128ae682fb794969435--b6fb8814df284c818683c52a097cc2ff 3ba59cda1b904b2082d41ccc59713efe b6fb8814df284c818683c52a097cc2ff--3ba59cda1b904b2082d41ccc59713efe 0867ccc3fe5d4af694749002a3815f8d RX(theta\u2082\u2082) 3ba59cda1b904b2082d41ccc59713efe--0867ccc3fe5d4af694749002a3815f8d e9354749c25b448b9dce0154624378ac RY(theta\u2082\u2088) 0867ccc3fe5d4af694749002a3815f8d--e9354749c25b448b9dce0154624378ac e66807378b8c478aabd5ac1e8ca85df5 RX(theta\u2083\u2084) e9354749c25b448b9dce0154624378ac--e66807378b8c478aabd5ac1e8ca85df5 3f33dc1d52cc47f6b24d91a4b119901f e66807378b8c478aabd5ac1e8ca85df5--3f33dc1d52cc47f6b24d91a4b119901f 3f33dc1d52cc47f6b24d91a4b119901f--2bd9fb3741bc4095bd333758dbedf3e5 22803fc9a72c407d92cb07f93ff8f32a 6e25f3f36ac74bc0af0292badc7bac48 RX(theta\u2085) 6ee72a52e35f4d46a175efcbbc2977ef--6e25f3f36ac74bc0af0292badc7bac48 575dc51c2253479c91ab025b44e17d51 RY(theta\u2081\u2081) 6e25f3f36ac74bc0af0292badc7bac48--575dc51c2253479c91ab025b44e17d51 e719b08a580b4685962360125329eb41 RX(theta\u2081\u2087) 575dc51c2253479c91ab025b44e17d51--e719b08a580b4685962360125329eb41 ee853b7f7c004895920c38dd2c488bd4 e719b08a580b4685962360125329eb41--ee853b7f7c004895920c38dd2c488bd4 d8798e94342e4971beff2211d8517cb8 RX(theta\u2082\u2083) ee853b7f7c004895920c38dd2c488bd4--d8798e94342e4971beff2211d8517cb8 c1622658b35e40ddb5c4b0a4ca508099 RY(theta\u2082\u2089) d8798e94342e4971beff2211d8517cb8--c1622658b35e40ddb5c4b0a4ca508099 40433b44c12a48c5ba5ab9e95b9087e5 RX(theta\u2083\u2085) c1622658b35e40ddb5c4b0a4ca508099--40433b44c12a48c5ba5ab9e95b9087e5 f273d98437b947d0a61c9e553f52ca4e 40433b44c12a48c5ba5ab9e95b9087e5--f273d98437b947d0a61c9e553f52ca4e f273d98437b947d0a61c9e553f52ca4e--22803fc9a72c407d92cb07f93ff8f32a"},{"location":"content/qml_constructors/#identity-initialized-ansatz","title":"Identity-initialized ansatz","text":"<p>It is widely known that parametrized quantum circuits are characterized by barren plateaus, where the gradient becomes exponentially small in the number of qubits. Here we include one of many techniques that have been proposed in recent years to mitigate this effect and facilitate <code>QNN</code>s training: Grant et al. showed that initializing the weights of a <code>QNN</code> so that each block of the circuit evaluates to identity reduces the effect of barren plateaus in the initial stage of training. In a similar fashion to <code>hea</code>, such circuit can be created via calling the associated function, <code>identity_initialized_ansatz</code>:</p> <pre><code>from qadence.constructors import identity_initialized_ansatz\nfrom qadence.draw import display\n\nn_qubits = 3\ndepth = 2\n\nansatz = identity_initialized_ansatz(n_qubits, depth)\n</code></pre> %3 cluster_fb46eaf4bbfc496fb2548091240ed02d BPMA-1 cluster_8b0e6d89b390401382d0bbe416f5e7a8 BPMA-0 ec28785fdd7e4c56b6678506768fcc42 0 5968fb4f883f45ed86b1ce148196d472 RX(iia_\u03b1\u2080\u2080) ec28785fdd7e4c56b6678506768fcc42--5968fb4f883f45ed86b1ce148196d472 267840f413bd4dbb8cb6460cd1286892 1 7f56e31d5c734a02ba439b5e2144562f RY(iia_\u03b1\u2080\u2083) 5968fb4f883f45ed86b1ce148196d472--7f56e31d5c734a02ba439b5e2144562f 4a9a75338590496b9d2837d9b3c69de2 7f56e31d5c734a02ba439b5e2144562f--4a9a75338590496b9d2837d9b3c69de2 ea34f77f91c14db5859299e5c0a0328f 4a9a75338590496b9d2837d9b3c69de2--ea34f77f91c14db5859299e5c0a0328f 3194b2fad9a342d19936a1a2197a77c0 RX(iia_\u03b3\u2080\u2080) ea34f77f91c14db5859299e5c0a0328f--3194b2fad9a342d19936a1a2197a77c0 96d7097979204986a01cf6ee9b114bcf 3194b2fad9a342d19936a1a2197a77c0--96d7097979204986a01cf6ee9b114bcf f4c66d2e1fef44b7ab4019c4e0b807cd 96d7097979204986a01cf6ee9b114bcf--f4c66d2e1fef44b7ab4019c4e0b807cd 521d97bdb2b14b87be27fcf1e9b8cb6e RY(iia_\u03b2\u2080\u2083) f4c66d2e1fef44b7ab4019c4e0b807cd--521d97bdb2b14b87be27fcf1e9b8cb6e 094db9746a98424e9a1beeb26fe99efa RX(iia_\u03b2\u2080\u2080) 521d97bdb2b14b87be27fcf1e9b8cb6e--094db9746a98424e9a1beeb26fe99efa 39bfb947196a4c9e9e5c023f358122c6 RX(iia_\u03b1\u2081\u2080) 094db9746a98424e9a1beeb26fe99efa--39bfb947196a4c9e9e5c023f358122c6 d983b33dbd6347929f529d5ff1dca490 RY(iia_\u03b1\u2081\u2083) 39bfb947196a4c9e9e5c023f358122c6--d983b33dbd6347929f529d5ff1dca490 fc2e334119b3478a926d38b765021ff5 d983b33dbd6347929f529d5ff1dca490--fc2e334119b3478a926d38b765021ff5 c0e46864410b40a98959d51b4e073704 fc2e334119b3478a926d38b765021ff5--c0e46864410b40a98959d51b4e073704 1be07372a9864bbbaabeb82e26e2602a RX(iia_\u03b3\u2081\u2080) c0e46864410b40a98959d51b4e073704--1be07372a9864bbbaabeb82e26e2602a f9120d4ba97a4902b8a587c30b8708f6 1be07372a9864bbbaabeb82e26e2602a--f9120d4ba97a4902b8a587c30b8708f6 268d60a5de01429f85f05748cad1eb83 f9120d4ba97a4902b8a587c30b8708f6--268d60a5de01429f85f05748cad1eb83 44c7ff7b2f104a2ea3ce8b9c4114d590 RY(iia_\u03b2\u2081\u2083) 268d60a5de01429f85f05748cad1eb83--44c7ff7b2f104a2ea3ce8b9c4114d590 71e124d57ab04d82b5d1c98af1b71cb6 RX(iia_\u03b2\u2081\u2080) 44c7ff7b2f104a2ea3ce8b9c4114d590--71e124d57ab04d82b5d1c98af1b71cb6 3411fcd493914f9493d543648a73ebf4 71e124d57ab04d82b5d1c98af1b71cb6--3411fcd493914f9493d543648a73ebf4 204dbf038b0a48f7bc52d3d7560efd0b d9584cbc795248a0a224fc6e125ce921 RX(iia_\u03b1\u2080\u2081) 267840f413bd4dbb8cb6460cd1286892--d9584cbc795248a0a224fc6e125ce921 4ba4dcb54bb24ad8b0ffe6060842749d 2 7ba2749b2fe74a34ae3c39f7ed40fe6c RY(iia_\u03b1\u2080\u2084) d9584cbc795248a0a224fc6e125ce921--7ba2749b2fe74a34ae3c39f7ed40fe6c 5b2cebfd64db48fea7514c331a2fa9bd X 7ba2749b2fe74a34ae3c39f7ed40fe6c--5b2cebfd64db48fea7514c331a2fa9bd 5b2cebfd64db48fea7514c331a2fa9bd--4a9a75338590496b9d2837d9b3c69de2 764fc2ff73934dc4a033ccee654442b4 5b2cebfd64db48fea7514c331a2fa9bd--764fc2ff73934dc4a033ccee654442b4 a373c996c8a849e199a72a6a8a0d5fd3 RX(iia_\u03b3\u2080\u2081) 764fc2ff73934dc4a033ccee654442b4--a373c996c8a849e199a72a6a8a0d5fd3 d13574f5836149b4801c27d6aad71b42 a373c996c8a849e199a72a6a8a0d5fd3--d13574f5836149b4801c27d6aad71b42 f7fd7dc72d884f5fb172039e1d69b555 X d13574f5836149b4801c27d6aad71b42--f7fd7dc72d884f5fb172039e1d69b555 f7fd7dc72d884f5fb172039e1d69b555--f4c66d2e1fef44b7ab4019c4e0b807cd 76d50060416a40f08ed5c4a9b550f658 RY(iia_\u03b2\u2080\u2084) f7fd7dc72d884f5fb172039e1d69b555--76d50060416a40f08ed5c4a9b550f658 6322e8b19b4740ef9f3fd12b3c492bb5 RX(iia_\u03b2\u2080\u2081) 76d50060416a40f08ed5c4a9b550f658--6322e8b19b4740ef9f3fd12b3c492bb5 378ec851807046f79518fcfc85e7aa78 RX(iia_\u03b1\u2081\u2081) 6322e8b19b4740ef9f3fd12b3c492bb5--378ec851807046f79518fcfc85e7aa78 593e999ab4dc46789ccf9bb192d3e3cf RY(iia_\u03b1\u2081\u2084) 378ec851807046f79518fcfc85e7aa78--593e999ab4dc46789ccf9bb192d3e3cf 54cc8f279c8b4853a6203b2e55417360 X 593e999ab4dc46789ccf9bb192d3e3cf--54cc8f279c8b4853a6203b2e55417360 54cc8f279c8b4853a6203b2e55417360--fc2e334119b3478a926d38b765021ff5 476c0923619341669e33fe6eb50049f9 54cc8f279c8b4853a6203b2e55417360--476c0923619341669e33fe6eb50049f9 02f7b000a743433f955ced4fb98ee079 RX(iia_\u03b3\u2081\u2081) 476c0923619341669e33fe6eb50049f9--02f7b000a743433f955ced4fb98ee079 86157dce4a2c4e4e92801f5176bf1233 02f7b000a743433f955ced4fb98ee079--86157dce4a2c4e4e92801f5176bf1233 3e3735f4e4674166b3438d409a677e77 X 86157dce4a2c4e4e92801f5176bf1233--3e3735f4e4674166b3438d409a677e77 3e3735f4e4674166b3438d409a677e77--268d60a5de01429f85f05748cad1eb83 b2dc6d2643fe4aeb8790c54f86fc2f7d RY(iia_\u03b2\u2081\u2084) 3e3735f4e4674166b3438d409a677e77--b2dc6d2643fe4aeb8790c54f86fc2f7d 54b1aa89961140ec93bbaeac2c462afe RX(iia_\u03b2\u2081\u2081) b2dc6d2643fe4aeb8790c54f86fc2f7d--54b1aa89961140ec93bbaeac2c462afe 54b1aa89961140ec93bbaeac2c462afe--204dbf038b0a48f7bc52d3d7560efd0b d1edff0c970f4434849fe47d618ae1de a4975739847a4ecda3320cc71fbc81bb RX(iia_\u03b1\u2080\u2082) 4ba4dcb54bb24ad8b0ffe6060842749d--a4975739847a4ecda3320cc71fbc81bb a66fb1ad05cf4ae8b02369253e0e4142 RY(iia_\u03b1\u2080\u2085) a4975739847a4ecda3320cc71fbc81bb--a66fb1ad05cf4ae8b02369253e0e4142 e873ae2f6256445abf5ee7659cd97db8 a66fb1ad05cf4ae8b02369253e0e4142--e873ae2f6256445abf5ee7659cd97db8 e4d7be71a6d246498819289d7a597319 X e873ae2f6256445abf5ee7659cd97db8--e4d7be71a6d246498819289d7a597319 e4d7be71a6d246498819289d7a597319--764fc2ff73934dc4a033ccee654442b4 41293b172bf64e17bdad33e76c72a999 RX(iia_\u03b3\u2080\u2082) e4d7be71a6d246498819289d7a597319--41293b172bf64e17bdad33e76c72a999 349a0fee955d45c69a4647948711b45f X 41293b172bf64e17bdad33e76c72a999--349a0fee955d45c69a4647948711b45f 349a0fee955d45c69a4647948711b45f--d13574f5836149b4801c27d6aad71b42 d9f3c648b9ad4c429af8a82cd5f9de11 349a0fee955d45c69a4647948711b45f--d9f3c648b9ad4c429af8a82cd5f9de11 cb9e021c3f454cfd8bf24093af4346d1 RY(iia_\u03b2\u2080\u2085) d9f3c648b9ad4c429af8a82cd5f9de11--cb9e021c3f454cfd8bf24093af4346d1 787d53da850841c6ba6b8d331b122872 RX(iia_\u03b2\u2080\u2082) cb9e021c3f454cfd8bf24093af4346d1--787d53da850841c6ba6b8d331b122872 e57fbc89a2204cc9af41f9cd49cb1ffa RX(iia_\u03b1\u2081\u2082) 787d53da850841c6ba6b8d331b122872--e57fbc89a2204cc9af41f9cd49cb1ffa a296cf0fee6543d7bb279bedf93d535d RY(iia_\u03b1\u2081\u2085) e57fbc89a2204cc9af41f9cd49cb1ffa--a296cf0fee6543d7bb279bedf93d535d ea9cd8b056a64063bc86cf140b627cfe a296cf0fee6543d7bb279bedf93d535d--ea9cd8b056a64063bc86cf140b627cfe c84ac7b049784da3850380dcdac3628c X ea9cd8b056a64063bc86cf140b627cfe--c84ac7b049784da3850380dcdac3628c c84ac7b049784da3850380dcdac3628c--476c0923619341669e33fe6eb50049f9 fd618d52675b41f981f0f72ca20c216a RX(iia_\u03b3\u2081\u2082) c84ac7b049784da3850380dcdac3628c--fd618d52675b41f981f0f72ca20c216a 9a498126dad540db9a8a24ed36254290 X fd618d52675b41f981f0f72ca20c216a--9a498126dad540db9a8a24ed36254290 9a498126dad540db9a8a24ed36254290--86157dce4a2c4e4e92801f5176bf1233 e37565f127e649bfa3d1d3badd234fe8 9a498126dad540db9a8a24ed36254290--e37565f127e649bfa3d1d3badd234fe8 0e8068155c1d43529fcccfec85e716de RY(iia_\u03b2\u2081\u2085) e37565f127e649bfa3d1d3badd234fe8--0e8068155c1d43529fcccfec85e716de 799d04693d8941868302686623a901de RX(iia_\u03b2\u2081\u2082) 0e8068155c1d43529fcccfec85e716de--799d04693d8941868302686623a901de 799d04693d8941868302686623a901de--d1edff0c970f4434849fe47d618ae1de"},{"location":"content/quantummodels/","title":"Quantum models","text":"<p>A quantum program can be expressed and executed using the <code>QuantumModel</code> type. It serves three primary purposes:</p> <p>Parameter handling: by conveniently handling and embedding the two parameter types that Qadence supports: feature and variational (see more details in the previous section).</p> <p>Differentiability: by enabling a differentiable backend that supports two differentiable modes: automatic differentiation (AD) and parameter shift rules (PSR). The former is used general differentiation in statevector simulators based on PyTorch and JAX. The latter is a quantum specific method used to differentiate gate parameters, and is enabled for all backends.</p> <p>Execution: by defining which backend the program is expected to be executed on. Qadence supports circuit compilation to the native backend representation.</p> <p>Backends</p> <p>The goal is for quantum models to be executed seemlessly on a number of different purpose backends: simulators, emulators or real hardware. By default, Qadence executes on the PyQTorch backend which implements a state vector simulator. Currently, this is the most feature rich backend. The Pulser backend is being developed, and currently supports a more limited set of functionalities (pulse sequences on programmable neutral atom arrays). The Horqrux backend, built on JAX, is also available, but currently not supported with the <code>QuantumModel</code> interface. For more information see the backend section.</p> <p>The base <code>QuantumModel</code> exposes the following methods:</p> <ul> <li><code>QuantumModel.run()</code>: To extract the wavefunction after circuit execution. Not supported by all backends.</li> <li><code>QuantumModel.sample()</code>: Sample a bitstring from the resulting quantum state after circuit execution. Supported by all backends.</li> <li><code>QuantumModel.expectation()</code>: Compute the expectation value of an observable.</li> </ul> <p>Every <code>QuantumModel</code> is an instance of a <code>torch.nn.Module</code> that enables differentiability for its <code>expectation</code> method. For statevector simulators, AD also works for the statevector itself.</p> <p>To construct a <code>QuantumModel</code>, the program block must first be initialized into a <code>QuantumCircuit</code> instance by combining it with a <code>Register</code>. An integer number can also be passed for the total number of qubits, which instantiates a <code>Register</code> automatically. The qubit register also includes topological information on the qubit layout, essential for digital-analog computations. However, we will explore that in a later tutorial. For now, let's construct a simple parametrized quantum circuit.</p> <pre><code>from qadence import QuantumCircuit, RX, RY, chain, kron\nfrom qadence import FeatureParameter, VariationalParameter\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, theta), RY(1, theta)),\n    kron(RX(0, phi), RY(1, phi)),\n)\n\ncircuit = QuantumCircuit(2, block)\nunique_params = circuit.unique_parameters\n</code></pre> <pre><code>unique_params = [theta, phi]\n</code></pre> <p>The model can then be instantiated. Similarly to the direct execution functions shown in the previous tutorial, the <code>run</code>, <code>sample</code> and <code>expectation</code> methods are available directly from the model.</p> <pre><code>import torch\nfrom qadence import QuantumModel, PI, Z\n\nobservable = Z(0) + Z(1)\n\nmodel = QuantumModel(circuit, observable)\n\nvalues = {\"phi\": torch.tensor([PI, PI/2])}\n\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\n</code></pre> <pre><code>wf = tensor([[ 0.1130+0.0000j, -0.3166+0.0000j,  0.0000+0.3166j,  0.0000-0.8870j],\n        [ 0.1834+0.0000j,  0.3870+0.0000j,  0.0000-0.3870j,  0.0000-0.8166j]])\nxs = [Counter({'11': 85, '10': 10, '01': 5}), Counter({'11': 71, '10': 17, '01': 8, '00': 4})]\nex = tensor([[-1.5479],\n        [-1.2665]])\n</code></pre> <p>By default, the <code>forward</code> method of <code>QuantumModel</code> calls <code>model.run()</code>. To define custom quantum models, the best way is to inherit from <code>QuantumModel</code> and override the <code>forward</code> method, as typically done with custom PyTorch Modules.</p> <p>The <code>QuantumModel</code> class provides convenience methods to manipulate parameters. Being a <code>torch.nn.Module</code>, all torch methods are also available.</p> <pre><code># To pass onto a torch optimizer\nparameter_generator = model.parameters()\n\n# Number of variational parameters\nnum_vparams = model.num_vparams\n\n# Dictionary to easily inspect variational parameter values\nvparams_values = model.vparams\n</code></pre> <pre><code>vparams_values = OrderedDict([('theta', tensor([0.6857]))])\n</code></pre>"},{"location":"content/quantummodels/#model-output","title":"Model output","text":"<p>The output of a quantum model is typically encoded in the measurement of an expectation value. In Qadence, one way to customize the number of outputs is by batching the number of observables at model creation by passing a list of blocks.</p> <pre><code>from torch import tensor\nfrom qadence import chain, kron, VariationalParameter, FeatureParameter\nfrom qadence import QuantumModel, QuantumCircuit, PI, Z, RX, CNOT\n\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, phi), RX(1, phi)),\n    CNOT(0, 1)\n)\n\ncircuit = QuantumCircuit(2, block)\n\nmodel = QuantumModel(circuit, [Z(0), Z(0) + Z(1)])\n\nvalues = {\"phi\": tensor(PI)}\n\nex = model.expectation(values)\n</code></pre> <pre><code>ex = tensor([[-1.0000e+00, -7.4988e-33]])\n</code></pre> <p>As mentioned in the previous tutorial, blocks can also be arbitrarily parameterized through multiplication, which allows the inclusion of trainable parameters in the definition of the observable.</p> <pre><code>from qadence import I, Z\n\na = VariationalParameter(\"a\")\nb = VariationalParameter(\"b\")\n\n# Magnetization with a trainable shift and scale\nobservable = a * I(0) + b * Z(0)\n\nmodel = QuantumModel(circuit, observable)\n</code></pre>"},{"location":"content/quantummodels/#quantum-neural-network-qnn","title":"Quantum Neural Network (QNN)","text":"<p>The <code>QNN</code> is a subclass of the <code>QuantumModel</code> geared towards quantum machine learning and parameter optimisation. See the quantum machine learning section section or the <code>QNN</code> API reference for more detailed information. There are three main differences in interface when compared with the <code>QuantumModel</code>:</p> <ul> <li>It is initialized with a list of the input parameter names, and then supports direct <code>torch.Tensor</code> inputs instead of the values dictionary shown above. The ordering of the input values should respect the order given in the input names.</li> <li>Passing an observable is mandatory.</li> <li>The <code>forward</code> method calls <code>model.expectation()</code>.</li> </ul> <pre><code>from torch import tensor\nfrom qadence import chain, kron, VariationalParameter, FeatureParameter\nfrom qadence import QNN, QuantumCircuit, PI, Z, RX, RY, CNOT\n\ntheta = FeatureParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\n\nblock = chain(\n    kron(RX(0, phi), RX(1, phi)),\n    kron(RY(0, theta), RY(1, theta)),\n    CNOT(0, 1)\n)\n\ncircuit = QuantumCircuit(2, block)\nobservable = Z(0) + Z(1)\n\nmodel = QNN(circuit, observable, inputs = [\"phi\", \"theta\"])\n\n# \"phi\" = PI, PI/2, \"theta\" = 0.0, 1.0\nvalues = tensor([[PI, 0.0], [PI/2, 1.0]])\n\nex = model(values)\n</code></pre> <pre><code>ex = tensor([[-7.4988e-33],\n        [ 1.1102e-16]])\n</code></pre>"},{"location":"content/register/","title":"Quantum registers","text":"<p>In Qadence, quantum programs can be executed by specifying the layout of a register of resources as a lattice. Built-in <code>Register</code> types can be used or constructed for arbitrary topologies. Common register topologies are available and illustrated in the plot below.</p> 2024-09-20T08:33:54.117300 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"content/register/#building-and-drawing-registers","title":"Building and drawing registers","text":"<p>Built-in topologies are directly accessible in the <code>Register</code> methods:</p> <pre><code>from qadence import Register\n\nreg = Register.all_to_all(n_qubits = 4)\nreg_line = Register.line(n_qubits = 4)\nreg_circle = Register.circle(n_qubits = 4)\nreg_squre = Register.square(qubits_side = 2)\nreg_rect = Register.rectangular_lattice(qubits_row = 2, qubits_col = 2)\nreg_triang = Register.triangular_lattice(n_cells_row = 2, n_cells_col = 2)\nreg_honey = Register.honeycomb_lattice(n_cells_row = 2, n_cells_col = 2)\n</code></pre> <p>The <code>Register</code> class builds on top of the NetworkX <code>Graph</code>, and the graphs can be visualized with the <code>reg.draw()</code> method</p> <p>Qubit coordinates are saved as node properties in the underlying NetworkX graph, but can be accessed directly with the <code>coords</code> property.</p> <p><pre><code>reg = Register.square(2)\nprint(reg.coords)\n</code></pre> <pre><code>{0: (0.5, -0.5), 1: (0.5, 0.5), 2: (-0.5, 0.5), 3: (-0.5, -0.5)}\n</code></pre>  By default, the coords are scaled such that the minimum distance between any two qubits is 1, unless the register is created directly from specific coordinates as shown below. The <code>spacing</code> argument can be used to set the minimum spacing. The <code>rescale_coords</code> method can be used to create a new register by rescaling the coordinates of an already created register.</p> <pre><code>scaled_reg_1 = Register.square(2, spacing = 4.0)\nscaled_reg_2 = reg.rescale_coords(scaling = 4.0)\nprint(scaled_reg_1.coords)\nprint(scaled_reg_2.coords)\n</code></pre> <pre><code>{0: (2.0, -2.0), 1: (2.0, 2.0), 2: (-2.0, 2.0), 3: (-2.0, -2.0)}\n{0: (2.0, -2.0), 1: (2.0, 2.0), 2: (-2.0, 2.0), 3: (-2.0, -2.0)}\n</code></pre> <p>The distance between qubits can also be directly accessed with the <code>distances</code> and <code>edge_distances</code> properties.</p> <pre><code>print(reg.distances)\nprint(reg.edge_distances)\n</code></pre> <pre><code>Distance between all qubit pairs:\n{(0, 1): 1.0, (0, 2): 1.4142135623730951, (0, 3): 1.0, (1, 2): 1.0, (1, 3): 1.4142135623730951, (2, 3): 1.0}\nDistance between qubits connect by an edge in the graph\n{(0, 1): 1.0, (0, 3): 1.0, (1, 2): 1.0, (2, 3): 1.0}\n</code></pre> <p>By calling the <code>Register</code> directly, either the number of nodes or a specific graph can be given as input. If passing a custom graph directly, the node positions will not be defined automatically, and should be previously saved in the <code>\"pos\"</code> node property. If not, <code>reg.coords</code> will return empty tuples and all distances will be 0.</p> <pre><code>import networkx as nx\n\n# Same as Register.all_to_all(n_qubits = 2):\nreg = Register(2)\n\n# Register from a custom graph:\ngraph = nx.complete_graph(3)\n\n# Set node positions, in this case a simple line:\nfor i, node in enumerate(graph.nodes):\n    graph.nodes[node][\"pos\"] = (1.0 * i, 0.0)\n\nreg = Register(graph)\n\nprint(reg.distances)\n</code></pre> <pre><code>{(0, 1): 1.0, (0, 2): 2.0, (1, 2): 1.0}\n</code></pre> <p>Alternatively, arbitrarily shaped registers can also be constructed by providing the node coordinates. In this case, there will be no edges automatically created in the connectivity graph.</p> <pre><code>import numpy as np\nfrom qadence import Register, PI\n\nreg = Register.from_coordinates(\n    [(x, np.sin(x)) for x in np.linspace(0, 2*PI, 10)]\n)\n\nreg.draw(show=False)\n</code></pre> 2024-09-20T08:33:54.487180 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/ <p>Units for qubit coordinates</p> <p>In general, Qadence makes no assumption about the units for qubit coordinates and distances. However, if used in the context of a Hamiltonian coefficient, care should be taken by the user to guarantee the quantity \\(H.t\\) is dimensionless for exponentiation in the PyQTorch backend, where it is assumed that \\(\\hbar = 1\\). For registers passed to the Pulser backend, coordinates are in \\(\\mu \\textrm{m}\\).</p>"},{"location":"content/register/#connectivity-graphs","title":"Connectivity graphs","text":"<p>Register topology is often assumed in digital simulations to be an all-to-all qubit connectivity. When running on real devices that enable the digital-analog computing paradigm, qubit interactions must be specified either by specifying distances between qubits, or by defining edges in the register connectivity graph.</p> <p>The abstract graph nodes and edges are accessible for direct usage.</p> <pre><code>from qadence import Register\n\nreg = Register.rectangular_lattice(2,3)\n</code></pre> <pre><code>reg.nodes = NodeView((0, 1, 2, 3, 4, 5))\nreg.edges = EdgeView([(0, 2), (0, 1), (1, 3), (2, 4), (2, 3), (3, 5), (4, 5)])\n</code></pre> <p>There is also an <code>all_node_pairs</code> property for convenience:</p> <pre><code>print(reg.all_node_pairs)\n</code></pre> <pre><code>[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)]\n</code></pre> <p>More details about the usage of <code>Register</code> types in the digital-analog paradigm can be found in the digital-analog basics section.</p>"},{"location":"content/serializ_and_prep/","title":"Serialization","text":"<p>Qadence offers convenience functions for serializing and deserializing any quantum program. This is useful for storing quantum programs and sending them for execution over the network via an API.</p> <p>Note</p> <p>Qadence currently uses a custom JSON serialization as interchange format. Support for QASM format for digital quantum programs is currently under consideration.</p> <ul> <li><code>serialize/deserialize</code>: serialize and deserialize a Qadence object into a dictionary</li> <li><code>save/load</code>: save and load a Qadence object to a file with one of the supported   formats. Currently, these are <code>.json</code> and the PyTorch-compatible <code>.pt</code> format.</li> </ul> <p>Let's start with serialization into a dictionary.</p> <pre><code>import torch\nfrom qadence import QuantumCircuit, QuantumModel, DiffMode\nfrom qadence import chain, hamiltonian_factory, feature_map, hea, Z\nfrom qadence.serialization import serialize, deserialize\n\nn_qubits = 4\n\nmy_block = chain(feature_map(n_qubits, param=\"x\"), hea(n_qubits, depth=2))\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n\n# Use the block defined above to create a quantum circuit\n# serialize/deserialize it\nqc = QuantumCircuit(n_qubits, my_block)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n\n# Let's wrap it in a QuantumModel\n# and serialize it\nqm = QuantumModel(qc, obs, diff_mode=DiffMode.AD)\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n\n# Check if the loaded QuantumModel returns the same expectation\nvalues = {\"x\": torch.rand(10)}\nassert torch.allclose(qm.expectation(values=values), qm_deserialized.expectation(values=values))\n</code></pre> <p>Finally, we can save the quantum circuit and the model with the two supported formats.</p> <pre><code>from qadence.serialization import serialize, deserialize, save, load, SerializationFormat\n\nqc_fname = \"circuit\"\nsave(qc, folder=\".\", file_name=qc_fname, format=SerializationFormat.PT)\nloaded_qc = load(f\"{qc_fname}.pt\")\nassert qc == loaded_qc\n\nqm_fname = \"model\"\nsave(qm, folder=\".\", file_name=qm_fname, format=SerializationFormat.JSON)\nmodel = load(f\"{qm_fname}.json\")\nassert isinstance(model, QuantumModel)\n</code></pre>"},{"location":"content/state_conventions/","title":"State Conventions","text":"<p>Here is an overview of the state conventions used in Qadence together with practical examples.</p>"},{"location":"content/state_conventions/#qubit-register-order","title":"Qubit register order","text":"<p>Qubit registers in quantum computing are often indexed in increasing or decreasing order from left to right. In Qadence, the convention is qubit indexation in increasing order. For example, a register of four qubits in bra-ket notation reads:</p> \\[|q_0, q_1, q_2, q_3\\rangle\\] <p>Furthermore, when displaying a quantum circuit, qubits are ordered from top to bottom.</p>"},{"location":"content/state_conventions/#basis-state-order","title":"Basis state order","text":"<p>Basis state ordering refers to how basis states are ordered when considering the conversion from bra-ket notation to the standard linear algebra basis. In Qadence, basis states are ordered in the following manner:</p> \\[ \\begin{align} |00\\rangle = [1, 0, 0, 0]^T\\\\ |01\\rangle = [0, 1, 0, 0]^T\\\\ |10\\rangle = [0, 0, 1, 0]^T\\\\ |11\\rangle = [0, 0, 0, 1]^T \\end{align} \\]"},{"location":"content/state_conventions/#endianness","title":"Endianness","text":"<p>Endianness refers to the storage convention for binary information (in bytes) in a classical memory register. In quantum computing, information is either stored in bits or in qubits. The most commonly used conventions are:</p> <ul> <li>A big-endian system stores the most significant bit of a binary word at the smallest memory address.</li> <li>A little-endian system stores the least significant bit of a binary word at the smallest memory address.</li> </ul> <p>Given the register convention in Qadence, the integer \\(2\\) written in binary big-endian as \\(10\\) can be encoded in a qubit register in both big-endian as \\(|10\\rangle\\) or little-endian as \\(|01\\rangle\\).</p> <p>The convention for Qadence is big-endian.</p>"},{"location":"content/state_conventions/#quantum-states","title":"Quantum states","text":"<p>In practical scenarios, conventions regarding register order, basis state order and endianness are very much intertwined, and identical results can be obtained by fixing or varying any of them. In Qadence, we assume that qubit ordering and basis state ordering is fixed, and allow an <code>endianness</code> argument that can be passed to control the expected result. Here are a few examples:</p> <p>A simple and direct way to exemplify the endianness convention is using convenience functions for state preparation.</p> <p>Bitstring convention as inputs</p> <p>When a bitstring is passed as input to a function for state preparation, it has to be understood in big-endian convention.</p> <pre><code>from qadence import Endianness, product_state\n\n# The state |10&gt;, the 3rd basis state.\nstate_big = product_state(\"10\", endianness=Endianness.BIG) # or just \"Big\"\n\n# The state |01&gt;, the 2nd basis state.\nstate_little = product_state(\"10\", endianness=Endianness.LITTLE) # or just \"Little\"\n</code></pre> <pre><code>State in big endian = tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\nState in little endian = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Here, a bitword expressed as a Python string to encode the integer 2 in big-endian is used to create the respective basis state in both conventions. However, note that the same results can be obtained by fixing the endianness convention as big-endian (thus creating the state \\(|10\\rangle\\) in both cases), and changing the basis state ordering. A similar argument holds for fixing both endianness and basis state ordering and simply changing the qubit index order.</p> <p>Another example where endianness directly comes into play is when measuring a register. A big- or little-endian measurement will choose the first or the last qubit, respectively, as the most significant bit. Let's see this in an example:</p> <pre><code>from qadence import I, H, sample\n\n# Create superposition state: |00&gt; + |01&gt; (normalized)\nblock = I(0) @ H(1)  # Identity on qubit 0, Hadamard on qubit 1\n\n# Generate bitword samples following both conventions\n# Samples \"00\" and \"01\"\nresult_big = sample(block, endianness=Endianness.BIG)\n# Samples \"00\" and \"10\"\nresult_little = sample(block, endianness=Endianness.LITTLE)\n</code></pre> <pre><code>Sample in big endian = [Counter({'01': 56, '00': 44})]\nSample in little endian = [Counter({'10': 52, '00': 48})]\n</code></pre> <p>In Qadence, endianness can be flipped for many relevant objects:</p> <pre><code>from qadence import invert_endianness\n\n# Equivalent to sampling in little-endian.\nflip_big_sample = invert_endianness(result_big)\n\n# Equivalent to a state created in little-endian.\nflip_big_state = invert_endianness(state_big)\n</code></pre> <pre><code>Flipped sample = [Counter({'10': 56, '00': 44})]\nFlipped state = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"content/state_conventions/#quantum-operations","title":"Quantum operations","text":"<p>When looking at the matricial form of quantum operations, the usage of the term endianness becomes slightly abusive. To exemplify, we may consider the <code>CNOT</code> operation with <code>control = 0</code> and <code>target = 1</code>. This operation is often described with two different matrices:</p> \\[ \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} \\qquad \\text{or} \\qquad \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] <p>The difference can be easily explained either by considering a different ordering of the qubit indices, or a different ordering of the basis states. In Qadence, both can be retrieved through the <code>endianness</code> argument:</p> <pre><code>from qadence import block_to_tensor, CNOT\n\nmatrix_big = block_to_tensor(CNOT(0, 1), endianness=Endianness.BIG)\nmatrix_little = block_to_tensor(CNOT(0, 1), endianness=Endianness.LITTLE)\n</code></pre> <pre><code>CNOT matrix in big endian =\n\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\n\nCNOT matrix in little endian =\n\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre>"},{"location":"content/state_conventions/#backends","title":"Backends","text":"<p>An important part of having clear state conventions is that we need to make sure our results are consistent accross different computational backends, which may have their own conventions. In Qadence, this is taken care of automatically: by calling operations for different backends, the result is expected to be equivalent up to qubit ordering.</p> <pre><code>from qadence import BackendName, RX, run, sample, PI\n\n# RX(PI/4) on qubit 1\nn_qubits = 2\nop = RX(1, PI/4)\n</code></pre> <pre><code>Same sampling order in big endian:\n\nOn PyQTorch = [Counter({'00': 84, '01': 16})]\nOn Braket = [Counter({'00': 89, '01': 11})]\nOn Pulser = [Counter({'00': 81, '01': 19})]\n\nSame wavefunction order:\n\nOn PyQTorch = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Braket = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Pulser = tensor([[0.9241+0.0000j, 0.0000-0.3822j, 0.0000+0.0000j, 0.0000+0.0000j]])\n</code></pre>"},{"location":"content/state_init/","title":"State initialization","text":"<p>Qadence offers convenience routines for preparing initial quantum states. These routines are divided into two approaches:</p> <ul> <li>As a dense matrix.</li> <li>From a suitable quantum circuit. This is available for every backend and it should be added in front of the desired quantum circuit to simulate.</li> </ul> <p>Let's illustrate the usage of the state preparation routine.</p> <pre><code>from qadence import random_state, product_state, is_normalized, StateGeneratorType\n\n# Random initial state.\n# the default `type` is StateGeneratorType.HaarMeasureFast\nstate = random_state(n_qubits=2, type=StateGeneratorType.RANDOM_ROTATIONS)\n\n# Check the normalization.\nassert is_normalized(state)\n\n# Product state from a given bitstring.\n# NB: Qadence follows the big endian convention.\nstate = product_state(\"01\")\n</code></pre> <pre><code>Random initial state generated with rotations:\n\nstate = [0.79202251+0.j         0.        +0.26684655j 0.        -0.52034457j\n 0.17531339+0.j        ]\n\nProduct state corresponding to bitstring '01':\n\nstate = [0.+0.j 1.+0.j 0.+0.j 0.+0.j]\n</code></pre> <p>Now we see how to generate the product state corresponding to the one above with a suitable quantum circuit.</p> <p><pre><code>from qadence import product_block, tag, hea, QuantumCircuit\nfrom qadence.draw import display\n\nstate_prep_block = product_block(\"01\")\n# display(state_prep_block)\n\n# Let's now prepare a circuit.\nn_qubits = 4\n\nstate_prep_block = product_block(\"0001\")\ntag(state_prep_block, \"Prep block\")\n\ncircuit_block = tag(hea(n_qubits, depth = 2), \"Circuit block\")\n\nqc_with_state_prep = QuantumCircuit(n_qubits, state_prep_block, circuit_block)\n</code></pre> %3 cluster_b56674d6e6a64da5b93f8616afa3e368 Circuit block cluster_0b523c8911da4e65ac7279d1a0cf1469 Prep block 9e8d768b3ec64acfb6b928a1994c55e5 0 6d3f0c71ca7a41cb90dbc7528b601ead 9e8d768b3ec64acfb6b928a1994c55e5--6d3f0c71ca7a41cb90dbc7528b601ead e9ae9a4e037e4911bcd4bf20fa77cb47 1 2ad14ca759694dcbb157103b83273e08 RX(theta\u2080) 6d3f0c71ca7a41cb90dbc7528b601ead--2ad14ca759694dcbb157103b83273e08 ac87b065584c4b7a8cc37d0c26d14bf4 RY(theta\u2084) 2ad14ca759694dcbb157103b83273e08--ac87b065584c4b7a8cc37d0c26d14bf4 7ca8a60510194930908f542bb698685b RX(theta\u2088) ac87b065584c4b7a8cc37d0c26d14bf4--7ca8a60510194930908f542bb698685b 25fa32709fdf4151931bb51f3b41191f 7ca8a60510194930908f542bb698685b--25fa32709fdf4151931bb51f3b41191f 8377a773195f4f6ba8d30abcfa2c92e2 25fa32709fdf4151931bb51f3b41191f--8377a773195f4f6ba8d30abcfa2c92e2 1cc33a6a576d4cf78322c3c93bc96ba9 RX(theta\u2081\u2082) 8377a773195f4f6ba8d30abcfa2c92e2--1cc33a6a576d4cf78322c3c93bc96ba9 d92f635fa84d4e9386c9f95e0a78e89e RY(theta\u2081\u2086) 1cc33a6a576d4cf78322c3c93bc96ba9--d92f635fa84d4e9386c9f95e0a78e89e 347dfa6d410f41709efb3dc53723f75d RX(theta\u2082\u2080) d92f635fa84d4e9386c9f95e0a78e89e--347dfa6d410f41709efb3dc53723f75d f260cf401ab44827a8f2edce8bb06dd2 347dfa6d410f41709efb3dc53723f75d--f260cf401ab44827a8f2edce8bb06dd2 de382b17a85d4947b52c7b3986ce9c9b f260cf401ab44827a8f2edce8bb06dd2--de382b17a85d4947b52c7b3986ce9c9b 64c3e5b8ceed4a469d4079c9ec76b2be de382b17a85d4947b52c7b3986ce9c9b--64c3e5b8ceed4a469d4079c9ec76b2be d17cd55b3c704e7bac8f20447c5263ec 3e5593d4cb7347d3b4a71b7fd90403a9 e9ae9a4e037e4911bcd4bf20fa77cb47--3e5593d4cb7347d3b4a71b7fd90403a9 f884b4dbe15b4c67a799ce35b15165e2 2 36084d6dfdcc4eb19942d51542eec39d RX(theta\u2081) 3e5593d4cb7347d3b4a71b7fd90403a9--36084d6dfdcc4eb19942d51542eec39d 2d68eb11305b4ecc9008a5d6e1cdfdc7 RY(theta\u2085) 36084d6dfdcc4eb19942d51542eec39d--2d68eb11305b4ecc9008a5d6e1cdfdc7 3a8010f26a7a4ad49a6a7f88474de6e8 RX(theta\u2089) 2d68eb11305b4ecc9008a5d6e1cdfdc7--3a8010f26a7a4ad49a6a7f88474de6e8 1ec76017b2d84aaeb9c0b61c437254ff X 3a8010f26a7a4ad49a6a7f88474de6e8--1ec76017b2d84aaeb9c0b61c437254ff 1ec76017b2d84aaeb9c0b61c437254ff--25fa32709fdf4151931bb51f3b41191f ddcb19f38d9a4d05b64d532901607cfd 1ec76017b2d84aaeb9c0b61c437254ff--ddcb19f38d9a4d05b64d532901607cfd 00bdb882ff6248768f41cca6decebab7 RX(theta\u2081\u2083) ddcb19f38d9a4d05b64d532901607cfd--00bdb882ff6248768f41cca6decebab7 b0fa564de65b4ab082c408dc3c674e1e RY(theta\u2081\u2087) 00bdb882ff6248768f41cca6decebab7--b0fa564de65b4ab082c408dc3c674e1e 18378b3c8b7345b7a3d5547d1e770f73 RX(theta\u2082\u2081) b0fa564de65b4ab082c408dc3c674e1e--18378b3c8b7345b7a3d5547d1e770f73 e99329d2904e4601884a3062282869e7 X 18378b3c8b7345b7a3d5547d1e770f73--e99329d2904e4601884a3062282869e7 e99329d2904e4601884a3062282869e7--f260cf401ab44827a8f2edce8bb06dd2 3121e28b1e8b4bbc934895233ff7c5ca e99329d2904e4601884a3062282869e7--3121e28b1e8b4bbc934895233ff7c5ca 3121e28b1e8b4bbc934895233ff7c5ca--d17cd55b3c704e7bac8f20447c5263ec 665e0d1eb98542f7ac86e5a0d54c0a6f f610e7c656e04531a1080df2b26af5c3 f884b4dbe15b4c67a799ce35b15165e2--f610e7c656e04531a1080df2b26af5c3 d344511b0896447b910436515fbf9975 3 170f172cd7bb4b7aa03f85570e2086ad RX(theta\u2082) f610e7c656e04531a1080df2b26af5c3--170f172cd7bb4b7aa03f85570e2086ad bd130024149d47f6a346e4102c7ad186 RY(theta\u2086) 170f172cd7bb4b7aa03f85570e2086ad--bd130024149d47f6a346e4102c7ad186 956ceaac32cf426698320b83401e9aaf RX(theta\u2081\u2080) bd130024149d47f6a346e4102c7ad186--956ceaac32cf426698320b83401e9aaf 17b7606720d64948b0df873831ad696f 956ceaac32cf426698320b83401e9aaf--17b7606720d64948b0df873831ad696f 26d4a928264e4ad79b97c0c401b70ef4 X 17b7606720d64948b0df873831ad696f--26d4a928264e4ad79b97c0c401b70ef4 26d4a928264e4ad79b97c0c401b70ef4--ddcb19f38d9a4d05b64d532901607cfd 6d67c0af80884fabadf16d7e49059fc6 RX(theta\u2081\u2084) 26d4a928264e4ad79b97c0c401b70ef4--6d67c0af80884fabadf16d7e49059fc6 1c5d88663c394091836aeba78abe5fe9 RY(theta\u2081\u2088) 6d67c0af80884fabadf16d7e49059fc6--1c5d88663c394091836aeba78abe5fe9 cde517ecc6bc4f9a8ccde39ba1d38976 RX(theta\u2082\u2082) 1c5d88663c394091836aeba78abe5fe9--cde517ecc6bc4f9a8ccde39ba1d38976 c9c446644d4b48c0af92b820f5d21c4f cde517ecc6bc4f9a8ccde39ba1d38976--c9c446644d4b48c0af92b820f5d21c4f c7c325cbf2b7488c911ffd7f8e369ec2 X c9c446644d4b48c0af92b820f5d21c4f--c7c325cbf2b7488c911ffd7f8e369ec2 c7c325cbf2b7488c911ffd7f8e369ec2--3121e28b1e8b4bbc934895233ff7c5ca c7c325cbf2b7488c911ffd7f8e369ec2--665e0d1eb98542f7ac86e5a0d54c0a6f 204ddf24c80f4411a3be963cc1cbc371 cf7ff9cdcb674548869e2b8e101965b6 X d344511b0896447b910436515fbf9975--cf7ff9cdcb674548869e2b8e101965b6 a1a6b2fc034e4cfbb0108900fe3475c3 RX(theta\u2083) cf7ff9cdcb674548869e2b8e101965b6--a1a6b2fc034e4cfbb0108900fe3475c3 500e877aef134765ba2099f619b033d5 RY(theta\u2087) a1a6b2fc034e4cfbb0108900fe3475c3--500e877aef134765ba2099f619b033d5 f6c2a6553f81412c8eae1a089c0bf62b RX(theta\u2081\u2081) 500e877aef134765ba2099f619b033d5--f6c2a6553f81412c8eae1a089c0bf62b 3f6b5cecb72d4c00a7be51f8a105b46b X f6c2a6553f81412c8eae1a089c0bf62b--3f6b5cecb72d4c00a7be51f8a105b46b 3f6b5cecb72d4c00a7be51f8a105b46b--17b7606720d64948b0df873831ad696f ea8ad21807a541b69060873c74c922a3 3f6b5cecb72d4c00a7be51f8a105b46b--ea8ad21807a541b69060873c74c922a3 2e95d67cc527418aaa1a4c2499c46222 RX(theta\u2081\u2085) ea8ad21807a541b69060873c74c922a3--2e95d67cc527418aaa1a4c2499c46222 fb67bf9f046e4f88a1251bcaf5680d88 RY(theta\u2081\u2089) 2e95d67cc527418aaa1a4c2499c46222--fb67bf9f046e4f88a1251bcaf5680d88 7e000fb399714f0e8dfe63cba7eac487 RX(theta\u2082\u2083) fb67bf9f046e4f88a1251bcaf5680d88--7e000fb399714f0e8dfe63cba7eac487 2a25ddfe95424a50b6d3a6a2362d3ba3 X 7e000fb399714f0e8dfe63cba7eac487--2a25ddfe95424a50b6d3a6a2362d3ba3 2a25ddfe95424a50b6d3a6a2362d3ba3--c9c446644d4b48c0af92b820f5d21c4f 98060d994c694c2980ac8f139accaca5 2a25ddfe95424a50b6d3a6a2362d3ba3--98060d994c694c2980ac8f139accaca5 98060d994c694c2980ac8f139accaca5--204ddf24c80f4411a3be963cc1cbc371  Several standard quantum states can be conveniently initialized in Qadence, both in statevector form as well as in block form as shown in following.</p>"},{"location":"content/state_init/#state-vector-initialization","title":"State vector initialization","text":"<p>Qadence offers a number of constructor functions for state vector preparation.</p> <pre><code>from qadence import uniform_state, zero_state, one_state\n\nn_qubits = 3\nbatch_size = 2\n\nuniform_state = uniform_state(n_qubits, batch_size)\nzero_state = zero_state(n_qubits, batch_size)\none_state = one_state(n_qubits, batch_size)\n</code></pre> <pre><code>Uniform state = \n\ntensor([[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n         0.3536+0.j],\n        [0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n         0.3536+0.j]])\nZero state = \n\ntensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nOne state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> <p>As already seen, product states can be easily created, even in batches:</p> <pre><code>from qadence import product_state, rand_product_state\n\n# From a bitsring \"100\"\nprod_state = product_state(\"100\", batch_size)\n\n# Or a random product state\nrand_state = rand_product_state(n_qubits, batch_size)\n</code></pre> <pre><code>Product state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n\nRandom state = \n\ntensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Creating a GHZ state:</p> <pre><code>from qadence import ghz_state\n\nghz = ghz_state(n_qubits, batch_size)\n</code></pre> <pre><code>GHZ state = \n\ntensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n         0.7071+0.j],\n        [0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n         0.7071+0.j]])\n</code></pre> <p>Creating a random state uniformly sampled from a Haar measure:</p> <pre><code>from qadence import random_state\n\nrand_haar_state = random_state(n_qubits, batch_size)\n</code></pre> <pre><code>Random state from Haar = \n\ntensor([[-0.2027-0.1964j, -0.3514-0.1442j,  0.1544-0.3021j,  0.2899+0.3444j,\n          0.4650-0.2876j,  0.0324+0.3107j, -0.1282-0.1695j,  0.1280-0.0138j],\n        [ 0.5771+0.2875j, -0.0638+0.2801j,  0.1174+0.2388j, -0.0277+0.1725j,\n          0.0063-0.1267j, -0.1059+0.0650j, -0.0797-0.4300j, -0.4060+0.1131j]])\n</code></pre> <p>Custom initial states can then be passed to either <code>run</code>, <code>sample</code> and <code>expectation</code> through the <code>state</code> argument</p> <pre><code>from qadence import random_state, product_state, CNOT, run\n\ninit_state = product_state(\"10\")\nfinal_state = run(CNOT(0, 1), state=init_state)\n</code></pre> <pre><code>Final state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre>"},{"location":"content/state_init/#block-initialization","title":"Block initialization","text":"<p>Not all backends support custom statevector initialization, however previous utility functions have their counterparts to initialize the respective blocks:</p> <pre><code>from qadence import uniform_block, one_block\n\nn_qubits = 3\n\nuniform_block = uniform_block(n_qubits)\n\none_block = one_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u251c\u2500\u2500 H(1)\n\u2514\u2500\u2500 H(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>Similarly, for product states:</p> <pre><code>from qadence import product_block, rand_product_block\n\nproduct_block = product_block(\"100\")\n\nrand_product_block = rand_product_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 I(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 I(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 I(2)\n</code></pre> <p>And GHZ states:</p> <pre><code>from qadence import ghz_block\n\nghz_block = ghz_block(n_qubits)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n    \u251c\u2500\u2500 CNOT(0, 1)\n    \u2514\u2500\u2500 CNOT(1, 2)\n</code></pre> <p>Initial state blocks can simply be chained at the start of a given circuit.</p>"},{"location":"content/state_init/#utility-functions","title":"Utility functions","text":"<p>Some state vector utility functions are also available. We can easily create the probability mass function of a given statevector using <code>torch.distributions.Categorical</code></p> <pre><code>from qadence import random_state, pmf\n\nn_qubits = 3\n\nstate = random_state(n_qubits)\ndistribution = pmf(state)\n</code></pre> <pre><code>Categorical(probs: torch.Size([1, 8]))\n</code></pre> <p>We can also check if a state is normalized:</p> <pre><code>from qadence import random_state, is_normalized\n\nstate = random_state(n_qubits)\nprint(is_normalized(state))\n</code></pre> <pre><code>True\n</code></pre> <p>Or normalize a state:</p> <pre><code>import torch\nfrom qadence import normalize, is_normalized\n\nstate = torch.tensor([[1, 1, 1, 1]], dtype = torch.cdouble)\nprint(normalize(state))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre>"},{"location":"content/time_dependent/","title":"Time-dependent generators","text":"<p>For use cases when the Hamiltonian of the system is time-dependent, Qadence provides a special parameter <code>TimePrameter(\"t\")</code> that denotes the explicit time dependence. Using this time parameter one can define a parameterized block acting as the generator passed to <code>HamEvo</code> that encapsulates the required time dependence function.</p> <pre><code>from qadence import X, Y, HamEvo, TimeParameter, Parameter, run\nfrom pyqtorch.utils import SolverType\nimport torch\n\n# simulation parameters\nduration = 1.0  # duration of time-dependent block simulation\node_solver = SolverType.DP5_SE  # time-dependent Schrodinger equation solver method\nn_steps_hevo = 500  # integration time steps used by solver\n\n# define block parameters\nt = TimeParameter(\"t\")\nomega_param = Parameter(\"omega\")\n\n# create time-dependent generator\ngenerator_td = omega_param * (t * X(0) + t**2 * Y(1))\n\n# create parameterized HamEvo block\nhamevo = HamEvo(generator_td, 0.0, duration=duration)\n\n# run simulation\nout_state = run(hamevo,\n                values={\"omega\": torch.tensor(10.0)},\n                configuration={\"ode_solver\": ode_solver,\n                               \"n_steps_hevo\": n_steps_hevo})\n\nprint(out_state)\n</code></pre> <pre><code>tensor([[-0.2785+0.0000j, -0.0541+0.0000j,  0.0000-0.9414j,  0.0000-0.1827j]])\n</code></pre> <p>Note that when using <code>HamEvo</code> with a time-dependent generator, its second argument <code>parameter</code> is not used and an arbitrary value can be passed to it. However, in case of time-dependent generator a value for <code>duration</code> argument to <code>HamEvo</code> must be passed in order to define the duration of the simulation. The unit of passed duration value \\(\\tau\\) must be aligned with the units of other parameters in the time-dependent generator so that the integral of generator \\(\\overset{\\tau}{\\underset{0}{\\int}}\\mathcal{\\hat{H}}(t){\\rm d}t\\) is dimensionless.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"getting_started/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"getting_started/CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"getting_started/CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"getting_started/CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in Qadence. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"getting_started/CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence, feel free to create an issue on qadence's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"getting_started/CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>We're excited that you're eager to contribute to Qadence. To contribute, fork the <code>main</code> branch of qadence repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/qadence</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/qadence.git\n</code></pre> <p>Next, navigate to your new qadence fork directory and mark the main qadence repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/qadence.git\n</code></pre>"},{"location":"getting_started/CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within qadence, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run qadence tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\npip install -e .\npytest\n</code></pre>"},{"location":"getting_started/CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful things for your workflow: linting and testing","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"getting_started/LICENSE/","title":"Apache License","text":"<p>Version 2.0, January 2004</p> <p>http://www.apache.org/licenses/</p>"},{"location":"getting_started/LICENSE/#terms-and-conditions-for-use-reproduction-and-distribution","title":"TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION","text":""},{"location":"getting_started/LICENSE/#1-definitions","title":"1. Definitions:","text":"<p>\"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.</p>"},{"location":"getting_started/LICENSE/#2-grant-of-copyright-license","title":"2. Grant of Copyright License.","text":"<p>Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.</p>"},{"location":"getting_started/LICENSE/#3-grant-of-patent-license","title":"3. Grant of Patent License.","text":"<p>Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.</p>"},{"location":"getting_started/LICENSE/#4-redistribution","title":"4. Redistribution.","text":"<p>You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:</p> <ul> <li> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> </li> <li> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> </li> <li> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> </li> <li> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> </li> </ul> <p>You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.</p>"},{"location":"getting_started/LICENSE/#5-submission-of-contributions","title":"5. Submission of Contributions.","text":"<p>Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.</p>"},{"location":"getting_started/LICENSE/#6-trademarks","title":"6. Trademarks.","text":"<p>This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.</p>"},{"location":"getting_started/LICENSE/#7-disclaimer-of-warranty","title":"7. Disclaimer of Warranty.","text":"<p>Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.</p>"},{"location":"getting_started/LICENSE/#8-limitation-of-liability","title":"8. Limitation of Liability.","text":"<p>In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.</p>"},{"location":"getting_started/LICENSE/#9-accepting-warranty-or-additional-liability","title":"9. Accepting Warranty or Additional Liability.","text":"<p>While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.</p>"},{"location":"getting_started/LICENSE/#end-of-terms-and-conditions","title":"END OF TERMS AND CONDITIONS","text":""},{"location":"getting_started/LICENSE/#appendix-how-to-apply-the-apache-license-to-your-work","title":"APPENDIX: How to apply the Apache License to your work.","text":"<p>To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!)  The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives.</p> <p>Copyright [yyyy] [name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <p>http://www.apache.org/licenses/LICENSE-2.0</p> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"getting_started/installation/","title":"Installation","text":"<p>Qadence can be installed from PyPI with <code>pip</code> as follows:</p> <pre><code>pip install qadence\n</code></pre> <p>By default, this will also install PyQTorch, a differentiable state vector simulator which serves as the main numerical backend for Qadence.</p> <p>It is possible to install additional backends and the circuit visualization library using the following extras:</p> <ul> <li><code>visualization</code>: to display quantum circuits.</li> <li><code>pulser</code>: the Pulser backend for composing, simulating and executing pulse sequences for neutral-atom quantum devices (in development).</li> </ul> <p>To install other backends or the visualization tool, please use:</p> <pre><code>pip install \"qadence[pulser, visualization]\"\n</code></pre> <p>Note</p> <p>In order to correctly install the <code>visualization</code> extra, the <code>graphviz</code> package needs to be installed in your system:</p> <pre><code># on Ubuntu\nsudo apt install graphviz\n\n# on MacOS\nbrew install graphviz\n\n# via conda\nconda install python-graphviz\n</code></pre>"},{"location":"getting_started/installation/#install-from-source","title":"Install from source","text":"<p>We recommend to use the <code>hatch</code> environment manager to install <code>qadence</code> from source:</p> <pre><code>python -m pip install hatch\n\n# get into a shell with all the dependencies\npython -m hatch shell\n\n# run a command within the virtual environment with all the dependencies\npython -m hatch run python my_script.py\n</code></pre> <p>Warning</p> <p><code>hatch</code> will not combine nicely with other environment managers such Conda. If you want to use Conda, install it from source using <code>pip</code>:</p> <pre><code># within the Conda environment\npython -m pip install -e .\n</code></pre>"},{"location":"getting_started/installation/#citation","title":"Citation","text":"<p>If you use Qadence for a publication, we kindly ask you to cite our work using the following BibTex entry:</p> <pre><code>@article{qadence2024pasqal,\n  title = {Qadence: a differentiable interface for digital-analog programs.},\n  author={Dominik Seitz and Niklas Heim and Jo\u00e3o P. Moutinho and Roland Guichard and Vytautas Abramavicius and Aleksander Wennersteen and Gert-Jan Both and Anton Quelle and Caroline de Groot and Gergana V. Velikova and Vincent E. Elfving and Mario Dagrada},\n  journal={arXiv:2401.09915},\n  url = {https://github.com/pasqal-io/qadence},\n  year = {2024}\n}\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This section is undergoing changes and most of the information here will be reorganized.</p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"tutorials/advanced_tutorials/","title":"Advanced Tutorials","text":"<p>In this section, advanced programming concepts and implementations in Qadence are examplified.</p>"},{"location":"tutorials/advanced_tutorials/custom-models/","title":"Custom quantum models","text":"<p>In <code>qadence</code>, the <code>QuantumModel</code> is the central class point for executing <code>QuantumCircuit</code>s.  The idea of a <code>QuantumModel</code> is to decouple the backend execution from the management of circuit parameters and desired quantum computation output.</p> <p>In the following, we create a custom <code>QuantumModel</code> instance which introduces some additional optimizable parameters: *  an adjustable scaling factor in front of the observable to measured *  adjustable scale and shift factors to be applied to the model output before returning the result</p> <p>This can be easily done using PyTorch flexible model definition, and it will automatically work with the rest of <code>qadence</code> infrastructure.</p> <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit\n\n\nclass CustomQuantumModel(QuantumModel):\n\n    def __init__(self, circuit: QuantumCircuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\"):\n        super().__init__(circuit, observable=observable, backend=backend, diff_mode=diff_mode)\n\n        self.n_qubits = circuit.n_qubits\n\n        # define some additional parameters which will scale and shift (variationally) the\n        # output of the QuantumModel\n        # you can use all torch machinery for building those\n        self.scale_out = torch.nn.Parameter(torch.ones(1))\n        self.shift_out = torch.nn.Parameter(torch.ones(1))\n\n    # override the forward pass of the model\n    # the forward pass is the output of your QuantumModel and in this case\n    # it's the (scaled) expectation value of the total magnetization with\n    # a variable coefficient in front\n    def forward(self, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n\n        # scale the observable\n        res = self.expectation(values)\n\n        # scale and shift the result before returning\n        return self.shift_out + res * self.scale_out\n</code></pre> <p>The custom model can be used like any other <code>QuantumModel</code>: <pre><code>from qadence import Parameter, RX, CNOT, QuantumCircuit\nfrom qadence import chain, kron, hamiltonian_factory, Z\nfrom sympy import acos\n\ndef quantum_circuit(n_qubits):\n\n    x = Parameter(\"x\", trainable=False)\n    fm = kron(RX(i, acos(x) * (i+1)) for i in range(n_qubits))\n\n    ansatz = kron(RX(i, f\"theta{i}\") for i in range(n_qubits))\n    ansatz = chain(ansatz, CNOT(0, n_qubits-1))\n\n    block = chain(fm, ansatz)\n    block.tag = \"circuit\"\n    return QuantumCircuit(n_qubits, block)\n\nn_qubits = 4\nbatch_size = 10\ncircuit = quantum_circuit(n_qubits)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)  # Total magnetization\n\nmodel = CustomQuantumModel(circuit, observable, backend=\"pyqtorch\")\n\nvalues = {\"x\": torch.rand(batch_size)}\nres = model(values)\nprint(\"Model output: \", res)\nassert len(res) == batch_size\n</code></pre> <pre><code>Model output:  tensor([[-0.1966],\n        [ 0.1529],\n        [ 3.7128],\n        [-0.6228],\n        [ 0.2757],\n        [ 1.7314],\n        [-0.3528],\n        [-0.3053],\n        [ 0.5187],\n        [-0.2887]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> </p>"},{"location":"tutorials/advanced_tutorials/custom-models/#quantum-model-with-wavefunction-overlaps","title":"Quantum model with wavefunction overlaps","text":"<p><code>QuantumModel</code>'s can also use different quantum operations in their forward pass, such as wavefunction overlaps described here. Beware that the resulting overlap tensor has to be differentiable to apply gradient-based optimization. This is only applicable to the <code>\"EXACT\"</code> overlap method.</p> <p>Here we show how to use overlap calculation when fitting a parameterized quantum circuit to act as a standard Hadamard gate.</p> <pre><code>from qadence import RY, RX, H, Overlap\n\n# create a quantum model which acts as an Hadamard gate after training\nclass LearnHadamard(QuantumModel):\n    def __init__(\n        self,\n        train_circuit: QuantumCircuit,\n        target_circuit: QuantumCircuit,\n        backend=\"pyqtorch\",\n    ):\n        super().__init__(circuit=train_circuit, backend=backend)\n        self.overlap_fn = Overlap(train_circuit, target_circuit, backend=backend, method=\"exact\", diff_mode='ad')\n\n    def forward(self):\n        return self.overlap_fn()\n\n    # compute the wavefunction of the associated train circuit\n    def wavefunction(self):\n        return model.overlap_fn.run({})\n\n\ntrain_circuit = QuantumCircuit(1, chain(RX(0, \"phi\"), RY(0, \"theta\")))\ntarget_circuit = QuantumCircuit(1, H(0))\n\nmodel = LearnHadamard(train_circuit, target_circuit)\n\n# get the overlap between model and target circuit wavefunctions\nprint(model())\n</code></pre> <pre><code>tensor([[0.8804]], grad_fn=&lt;UnsqueezeBackward0&gt;)\n</code></pre> <p>This model can then be trained with the standard Qadence helper functions.</p> <pre><code>from qadence import run\nfrom qadence.ml_tools import train_with_grad, TrainConfig\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n\ndef loss_fn(model: LearnHadamard, _unused) -&gt; tuple[torch.Tensor, dict]:\n    loss = criterion(torch.tensor([[1.0]]), model())\n    return loss, {}\n\nconfig = TrainConfig(max_iter=2500)\nmodel, optimizer = train_with_grad(\n    model, None, optimizer, config, loss_fn=loss_fn\n)\n\nwf_target = run(target_circuit)\nassert torch.allclose(wf_target, model.wavefunction(), atol=1e-2)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/advanced_tutorials/differentiability/","title":"Differentiability","text":"<p>Many application in quantum computing and quantum machine learning more specifically requires the differentiation of a quantum circuit with respect to its parameters.</p> <p>In Qadence, we perform quantum computations via the <code>QuantumModel</code> interface. The derivative of the outputs of quantum models with respect to feature and variational parameters in the quantum circuit can be implemented in Qadence with two different modes:</p> <ul> <li>Automatic differentiation (AD) mode <sup>1</sup>. This mode allows to differentiation both <code>run()</code> and <code>expectation()</code> methods of the <code>QuantumModel</code> and it is the fastest available differentiation method. Under the hood, it is based on the PyTorch autograd engine wrapped by the <code>DifferentiableBackend</code> class. This mode is not working on quantum devices.</li> <li>Generalized parameter shift rule (GPSR) mode. This is general implementation of the well known parameter  shift rule algorithm <sup>2</sup> which works for arbitrary quantum operations <sup>3</sup>. This mode is only applicable to  the <code>expectation()</code> method of <code>QuantumModel</code> but it is compatible with execution or quantum devices.</li> </ul>"},{"location":"tutorials/advanced_tutorials/differentiability/#automatic-differentiation","title":"Automatic differentiation","text":"<p>Automatic differentiation <sup>1</sup> is a procedure to derive a complex function defined as a sequence of elementary mathematical operations in the form of a computer program. Automatic differentiation is a cornerstone of modern machine learning and a crucial ingredient of its recent successes. In its so-called reverse mode, it follows this sequence of operations in reverse order by systematically applying the chain rule to recover the exact value of derivative. Reverse mode automatic differentiation is implemented in Qadence leveraging the PyTorch <code>autograd</code> engine.</p> <p>Only available via the PyQTorch or Horqrux backends</p> <p>Currently, automatic differentiation mode is only available when the <code>pyqtorch</code> or <code>horqrux</code> backends are selected.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#generalized-parameter-shift-rule","title":"Generalized parameter shift rule","text":"<p>The generalized parameter shift rule implementation in Qadence was introduced in <sup>3</sup>. Here the standard parameter shift rules, which only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, was generalized to work with arbitrary generators of quantum operations.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\left\\{ \\lambda_n\\right\\}\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\(\\left\\{ \\Delta_s\\right\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> <p>\\(\\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation}\\)</p> <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> <p>\\(\\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation}\\)</p> <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#adjoint-differentiation","title":"Adjoint Differentiation","text":"<p>Qadence also offers a memory-efficient, non-device compatible alternative to automatic differentation, called 'Adjoint Differentiation' <sup>4</sup> and allows for precisely calculating the gradients of variational parameters in O(P) time and using O(1) state-vectors. Adjoint Differentation is currently only supported by the Torch Engine and allows for first-order derivatives only.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#usage","title":"Usage","text":""},{"location":"tutorials/advanced_tutorials/differentiability/#basics","title":"Basics","text":"<p>In Qadence, the differentiation modes can be selected via the <code>diff_mode</code> argument of the QuantumModel class. It either accepts a <code>DiffMode</code>(<code>DiffMode.GSPR</code>, <code>DiffMode.AD</code> or <code>DiffMode.ADJOINT</code>) or a string (<code>\"gpsr\"\"</code>, <code>\"ad\"</code> or <code>\"adjoint\"</code>). The code in the box below shows how to create <code>QuantumModel</code> instances with all available differentiation modes.</p> <pre><code>from qadence import (FeatureParameter, RX, Z, hea, chain,\n                    hamiltonian_factory, QuantumCircuit,\n                    QuantumModel, BackendName, DiffMode)\nimport torch\n\nn_qubits = 2\n\n# Define a symbolic parameter to differentiate with respect to\nx = FeatureParameter(\"x\")\n\nblock = chain(hea(n_qubits, 1), RX(0, x))\n\n# create quantum circuit\ncircuit = QuantumCircuit(n_qubits, block)\n\n# create total magnetization cost operator\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n\n# create models with AD, ADJOINT and GPSR differentiation engines\nmodel_ad = QuantumModel(circuit, obs,\n                        backend=BackendName.PYQTORCH,\n                        diff_mode=DiffMode.AD)\nmodel_adjoint = QuantumModel(circuit, obs,\n                        backend=BackendName.PYQTORCH,\n                        diff_mode=DiffMode.ADJOINT)\nmodel_gpsr = QuantumModel(circuit, obs,\n                          backend=BackendName.PYQTORCH,\n                          diff_mode=DiffMode.GPSR)\n\n# Create concrete values for the parameter we want to differentiate with respect to\nxs = torch.linspace(0, 2*torch.pi, 100, requires_grad=True)\nvalues = {\"x\": xs}\n\n# calculate function f(x)\nexp_val_ad = model_ad.expectation(values)\nexp_val_adjoint = model_adjoint.expectation(values)\nexp_val_gpsr = model_gpsr.expectation(values)\n\n# calculate derivative df/dx using the PyTorch\n# autograd engine\ndexpval_x_ad = torch.autograd.grad(\n    exp_val_ad, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_adjoint = torch.autograd.grad(\n    exp_val_adjoint, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_gpsr = torch.autograd.grad(\n    exp_val_gpsr, values[\"x\"], torch.ones_like(exp_val_gpsr), create_graph=True\n)[0]\n</code></pre> <p>We can plot the resulting derivatives and see that in both cases they coincide.</p> <pre><code>import matplotlib.pyplot as plt\n\n# plot f(x) and df/dx derivatives calculated using AD ,ADJOINT and GPSR\n# differentiation engines\nfig, ax = plt.subplots()\nax.scatter(xs.detach().numpy(),\n           exp_val_ad.detach().numpy(),\n           label=\"f(x)\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_ad.detach().numpy(),\n           label=\"df/dx AD\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_adjoint.detach().numpy(),\n           label=\"df/dx ADJOINT\")\nax.scatter(xs.detach().numpy(),\n           dexpval_x_gpsr.detach().numpy(),\n           s=5,\n           label=\"df/dx GPSR\")\nplt.legend()\n</code></pre> 2024-09-20T08:34:07.506832 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/advanced_tutorials/differentiability/#low-level-control-on-the-shift-values","title":"Low-level control on the shift values","text":"<p>In order to get a finer control over the GPSR differentiation engine we can use the low-level Qadence API to define a <code>DifferentiableBackend</code>.</p> <pre><code>from qadence.engines.torch import DifferentiableBackend\nfrom qadence.backends.pyqtorch import Backend as PyQBackend\n\n# define differentiable quantum backend\nquantum_backend = PyQBackend()\nconv = quantum_backend.convert(circuit, obs)\npyq_circ, pyq_obs, embedding_fn, params = conv\ndiff_backend = DifferentiableBackend(quantum_backend, diff_mode=DiffMode.GPSR, shift_prefac=0.2)\n\n# calculate function f(x)\nexpval = diff_backend.expectation(pyq_circ, pyq_obs, embedding_fn(params, values))\n</code></pre> <p>Here we passed an additional argument <code>shift_prefac</code> to the <code>DifferentiableBackend</code> instance that governs the magnitude of shifts \\(\\delta\\equiv\\alpha\\delta^\\prime\\) shown in equation (2) above. In this relation \\(\\delta^\\prime\\) is set internally and \\(\\alpha\\) is the value passed by <code>shift_prefac</code> and the resulting shift value \\(\\delta\\) is then used in all the following GPSR calculations.</p> <p>Tuning parameter \\(\\alpha\\) is useful to improve results when the generator \\(\\hat{G}\\) or the quantum operation is a dense matrix, for example a complex <code>HamEvo</code> operation; if many entries of this matrix are sufficiently larger than 0 the operation is equivalent to a strongly interacting system. In such case parameter \\(\\alpha\\) should be gradually lowered in order to achieve exact derivative values.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#low-level-differentiation-of-qadence-circuits-using-jax","title":"Low-level differentiation of qadence circuits using JAX","text":"<p>For users interested in using the <code>JAX</code> engine instead, we show how to run and differentiate qadence programs using the <code>horqrux</code> backend under qadence examples.</p>"},{"location":"tutorials/advanced_tutorials/differentiability/#references","title":"References","text":"<ol> <li> <p>A. G. Baydin et al., Automatic Differentiation in Machine Learning: a Survey \u21a9\u21a9</p> </li> <li> <p>Schuld et al., Evaluating analytic gradients on quantum hardware (2018). \u21a9</p> </li> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9\u21a9</p> </li> <li> <p>Tyson et al., Efficient calculation of gradients in classical simulations of variational quantum algorithms \u21a9</p> </li> </ol>"},{"location":"tutorials/advanced_tutorials/profiling-and-debugging/","title":"Profiling and debugging on CUDA devices","text":"<p>For this to work, you'll have to have the right to access perf counters on your machine (for example with sudo or inside a Docker container). See: https://docs.nvidia.com/deeplearning/frameworks/dlprof-user-guide/index.html.</p> <pre><code>$ pip install nvidia-pyindex\n$ pip install nvidia-dlprof[pytorch]\n</code></pre> <p>Make sure that your entrypoint is an executable script. That means that it must start with a she-bang on the top line, e.g. <pre><code>#!/bin/python\n</code></pre> and have execution rights <pre><code>$ chmod +x your_script.py\n</code></pre></p> <p>Lastly it's recommended to add <pre><code>import nvidia_dlprof_pytorch_nvtx\nnvidia_dlprof_pytorch_nvtx.init()\n</code></pre> To your script in the beginning enable extra annotations of PyTorch functions.</p> <p>You can then use dlprof to profile. <pre><code>dlprof --mode=pytorch your_script.py\n</code></pre></p> <pre><code>PYQ_LOG_LEVEL=info QADENCE_LOG_LEVEL=debug dlprof --mode=pytorch examples/backends/differentiable_backend.py\n</code></pre> <p>For example to achieve this through Docker we can start a session in the shell, also mounting our local Qadence version and PyQTorch (Both optional, but you probably need to mount your script at least) <pre><code>$ docker run --rm --gpus=1 --shm-size=1g --ulimit memlock=-1 \\\n --ulimit stack=67108864 -it -p8000:8000 -v./:/opt/qadence -v ../PyQ:/opt/pyqtorch pytorch:24.02-py3 bash\n</code></pre> (You may need to jump through extra hoops to make Docker access the GPUs if you have error messages like <code>docker: Error response from daemon: could not select device driver \"\" with capabilities: [[gpu]].</code>)</p> <p>After this you should have a shell inside the container and you can <pre><code>root@2a85826c4e7b:/workspace# cd /opt/qadence/\nroot@2a85826c4e7b:/opt/qadence# pip3 install -e .\nroot@2a85826c4e7b:/opt/qadence# pip3 install -e ../pyqtorch/\nroot@2a85826c4e7b:/opt/qadence# pip3 install nvidia-dlprof[pytorch]\nroot@2a85826c4e7b:/opt/qadence# PYQ_LOG_LEVEL=debug QADENCE_LOG_LEVEL=debug dlprof --mode=pytorch --nsys_opts=\"-t cuda,nvtx,cublas,cusparse,cusparse-verbose,cublas-verbose --force-overwrite true\" examples/models/quantum_model.py\n</code></pre></p> <p>Where we have <code>--force-overwrite true</code> to always store the latest profiling result (hence you must rename the file) if you wish to keep several. We add <code>cublas,cusparse,cusparse-verbose,cublas-verbose</code> do get more details about the numerical backend pacakges being used.</p>"},{"location":"tutorials/advanced_tutorials/projectors/","title":"Projector blocks","text":"<p>This section introduces the <code>ProjectorBlock</code> as an implementation for the quantum mechanical projection operation onto the subspace spanned by \\(|a\\rangle\\): \\(\\mathbb{\\hat{P}}=|a\\rangle \\langle a|\\). It evaluates the outer product for bras and kets expressed as bitstrings for a given qubit support. They have to possess matching lengths.</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence.operations import Projector  # Projector as an operation.\n\n# Define a projector for |1&gt; onto the qubit labelled 0.\nprojector_block = Projector(ket=\"1\", bra=\"1\", qubit_support=0)\n\n# As any block, the matrix representation can be retrieved.\nprojector_matrix = block_to_tensor(projector_block)\n</code></pre> <pre><code>projector matrix = tensor([[[0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j]]])\n</code></pre> <p>Other standard operations are expressed as projectors in Qadence. For instance, the number operator is the projector onto the 1-subspace, \\(N=|1\\rangle\\langle 1|\\).</p> <p>In fact, projectors can be used to compose any arbitrary operator. For example, the <code>CNOT</code> can be defined as \\(\\textrm{CNOT}(i,j)=|0\\rangle\\langle 0|_i\\otimes \\mathbb{I}_j+|1\\rangle\\langle 1|_i\\otimes X_j\\) and we can compare its matrix representation with the native one in Qadence:</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence import kron, I, X, CNOT\n\n# Define a projector for |0&gt; onto the qubit labelled 0.\nprojector0 = Projector(ket=\"0\", bra=\"0\", qubit_support=0)\n\n# Define a projector for |1&gt; onto the qubit labelled 0.\nprojector1 = Projector(ket=\"1\", bra=\"1\", qubit_support=0)\n\n# Construct the projector controlled CNOT.\nprojector_cnot = kron(projector0, I(1)) + kron(projector1, X(1))\n\n# Get the underlying unitary.\nprojector_cnot_matrix = block_to_tensor(projector_cnot)\n\n# Qadence CNOT unitary.\nqadence_cnot_matrix = block_to_tensor(CNOT(0,1))\n</code></pre> <pre><code>projector cnot matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\nqadence cnot matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> <p>Another example is the canonical SWAP unitary that can be defined as \\(SWAP=|00\\rangle\\langle 00|+|01\\rangle\\langle 10|+|10\\rangle\\langle 01|+|11\\rangle\\langle 11|\\). Indeed, it can be shown that their matricial representations are again identical:</p> <pre><code>from qadence.blocks import block_to_tensor\nfrom qadence import SWAP\n\n# Define all projectors.\nprojector00 = Projector(ket=\"00\", bra=\"00\", qubit_support=(0, 1))\nprojector01 = Projector(ket=\"01\", bra=\"10\", qubit_support=(0, 1))\nprojector10 = Projector(ket=\"10\", bra=\"01\", qubit_support=(0, 1))\nprojector11 = Projector(ket=\"11\", bra=\"11\", qubit_support=(0, 1))\n\n# Construct the SWAP gate.\nprojector_swap = projector00 + projector10 + projector01 + projector11\n\n# Get the underlying unitary.\nprojector_swap_matrix = block_to_tensor(projector_swap)\n\n# Qadence SWAP unitary.\nqadence_swap_matrix = block_to_tensor(SWAP(0,1))\n</code></pre> <pre><code>projector swap matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]]])\nqadence swap matrix = tensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n         [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n         [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]]], grad_fn=&lt;UnsafeViewBackward0&gt;)\n</code></pre> <p>Warning</p> <p>Projectors are non-unitary operators, only supported by the PyQTorch backend.</p> <p>To examplify this point, let's run some non-unitary computation involving projectors.</p> <pre><code>from qadence import chain, run\nfrom qadence.operations import H, CNOT\n\n# Define a projector for |1&gt; onto the qubit labelled 1.\nprojector_block = Projector(ket=\"1\", bra=\"1\", qubit_support=1)\n\n# Some non-unitary computation.\nnon_unitary_block = chain(H(0), CNOT(0,1), projector_block)\n\n# Projected wavefunction becomes unnormalized\nprojected_wf = run(non_unitary_block)  # Run on PyQTorch.\n</code></pre> <pre><code>projected_wf = tensor([[0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre>"},{"location":"tutorials/development/architecture/","title":"Architecture and sharp bits","text":"<p>Qadence as a software library mixes functional and object-oriented programming. We do that by maintaining core objects and operating on them with functions.</p> <p>Furthermore, Qadence strives at keeping the lower level abstraction layers for automatic differentiation and quantum computation fully stateless while only the frontend layer which is the main user-facing interface is stateful.</p> <p>Code design philosopy</p> <p>Functional, stateless core with object-oriented, stateful user interface.</p>"},{"location":"tutorials/development/architecture/#abstraction-layers","title":"Abstraction layers","text":"<p>In Qadence there are 4 main objects spread across 3 different levels of abstraction:</p> <ul> <li> <p>Frontend layer: The user facing layer and encompasses two objects:</p> <ul> <li><code>QuantumCircuit</code>: A class representing an abstract quantum   circuit not tight not any particular framework. Parameters are represented symbolically using   <code>sympy</code> expressions.</li> <li><code>QuantumModel</code>: The models are higher-level abstraction   providing an interface for executing different kinds of common quantum computing models such   quantum neural networks (QNNs), quantum kernels etc.</li> </ul> </li> <li> <p>Differentiation layer: Intermediate layer has the purpose of integrating quantum   computation with a given automatic differentiation engine. It is meant to be purely stateless and   contains one object:</p> <ul> <li><code>DifferentiableBackend</code>:   An abstract class whose concrete implementation wraps a quantum backend and make it   automatically differentiable using different engines (e.g. PyTorch or Jax).   Note, that today only PyTorch is supported but there is plan to add also a Jax   differentiable backend which will require some changes in the base class implementation.</li> </ul> </li> <li> <p>Quantum layer: The lower-level layer which directly interfaces with quantum emulators   and processing units. It is meant to be purely stateless and it contains one base object which is   specialized for each supported backend:</p> <ul> <li><code>Backend</code>: An abstract class whose concrete implementation   enables the execution of quantum circuit with a variety of quantum backends (normally non   automatically differentiable by default) such as PyQTorch, Pulser or Braket.</li> </ul> </li> </ul>"},{"location":"tutorials/development/architecture/#main-components","title":"Main components","text":""},{"location":"tutorials/development/architecture/#quantumcircuit","title":"<code>QuantumCircuit</code>","text":"<p>We consider <code>QuantumCircuit</code> to be an abstract object, i.e. it is not tied to any backend. However, it blocks are even more abstract. This is because we consider <code>QuantumCircuit</code>s \"real\", whereas the blocks are largely considered just syntax.</p> <p>Unitary <code>QuantumCircuits</code> (this encompasses digital, or gate-based, circuits as well as analog circuits) are constructed by [<code>PrimitiveBlocks</code>] using a syntax that allows you to execute them in sequence, dubbed <code>ChainBlock</code> in the code, or in parallel (i.e. at the same time) where applicable, dubbed <code>KronBlock</code> in the code. Notice that this differs from other packages by providing more control of the layout of the circuit than conventional packages like Qiskit, and from Yao where the blocks are the primary type.</p>"},{"location":"tutorials/development/architecture/#quantummodel","title":"<code>QuantumModel</code>","text":"<p><code>QuantumModel</code>s are meant to be the main entry point for quantum computations in <code>qadence</code>. In general, they take one or more quantum circuit as input and they wrap all the necessary boiler plate code to make the circuit executable and differentiable on the chosen backend.</p> <p>Models are meant to be specific for a certain kind of quantum problem or algorithm and you can easily create new ones starting from the base class <code>QuantumModel</code>, as explained in the custom model tutorial. Currently, Qadence offers a <code>QNN</code> model class which provides convenient methods to work with quantum neural networks with multi-dimensional inputs and outputs.</p>"},{"location":"tutorials/development/architecture/#differentiablebackend","title":"<code>DifferentiableBackend</code>","text":"<p>The differentiable backend is a thin wrapper which takes as input a <code>QuantumCircuit</code> instance and a chosen quantum backend and make the circuit execution routines (expectation value, overalap, etc.) differentiable. Qadence offers both a PyTorch and Jax differentiation engine.</p>"},{"location":"tutorials/development/architecture/#quantum-backend","title":"Quantum <code>Backend</code>","text":"<p>For execution the primary object is the <code>Backend</code>. Backends maintain the same user-facing interface, and internally connects to other libraries to execute circuits. Those other libraries can execute the code on QPUs and local or cloud-based emulators. The <code>Backends</code> use PyTorch tensors to represent data and leverages PyTorchs autograd to help compute derivatives of circuits.</p>"},{"location":"tutorials/development/architecture/#symbolic-parameters","title":"Symbolic parameters","text":"<p>To illustrate how parameters work in Qadence, let's consider the following simple block composed of just two rotations:</p> <pre><code>import sympy\nfrom qadence import Parameter, RX\n\nparam = Parameter(\"phi\", trainable=False)\nblock = RX(0, param) * RX(1, sympy.acos(param))\n</code></pre> <p>The rotation angles assigned to <code>RX</code> (and to any Qadence quantum operation) are defined as arbitrary expressions of <code>Parameter</code>'s. <code>Parameter</code> is a subclass of <code>sympy.Symbol</code>, thus fully interoperable with it.</p> <p>To assign values of the parameter <code>phi</code> in a quantum model, one should use a dictionary containing the a key with parameter name and the corresponding values values:</p> <pre><code>import torch\nfrom qadence import run\n\nvalues = {\"phi\": torch.rand(10)}\nwf = run(block, values=values)\n</code></pre> <p>This is the only interface for parameter assignment exposed to the user. Under the hood, parameters applied to every quantum operation are identified in different ways:</p> <ul> <li> <p>By default, with a stringified version of the <code>sympy</code> expression supplied to the quantum operation. Notice that multiple operations can have the same expression.</p> </li> <li> <p>In certain case, e.g. for constructing parameter shift rules, one must access a unique identifier of the parameter for each quantum operation. Therefore, Qadence also creates unique identifiers for each parametrized operation (see the <code>ParamMap</code> class).</p> </li> </ul> <p>By default, when one constructs a new backend, the parameter identifiers are the <code>sympy</code> expressions which are used when converting an abstract block into a native circuit for the chosen backend. However, one can use the unique identifiers as parameter names by setting the private flag <code>_use_gate_params</code> to <code>True</code> in the backend configuration <code>BackendConfiguration</code>. This is automatically set when PSR differentiation is selected (see next section for more details).</p> <p>You can see the logic for choosing the parameter identifier in <code>get_param_name</code>.</p>"},{"location":"tutorials/development/architecture/#differentiation-with-parameter-shift-rules-psr","title":"Differentiation with parameter shift rules (PSR)","text":"<p>In Qadence, parameter shift rules are applied by implementing a custom <code>torch.autograd.Function</code> class for PyTorch and the <code>custom_vjp</code> in the Jax Engine, respectively.</p> <p>A custom PyTorch <code>Function</code> looks like this:</p> <pre><code>import torch\nfrom torch.autograd import Function\n\nclass CustomFunction(Function):\n\n    # forward pass implementation giving the output of the module\n    @staticmethod\n    def forward(ctx, inputs: torch.Tensor, params: torch.Tensor):\n        ctx.save_for_backward(inputs, params)\n        ...\n\n    # backward pass implementation giving the derivative of the module\n    # with respect to the parameters. This must return the whole vector-jacobian\n    # product to integrate within the autograd engine\n    @staticmethod\n    def backward(ctx, grad_output: torch.Tensor):\n        inputs, params = ctx.saved_tensors\n        ...\n</code></pre> <p>The class <code>PSRExpectation</code> under <code>qadence.engines.torch.differentiable_expectation</code> implements parameter shift rules for all parameters using a custom function as the one above. There are a few implementation details to keep in mind if you want to modify the PSR code:</p> <ul> <li> <p>PyTorch <code>Function</code> only works with tensor arguments. Parameters in Qadence are passed around as   dictionaries with parameter names as keys and current parameter values (tensors)   as values. This works for both variational and feature parameters. However, the <code>Function</code> class   only work with PyTorch tensors as input, not dictionaries. Therefore, the forward pass of   <code>PSRExpectation</code> accepts one argument <code>param_keys</code> with the   parameter keys and a variadic positional argument <code>param_values</code> with the parameter values one by   one. The dictionary is reconstructed within the <code>forward()</code> pass body.</p> </li> <li> <p>Higher-order derivatives with PSR. Higher-order PSR derivatives can be tricky. Parameter shift   rules calls, under the hood, the <code>QuantumBackend</code> expectation value routine that usually yield a   non-differentiable output. Therefore, a second call to the backward pass would not work. However,   Qadence employs a very simple trick to make higher-order derivatives work: instead of using   directly the expectation value of the quantum backend, the PSR backward pass uses the PSR forward   pass itself as expectation value function (see the code below). In this way, multiple calls to the   backward pass are allowed since the <code>expectation_fn</code> routine is always differentiable by   definition. Notice that this implementation is simple but suboptimal since, in some corner cases,   higher-order derivates might include some repeated terms that, with this implementation, are   always recomputed.</p> </li> </ul> <pre><code># expectation value used in the PSR backward pass\ndef expectation_fn(params: dict[str, Tensor]) -&gt; Tensor:\n    return PSRExpectation.apply(\n        ctx.expectation_fn,\n        ctx.param_psrs,\n        params.keys(),\n        *params.values(),\n    )\n</code></pre> <ul> <li> <p>Operation parameters must be uniquely identified for PSR to work. Parameter shift rules work at the level of individual quantum operations. This means that, given a parameter <code>x</code>, one needs to sum the contributions from shifting the parameter values of all the operation where the parameter <code>x</code> appears. When constructing the PSR rules, one must access a unique parameter identifier for each operation even if the corresponding user-facing parameter is the same. Therefore, when PSR differentiation is selected, the flag <code>_use_gate_params</code> is automatically set to <code>True</code> in the backend configuration <code>BackendConfiguration</code> (see previous section).</p> </li> <li> <p>PSR must not be applied to observable parameters. In Qadence, Pauli observables can also be parametrized. However, the tunable parameters of observables are purely classical and should not be included in the differentiation with PSRs. However, the quantum expectation value depends on them, thus they still need to enter into the PSR evaluation. To solve this issue, the code sets the <code>requires_grad</code> attribute of all observable parameters to <code>False</code> when constructing the PSRs for the circuit as in the snippet below:</p> </li> </ul> <pre><code>for obs in observable:\n    for param_id, _ in uuid_to_eigen(obs).items():\n        param_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\n</code></pre>"},{"location":"tutorials/development/draw/","title":"<code>qadence.draw</code> example plots","text":"<p>Mostly for quick, manual checking of correct plotting output.</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\n\nb = kron(X(0), Y(1))\n</code></pre> %3 abfd032b8e7247f8b271c4b0134f1d89 0 41b8c4ce6d0e4076940eaebd1e0d2982 X abfd032b8e7247f8b271c4b0134f1d89--41b8c4ce6d0e4076940eaebd1e0d2982 a62fa9d8a530436bbced3c10bed2d6c9 1 aa3feeceff4a4017869ea0f7f267514a 41b8c4ce6d0e4076940eaebd1e0d2982--aa3feeceff4a4017869ea0f7f267514a c8735a5ab7b947e89f14b34edfa32912 60bac353194d4fd598ec51bae2336e21 Y a62fa9d8a530436bbced3c10bed2d6c9--60bac353194d4fd598ec51bae2336e21 60bac353194d4fd598ec51bae2336e21--c8735a5ab7b947e89f14b34edfa32912 <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\n\nb = chain(X(0), Y(0))\n</code></pre> %3 fa151c28fcff4938adfb87cd634fba9c 0 c2b6e14872324614b64f18a74f9dd485 X fa151c28fcff4938adfb87cd634fba9c--c2b6e14872324614b64f18a74f9dd485 2cdd542c69fd4fb89342ef11869d833c Y c2b6e14872324614b64f18a74f9dd485--2cdd542c69fd4fb89342ef11869d833c 3c4bbe9f2e8348c1bc7315af83ba43a8 2cdd542c69fd4fb89342ef11869d833c--3c4bbe9f2e8348c1bc7315af83ba43a8 <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\n\nb = chain(X(0), Y(1))\n</code></pre> %3 4bf3b56e16564646bda87b70cf3919ec 0 79211878871043c29db8e8dd5dac2cbd X 4bf3b56e16564646bda87b70cf3919ec--79211878871043c29db8e8dd5dac2cbd b9929934bacd4fde91f710ef7c035fd5 1 913188d0c0cb4982ab9b8aa54b47dc12 79211878871043c29db8e8dd5dac2cbd--913188d0c0cb4982ab9b8aa54b47dc12 46d30057bdc644e4aae485418f878268 913188d0c0cb4982ab9b8aa54b47dc12--46d30057bdc644e4aae485418f878268 07ef90f2d7fd4f87903bb05b48920b67 c516df70af2249309549509e4cca6631 b9929934bacd4fde91f710ef7c035fd5--c516df70af2249309549509e4cca6631 0adcdc9a35f3414b9d433a6961e71f8e Y c516df70af2249309549509e4cca6631--0adcdc9a35f3414b9d433a6961e71f8e 0adcdc9a35f3414b9d433a6961e71f8e--07ef90f2d7fd4f87903bb05b48920b67 <pre><code>from qadence import X, Y, add\nfrom qadence.draw import display\n\nb = add(X(0), Y(1), X(2))\n</code></pre> %3 cluster_152d6d037a9e42e9a1862cda0212d366 d60c13967b4d448fa6f859968700452c 0 c655e535367f41bc8df64d20085b433a d60c13967b4d448fa6f859968700452c--c655e535367f41bc8df64d20085b433a 5b3c71902e4e428db2edac9e5d232ac8 1 2d4cf7bb09184dd89950f85b7cb5e78e c655e535367f41bc8df64d20085b433a--2d4cf7bb09184dd89950f85b7cb5e78e 4d7a2f20350d427eaa699ce05ea8c177 dd395aef845c414daeb9e32b7dc24419 AddBlock 5b3c71902e4e428db2edac9e5d232ac8--dd395aef845c414daeb9e32b7dc24419 b5dc141e972c40bc9d86976181a97589 2 dd395aef845c414daeb9e32b7dc24419--4d7a2f20350d427eaa699ce05ea8c177 b7dc058375df450290f15ab83ddf31b3 5e9d5bfee543482dbb737e424234bdb7 b5dc141e972c40bc9d86976181a97589--5e9d5bfee543482dbb737e424234bdb7 5e9d5bfee543482dbb737e424234bdb7--b7dc058375df450290f15ab83ddf31b3 <pre><code>from qadence import CNOT, RX, HamEvo, X, Y, Z, chain, kron\n\nrx = kron(RX(3,0.5), RX(2, \"x\"))\nrx.tag = \"rx\"\ngen = chain(Z(i) for i in range(4))\n\n# `chain` puts things in sequence\nblock = chain(\n    kron(X(0), Y(1), rx),\n    CNOT(2,3),\n    HamEvo(gen, 10)\n)\n</code></pre> %3 cluster_3ba698d1bf1c4d9f901595d331a771d8 cluster_e0b1d40be44c4cb78cce4514937c3342 rx 8c6f56369b92495eb9fdec7fd017526e 0 19667cb34995478a91b0e4fae2241d94 X 8c6f56369b92495eb9fdec7fd017526e--19667cb34995478a91b0e4fae2241d94 2dd9327eb71b4b04bafb63b0a19b9990 1 fab72cff9c004b0aa47ce65a7f9ace86 19667cb34995478a91b0e4fae2241d94--fab72cff9c004b0aa47ce65a7f9ace86 4afe6498d0ff4b2bbbb88ea72bdf523f fab72cff9c004b0aa47ce65a7f9ace86--4afe6498d0ff4b2bbbb88ea72bdf523f e9ff110f4ac94805b1d489a477d1100a 4afe6498d0ff4b2bbbb88ea72bdf523f--e9ff110f4ac94805b1d489a477d1100a 7b4f4d512f314547a1b6378eff7a0e83 12ee4304688c421bac34213c3cc7ca84 Y 2dd9327eb71b4b04bafb63b0a19b9990--12ee4304688c421bac34213c3cc7ca84 f6a184852f5f4acd94049e2ef1674964 2 4d9ab926d1a44a0c8a9ddfb4ea1b1f61 12ee4304688c421bac34213c3cc7ca84--4d9ab926d1a44a0c8a9ddfb4ea1b1f61 18e4a852ad134155980524d4b3039601 HamEvo 4d9ab926d1a44a0c8a9ddfb4ea1b1f61--18e4a852ad134155980524d4b3039601 18e4a852ad134155980524d4b3039601--7b4f4d512f314547a1b6378eff7a0e83 66168c0bd1e34e178be15f6c5f4bf791 77be47ffc7ed494f9d4a0d51ee46c38e RX(x) f6a184852f5f4acd94049e2ef1674964--77be47ffc7ed494f9d4a0d51ee46c38e fdce2191b44143e380febc2db97ca9f4 3 9a908ceda21d42f8829367849c0e730a 77be47ffc7ed494f9d4a0d51ee46c38e--9a908ceda21d42f8829367849c0e730a 80709b9f73044b9ca1e8fdef0c4da03c t = 10 9a908ceda21d42f8829367849c0e730a--80709b9f73044b9ca1e8fdef0c4da03c 80709b9f73044b9ca1e8fdef0c4da03c--66168c0bd1e34e178be15f6c5f4bf791 9c715679956044d28e1d23b72ca56742 8e1cc2f697674a11803c4ccbecc2dbc9 RX(0.5) fdce2191b44143e380febc2db97ca9f4--8e1cc2f697674a11803c4ccbecc2dbc9 4c19b429c2264d9aa739e05a04460b64 X 8e1cc2f697674a11803c4ccbecc2dbc9--4c19b429c2264d9aa739e05a04460b64 4c19b429c2264d9aa739e05a04460b64--9a908ceda21d42f8829367849c0e730a d8b0bfda55944e41bd4c8ec0d0155931 4c19b429c2264d9aa739e05a04460b64--d8b0bfda55944e41bd4c8ec0d0155931 d8b0bfda55944e41bd4c8ec0d0155931--9c715679956044d28e1d23b72ca56742 <pre><code>from qadence import feature_map, hea, chain\n\nblock = chain(feature_map(4, reupload_scaling=\"Tower\"), hea(4,2))\n</code></pre> %3 cluster_7ff107da122649339f838293b7e05d7f HEA cluster_8774637ee56d43a9ba7a140be23d1eb1 Tower Fourier FM 34db9b27200349c3a0a32a6441b76d9e 0 513362f4086947bbb6dc0df3c776458e RX(1.0*phi) 34db9b27200349c3a0a32a6441b76d9e--513362f4086947bbb6dc0df3c776458e 23b107471c374d819f6307b197289c5f 1 751167faa4f94e00bf293f80efdf764f RX(theta\u2080) 513362f4086947bbb6dc0df3c776458e--751167faa4f94e00bf293f80efdf764f f99742784e1649e68162fb37cb488ef6 RY(theta\u2084) 751167faa4f94e00bf293f80efdf764f--f99742784e1649e68162fb37cb488ef6 ef08b0f51af74066ada83772e1a0cdbe RX(theta\u2088) f99742784e1649e68162fb37cb488ef6--ef08b0f51af74066ada83772e1a0cdbe e14ebeee701b40c7a0601bc6c584de49 ef08b0f51af74066ada83772e1a0cdbe--e14ebeee701b40c7a0601bc6c584de49 e6282eb913db46fda21e1c73eee5b37e e14ebeee701b40c7a0601bc6c584de49--e6282eb913db46fda21e1c73eee5b37e 1b33664ac61047c7a00e0881ba6c0131 RX(theta\u2081\u2082) e6282eb913db46fda21e1c73eee5b37e--1b33664ac61047c7a00e0881ba6c0131 2153beb5302140eba2c0bcd8862edc2f RY(theta\u2081\u2086) 1b33664ac61047c7a00e0881ba6c0131--2153beb5302140eba2c0bcd8862edc2f c079e4fb10184ed98b83580d3f7caa26 RX(theta\u2082\u2080) 2153beb5302140eba2c0bcd8862edc2f--c079e4fb10184ed98b83580d3f7caa26 ee998453d4764b46884d92576e2172d8 c079e4fb10184ed98b83580d3f7caa26--ee998453d4764b46884d92576e2172d8 309f7117df67451e80d3c457afdf8a41 ee998453d4764b46884d92576e2172d8--309f7117df67451e80d3c457afdf8a41 b4f48d56b780414fa7eb8e763e2ed2a3 309f7117df67451e80d3c457afdf8a41--b4f48d56b780414fa7eb8e763e2ed2a3 63198c2d85d4404a9cb3459a60882ba2 dde30897b64f4560a3bcf9c503044665 RX(2.0*phi) 23b107471c374d819f6307b197289c5f--dde30897b64f4560a3bcf9c503044665 5c3ca30f1ae8448ab6dcf38f48b4375e 2 e30be129a8e545d2b53d577679177e5c RX(theta\u2081) dde30897b64f4560a3bcf9c503044665--e30be129a8e545d2b53d577679177e5c fdf03e98ed784494811d4df7d1e3d0f1 RY(theta\u2085) e30be129a8e545d2b53d577679177e5c--fdf03e98ed784494811d4df7d1e3d0f1 5d37594fdf344c5b88761cec76ce2ef3 RX(theta\u2089) fdf03e98ed784494811d4df7d1e3d0f1--5d37594fdf344c5b88761cec76ce2ef3 be742bece38c44b3badc71087d486a07 X 5d37594fdf344c5b88761cec76ce2ef3--be742bece38c44b3badc71087d486a07 be742bece38c44b3badc71087d486a07--e14ebeee701b40c7a0601bc6c584de49 16676cbcf49c43dd948797910a954719 be742bece38c44b3badc71087d486a07--16676cbcf49c43dd948797910a954719 f152b7fb1044449ca38b7b6d362d1ed7 RX(theta\u2081\u2083) 16676cbcf49c43dd948797910a954719--f152b7fb1044449ca38b7b6d362d1ed7 5dd2022b5ac544e8828dfb9905261530 RY(theta\u2081\u2087) f152b7fb1044449ca38b7b6d362d1ed7--5dd2022b5ac544e8828dfb9905261530 43d6a3cf1302448888e660b8f6ccaead RX(theta\u2082\u2081) 5dd2022b5ac544e8828dfb9905261530--43d6a3cf1302448888e660b8f6ccaead 400d579a67b049548840189d7b6e6a8b X 43d6a3cf1302448888e660b8f6ccaead--400d579a67b049548840189d7b6e6a8b 400d579a67b049548840189d7b6e6a8b--ee998453d4764b46884d92576e2172d8 58b34480c74b49a3ad987bf5218c3ce9 400d579a67b049548840189d7b6e6a8b--58b34480c74b49a3ad987bf5218c3ce9 58b34480c74b49a3ad987bf5218c3ce9--63198c2d85d4404a9cb3459a60882ba2 c316d05af6b440fd9de7c47cbe488e51 395a7ade8c0046c58cbc5826b3a03d1e RX(3.0*phi) 5c3ca30f1ae8448ab6dcf38f48b4375e--395a7ade8c0046c58cbc5826b3a03d1e 4f43ef0d413e464d8ac8ba51e7fc6322 3 358a0b8c38ae4bedb6c4414a68d91ac6 RX(theta\u2082) 395a7ade8c0046c58cbc5826b3a03d1e--358a0b8c38ae4bedb6c4414a68d91ac6 ba611b43f32d4754900ed6e69368d6c4 RY(theta\u2086) 358a0b8c38ae4bedb6c4414a68d91ac6--ba611b43f32d4754900ed6e69368d6c4 b75a6a16840d494eb18ccfc49dc07af3 RX(theta\u2081\u2080) ba611b43f32d4754900ed6e69368d6c4--b75a6a16840d494eb18ccfc49dc07af3 172a7b5750d44e3a93b0cf643b2b02f3 b75a6a16840d494eb18ccfc49dc07af3--172a7b5750d44e3a93b0cf643b2b02f3 6b9614929cb74e7f928d40cb3addbdae X 172a7b5750d44e3a93b0cf643b2b02f3--6b9614929cb74e7f928d40cb3addbdae 6b9614929cb74e7f928d40cb3addbdae--16676cbcf49c43dd948797910a954719 eab5be6bace345d69c220d0423530074 RX(theta\u2081\u2084) 6b9614929cb74e7f928d40cb3addbdae--eab5be6bace345d69c220d0423530074 b14f5fa955e3421ca005ee80b6cfb146 RY(theta\u2081\u2088) eab5be6bace345d69c220d0423530074--b14f5fa955e3421ca005ee80b6cfb146 bed0b4f907af4bb38a8bf68cf4a6b8e3 RX(theta\u2082\u2082) b14f5fa955e3421ca005ee80b6cfb146--bed0b4f907af4bb38a8bf68cf4a6b8e3 36d13b6d14284f9d81cedf1397235edd bed0b4f907af4bb38a8bf68cf4a6b8e3--36d13b6d14284f9d81cedf1397235edd 794bac5e32e345c1a91fc39d2d108ee1 X 36d13b6d14284f9d81cedf1397235edd--794bac5e32e345c1a91fc39d2d108ee1 794bac5e32e345c1a91fc39d2d108ee1--58b34480c74b49a3ad987bf5218c3ce9 794bac5e32e345c1a91fc39d2d108ee1--c316d05af6b440fd9de7c47cbe488e51 ca5f390fd2f2485db188e57c96df94fc 83e0aa9cfde54a17af89417aedb54fb5 RX(4.0*phi) 4f43ef0d413e464d8ac8ba51e7fc6322--83e0aa9cfde54a17af89417aedb54fb5 53b5f71dd19f496a8b5efd8ab9896e30 RX(theta\u2083) 83e0aa9cfde54a17af89417aedb54fb5--53b5f71dd19f496a8b5efd8ab9896e30 e0f4f615860d41de88bb76818666f09b RY(theta\u2087) 53b5f71dd19f496a8b5efd8ab9896e30--e0f4f615860d41de88bb76818666f09b 982d0cf2594644af9e96be9202769a12 RX(theta\u2081\u2081) e0f4f615860d41de88bb76818666f09b--982d0cf2594644af9e96be9202769a12 b257b5c8cb76418b8a8bbf58c8dec683 X 982d0cf2594644af9e96be9202769a12--b257b5c8cb76418b8a8bbf58c8dec683 b257b5c8cb76418b8a8bbf58c8dec683--172a7b5750d44e3a93b0cf643b2b02f3 2e4a7bb8a2cd492c861e392d62d0caf6 b257b5c8cb76418b8a8bbf58c8dec683--2e4a7bb8a2cd492c861e392d62d0caf6 8b5fa6bac87c4701a80ec3734a93eb82 RX(theta\u2081\u2085) 2e4a7bb8a2cd492c861e392d62d0caf6--8b5fa6bac87c4701a80ec3734a93eb82 1bfd87a952e74534b0d612ba6511c600 RY(theta\u2081\u2089) 8b5fa6bac87c4701a80ec3734a93eb82--1bfd87a952e74534b0d612ba6511c600 f283fd4ec5794f7aad3f70a20c25f238 RX(theta\u2082\u2083) 1bfd87a952e74534b0d612ba6511c600--f283fd4ec5794f7aad3f70a20c25f238 db3263059e0143dcbd3ddefcd4b2564f X f283fd4ec5794f7aad3f70a20c25f238--db3263059e0143dcbd3ddefcd4b2564f db3263059e0143dcbd3ddefcd4b2564f--36d13b6d14284f9d81cedf1397235edd adff8c83a1ef4eefaf76c9051835a0b6 db3263059e0143dcbd3ddefcd4b2564f--adff8c83a1ef4eefaf76c9051835a0b6 adff8c83a1ef4eefaf76c9051835a0b6--ca5f390fd2f2485db188e57c96df94fc <pre><code>from qadence import QuantumModel, QuantumCircuit, total_magnetization, hea\n\nmodel = QuantumModel(QuantumCircuit(3, hea(3,2)), total_magnetization(3))\n</code></pre> %3 cluster_455b3f72ca8a4f63a2ab44c035bd9ebe Obs. cluster_c827464410714f95a90b96a7688f6a61 cluster_49414dd469954280af8f9031bbbc18e5 HEA 1ee5ecc6366a48c4a0258886fa6ffa28 0 ec908f7824944d7eb29cbe583372a408 RX(theta\u2080) 1ee5ecc6366a48c4a0258886fa6ffa28--ec908f7824944d7eb29cbe583372a408 a0a6e4f090764215adb31dc8bc2abeb6 1 ee1896d7a21743b68804c3d151e0d767 RY(theta\u2083) ec908f7824944d7eb29cbe583372a408--ee1896d7a21743b68804c3d151e0d767 dd14ce3c500842ec89ea2a2ded0c8eab RX(theta\u2086) ee1896d7a21743b68804c3d151e0d767--dd14ce3c500842ec89ea2a2ded0c8eab 5439e7c25825426c83342a7b8ceba163 dd14ce3c500842ec89ea2a2ded0c8eab--5439e7c25825426c83342a7b8ceba163 a45749a8c4f64a51b0d9b2c18fdd5d29 5439e7c25825426c83342a7b8ceba163--a45749a8c4f64a51b0d9b2c18fdd5d29 affc93faf491481598f9020955bf74f1 RX(theta\u2089) a45749a8c4f64a51b0d9b2c18fdd5d29--affc93faf491481598f9020955bf74f1 185af4270400454bb359c5d60e2f4a16 RY(theta\u2081\u2082) affc93faf491481598f9020955bf74f1--185af4270400454bb359c5d60e2f4a16 aad70295302640819d166e887a572737 RX(theta\u2081\u2085) 185af4270400454bb359c5d60e2f4a16--aad70295302640819d166e887a572737 047be8cfb2044450af9e203cf160483f aad70295302640819d166e887a572737--047be8cfb2044450af9e203cf160483f 6eb1a9e988654fcd9f2fad87042a6ccb 047be8cfb2044450af9e203cf160483f--6eb1a9e988654fcd9f2fad87042a6ccb 96d2ca428df546289cd075c52736cbf4 6eb1a9e988654fcd9f2fad87042a6ccb--96d2ca428df546289cd075c52736cbf4 2faa37cc0477465e9196d10a3326b211 96d2ca428df546289cd075c52736cbf4--2faa37cc0477465e9196d10a3326b211 8d3154ec0ace4ec895caca77fdb2d8b2 7fa26a5cb8824fe0b99db04826ced054 RX(theta\u2081) a0a6e4f090764215adb31dc8bc2abeb6--7fa26a5cb8824fe0b99db04826ced054 9a87ee73119f4ee6a2f78e567f6146a8 2 47b3e42d95b9415fb509383f80f5d665 RY(theta\u2084) 7fa26a5cb8824fe0b99db04826ced054--47b3e42d95b9415fb509383f80f5d665 9b733197d0a94b0a81acba66733e7e5d RX(theta\u2087) 47b3e42d95b9415fb509383f80f5d665--9b733197d0a94b0a81acba66733e7e5d 5092a0050cce4cc6a78b02a5ecc63af4 X 9b733197d0a94b0a81acba66733e7e5d--5092a0050cce4cc6a78b02a5ecc63af4 5092a0050cce4cc6a78b02a5ecc63af4--5439e7c25825426c83342a7b8ceba163 51c91fba1a5244e29cb71a626940cf37 5092a0050cce4cc6a78b02a5ecc63af4--51c91fba1a5244e29cb71a626940cf37 270e2900dff1411ea2840e311f7e04fe RX(theta\u2081\u2080) 51c91fba1a5244e29cb71a626940cf37--270e2900dff1411ea2840e311f7e04fe bb3769c173a243e88013d53cc574fe73 RY(theta\u2081\u2083) 270e2900dff1411ea2840e311f7e04fe--bb3769c173a243e88013d53cc574fe73 610e36c8c9084eb28297925b706ebf4c RX(theta\u2081\u2086) bb3769c173a243e88013d53cc574fe73--610e36c8c9084eb28297925b706ebf4c c521220b375f44c3b7532558f0d9d764 X 610e36c8c9084eb28297925b706ebf4c--c521220b375f44c3b7532558f0d9d764 c521220b375f44c3b7532558f0d9d764--047be8cfb2044450af9e203cf160483f c1498719b3524a5e8598db75b6c4e162 c521220b375f44c3b7532558f0d9d764--c1498719b3524a5e8598db75b6c4e162 64db5a9f7cdc43e8832db77ae6908614 AddBlock c1498719b3524a5e8598db75b6c4e162--64db5a9f7cdc43e8832db77ae6908614 64db5a9f7cdc43e8832db77ae6908614--8d3154ec0ace4ec895caca77fdb2d8b2 5a84d825eeae42be9f99899d1d323c1a fc31a341b2c946d29df6d9c4f9a05ce8 RX(theta\u2082) 9a87ee73119f4ee6a2f78e567f6146a8--fc31a341b2c946d29df6d9c4f9a05ce8 c0421d1a570e4ea6bd63620f4e6aeddc RY(theta\u2085) fc31a341b2c946d29df6d9c4f9a05ce8--c0421d1a570e4ea6bd63620f4e6aeddc 4dcde61fbaf04776b88e10caebdd295b RX(theta\u2088) c0421d1a570e4ea6bd63620f4e6aeddc--4dcde61fbaf04776b88e10caebdd295b 3be17655c4874be2b0a87125cbe76fe0 4dcde61fbaf04776b88e10caebdd295b--3be17655c4874be2b0a87125cbe76fe0 324b8d1acb814cca96f291329129639b X 3be17655c4874be2b0a87125cbe76fe0--324b8d1acb814cca96f291329129639b 324b8d1acb814cca96f291329129639b--51c91fba1a5244e29cb71a626940cf37 ba1f3f142cdb4b9ea5f5352c6cf2ef69 RX(theta\u2081\u2081) 324b8d1acb814cca96f291329129639b--ba1f3f142cdb4b9ea5f5352c6cf2ef69 795cb60273b94485b222ef92aa221127 RY(theta\u2081\u2084) ba1f3f142cdb4b9ea5f5352c6cf2ef69--795cb60273b94485b222ef92aa221127 483800da5166419787e91c0bedb3c9b7 RX(theta\u2081\u2087) 795cb60273b94485b222ef92aa221127--483800da5166419787e91c0bedb3c9b7 5170b78bb310479389341e1478add4b9 483800da5166419787e91c0bedb3c9b7--5170b78bb310479389341e1478add4b9 20edbf8e3fe348a1a9f3feb5c2b109cb X 5170b78bb310479389341e1478add4b9--20edbf8e3fe348a1a9f3feb5c2b109cb 20edbf8e3fe348a1a9f3feb5c2b109cb--c1498719b3524a5e8598db75b6c4e162 aafd7c7fb0694057bc73437c4269ff84 20edbf8e3fe348a1a9f3feb5c2b109cb--aafd7c7fb0694057bc73437c4269ff84 aafd7c7fb0694057bc73437c4269ff84--5a84d825eeae42be9f99899d1d323c1a <pre><code>from qadence import *\n\nb = chain(SWAP(0,1), SWAP(0,3))\n</code></pre> %3 4b212044b1d74ad6964311d0132f0187 0 2a2153d7578c400ea964bd3cb60c0524 4b212044b1d74ad6964311d0132f0187--2a2153d7578c400ea964bd3cb60c0524 fd6a4a50ae224d3c9c4f5477c9af1a35 1 534c0c50033c46b3a00914248897e748 799736d0d56040fb9fe5d6c315440678 2a2153d7578c400ea964bd3cb60c0524--799736d0d56040fb9fe5d6c315440678 bf010d1736264c8fb44396b9340c72b9 534c0c50033c46b3a00914248897e748--bf010d1736264c8fb44396b9340c72b9 8cb35584df99467ca0e84328b4165078 9fdc5eed4e064a5fb18e39e32542e4ce bf010d1736264c8fb44396b9340c72b9--9fdc5eed4e064a5fb18e39e32542e4ce 36af6ce1ca3e4b3dbd2903f3e9cae776 8cb35584df99467ca0e84328b4165078--36af6ce1ca3e4b3dbd2903f3e9cae776 574c2688c81548c1b798d7b52a1f49ac bfd2149808e04779a3eb80c1c74d106b fd6a4a50ae224d3c9c4f5477c9af1a35--bfd2149808e04779a3eb80c1c74d106b d2f33a3d3c784eeeb505315ceb4732ca 2 bfd2149808e04779a3eb80c1c74d106b--534c0c50033c46b3a00914248897e748 dbb4782a38174b199ba6496105987cf9 799736d0d56040fb9fe5d6c315440678--dbb4782a38174b199ba6496105987cf9 5c65ffbb0f974eec9c50f1851e63a2b1 dbb4782a38174b199ba6496105987cf9--5c65ffbb0f974eec9c50f1851e63a2b1 5c65ffbb0f974eec9c50f1851e63a2b1--574c2688c81548c1b798d7b52a1f49ac 44ac544f6bd84c1bbc4706c5d49535e3 f0431e2c28f341099544a2b4c90f69db d2f33a3d3c784eeeb505315ceb4732ca--f0431e2c28f341099544a2b4c90f69db 750ab4e0bc034498865540d69940c83c 3 0869d18fa2b5491f9075c31579aa804e f0431e2c28f341099544a2b4c90f69db--0869d18fa2b5491f9075c31579aa804e 943a48527a324d048d6cf09d7a27cae3 0869d18fa2b5491f9075c31579aa804e--943a48527a324d048d6cf09d7a27cae3 ae73380afffe478182cea04d4d1c2ba0 943a48527a324d048d6cf09d7a27cae3--ae73380afffe478182cea04d4d1c2ba0 ae73380afffe478182cea04d4d1c2ba0--44ac544f6bd84c1bbc4706c5d49535e3 a9dac20e1692473f81fd87fdd368d562 883b90ba93e4470598e81f5208885573 750ab4e0bc034498865540d69940c83c--883b90ba93e4470598e81f5208885573 d8ce3cf1a30e419086fb46e01cf327c8 883b90ba93e4470598e81f5208885573--d8ce3cf1a30e419086fb46e01cf327c8 f3b1a98b849b48b18e71faca073de9db d8ce3cf1a30e419086fb46e01cf327c8--f3b1a98b849b48b18e71faca073de9db f3b1a98b849b48b18e71faca073de9db--8cb35584df99467ca0e84328b4165078 9fdc5eed4e064a5fb18e39e32542e4ce--a9dac20e1692473f81fd87fdd368d562 <pre><code>from qadence import *\n\nb = chain(CPHASE(0, 1, 0.5), CPHASE(0, 2, 0.5), CPHASE(0, 3, 0.5))\n</code></pre> %3 e0ce6aa5110043ce964f8aac8f0ad8be 0 c557b71108fb4f98bbda8c22511a31e6 e0ce6aa5110043ce964f8aac8f0ad8be--c557b71108fb4f98bbda8c22511a31e6 1f568e89c6664e0fab50f2f6e1e97438 1 4211d6eb76924982bfd082926016587c c557b71108fb4f98bbda8c22511a31e6--4211d6eb76924982bfd082926016587c b69ace054c694c5f83b6763879bbd59f 4211d6eb76924982bfd082926016587c--b69ace054c694c5f83b6763879bbd59f 34a00b9c1384416ba2ea73d0d96d06ed b69ace054c694c5f83b6763879bbd59f--34a00b9c1384416ba2ea73d0d96d06ed ecb18316831349f7b21a4e202adf513b defeb902f96c422e97ca3182c079bf3a PHASE(0.5) 1f568e89c6664e0fab50f2f6e1e97438--defeb902f96c422e97ca3182c079bf3a f3390ba356a847889886546bd06c472a 2 defeb902f96c422e97ca3182c079bf3a--c557b71108fb4f98bbda8c22511a31e6 3bec5e27c4f14e88b1c16ffb21587124 defeb902f96c422e97ca3182c079bf3a--3bec5e27c4f14e88b1c16ffb21587124 48039cd7c329485d866a0660cefbfb9d 3bec5e27c4f14e88b1c16ffb21587124--48039cd7c329485d866a0660cefbfb9d 48039cd7c329485d866a0660cefbfb9d--ecb18316831349f7b21a4e202adf513b 265fc25500c04fbb99be1911c22980f9 beda05b6ed994aa086433f8c3a1cf8a8 f3390ba356a847889886546bd06c472a--beda05b6ed994aa086433f8c3a1cf8a8 67e901d8f3664c7b90dd50440418c3e5 3 e8127c6024164459917a2d78d3e5edeb PHASE(0.5) beda05b6ed994aa086433f8c3a1cf8a8--e8127c6024164459917a2d78d3e5edeb e8127c6024164459917a2d78d3e5edeb--4211d6eb76924982bfd082926016587c fc533fbc087e4c6d87ad63e89d29d765 e8127c6024164459917a2d78d3e5edeb--fc533fbc087e4c6d87ad63e89d29d765 fc533fbc087e4c6d87ad63e89d29d765--265fc25500c04fbb99be1911c22980f9 3d00097842264f0a8ebcd43d717335e5 86daaa7d02964840b1b84d0ba016ce9c 67e901d8f3664c7b90dd50440418c3e5--86daaa7d02964840b1b84d0ba016ce9c be29102b4cdf422b9b4f645a27fc627f 86daaa7d02964840b1b84d0ba016ce9c--be29102b4cdf422b9b4f645a27fc627f 877139e282274d6cad2da01255cb99d6 PHASE(0.5) be29102b4cdf422b9b4f645a27fc627f--877139e282274d6cad2da01255cb99d6 877139e282274d6cad2da01255cb99d6--b69ace054c694c5f83b6763879bbd59f 877139e282274d6cad2da01255cb99d6--3d00097842264f0a8ebcd43d717335e5"},{"location":"tutorials/development/draw/#developer-documentation","title":"Developer documentation","text":"<p>This section contains examples in pure graphviz that can be used to understand roughly what is done in the actual drawing backend.</p> <pre><code>import graphviz\n\nfont_name = \"Sans-Serif\"\nfont_size = \"8\"\n\ngraph_attr = {\n    \"rankdir\": \"LR\",  # LR = left to right, TB = top to bottom\n    \"nodesep\": \"0.1\",  # In inches, tells distance between nodes without edges\n    \"compound\": \"true\",  # Needed to draw properly edges in hamevo when content is hidden\n    \"splines\": \"false\",  # Needed to draw control gates vertical lines one over the other\n}  # These are the default values for graphs\n\nnode_attr = {\n    \"shape\": \"box\",  # 'box' for normal nodes, 'point' for control gates or 'plaintext' for starting nodes (the qubit label).\n    \"style\": \"rounded\",  # Unfortunately we can't specify the radius of the rounded, at least for this version\n    \"fontname\": font_name,\n    \"fontsize\": font_size,\n    \"width\": \"0.1\",  # In inches, it doesn't get tinier than the label font.\n    \"height\": \"0.1\"  # In inches, it doesn't get tinier than the label font.\n}  # These are the defaults values that can be overridden at node declaration.\n\ndefault_cluster_attr = {\n    \"fontname\": font_name,\n    \"fontsize\": font_size,\n    \"labelloc\": \"b\",  # location of cluster label. b as bottom, t as top\n    \"style\": \"rounded\"\n} # These are the defaults values that can be overridden at sub graph declaration\n\nhamevo_cluster_attr = {\n    \"label\": \"HamEvo(t=10)\"\n}\nhamevo_cluster_attr.update(default_cluster_attr)\n\nh = graphviz.Graph(graph_attr=graph_attr, node_attr=node_attr)\nh.node(\"Hello World!\")\nh\n</code></pre> <pre><code>\n</code></pre> <pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n\n# Add start and end nodes\nfor i in range(4):\n    h.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\n    h.node(f'e{i}', style='invis', group=f\"{i}\")\n\n# Add nodes\nh.node('X', group=\"0\")\nh.node('Y', group=\"1\")\n\n# Add hamevo and its nodes\nhamevo = graphviz.Graph(name='cluster_hamevo', graph_attr=hamevo_cluster_attr)\nfor i in range(4):\n    hamevo.node(f'z{i}', shape=\"box\", style=\"invis\", label=f'{i}', group=f\"{i}\")\nh.subgraph(hamevo)\n\n# Add rx gates cluster and its nodes\ncluster_attr = {\"label\": \"RX gates\"}\ncluster_attr.update(default_cluster_attr)\ncluster = graphviz.Graph(name=\"cluster_0\", graph_attr=cluster_attr)\ncluster.node('RX(x)', group=\"2\")\ncluster.node('RX(0.5)', group=\"3\")\nh.subgraph(cluster)\n\nh.node('cnot0', label='', shape='point', width='0.1', group='0')\nh.node('cnot1', label='X', group='1')\nh.node('cnot2', label='', shape='point', width='0.1', group='2')\nh.node('cnot3', label='', shape='point', width='0.1', group='3')\n\n# Add edges\nh.edge('s0', 'X')\nh.edge('X', 'cnot0')\nh.edge('cnot0', 'z0', lhead='cluster_hamevo')\nh.edge('z0', 'e0', ltail='cluster_hamevo')\nh.edge('s1', 'Y')\nh.edge('Y', 'cnot1')\nh.edge('cnot1', 'z1', lhead='cluster_hamevo')\nh.edge('z1', 'e1', ltail='cluster_hamevo')\nh.edge('s2', 'RX(x)')\nh.edge('RX(x)', 'cnot2')\nh.edge('cnot2', 'z2', lhead='cluster_hamevo')\nh.edge('z2', 'e2', ltail='cluster_hamevo')\nh.edge('s3', 'RX(0.5)')\nh.edge('RX(0.5)', 'cnot3')\nh.edge('cnot3', 'z3', lhead='cluster_hamevo')\nh.edge('z3', 'e3', ltail='cluster_hamevo')\nh.edge('cnot1', 'cnot0', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot2', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot3', constraint='false')  # constraint: false is needed to draw vertical edges\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/development/draw/#example-of-cluster-of-clusters","title":"Example of cluster of clusters","text":"<pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n\n# Define start and end nodes\nfor i in range(4):\n    h.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\n    h.node(f'e{i}', style='invis', group=f\"{i}\")\n\n# Define outer cluster\ncluster_attr = {\"label\": \"Outer cluster\"}\ncluster_attr.update(default_cluster_attr)\nouter_cluster = graphviz.Graph(name=\"cluster_outer\", graph_attr=cluster_attr)\n\n# Define inner cluster 1 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 1\"}\ncluster_attr.update(default_cluster_attr)\ninner1_cluster = graphviz.Graph(name=\"cluster_inner1\", graph_attr=cluster_attr)\ninner1_cluster.node(\"a0\", group=\"0\")\ninner1_cluster.node(\"a1\", group=\"1\")\nouter_cluster.subgraph(inner1_cluster)\n\n# Define inner cluster 2 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 2\"}\ncluster_attr.update(default_cluster_attr)\ninner2_cluster = graphviz.Graph(name=\"cluster_inner2\", graph_attr=cluster_attr)\ninner2_cluster.node(\"a2\", group=\"2\")\ninner2_cluster.node(\"a3\", group=\"3\")\nouter_cluster.subgraph(inner2_cluster)\n\n# This has to be done here, after inner clusters definitions\nh.subgraph(outer_cluster)\n\n# Define more nodes\nfor i in range(4):\n    h.node(f\"b{i}\", group=f\"{i}\")\n\nfor i in range(4):\n    h.edge(f's{i}', f'a{i}')\n    h.edge(f'a{i}', f'b{i}')\n    h.edge(f'b{i}', f'e{i}')\n\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/digital_analog_qc/","title":"Digital-Analog Quantum Computation","text":"<p>Digital-analog quantum computation (DAQC) is a universal quantum computing paradigm<sup>1</sup>, based on two primary computations:</p> <ul> <li>Fast single-qubit operations (digital).</li> <li>Multi-partite entangling operations acting on all qubits (analog).</li> </ul> <p>A promising quantum computing platform for the implementation of the DAQC paradigm is neutral-atoms, where both these computations are realizable.</p>"},{"location":"tutorials/digital_analog_qc/#digital-analog-emulation","title":"Digital-analog emulation","text":"<p>Qadence simplifies the execution of DAQC programs on either emulated or real devices by providing a simplified interface for customizing interactions and interfacing with pulse-level programming in <code>Pulser</code><sup>3</sup>.</p>"},{"location":"tutorials/digital_analog_qc/#digital-analog-transformation","title":"Digital-analog transformation","text":"<p>Furthermore, the essence of digital-analog computation is the ability to represent any analog operation, i.e. any arbitrary Hamiltonian, using an auxiliary device-amenable Hamiltonian, such as the ubiquitous Ising model<sup>2</sup>. This is at the core of the DAQC implementation in Qadence.</p>"},{"location":"tutorials/digital_analog_qc/#execution-on-rydberg-atom-arrays-with-restriced-addressability","title":"Execution on Rydberg atom arrays with restriced addressability","text":"<p>Finally, Qadence offers some convenience constructors and interfaces to execute programs compatible with a DAQC flavor featuring only a restricted access to individual qubit addressability with always-on interaction. This regime is common in currently available neutral atom quantum computers.</p>"},{"location":"tutorials/digital_analog_qc/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/analog-basics/","title":"Basic operations on neutral-atoms","text":"<p>Warning</p> <p>The digital-analog emulation framework is under construction and more changes to the interface may still occur.</p> <p>Qadence includes primitives for the construction of programs implemented on a set of interacting qubits. The goal is to build digital-analog programs that better represent the reality of interacting qubit platforms, such as neutral-atoms, while maintaining a simplified interface for users coming from a digital quantum computing background that may not be as familiar with pulse-level programming.</p> <p>To build the intuition for the interface in Qadence, it is important to go over some of the underlying physics. We can write a general Hamiltonian for a set of \\(n\\) interacting qubits as</p> \\[ \\mathcal{H} = \\sum_{i=0}^{n-1}\\left(\\mathcal{H}^\\text{d}_{i}(t) + \\sum_{j&lt;i}\\mathcal{H}^\\text{int}_{ij}\\right), \\] <p>where the driving Hamiltonian \\(\\mathcal{H}^\\text{d}_{i}\\) describes the pulses used to control single-qubit rotations, and the interaction Hamiltonian \\(\\mathcal{H}^\\text{int}_{ij}\\) describes the natural interaction between qubits.</p>"},{"location":"tutorials/digital_analog_qc/analog-basics/#rydberg-atoms","title":"Rydberg atoms","text":"<p>For the purpose of digital-analog emulation of neutral-atom systems in Qadence, we now consider a simplified time-independent global driving Hamiltonian, written as</p> \\[ \\mathcal{H}^\\text{d}_{i} = \\frac{\\Omega}{2}\\left(\\cos(\\phi) X_i - \\sin(\\phi) Y_i \\right) - \\delta N_i \\] <p>where \\(\\Omega\\) is the Rabi frequency, \\(\\delta\\) is the detuning, \\(\\phi\\) is the phase, \\(X_i\\) and \\(Y_i\\) are the standard Pauli operators, and \\(N_i=\\frac{1}{2}(I_i-Z_i)\\) is the number operator. This Hamiltonian allows arbitrary global single-qubit rotations to be written, meaning that the values set for \\((\\Omega,\\phi,\\delta)\\) are the same accross the qubit support.</p> <p>For the interaction term, Rydberg atoms typically allow both an Ising and an XY mode of operation. For now, we focus on the Ising interaction, where the Hamiltonian is written as</p> \\[ \\mathcal{H}^\\text{int}_{ij} = \\frac{C_6}{r_{ij}^6}N_iN_j \\] <p>where \\(r_{ij}\\) is the distance between atoms \\(i\\) and \\(j\\), and \\(C_6\\) is a coefficient depending on the specific Rydberg level of the excited state used in the computational logic states. A typical value for rydberg level of 60 is \\(C_6\\approx 866~[\\text{rad} . \\mu \\text{m}^6 / \\text{ns}]\\).</p> <p>For a given register of atoms prepared in some spatial coordinates, the Hamiltonians described will generate the dynamics of some unitary operation as</p> \\[ U(t, \\Omega, \\delta, \\phi) = \\exp(-i\\mathcal{H}t) \\] <p>where we specify the final parameter \\(t\\), the duration of the operation.</p> <p>Qadence uses the following units for user-specified parameters:</p> <ul> <li>Rabi frequency and detuning \\(\\Omega\\), \\(\\delta\\): \\([\\text{rad}/\\mu \\text{s}]\\)</li> <li>Phase \\(\\phi\\): \\([\\text{rad}]\\)</li> <li>Duration \\(t\\): \\([\\text{ns}]\\)</li> <li>Atom coordinates: \\([\\mu \\text{m}]\\)</li> </ul>"},{"location":"tutorials/digital_analog_qc/analog-basics/#in-practice","title":"In practice","text":"<p>Given the Hamiltonian description in the previous section, we will now go over a few examples of the standard operations available in Qadence.</p>"},{"location":"tutorials/digital_analog_qc/analog-basics/#arbitrary-rotation","title":"Arbitrary rotation","text":"<p>To start, we will exemplify the a general rotation on a set of atoms. To create an arbitrary register of atoms, we refer the user to the register creation tutorial. Below, we create a line register of three qubits with a separation of \\(8~\\mu\\text{m}\\). This is a typical value used in combination with a standard experimental setup of neutral atoms such that the interaction term in the Hamiltonian can effectively be used for computations.</p> <pre><code>from qadence import Register\n\nreg = Register.line(3, spacing=8.0)  # Atom spacing in \u03bcm\n</code></pre> <p>Currently, the most general rotation operation uses the <code>AnalogRot</code> operation, which essentially implements \\(U(t, \\Omega, \\delta, \\phi)\\) defined above.</p> <pre><code>from qadence import AnalogRot, PI\n\nrot_op = AnalogRot(\n    duration = 500., # [ns]\n    omega = PI, # [rad/\u03bcs]\n    delta = PI, # [rad/\u03bcs]\n    phase = PI, # [rad]\n)\n</code></pre> <p>Note that in the code above a specific qubit support is not defined. By default this operation applies a global rotation on all qubits. We can define a circuit using the 3-qubit register and run it in the pyqtorch backend:</p> <pre><code>from qadence import BackendName, run\n\nwf = run(reg, rot_op, backend = BackendName.PYQTORCH)\n\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4248-0.2411j, -0.1687+0.3156j, -0.1696+0.2676j, -0.2040-0.2671j,\n         -0.1687+0.3156j,  0.0014-0.2721j, -0.2040-0.2671j,  0.3034-0.1130j]])\n</code></pre> Under the hood of AnalogRot      To be fully explicit about what goes on under the hood of `AnalogRot`, we can look at the example     code below.      <pre><code>from qadence import BackendName, HamEvo, X, Y, N, add, run, PI\nfrom qadence.analog.constants import C6_DICT\nfrom math import cos, sin\n\n# Following the 3-qubit register above\nn_qubits = 3\ndx = 8.0\n\n# Parameters used in the AnalogRot\nduration = 500.\nomega = PI\ndelta = PI\nphase = PI\n\n# Building the terms in the driving Hamiltonian\nh_x = (omega / 2) * cos(phase) * add(X(i) for i in range(n_qubits))\nh_y = (-1.0 * omega / 2) * sin(phase) * add(Y(i) for i in range(n_qubits))\nh_n = -1.0 * delta * add(N(i) for i in range(n_qubits))\n\n# Building the interaction Hamiltonian\n\n# Dictionary of coefficient values for each Rydberg level, which is 60 by default\nc_6 = C6_DICT[60]\n\nh_int = c_6 * (\n    1/(dx**6) * (N(0)@N(1)) +\n    1/(dx**6) * (N(1)@N(2)) +\n    1/((2*dx)**6) * (N(0)@N(2))\n)\n\nhamiltonian = h_x + h_y + h_n + h_int\n\n# Convert duration to \u00b5s due to the units of the Hamiltonian\nexplicit_rot = HamEvo(hamiltonian, duration / 1000)\n\nwf = run(n_qubits, explicit_rot, backend = BackendName.PYQTORCH)\n\n# We get the same final wavefunction\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4248-0.2411j, -0.1687+0.3156j, -0.1696+0.2676j, -0.2040-0.2671j,\n         -0.1687+0.3156j,  0.0014-0.2721j, -0.2040-0.2671j,  0.3034-0.1130j]])\n</code></pre> <p>When sending the <code>AnalogRot</code> operation to the pyqtorch backend, Qadence automatically builds the correct Hamiltonian and the corresponding <code>HamEvo</code> operation with the added qubit interactions, as shown explicitly in the minimized section above. However, this operation is also supported in the Pulser backend, where the correct pulses are automatically created.</p> <pre><code>wf = run(\n    reg,\n    rot_op,\n    backend = BackendName.PULSER,\n)\n\nprint(wf)\n</code></pre> <pre><code>tensor([[ 0.4254-0.2408j, -0.1688+0.3157j, -0.1698+0.2678j, -0.2044-0.2666j,\n         -0.1688+0.3157j,  0.0010-0.2721j, -0.2044-0.2666j,  0.3024-0.1138j]])\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#rx-ry-rz-rotations","title":"RX / RY / RZ rotations","text":"<p>The <code>AnalogRot</code> provides full control over the parameters of \\(\\mathcal{H}^\\text{d}\\), but users coming from a digital quantum computing background may be more familiar with the standard <code>RX</code>, <code>RY</code> and <code>RZ</code> rotations, also available in Qadence. For the emulated analog interface, Qadence provides alternative <code>AnalogRX</code>, <code>AnalogRY</code> and <code>AnalogRZ</code> operations which call <code>AnalogRot</code> under the hood to represent the rotations accross the respective axis.</p> <p>For a given angle of rotation \\(\\theta\\) provided to each of these operations, currently a set of hardcoded assumptions are made on the tunable Hamiltonian parameters:</p> \\[ \\begin{aligned} \\text{RX}:&amp; \\quad \\Omega = \\pi, \\quad \\delta = 0, \\quad \\phi = 0, \\quad t = (\\theta/\\Omega)\\times 10^3 \\\\ \\text{RY}:&amp; \\quad \\Omega = \\pi, \\quad \\delta = 0, \\quad \\phi = -\\pi/2, \\quad t = (\\theta/\\Omega)\\times 10^3 \\\\ \\text{RZ}:&amp; \\quad \\Omega = 0, \\quad \\delta = \\pi, \\quad \\phi = 0, \\quad t = (\\theta/\\delta)\\times 10^3 \\\\ \\end{aligned} \\] <p>Note that the \\(\\text{RZ}\\) operation as defined above includes a global phase compared to the standard \\(\\text{RZ}\\) rotation since it evolves \\(\\exp\\left(-i\\frac{\\theta}{2}\\frac{I-Z}{2}\\right)\\) instead of \\(\\exp\\left(-i\\frac{\\theta}{2}Z\\right)\\) given the detuning operator in \\(\\mathcal{H}^\\text{d}\\).</p> <p>Warning</p> <p>As shown above, the values of \\(\\Omega\\) and \\(\\delta\\) are currently hardcoded in these operators, and the effective angle of rotation is controlled by varying the duration of the evolution. Currently, the best way to overcome this is to use <code>AnalogRot</code> directly, but more general and convenient options will be provided soon in an improved interface.</p> <p>Below we exemplify the usage of <code>AnalogRX</code>:</p> <pre><code>from qadence import Register, BackendName\nfrom qadence import RX, AnalogRX, random_state, equivalent_state, kron, run, PI\n\nn_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\n# Rotation angle\ntheta = PI\n\n# Analog rotation using the Rydberg Hamiltonian\nrot_analog = AnalogRX(angle = theta)\n\n# Equivalent full-digital global rotation\nrot_digital = kron(RX(i, theta) for i in range(n_qubits))\n\n# Some random initial state\ninit_state = random_state(n_qubits)\n\n# Compare the final state using the full digital and the AnalogRX\nwf_analog_pyq = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\n\nwf_digital_pyq = run(\n    reg,\n    rot_digital,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_digital_pyq, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  False\n</code></pre> <p>As we can see, running a global <code>RX</code> or the <code>AnalogRX</code> does not result in equivalent states at the end, given that the digital <code>RX</code> operation does not include the interaction between the qubits. By setting <code>dx</code> very high in the code above the interaction will be less significant and the results will match.</p> <p>However, if we compare with the Pulser backend, we see that the results for <code>AnalogRX</code> are consistent with the expected results from a real device:</p> <pre><code>wf_analog_pulser = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PULSER,\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_analog_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#evolving-the-interaction-term","title":"Evolving the interaction term","text":"<p>Finally, besides applying specific qubit rotations, we can also choose to evolve only the interaction term \\(\\mathcal{H}^\\text{int}\\), equivalent to setting \\(\\Omega = \\delta = \\phi = 0\\). To do so, Qadence provides the function <code>AnalogInteraction</code> which does exactly this.</p> <pre><code>from qadence import Register, BackendName, random_state, equivalent_state, AnalogInteraction, run\n\nn_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\nduration = 1000.\nop = AnalogInteraction(duration = duration)\n\ninit_state = random_state(n_qubits)\n\nwf_pyq = run(reg, op, state = init_state, backend = BackendName.PYQTORCH)\nwf_pulser = run(reg, op, state = init_state, backend = BackendName.PULSER)\n\nbool_equiv = equivalent_state(wf_pyq, wf_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#device-specifications-in-qadence","title":"Device specifications in Qadence","text":"<p>As a way to control other specifications of the interacting Rydberg atoms, Qadence provides a <code>RydbergDevice</code> class, which is currently used for both the pyqtorch and the pulser backends. Below we initialize a Rydberg device showcasing all the possible options.</p> <pre><code>from qadence import RydbergDevice, DeviceType, Interaction, PI\n\ndevice_specs = RydbergDevice(\n    interaction=Interaction.NN, # Or Interaction.XY, supported only for pyqtorch\n    rydberg_level=60, # Integer value affecting the C_6 coefficient\n    coeff_xy=3700.00, # C_3 coefficient for the XY interaction\n    max_detuning=2 * PI * 4, # Max value for delta, currently only used in pulser\n    max_amp=2 * PI * 3, # Max value for omega, currently only used in pulser\n    pattern=None, # Semi-local addressing pattern, see the relevant tutorial\n    type=DeviceType.IDEALIZED, # Pulser device to which the qadence device is converted in that backend\n)\n</code></pre> <p>The values above are the defaults when simply running <code>device_specs = RydbergDevice()</code>. The convenience wrappers <code>IdealDevice()</code> or <code>RealisticDevice()</code> can also be used which simply change the <code>type</code> for the Pulser backend, but also allow an <code>AddressingPattern</code> passed in the <code>pattern</code> argument (see the relevant tutorial here).</p> <p>Warning</p> <p>Currently, the options above are not fully integrated in both backends and this class should mostly be used if a user wishes to experiment with a different <code>rydberg_level</code>, or to change the device type for the pulser backend.</p> <p>Planned features to add to the RydbergDevice include the definition of custom interaction functions, the control of other drive Hamiltonian parameters so that \\(\\Omega\\), \\(\\delta\\) and \\(\\phi\\) are not hardcoded when doing analog rotations, and the usage of the <code>max_detuning</code> and <code>max_amp</code> to control those respective parameters when training models in the pyqtorch backend.</p> <p>Finally, to change a given simulation, the device specifications are integrated in the Qadence <code>Register</code>. By default, all registers initialize an <code>IdealDevice()</code> under the hood. Below we run a quick test for a different rydberg level.</p> <pre><code>from qadence import Register, BackendName, random_state, equivalent_state, run\nfrom qadence import AnalogRX, RydbergDevice, PI\n\ndevice_specs = RydbergDevice(rydberg_level = 70)\n\nn_qubits_side = 2\nreg = Register.square(\n    n_qubits_side,\n    spacing = 8.0,\n    device_specs = device_specs\n)\n\nrot_analog = AnalogRX(angle = PI)\n\ninit_state = random_state(n_qubits = 4)\n\nwf_analog_pyq = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PYQTORCH\n)\n\nwf_analog_pulser = run(\n    reg,\n    rot_analog,\n    state = init_state,\n    backend = BackendName.PULSER\n)\n\nbool_equiv = equivalent_state(wf_analog_pyq, wf_analog_pulser, atol = 1e-03)\n\nprint(\"States equivalent: \", bool_equiv)\n</code></pre> <pre><code>States equivalent:  True\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-basics/#technical-details","title":"Technical details","text":"<p>Warning</p> <p>The details described here are relevant in the current version but will be lifted soon for the next version of the emulated analog interface.</p> <p>In the previous section we have exemplified the main ingredients of the current user-facing functionalities of the emulated analog interface, and in the next tutorial on Quantum Circuit Learning we will exmplify its usage in a simple QML example. Here we specify some extra details of this interface.</p> <p>In the block system, all analog rotation operators initialize a <code>ConstantAnalogRotation</code> block, while the <code>AnalogInteraction</code> operation initializes an <code>InteractionBlock</code>. As we have shown, by default, these blocks use a global qubit support, which can be passed explicitly by setting <code>qubit_support = QubitSupportType.GLOBAL</code>. However, composing blocks using <code>kron</code> with local qubit supports and different durations is not allowed.</p> <pre><code>from qadence import AnalogRX, AnalogRY, Register, kron\n\ndx = 8.0\nreg = Register.from_coordinates([(0, 0), (dx, 0)])\n\n# Does not work (the angle affects the duration, as seen above):\nrot_0 = AnalogRX(angle = 1.0, qubit_support = (0,))\nrot_1 = AnalogRY(angle = 2.0, qubit_support = (1,))\n\ntry:\n    block = kron(rot_0, rot_1)\nexcept ValueError as error:\n    print(\"Error:\", error)\n\n# Works:\nrot_0 = AnalogRX(angle = 1.0, qubit_support = (0,))\nrot_1 = AnalogRY(angle = 1.0, qubit_support = (1,))\n\nblock = kron(rot_0, rot_1)\n</code></pre> <pre><code>Error: Kron'ed blocks have to have same duration.\n</code></pre> <p>Using <code>chain</code> is only supported between analog blocks with global qubit support:</p> <pre><code>from qadence import chain\n\nrot_0 = AnalogRX(angle = 1.0, qubit_support = \"global\")\nrot_1 = AnalogRY(angle = 2.0, qubit_support = \"global\")\n\nblock = chain(rot_0, rot_1)\n</code></pre> <p>The restrictions above only apply to the analog blocks, and analog and digital blocks can currently be composed.</p> <pre><code>from qadence import RX\n\nrot_0 = AnalogRX(angle = 1.0, qubit_support = \"global\")\nrot_1 = AnalogRY(angle = 2.0, qubit_support = (0,))\nrot_digital = RX(1, 1.0)\n\nblock_0 = chain(rot_0, rot_digital)\nblock_1 = kron(rot_1, rot_digital)\n</code></pre>"},{"location":"tutorials/digital_analog_qc/analog-blocks-qcl/","title":"Fitting a function with analog blocks","text":"<p>Analog blocks can be parametrized in the usual Qadence manner. Like any other parameters, they can be optimized. The next snippet exemplifies the creation of an analog and parameterized ansatz to fit a simple function. First, define a register and feature map block. We again use a default spacing of \\(8~\\mu\\text{m}\\) as done in the basic tutorial.</p> <pre><code>from qadence import Register, FeatureParameter, chain\nfrom qadence import AnalogRX, AnalogRY, AnalogRZ, AnalogInteraction\nfrom sympy import acos\n\n# Line register\nn_qubits = 2\nregister = Register.line(n_qubits, spacing = 8.0)\n\n# The input feature x for the circuit to learn f(x)\nx = FeatureParameter(\"x\")\n\n# Feature map with a few global analog rotations\nfm = chain(\n    AnalogRX(x),\n    AnalogRY(2*x),\n    AnalogRZ(3*x),\n)\n</code></pre> <p>Next, we define the ansatz with parameterized rotations.</p> <pre><code>from qadence import hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel, BackendName, DiffMode\nfrom qadence import VariationalParameter\n\nt_0 = 1000. * VariationalParameter(\"t_0\")\nt_1 = 1000. * VariationalParameter(\"t_1\")\nt_2 = 1000. * VariationalParameter(\"t_2\")\n\n# Creating the ansatz with parameterized rotations and wait time\nansatz = chain(\n    AnalogRX(\"tht_0\"),\n    AnalogRY(\"tht_1\"),\n    AnalogRZ(\"tht_2\"),\n    AnalogInteraction(t_0),\n    AnalogRX(\"tht_3\"),\n    AnalogRY(\"tht_4\"),\n    AnalogRZ(\"tht_5\"),\n    AnalogInteraction(t_1),\n    AnalogRX(\"tht_6\"),\n    AnalogRY(\"tht_7\"),\n    AnalogRZ(\"tht_8\"),\n    AnalogInteraction(t_2),\n)\n</code></pre> <p>We define the measured observable as the total magnetization, and build the <code>QuantumModel</code>.</p> <pre><code># Total magnetization observable\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n\n# Defining the circuit and observable\ncircuit = QuantumCircuit(register, fm, ansatz)\n\nmodel = QuantumModel(\n    circuit,\n    observable = observable,\n    backend = BackendName.PYQTORCH,\n    diff_mode = DiffMode.AD\n)\n</code></pre> <p>Now we can define the function to fit as well as our training and test data.</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\n\n# Function to fit:\ndef f(x):\n    return x**2\n\nx_test = torch.linspace(-1.0, 1.0, steps=100)\ny_test = f(x_test)\n\nx_train = torch.linspace(-1.0, 1.0, steps=10)\ny_train = f(x_train)\n\n# Initial prediction from the model, to be visualized later\ny_pred_initial = model.expectation({\"x\": x_test}).detach()\n</code></pre> <p>Finally we define a simple loss function and training loop.</p> <pre><code>mse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ndef loss_fn(x_train, y_train):\n    out = model.expectation({\"x\": x_train})\n    loss = mse_loss(out.squeeze(), y_train)\n    return loss\n\nn_epochs = 200\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_fn(x_train, y_train)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And with the model trained we can plot the final results.</p> <pre><code>y_pred_final = model.expectation({\"x\": x_test}).detach()\n\nplt.plot(x_test, y_pred_initial, label = \"Initial prediction\")\nplt.plot(x_test, y_pred_final, label = \"Final prediction\")\nplt.scatter(x_train, y_train, label = \"Training points\")\n</code></pre> 2024-09-20T08:34:25.523146 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/analog-qubo/","title":"Solve a QUBO problem","text":"<p>In this notebook, we solve a quadratic unconstrained binary optimization (QUBO) problem with Qadence. QUBOs are very popular combinatorial optimization problems with a wide range of applications. Here, we solve the problem using the QAOA <sup>1</sup> variational algorithm by embedding the QUBO problem weights onto a register as standard for neutral atom quantum devices.</p> <p>Additional background information on QUBOs can be found here, directly solved using the pulse-level interface Pulser.</p>"},{"location":"tutorials/digital_analog_qc/analog-qubo/#define-and-solve-qubo","title":"Define and solve QUBO","text":"Pre-requisite: optimal register coordinates for embedding the QUBO problem <p>A basic ingredient for solving a QUBO problem with a neutral atom device is to embed the problem onto the atomic register. In short, embedding algorithms cast the problem onto a graph mapped onto the register by optimally finding atomic coordinates. A discussion on the embedding algorithms is beyond the scope of this tutorial and a simplified version taken from here is added below.</p> <pre><code>import numpy as np\nimport numpy.typing as npt\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\nfrom qadence import RydbergDevice\n\ndef qubo_register_coords(Q: np.ndarray, device: RydbergDevice) -&gt; list:\n    \"\"\"Compute coordinates for register.\"\"\"\n\n    def evaluate_mapping(new_coords, *args):\n        \"\"\"Cost function to minimize. Ideally, the pairwise\n        distances are conserved\"\"\"\n        Q, shape = args\n        new_coords = np.reshape(new_coords, shape)\n        interaction_coeff = device.rydberg_level\n        new_Q = squareform(interaction_coeff / pdist(new_coords) ** 6)\n        return np.linalg.norm(new_Q - Q)\n\n    shape = (len(Q), 2)\n    np.random.seed(0)\n    x0 = np.random.random(shape).flatten()\n    res = minimize(\n        evaluate_mapping,\n        x0,\n        args=(Q, shape),\n        method=\"Nelder-Mead\",\n        tol=1e-6,\n        options={\"maxiter\": 200000, \"maxfev\": None},\n    )\n    return [(x, y) for (x, y) in np.reshape(res.x, (len(Q), 2))]\n</code></pre> <p>With the embedding routine under our belt, let's start by adding the required imports and ensure the reproducibility of this tutorial.</p> <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit, Register\nfrom qadence import RydbergDevice, AnalogRX, AnalogRZ, chain\nfrom qadence.ml_tools import train_gradient_free, TrainConfig, num_parameters\nimport nevergrad as ng\nimport matplotlib.pyplot as plt\n\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n</code></pre> <p>The QUBO problem is initially defined by a graph of weighted edges and a cost function to be optimized. The weighted edges are represented by a real-valued symmetric matrix <code>Q</code> which is used throughout the tutorial.</p> <pre><code># QUBO problem weights (real-value symmetric matrix)\nQ = np.array(\n    [\n        [-10.0, 19.7365809, 19.7365809, 5.42015853, 5.42015853],\n        [19.7365809, -10.0, 20.67626392, 0.17675796, 0.85604541],\n        [19.7365809, 20.67626392, -10.0, 0.85604541, 0.17675796],\n        [5.42015853, 0.17675796, 0.85604541, -10.0, 0.32306662],\n        [5.42015853, 0.85604541, 0.17675796, 0.32306662, -10.0],\n    ]\n)\n\ndef loss(model: QuantumModel, *args) -&gt; tuple[float, dict]:\n    to_arr_fn = lambda bitstring: np.array(list(bitstring), dtype=int)\n    cost_fn = lambda arr: arr.T @ Q @ arr\n    samples = model.sample({}, n_shots=1000)[0]  # extract samples\n    cost_fn = sum(samples[key] * cost_fn(to_arr_fn(key)) for key in samples)\n    return cost_fn / sum(samples.values()), {}  # We return an optional metrics dict\n</code></pre> <p>The QAOA algorithm needs a variational quantum circuit with optimizable parameters. For that purpose, we use a fully analog circuit composed of two global rotations per layer on different axes of the Bloch sphere. The first rotation corresponds to the mixing Hamiltonian and the second one to the embedding Hamiltonian <sup>1</sup>. In this setting, the embedding is realized by the appropriate register coordinates and the resulting qubit interaction.</p> Rydberg level <p>The Rydberg level is set to 70. We initialize the weighted register graph from the QUBO definition similarly to what is done in the original tutorial, and set the device specifications with the updated Rydberg level.</p> <pre><code># Device specification and atomic register\ndevice = RydbergDevice(rydberg_level=70)\n\nreg = Register.from_coordinates(\n    qubo_register_coords(Q, device), device_specs=device\n)\n\n# Analog variational quantum circuit\nlayers = 2\nblock = chain(*[AnalogRX(f\"t{i}\") * AnalogRZ(f\"s{i}\") for i in range(layers)])\ncircuit = QuantumCircuit(reg, block)\n</code></pre> <pre><code>\n</code></pre> <p>By feeding the circuit to a <code>QuantumModel</code> we can check the initial counts where no clear solution can be found:</p> <pre><code>model = QuantumModel(circuit)\ninitial_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> <pre><code>initial_counts = Counter({'01000': 197, '00001': 193, '00010': 189, '00100': 174, '10000': 169, '00000': 78})\n</code></pre> <p>Finally, we can proceed with the variational optimization. The cost function defined above is derived from bitstring computations and therefore non differentiable. We use Qadence ML facilities to run gradient-free optimizations using the <code>nevergrad</code> library.</p> <pre><code>config = TrainConfig(max_iter=100)\noptimizer = ng.optimizers.NGOpt(\n    budget=config.max_iter, parametrization=num_parameters(model)\n)\ntrain_gradient_free(model, None, optimizer, config, loss)\n\noptimal_counts = model.sample({}, n_shots=1000)[0]\n</code></pre>   optimal_count = Counter({'00100': 191, '10000': 190, '00001': 183, '01000': 181, '00010': 163, '00000': 92})    <p>Finally, let's plot the solution. The expected bitstrings are marked in red.</p> <pre><code># Known solutions to the QUBO problem.\nsolution_bitstrings = [\"01011\", \"00111\"]\n\ndef plot_distribution(C, ax, title):\n    C = dict(sorted(C.items(), key=lambda item: item[1], reverse=True))\n    indexes = solution_bitstrings # QUBO solutions\n    color_dict = {key: \"r\" if key in indexes else \"g\" for key in C}\n    ax.set_xlabel(\"bitstrings\")\n    ax.set_ylabel(\"counts\")\n    ax.set_xticks([i for i in range(len(C.keys()))], C.keys(), rotation=90)\n    ax.bar(list(C.keys())[:20], list(C.values())[:20])\n    ax.set_title(title)\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 4))\nplot_distribution(initial_counts, axs[0], \"Initial counts\")\nplot_distribution(optimal_counts, axs[1], \"Optimal counts\")\n</code></pre> 2024-09-20T08:34:28.813695 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/analog-qubo/#references","title":"References","text":"<ol> <li> <p>Edward Farhi, Jeffrey Goldstone, Sam Gutmann, A Quantum Approximate Optimization Algorithm, arXiv:1411.4028 (2014) \u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/","title":"<code>CNOT</code> with interacting qubits","text":"<p>Digital-analog quantum computing focuses on using single qubit digital gates combined with more complex and device-dependent analog interactions to represent quantum programs. This paradigm has been shown to be universal for quantum computation<sup>1</sup>. However, while this approach may have advantages when adapting quantum programs to real devices, known quantum algorithms are very often expressed in a fully digital paradigm. As such, it is also important to have concrete ways to transform from one paradigm to another.</p> <p>This tutorial will exemplify the DAQC transformation starting with the representation of a simple digital <code>CNOT</code> using the universality of the Ising Hamiltonian<sup>2</sup>.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#cnot-with-cphase","title":"<code>CNOT</code> with <code>CPHASE</code>","text":"<p>Let's look at a single example of how the digital-analog transformation can be used to perform a <code>CNOT</code> on two qubits inside a register of globally interacting qubits.</p> <p>First, note that the <code>CNOT</code> can be decomposed with two Hadamard and a <code>CPHASE</code> gate with \\(\\phi=\\pi\\):</p> <pre><code>import torch\nfrom qadence import chain, sample, product_state\n\nfrom qadence.draw import display\nfrom qadence import X, I, Z, H, N, CPHASE, CNOT, HamEvo, PI\n\nn_qubits = 2\n\n# CNOT gate\ncnot_gate = CNOT(0, 1)\n\n# CNOT decomposed\nphi = PI\ncnot_decomp = chain(H(1), CPHASE(0, 1, phi), H(1))\n\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample from CNOT gate and 100 shots = [Counter({'11': 100})]\nsample from decomposed CNOT gate and 100 shots = [Counter({'11': 100})]\n</code></pre> <p>The <code>CPHASE</code> matrix is diagonal, and can be implemented by exponentiating an Ising-like Hamiltonian, or generator,</p> \\[\\text{CPHASE}(i,j,\\phi)=\\text{exp}\\left(-i\\phi \\mathcal{H}_\\text{CP}(i, j)\\right)\\] \\[\\begin{aligned} \\mathcal{H}_\\text{CP}&amp;=-\\frac{1}{4}(I_i-Z_i)(I_j-Z_j)\\\\ &amp;=-N_iN_j \\end{aligned}\\] <p>where the number operator \\(N_i = \\frac{1}{2}(I_i-Z_i)=\\hat{n}_i\\) is used, leading to an Ising-like interaction \\(\\hat{n}_i\\hat{n}_j\\) realisable in neutral-atom systems. Let's rebuild the <code>CNOT</code> using this evolution.</p> <pre><code>from qadence import kron, block_to_tensor\n\n# Hamiltonian for the CPHASE gate\nh_cphase = (-1.0) * kron(N(0), N(1))\n\n# Exponentiating and time-evolving the Hamiltonian until t=phi.\ncphase_evo = HamEvo(h_cphase, phi)\n\n# Check that we have the CPHASE gate:\ncphase_matrix = block_to_tensor(CPHASE(0, 1, phi))\ncphase_evo_matrix = block_to_tensor(cphase_evo)\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix: True\n</code></pre> <p>Now that the <code>CPHASE</code> generator is checked, it can be applied to the <code>CNOT</code>:</p> <pre><code># CNOT with Hamiltonian Evolution\ncnot_evo = chain(\n    H(1),\n    cphase_evo,\n    H(1)\n)\n\n# Initialize state to check CNOTs sample outcomes.\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample cnot_gate = [Counter({'11': 100})]\nsample cnot_evo = [Counter({'11': 100})]\n</code></pre> <p>Thus, a <code>CNOT</code> gate can be created by combining a few single-qubit gates together with a two-qubit Ising interaction between the control and the target qubit which is the essence of the Ising transform proposed in the seminal DAQC paper<sup>2</sup> for \\(ZZ\\) interactions. In Qadence, both \\(ZZ\\) and \\(NN\\) interactions are supported.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#cnot-in-an-interacting-system-of-three-qubits","title":"<code>CNOT</code> in an interacting system of three qubits","text":"<p>Consider a simple experimental setup with \\(n=3\\) interacting qubits laid out in a triangular grid. For the sake of simplicity, all qubits interact with each other with an \\(NN\\)-Ising interaction of constant strength \\(g_\\text{int}\\). The Hamiltonian for the system can be written by summing interaction terms over all pairs:</p> \\[\\mathcal{H}_\\text{sys}=\\sum_{i=0}^{n}\\sum_{j=0}^{i-1}g_\\text{int}N_iN_j,\\] <p>which in this case leads to only three interaction terms,</p> \\[\\mathcal{H}_\\text{sys}=g_\\text{int}(N_0N_1+N_1N_2+N_0N_2)\\] <p>This generator can be easily built in Qadence:</p> <pre><code>from qadence import add, kron\nn_qubits = 3\n\n# Interaction strength.\ng_int = 1.0\n\n# Build a list of interactions.\ninteraction_list = []\nfor i in range(n_qubits):\n    for j in range(i):\n        interaction_list.append(g_int * kron(N(i), N(j)))\n\nh_sys = add(*interaction_list)\n</code></pre> <pre><code>h_sys = AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: 1.000] \n\u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(2)\n\u2502       \u2514\u2500\u2500 N(0)\n\u2514\u2500\u2500 [mul: 1.000] \n    \u2514\u2500\u2500 KronBlock(1,2)\n        \u251c\u2500\u2500 N(2)\n        \u2514\u2500\u2500 N(1)\n</code></pre> <p>Now let's consider that the experimental system is fixed, and qubits can not be isolated one from another. The options are:</p> <ul> <li>Turn on or off the global system Hamiltonian.</li> <li>Perform local single-qubit rotations.</li> </ul> <p>To perform a fully digital <code>CNOT(0,1)</code>, the interacting control on qubit 0 and target on qubit 1 must be isolated from the third one to implement the gate directly. While this can be achieved for a three-qubit system, it becomes experimentally untractable when scaling the qubit count.</p> <p>However, this is not the case within the digital-analog paradigm. In fact, the two qubit Ising interaction required for the <code>CNOT</code> can be represented with a combination of the global system Hamiltonian and a specific set of single-qubit rotations. Full details about this transformation are to be found in the DAQC paper<sup>2</sup> but a more succint yet in-depth description takes place in the next section. It is conveniently available in Qadence by calling the <code>daqc_transform</code> function.</p> <p>In the most general sense, the <code>daqc_transform</code> function will return a circuit that represents the evolution of a target Hamiltonian \\(\\mathcal{H}_\\text{target}\\) (here the unitary of the gate) until a specified time \\(t_f\\) by using only the evolution of a build Hamiltonian \\(\\mathcal{H}_\\text{build}\\) (here \\(\\mathcal{H}_\\text{sys}\\)) together with local \\(X\\)-gates. In Qadence, <code>daqc_transform</code> is applicable for \\(\\mathcal{H}_\\text{target}\\) and \\(\\mathcal{H}_\\text{build}\\) composed only of \\(ZZ\\)- or \\(NN\\)-interactions. These generators are parsed by the <code>daqc_transform</code> function and the appropriate type is automatically determined together with the appropriate single-qubit detunings and global phases.</p> <p>Let's apply it for the <code>CNOT</code> implementation:</p> <pre><code>from qadence import daqc_transform, Strategy\n\n# Settings for the target CNOT operation\ni = 0  # Control qubit\nj = 1  # Target qubit\nk = 2  # The extra qubit\n\n# Define the target CNOT operation\n# by composing with identity on the extra qubit.\ncnot_target = kron(CNOT(i, j), I(k))\n\n# The two-qubit NN-Ising interaction term for the CPHASE\nh_int = (-1.0) * kron(N(i), N(j))\n\n# Transforming the two-qubit Ising interaction using only our system Hamiltonian\ntransformed_ising = daqc_transform(\n    n_qubits=3,        # Total number of qubits in the transformation\n    gen_target=h_int,  # The target Ising generator\n    t_f=PI,            # The target evolution time\n    gen_build=h_sys,   # The building block Ising generator to be used\n    strategy=Strategy.SDAQC,   # Currently only sDAQC is implemented\n    ignore_global_phases=False  # Global phases from mapping between Z and N\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_6fb0152f58204b4c89185359ff5ff192 cluster_35bb67d182df449287e395f48c81cfdf cluster_b3e270c49c194cab9d9f623aeb72fa76 cluster_7f4ffb432d9c40738828cc08480e1585 cluster_04d699874eac4062b9fbca1d7c1f0b33 cluster_edbbf8e155c048879b9237c85461d1f1 cluster_8a98cc9a2625447fb7d5be87d8ddcef3 1c0cdb666add4bb0a3c42bda71a362a2 0 09834e1ef1834aea8dd7d3b094a2b509 HamEvo 1c0cdb666add4bb0a3c42bda71a362a2--09834e1ef1834aea8dd7d3b094a2b509 cd656fd00a3a4d1b98b58d57bf620d2a 1 e90e9cb91aea4e2ba943a30b90fad68a HamEvo 09834e1ef1834aea8dd7d3b094a2b509--e90e9cb91aea4e2ba943a30b90fad68a f3947713fa1d40f280bd665026a3bf99 HamEvo e90e9cb91aea4e2ba943a30b90fad68a--f3947713fa1d40f280bd665026a3bf99 fecc4b33366d436b932f4d7a87a81ddf X f3947713fa1d40f280bd665026a3bf99--fecc4b33366d436b932f4d7a87a81ddf 2979478688a24268aec0db62580ba2c4 HamEvo fecc4b33366d436b932f4d7a87a81ddf--2979478688a24268aec0db62580ba2c4 c7b6054d4bc5449998b2b4463cf70f79 HamEvo 2979478688a24268aec0db62580ba2c4--c7b6054d4bc5449998b2b4463cf70f79 432aa2524f7d4cb588cfc8e7645f4978 X c7b6054d4bc5449998b2b4463cf70f79--432aa2524f7d4cb588cfc8e7645f4978 41c6acf7ce66497396810ddb3b7c37eb 432aa2524f7d4cb588cfc8e7645f4978--41c6acf7ce66497396810ddb3b7c37eb 5428e023689b45ff950f808a7357a6ca HamEvo 41c6acf7ce66497396810ddb3b7c37eb--5428e023689b45ff950f808a7357a6ca 938c944353d249ddb44e24f870fae138 HamEvo 5428e023689b45ff950f808a7357a6ca--938c944353d249ddb44e24f870fae138 1663cde9797d4c50b06a3b17e88972e0 938c944353d249ddb44e24f870fae138--1663cde9797d4c50b06a3b17e88972e0 95a4c396693f4f408aa73fd408c9c10a 1663cde9797d4c50b06a3b17e88972e0--95a4c396693f4f408aa73fd408c9c10a b6431f751ae14ea8ae0706fd064c9752 d8db54775cde4ae196565c055a9b0451 t = -3.14 cd656fd00a3a4d1b98b58d57bf620d2a--d8db54775cde4ae196565c055a9b0451 0249598ea58e4b8b88b82e6f83e59393 2 45d6d609795945c69488fcbb038c0949 t = 3.142 d8db54775cde4ae196565c055a9b0451--45d6d609795945c69488fcbb038c0949 b57a33362bf94ff6afbaa2542c1f3fcb t = -3.14 45d6d609795945c69488fcbb038c0949--b57a33362bf94ff6afbaa2542c1f3fcb 6fab2bdeca2c4fef861673a9b10c04ff b57a33362bf94ff6afbaa2542c1f3fcb--6fab2bdeca2c4fef861673a9b10c04ff 946adf4e8f704dc0ab912927817bfc07 t = 1.571 6fab2bdeca2c4fef861673a9b10c04ff--946adf4e8f704dc0ab912927817bfc07 5ede70a677904ea4b60927a6d47d0868 t = 1.571 946adf4e8f704dc0ab912927817bfc07--5ede70a677904ea4b60927a6d47d0868 1eac0f36ae164301869a7ea2b6342f02 5ede70a677904ea4b60927a6d47d0868--1eac0f36ae164301869a7ea2b6342f02 4e237d9c13d84624bd8276aa362163ee X 1eac0f36ae164301869a7ea2b6342f02--4e237d9c13d84624bd8276aa362163ee 193ffcbcb90b425a8ee29c274887c2e5 t = 1.571 4e237d9c13d84624bd8276aa362163ee--193ffcbcb90b425a8ee29c274887c2e5 28e6125c4b6d4d33bd5da327f3f75b98 t = 1.571 193ffcbcb90b425a8ee29c274887c2e5--28e6125c4b6d4d33bd5da327f3f75b98 b975389ebcbd403890ee7115dab89dbe X 28e6125c4b6d4d33bd5da327f3f75b98--b975389ebcbd403890ee7115dab89dbe b975389ebcbd403890ee7115dab89dbe--b6431f751ae14ea8ae0706fd064c9752 dc932613cf4b4a4f9354a3a4be1d2b48 bb39dec877304d60b5abd7564522baba 0249598ea58e4b8b88b82e6f83e59393--bb39dec877304d60b5abd7564522baba 2d5862b65d6b4f98b485baa7d8ba61d3 bb39dec877304d60b5abd7564522baba--2d5862b65d6b4f98b485baa7d8ba61d3 18ef03329ac54ca88ea27f97ddb111ef 2d5862b65d6b4f98b485baa7d8ba61d3--18ef03329ac54ca88ea27f97ddb111ef f5728a14258543b884c32af230bc6e0a X 18ef03329ac54ca88ea27f97ddb111ef--f5728a14258543b884c32af230bc6e0a 092854c4d6094f9c87c929d2bc2aba88 f5728a14258543b884c32af230bc6e0a--092854c4d6094f9c87c929d2bc2aba88 3f468b9a2f104004bcf3d8c509cbea32 092854c4d6094f9c87c929d2bc2aba88--3f468b9a2f104004bcf3d8c509cbea32 34074d0179fd477aa41d76b3cb4585bc X 3f468b9a2f104004bcf3d8c509cbea32--34074d0179fd477aa41d76b3cb4585bc 739ff00e61544ed2b79a6f3c5e2985e5 X 34074d0179fd477aa41d76b3cb4585bc--739ff00e61544ed2b79a6f3c5e2985e5 af68dc3d19794a20913d86e171f6e315 739ff00e61544ed2b79a6f3c5e2985e5--af68dc3d19794a20913d86e171f6e315 3f4a7131633e41fcb76795208f8a00d0 af68dc3d19794a20913d86e171f6e315--3f4a7131633e41fcb76795208f8a00d0 a719d2fc89624d6c8fcc5d3a8bbe60ce X 3f4a7131633e41fcb76795208f8a00d0--a719d2fc89624d6c8fcc5d3a8bbe60ce a719d2fc89624d6c8fcc5d3a8bbe60ce--dc932613cf4b4a4f9354a3a4be1d2b48 <p>The output circuit displays three groups of system Hamiltonian evolutions which account for global-phases and single-qubit detunings related to the mapping between the \\(Z\\) and \\(N\\) operators. Optionally, global phases can be ignored.</p> <p>In general, the mapping of a \\(n\\)-qubit Ising Hamiltonian to another will require at most \\(n(n-1)\\) evolutions. The transformed circuit performs these evolutions for specific times that are computed from the solution of a linear system of equations involving the set of interactions in the target and build Hamiltonians.</p> <p>In this case, the mapping is exact when using the step-wise DAQC strategy (<code>Strategy.SDAQC</code>) available in Qadence. In banged DAQC (<code>Strategy.BDAQC</code>) the mapping is approximate, but easier to implement on a physical device with always-on interactions such as neutral-atom systems.</p> <p>Just as before, the transformed Ising circuit can be checked to exactly recover the <code>CPHASE</code> gate:</p> <pre><code># CPHASE on (i, j), Identity on third qubit:\ncphase_matrix = block_to_tensor(kron(CPHASE(i, j, phi), I(k)))\n\n# CPHASE using the transformed circuit:\ncphase_evo_matrix = block_to_tensor(transformed_ising)\n\n# Check that it implements the CPHASE.\n# Will fail if global phases are ignored.\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix : True\n</code></pre> <p>The <code>CNOT</code> gate can now finally be built:</p> <pre><code>from qadence import equivalent_state, run, sample\n\ncnot_daqc = chain(\n    H(j),\n    transformed_ising,\n    H(j)\n)\n\n# And finally apply the CNOT on a specific 3-qubit initial state:\ninit_state = product_state(\"101\")\n\n# Check we get an equivalent wavefunction\nwf_cnot = run(n_qubits, block=cnot_target, state=init_state)\nwf_daqc = run(n_qubits, block=cnot_daqc, state=init_state)\n\n# Visualize the CNOT bit-flip in samples.\n</code></pre> <pre><code>wf_cnot == wf_dacq : True\nsample cnot_target = [Counter({'111': 100})]\nsample cnot_dacq = [Counter({'111': 100})]\n</code></pre> <p>As one can see, a <code>CNOT</code> operation has been succesfully implemented on the desired target qubits by using only the global system as the building block Hamiltonian and single-qubit rotations. Decomposing a single digital gate into an Ising Hamiltonian serves as a proof of principle for the potential of this technique to represent universal quantum computation.</p>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#technical-details-on-the-daqc-transformation","title":"Technical details on the DAQC transformation","text":"<ul> <li>The mapping between target generator and final circuit is performed by solving a linear system of size \\(n(n-1)\\) where \\(n\\) is the number of qubits, so it can be computed efficiently (i.e., with a polynomial cost in the number of qubits).</li> <li>The linear system to be solved is actually not invertible for \\(n=4\\) qubits. This is very specific edge case requiring a workaround, that is currently not yet implemented.</li> <li>As mentioned, the final circuit has at most \\(n(n-1)\\) slices, so there is at most a quadratic overhead in circuit depth.</li> </ul> <p>Finally, and most important to its usage:</p> <ul> <li>The target Hamiltonian should be sufficiently represented in the building block Hamiltonian.</li> </ul> <p>To illustrate this point, consider the following target and build Hamiltonians:</p> <pre><code># Interaction between qubits 0 and 1\ngen_target = 1.0 * (Z(0) @ Z(1))\n\n# Fixed interaction between qubits 1 and 2, and customizable between 0 and 1\ndef gen_build(g_int):\n    return g_int * (Z(0) @ Z(1)) + 1.0 * (Z(1) @ Z(2))\n</code></pre> <p>And now we perform the DAQC transform by setting <code>g_int=1.0</code>, exactly matching the target Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\n    n_qubits=3,\n    gen_target=gen_target,\n    t_f=1.0,\n    gen_build=gen_build(g_int=1.0),\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_e30ed3611ddc44118168138a2a691448 cluster_b3f0a65728b2436b82afdfa8aaa8a087 03d92dde30d4479685e9f31c11108443 0 6e71fe179c3d4e2e8527de643a73f0dc X 03d92dde30d4479685e9f31c11108443--6e71fe179c3d4e2e8527de643a73f0dc 69877bd517954d878950fd366bebab38 1 4791aa25df3c4237a0e0cf8b7f809c85 HamEvo 6e71fe179c3d4e2e8527de643a73f0dc--4791aa25df3c4237a0e0cf8b7f809c85 f7c2f376863c40e08817e52fc8aeac9c X 4791aa25df3c4237a0e0cf8b7f809c85--f7c2f376863c40e08817e52fc8aeac9c d1cde4877d1a4b59a2e549753303d336 f7c2f376863c40e08817e52fc8aeac9c--d1cde4877d1a4b59a2e549753303d336 9d4f1f8e8a724fc3b17d4635ad8c7194 HamEvo d1cde4877d1a4b59a2e549753303d336--9d4f1f8e8a724fc3b17d4635ad8c7194 c7fab87518744d088b8d950c2db07cc8 9d4f1f8e8a724fc3b17d4635ad8c7194--c7fab87518744d088b8d950c2db07cc8 747f8ab8e94e427abac4ecbf6cbff69f c7fab87518744d088b8d950c2db07cc8--747f8ab8e94e427abac4ecbf6cbff69f b8788dfe7ee04a9cb0a773124e607605 855f8c8ca06f4eecafc5ffd91262b45c 69877bd517954d878950fd366bebab38--855f8c8ca06f4eecafc5ffd91262b45c c921dde6285d4a259c769bb4018861bd 2 e51e8733d1684635a807ae4a76b446c8 t = -0.50 855f8c8ca06f4eecafc5ffd91262b45c--e51e8733d1684635a807ae4a76b446c8 8324ba2b83a0409b8d7a61a756a8c38b e51e8733d1684635a807ae4a76b446c8--8324ba2b83a0409b8d7a61a756a8c38b 73d547f6f4714eb78f3c8a4dbe9a7186 X 8324ba2b83a0409b8d7a61a756a8c38b--73d547f6f4714eb78f3c8a4dbe9a7186 791027d5f9c244beb66a3dc9f43edf5d t = -0.50 73d547f6f4714eb78f3c8a4dbe9a7186--791027d5f9c244beb66a3dc9f43edf5d b1caa796e6894a0fa6161b87cf093f63 X 791027d5f9c244beb66a3dc9f43edf5d--b1caa796e6894a0fa6161b87cf093f63 b1caa796e6894a0fa6161b87cf093f63--b8788dfe7ee04a9cb0a773124e607605 7a0fc45a6a374794b2f88960c8558923 ddd7130d805c4134ad17bd7c7a290e87 X c921dde6285d4a259c769bb4018861bd--ddd7130d805c4134ad17bd7c7a290e87 8782c1c57c6c4bea810666c19eee83d4 ddd7130d805c4134ad17bd7c7a290e87--8782c1c57c6c4bea810666c19eee83d4 193dfe910fb24cb28847a8721699d51f X 8782c1c57c6c4bea810666c19eee83d4--193dfe910fb24cb28847a8721699d51f b563c98936ce4e5d9c5390ff356a114c X 193dfe910fb24cb28847a8721699d51f--b563c98936ce4e5d9c5390ff356a114c 99232d1c112f499982f92248c273314f b563c98936ce4e5d9c5390ff356a114c--99232d1c112f499982f92248c273314f 05b4c264dc9c4c5c8d537bec86c5e92a X 99232d1c112f499982f92248c273314f--05b4c264dc9c4c5c8d537bec86c5e92a 05b4c264dc9c4c5c8d537bec86c5e92a--7a0fc45a6a374794b2f88960c8558923 <p>Now, if the interaction between qubits 0 and 1 is weakened in the build Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\n    n_qubits=3,\n    gen_target=gen_target,\n    t_f=1.0,\n    gen_build=gen_build(g_int=0.001),\n)\n\n# display(transformed_ising)\n</code></pre> %3 cluster_0659708993aa4c2d9d14a575007d0b90 cluster_e8ffabf12552431eb392413f6606fa60 640929f8a337491e8b8d6f4542ed318c 0 dac4eaeaa6d04cf1869318aa2773d279 X 640929f8a337491e8b8d6f4542ed318c--dac4eaeaa6d04cf1869318aa2773d279 f9adc240018343efa40d02bdf035e1ae 1 88e94897a5894db8a36cf6d46515e630 HamEvo dac4eaeaa6d04cf1869318aa2773d279--88e94897a5894db8a36cf6d46515e630 cc81247d9a1f49d0b9df55e789462383 X 88e94897a5894db8a36cf6d46515e630--cc81247d9a1f49d0b9df55e789462383 264a38af53e94122aa1d566ce39431f0 cc81247d9a1f49d0b9df55e789462383--264a38af53e94122aa1d566ce39431f0 d6af009949b44b478caf169b720d3ed6 HamEvo 264a38af53e94122aa1d566ce39431f0--d6af009949b44b478caf169b720d3ed6 6e44084eacc943bab7290dbddf2eca12 d6af009949b44b478caf169b720d3ed6--6e44084eacc943bab7290dbddf2eca12 d31857b52c7040b1b07da0936d6b8c6b 6e44084eacc943bab7290dbddf2eca12--d31857b52c7040b1b07da0936d6b8c6b b83074040bea492aa1c8d3aae630e131 b4175003654144db96dabb6d236dcdc3 f9adc240018343efa40d02bdf035e1ae--b4175003654144db96dabb6d236dcdc3 0850c754048e4165b6121a3270636e4f 2 4e8d3c6141e84c9c9c16fba8b7101b29 t = -500. b4175003654144db96dabb6d236dcdc3--4e8d3c6141e84c9c9c16fba8b7101b29 e2e153c8802d4fd69bd11ac3aa539d3a 4e8d3c6141e84c9c9c16fba8b7101b29--e2e153c8802d4fd69bd11ac3aa539d3a ebc690fdade84e418c645a0ea15fd182 X e2e153c8802d4fd69bd11ac3aa539d3a--ebc690fdade84e418c645a0ea15fd182 92ddd19d4d3a46b7832781fef2ff25b8 t = -500. ebc690fdade84e418c645a0ea15fd182--92ddd19d4d3a46b7832781fef2ff25b8 e7ffcecb9238421d9caf4639b496bc0a X 92ddd19d4d3a46b7832781fef2ff25b8--e7ffcecb9238421d9caf4639b496bc0a e7ffcecb9238421d9caf4639b496bc0a--b83074040bea492aa1c8d3aae630e131 9b15f91db26740668a6d2b7b31ca09fe e5d86795b85d45e4b99ec6705fcbe8de X 0850c754048e4165b6121a3270636e4f--e5d86795b85d45e4b99ec6705fcbe8de a3f53c864efd45cd97db2c94eafc2465 e5d86795b85d45e4b99ec6705fcbe8de--a3f53c864efd45cd97db2c94eafc2465 cd50c82e5ea242fe8661c246665e3fa5 X a3f53c864efd45cd97db2c94eafc2465--cd50c82e5ea242fe8661c246665e3fa5 50e7cce150d347f597f37c0b8d153d69 X cd50c82e5ea242fe8661c246665e3fa5--50e7cce150d347f597f37c0b8d153d69 a62f5a5e6079474a888ab14d1d1ff89e 50e7cce150d347f597f37c0b8d153d69--a62f5a5e6079474a888ab14d1d1ff89e 61dec6f253bd4b2487cfaf13109b34e9 X a62f5a5e6079474a888ab14d1d1ff89e--61dec6f253bd4b2487cfaf13109b34e9 61dec6f253bd4b2487cfaf13109b34e9--9b15f91db26740668a6d2b7b31ca09fe <p>The times slices using the build Hamiltonian need now to evolve for much longer to represent the same interaction since it is not sufficiently represented in the building block Hamiltonian.</p> <p>In the limit where that interaction is not present, the transform will not work:</p> <pre><code>try:\n    transformed_ising = daqc_transform(\n        n_qubits=3,\n        gen_target=gen_target,\n        t_f=1.0,\n        gen_build=gen_build(g_int = 0.0),\n    )\nexcept ValueError as error:\n    print(\"Error:\", error)\n</code></pre> <pre><code>Error: Incompatible interactions between target and build Hamiltonians.\n</code></pre>"},{"location":"tutorials/digital_analog_qc/daqc-cnot/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/","title":"Fitting a function with a Hamiltonian ansatz","text":"<p>In the analog QCL tutorial we used analog blocks to learn a function of interest. The analog blocks are a direct abstraction of device execution with global addressing. However, we may want to directly program an Hamiltonian-level ansatz to have a finer control on our model. In Qadence this can easily be done through digital-analog programs. In this tutorial we will solve a simple QCL problem with this approach.</p>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#setting-up-the-problem","title":"Setting up the problem","text":"<p>The example problem considered is to fit a function of interest in a specified range. Below we define and plot the function \\(f(x)=x^5\\).</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\n\n# Function to fit:\ndef f(x):\n    return x**5\n\nxmin = -1.0\nxmax = 1.0\nn_test = 100\n\nx_test = torch.linspace(xmin, xmax, steps = n_test)\ny_test = f(x_test)\n\nplt.plot(x_test, y_test)\nplt.xlim((-1.1, 1.1))\nplt.ylim((-1.1, 1.1))\n</code></pre> 2024-09-20T08:34:29.184268 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#digital-analog-ansatz","title":"Digital-Analog Ansatz","text":"<p>We start by defining the register of qubits. The topology we use now will define the interactions in the entangling Hamiltonian. As an example, we can define a rectangular lattice with 6 qubits.</p> <pre><code>from qadence import Register\n\nreg = Register.rectangular_lattice(\n    qubits_row = 3,\n    qubits_col = 2,\n)\n</code></pre> <p>Inspired by the Ising interaction mode of Rydberg atoms, we can now define an interaction Hamiltonian as \\(\\mathcal{H}_{ij}=\\frac{1}{r_{ij}^6}N_iN_j\\), where \\(N_i=(1/2)(I_i-Z_i)\\) is the number operator and and \\(r_{ij}\\) is the distance between qubits \\(i\\) and \\(j\\). We can easily instatiate this interaction Hamiltonian from the register information:</p> <pre><code>from qadence import N, add\n\ndef h_ij(i: int, j: int):\n    return N(i)@N(j)\n\nh_int = add(h_ij(*edge)/r**6 for edge, r in reg.edge_distances.items())\n</code></pre> <p>To build the digital-analog ansatz we can make use of the standard <code>hea</code> function by specifying we want to use the <code>Strategy.SDAQC</code> and passing the Hamiltonian we created as the entangler, as see in the QML constructors tutorial. The entangling operation will be replaced by the evolution of this Hamiltonian <code>HamEvo(h_int, t)</code>, where the time parameter <code>t</code> is considered to be a variational parameter at each layer.</p> <pre><code>from qadence import hea, Strategy, RX, RY\n\ndepth = 2\n\nda_ansatz = hea(\n    n_qubits = reg.n_qubits,\n    depth = depth,\n    operations = [RX, RY, RX],\n    entangler = h_int,\n    strategy = Strategy.SDAQC,\n)\n\nprint(html_string(da_ansatz))\n</code></pre> %3 cluster_f3bcc41c5b3b424d875afd31a1f5f591 cluster_690d521b60b540a387a07fae89d85e27 fc300def63f54848a032f6d9e4fda38b 0 5256d81b63d34ab6818f747352f97222 RX(theta\u2080) fc300def63f54848a032f6d9e4fda38b--5256d81b63d34ab6818f747352f97222 8b7a5dfee77d4299bea4973fa9d244f5 1 ad8a4cc0e7f349c7a021e0c1bf8013b1 RY(theta\u2086) 5256d81b63d34ab6818f747352f97222--ad8a4cc0e7f349c7a021e0c1bf8013b1 303a6cbe629448d28ad25814aacc8557 RX(theta\u2081\u2082) ad8a4cc0e7f349c7a021e0c1bf8013b1--303a6cbe629448d28ad25814aacc8557 00dfc18452094b1ca3f71e87249e2ae6 303a6cbe629448d28ad25814aacc8557--00dfc18452094b1ca3f71e87249e2ae6 6bbe774c468443168056a6d1f912b9d4 RX(theta\u2081\u2088) 00dfc18452094b1ca3f71e87249e2ae6--6bbe774c468443168056a6d1f912b9d4 6c2a2b5bc1f34ba381a0b6abd5a7e781 RY(theta\u2082\u2084) 6bbe774c468443168056a6d1f912b9d4--6c2a2b5bc1f34ba381a0b6abd5a7e781 4ca494452f984b538e692cb3e2f472be RX(theta\u2083\u2080) 6c2a2b5bc1f34ba381a0b6abd5a7e781--4ca494452f984b538e692cb3e2f472be 6daa560676284227bb37907dbb2fb035 4ca494452f984b538e692cb3e2f472be--6daa560676284227bb37907dbb2fb035 3a1cfa8cfbbe46b9b5c8c35a3e5255ce 6daa560676284227bb37907dbb2fb035--3a1cfa8cfbbe46b9b5c8c35a3e5255ce df9428bb42dc43e9a5e6a1cc4bfc86c5 d30ead2adff84c89bf48d94d4a55e2e5 RX(theta\u2081) 8b7a5dfee77d4299bea4973fa9d244f5--d30ead2adff84c89bf48d94d4a55e2e5 25acd838f37749dd81b4a83018f52d13 2 4cbd0a5fe3b244fcb312e824d82454b7 RY(theta\u2087) d30ead2adff84c89bf48d94d4a55e2e5--4cbd0a5fe3b244fcb312e824d82454b7 a0acfe627f4d40c6b523131347cd4388 RX(theta\u2081\u2083) 4cbd0a5fe3b244fcb312e824d82454b7--a0acfe627f4d40c6b523131347cd4388 c88c8fe8e9e64b79b5b6a2418bde7d25 a0acfe627f4d40c6b523131347cd4388--c88c8fe8e9e64b79b5b6a2418bde7d25 b2fac016600b4f2cada30c7a0cbd353b RX(theta\u2081\u2089) c88c8fe8e9e64b79b5b6a2418bde7d25--b2fac016600b4f2cada30c7a0cbd353b 1f8608f28188459bb68d8af6af581905 RY(theta\u2082\u2085) b2fac016600b4f2cada30c7a0cbd353b--1f8608f28188459bb68d8af6af581905 61ed0580a9114606b901e34e5626a58c RX(theta\u2083\u2081) 1f8608f28188459bb68d8af6af581905--61ed0580a9114606b901e34e5626a58c 0910cc4d03d74d5cbd157426d89201c1 61ed0580a9114606b901e34e5626a58c--0910cc4d03d74d5cbd157426d89201c1 0910cc4d03d74d5cbd157426d89201c1--df9428bb42dc43e9a5e6a1cc4bfc86c5 e616f88cc0ef48159e94e88a85780990 bfbd605e82aa42a381a913df9cf37f9f RX(theta\u2082) 25acd838f37749dd81b4a83018f52d13--bfbd605e82aa42a381a913df9cf37f9f 345202ff2f5c4e7ab135ba64391114fb 3 f4bb4327ece14f47ad0141a8d7d62b44 RY(theta\u2088) bfbd605e82aa42a381a913df9cf37f9f--f4bb4327ece14f47ad0141a8d7d62b44 fd0ae8cf5d67474bbc4d6fac813984f7 RX(theta\u2081\u2084) f4bb4327ece14f47ad0141a8d7d62b44--fd0ae8cf5d67474bbc4d6fac813984f7 0493cd66647f43098c7a8b0e82e26371 HamEvo fd0ae8cf5d67474bbc4d6fac813984f7--0493cd66647f43098c7a8b0e82e26371 8a56522616ee4381bb33069edf186756 RX(theta\u2082\u2080) 0493cd66647f43098c7a8b0e82e26371--8a56522616ee4381bb33069edf186756 91652dae81be445a82ebaaf604017f03 RY(theta\u2082\u2086) 8a56522616ee4381bb33069edf186756--91652dae81be445a82ebaaf604017f03 3ddb1c36e51d4a1faa2009b4806cd952 RX(theta\u2083\u2082) 91652dae81be445a82ebaaf604017f03--3ddb1c36e51d4a1faa2009b4806cd952 033af10e7bd146628f3f35d28c61519d HamEvo 3ddb1c36e51d4a1faa2009b4806cd952--033af10e7bd146628f3f35d28c61519d 033af10e7bd146628f3f35d28c61519d--e616f88cc0ef48159e94e88a85780990 40545bf75f99460e8d1c517e50f7e9b3 61caa7a4ec4040d291751d3453d27789 RX(theta\u2083) 345202ff2f5c4e7ab135ba64391114fb--61caa7a4ec4040d291751d3453d27789 ef2f10a9351342048e3080d07f9335a5 4 33172ab3185d4d5797f97c456defd888 RY(theta\u2089) 61caa7a4ec4040d291751d3453d27789--33172ab3185d4d5797f97c456defd888 b092c72e5a454f93b35a949234aa4754 RX(theta\u2081\u2085) 33172ab3185d4d5797f97c456defd888--b092c72e5a454f93b35a949234aa4754 d5f5b13e09184879b85928b442e3c223 t = theta_t\u2080 b092c72e5a454f93b35a949234aa4754--d5f5b13e09184879b85928b442e3c223 5eeb1ee2141a4ad789d6f81ab44f7212 RX(theta\u2082\u2081) d5f5b13e09184879b85928b442e3c223--5eeb1ee2141a4ad789d6f81ab44f7212 d5e9ef2e1c554f668cc971b3ad874b3b RY(theta\u2082\u2087) 5eeb1ee2141a4ad789d6f81ab44f7212--d5e9ef2e1c554f668cc971b3ad874b3b 556d04980cec41c0b33c9cfc2dc8946b RX(theta\u2083\u2083) d5e9ef2e1c554f668cc971b3ad874b3b--556d04980cec41c0b33c9cfc2dc8946b f8f6caaca8424c13856e16a1489b8b83 t = theta_t\u2081 556d04980cec41c0b33c9cfc2dc8946b--f8f6caaca8424c13856e16a1489b8b83 f8f6caaca8424c13856e16a1489b8b83--40545bf75f99460e8d1c517e50f7e9b3 962fbbda8a204800b4aadba34e7f9956 b0b0bac36dd0432a855387bb030b8cfd RX(theta\u2084) ef2f10a9351342048e3080d07f9335a5--b0b0bac36dd0432a855387bb030b8cfd 68f7dbdf78c046f78b8b732c6485c728 5 cd2e511957104b3f99239dd03a1be2c4 RY(theta\u2081\u2080) b0b0bac36dd0432a855387bb030b8cfd--cd2e511957104b3f99239dd03a1be2c4 b2fe898158e448feac03b86d22987cb0 RX(theta\u2081\u2086) cd2e511957104b3f99239dd03a1be2c4--b2fe898158e448feac03b86d22987cb0 6c080ad35e804e53a24329a6d7201c92 b2fe898158e448feac03b86d22987cb0--6c080ad35e804e53a24329a6d7201c92 782b7c197f3545b099ddb1ebe69c6311 RX(theta\u2082\u2082) 6c080ad35e804e53a24329a6d7201c92--782b7c197f3545b099ddb1ebe69c6311 3f6382dc168949a196fe0fe44f59a8e5 RY(theta\u2082\u2088) 782b7c197f3545b099ddb1ebe69c6311--3f6382dc168949a196fe0fe44f59a8e5 89f56e509ec74e77a8fe2bcd4c3d7421 RX(theta\u2083\u2084) 3f6382dc168949a196fe0fe44f59a8e5--89f56e509ec74e77a8fe2bcd4c3d7421 ad6c7f538b1944ff99839f387f97a3b6 89f56e509ec74e77a8fe2bcd4c3d7421--ad6c7f538b1944ff99839f387f97a3b6 ad6c7f538b1944ff99839f387f97a3b6--962fbbda8a204800b4aadba34e7f9956 a963faa91b3548b09b53107f22fea234 312fbd5a6a7c42ce82a3178f0890f2a1 RX(theta\u2085) 68f7dbdf78c046f78b8b732c6485c728--312fbd5a6a7c42ce82a3178f0890f2a1 527d792176e94e5c84891df04f7f448e RY(theta\u2081\u2081) 312fbd5a6a7c42ce82a3178f0890f2a1--527d792176e94e5c84891df04f7f448e ae5a9a46469b474e9e03952f32228d4c RX(theta\u2081\u2087) 527d792176e94e5c84891df04f7f448e--ae5a9a46469b474e9e03952f32228d4c e26b2a85f23c4aacb6ba297e5d12a157 ae5a9a46469b474e9e03952f32228d4c--e26b2a85f23c4aacb6ba297e5d12a157 5fffa588b2474625b53a99390104b339 RX(theta\u2082\u2083) e26b2a85f23c4aacb6ba297e5d12a157--5fffa588b2474625b53a99390104b339 e695ba672e114d28939e59f629ef32fc RY(theta\u2082\u2089) 5fffa588b2474625b53a99390104b339--e695ba672e114d28939e59f629ef32fc 20de194021f84f85a35ae88be8523520 RX(theta\u2083\u2085) e695ba672e114d28939e59f629ef32fc--20de194021f84f85a35ae88be8523520 b6d27eb684734d88aa3ad7cb327cf4e4 20de194021f84f85a35ae88be8523520--b6d27eb684734d88aa3ad7cb327cf4e4 b6d27eb684734d88aa3ad7cb327cf4e4--a963faa91b3548b09b53107f22fea234"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#creating-the-quantummodel","title":"Creating the QuantumModel","text":"<p>The rest of the procedure is the same as any other Qadence workflow. We start by defining a feature map for input encoding and an observable for output decoding.</p> <pre><code>from qadence import feature_map, BasisSet, ReuploadScaling\nfrom qadence import Z, I\n\nfm = feature_map(\n    n_qubits = reg.n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Total magnetization\nobservable = add(Z(i) for i in range(reg.n_qubits))\n</code></pre> <p>And we have all the ingredients to initialize the <code>QuantumModel</code>:</p> <pre><code>from qadence import QuantumCircuit, QuantumModel\n\ncircuit = QuantumCircuit(reg, fm, da_ansatz)\n\nmodel = QuantumModel(circuit, observable = observable)\n</code></pre>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#training-the-model","title":"Training the model","text":"<p>We can now train the model. We use a set of 20 equally spaced training points.</p> <pre><code># Chebyshev FM does not accept x = -1, 1\nxmin = -0.99\nxmax = 0.99\nn_train = 20\n\nx_train = torch.linspace(xmin, xmax, steps = n_train)\ny_train = f(x_train)\n\n# Initial model prediction\ny_pred_initial = model.expectation({\"x\": x_test}).detach()\n</code></pre> <p>And we use a simple custom training loop.</p> <pre><code>criterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nn_epochs = 200\n\ndef loss_fn(x_train, y_train):\n    out = model.expectation({\"x\": x_train})\n    loss = criterion(out.squeeze(), y_train)\n    return loss\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_fn(x_train, y_train)\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"tutorials/digital_analog_qc/digital-analog-qcl/#results","title":"Results","text":"<p>Finally we can plot the resulting trained model.</p> <pre><code>y_pred_final = model.expectation({\"x\": x_test}).detach()\n\nplt.plot(x_test, y_pred_initial, label = \"Initial prediction\")\nplt.plot(x_test, y_pred_final, label = \"Final prediction\")\nplt.scatter(x_train, y_train, label = \"Training points\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend()\nplt.xlim((-1.1, 1.1))\nplt.ylim((-1.1, 1.1))\n</code></pre> 2024-09-20T08:34:38.366156 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/","title":"Pulse-level programming with Pulser","text":"<p>Qadence offers a direct interface with Pulser<sup>1</sup>, an open-source pulse-level interface written in Python and specifically designed for programming neutral atom quantum computers.</p> <p>Using directly Pulser requires advanced knowledge on pulse-level programming and on how neutral atom devices work. Qadence abstracts this complexity out by using the familiar block-based interface for building pulse sequences in Pulser while leaving the possibility to directly manipulate them if required by, for instance, optimal pulse shaping.</p> <p>Note</p> <p>The Pulser backend is still experimental and the interface might change in the future. Please note that it does not support <code>DiffMode.AD</code>.</p> <p>Note</p> <p>With the Pulser backend, <code>qadence</code> simulations can be executed on the cloud emulators available on the PASQAL cloud platform. In order to do so, make to have valid credentials for the PASQAL cloud platform and use the following configuration for the Pulser backend:</p> <pre><code>config = {\n    \"cloud_configuration\": {\n        \"username\": \"&lt;changeme&gt;\",\n        \"password\": \"&lt;changeme&gt;\",\n        \"project_id\": \"&lt;changeme&gt;\",  # the project should have access to emulators\n        \"platform\": \"EMU_FREE\"  # choose between `EMU_TN` and `EMU_FREE`\n    }\n}\n</code></pre> <p>For inquiries and more details on the cloud credentials, please contact info@pasqal.com.</p>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#default-qubit-interaction","title":"Default qubit interaction","text":"<p>When simulating pulse sequences written using Pulser, the underlying constructed Hamiltonian is equivalent to a digital-analog quantum computing program (see digital-analog emulation for more details) with the following interaction term:</p> \\[ \\mathcal{H}_{\\textrm{int}} = \\sum_{i&lt;j} \\frac{C_6}{|R_i - R_j|^6} \\hat{n}_i \\hat{n}_j \\] <p>where \\(C_6\\) is an interaction strength coefficient dependent on the principal quantum number of chosen the neutral atom system, \\(R_i\\) are atomic positions in Cartesian coordinates and \\(\\hat{n} = \\frac{1-\\sigma^z_i}{2}\\) the number operator.</p> <p>Note</p> <p>The Ising interaction is always-on for all computations performed with the Pulser backend. It cannot be switched off.</p>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#available-quantum-operations","title":"Available quantum operations","text":"<p>Currently, the Pulser backend supports the following operations:</p> gate description trainable parameter <code>RX</code>, <code>RY</code> Single qubit rotations. Notice that the interaction is on and this affects the resulting gate fidelity. rotation angle <code>AnalogRX</code>, <code>AnalogRY</code>, <code>AnalogRZ</code> Span a single qubit rotation among the entire register. rotation angle <code>entangle</code> Fully entangle the register. interaction time <code>AnalogInteraction</code> An idle block to to free-evolve for a duration according to the interaction. free evolution time"},{"location":"tutorials/digital_analog_qc/pulser-basic/#sequence-the-bell-state-on-a-two-qubit-register","title":"Sequence the Bell state on a two qubit register","text":"<p>The next example illustrates how to create a pulse sequence to prepare a Bell state. This is a sequence of an entanglement operation, represented as an <code>entangle</code> gate (using <code>CZ</code> interactions) in the \\(X\\)-basis and a \\(Y\\) rotation for readout in the \\(Z\\)-basis:</p> <pre><code>from qadence import chain, entangle, RY\n\nbell_state = chain(\n   entangle(\"t\", qubit_support=(0,1)),\n   RY(0, \"y\"),\n)\n</code></pre> <pre><code>bell_state = ChainBlock(0,1)\n\u251c\u2500\u2500 AnalogEntanglement(t=0.3732283455423252, support=(0, 1))\n\u2514\u2500\u2500 RY(0) [params: ['y']]\n</code></pre> <p>Next, a <code>Register</code> with two qubits is combined with the resulting <code>ChainBlock</code> to form a circuit. Then, the <code>QuantumModel</code> converts the circuit into a proper parametrized pulse sequence with the Pulser backend. Supplying the parameter values allows to sample the pulse sequence outcome:</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom qadence import Register, QuantumCircuit, QuantumModel, PI\n\nregister = Register.line(2, spacing = 8.0)  # Two qubits with a distance of 8\u00b5m\ncircuit = QuantumCircuit(register, bell_state)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\n\nparams = {\n    \"t\": torch.tensor([1000]),  # ns\n    \"y\": torch.tensor([3*PI/2]),\n}\n\n# Return the final state vector\nfinal_vector = model.run(params)\n\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>final_vector = tensor([[-0.7114-0.0169j, -0.0339+0.0156j,  0.0109-0.0457j,  0.6630-0.2244j]])\nsample = Counter({'00': 30, '11': 20})\n</code></pre> <p>Plot the distribution:</p> <p><pre><code>\n</code></pre> 2024-09-20T08:34:38.651350 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/  One can visualise the pulse sequence with different parameters using the <code>assign_paramters</code> method.</p> <pre><code>model.assign_parameters(params).draw(show=False)\n</code></pre> 2024-09-20T08:34:38.743094 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#change-device-specifications","title":"Change device specifications","text":"<p>At variance with other backends, Pulser provides the concept of <code>Device</code>. A <code>Device</code> instance encapsulates all the properties for the definition of a real neutral atoms processor, including but not limited to the maximum laser amplitude for pulses, the maximum distance between two qubits and the maximum duration of the pulse. For more information, please check this tutorial.</p> <p>Qadence offers a simplified interface with only two devices which are detailed here:</p> <ul> <li><code>IDEALIZED</code> (default): ideal device which should be used only for testing purposes. It does not restrict the simulation of pulse sequences.</li> <li><code>REALISTIC</code>: device specification close to real neutral atom quantum processors.</li> </ul> <p>Note</p> <p>If you want to perform simulations closer to the specifications of real neutral atom machines, always select the <code>REALISTIC</code> device.</p> <p>One can use the <code>Configuration</code> of the Pulser backend to select the appropriate device:</p> <pre><code>from qadence import BackendName, DiffMode\nfrom qadence import RealisticDevice\n\n# Choose a realistic device\nregister = Register.line(2, spacing = 8.0, device_specs = RealisticDevice())\n\ncircuit = QuantumCircuit(register, bell_state)\n\nmodel = QuantumModel(\n    circuit,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR,\n)\n\nparams = {\n    \"t\": torch.tensor([1000]),  # ns\n    \"y\": torch.tensor([3*PI/2]),\n}\n\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>sample = Counter({'00': 27, '11': 21, '10': 2})\n</code></pre>"},{"location":"tutorials/digital_analog_qc/pulser-basic/#create-a-custom-gate","title":"Create a custom gate","text":"<p>A major advantage of the block-based interface in Qadence is the ease to compose complex operations from a restricted set of primitive ones. In the following, a custom entanglement operation is used as an example.</p> <p>The operation consists of moving all the qubits to the \\(X\\)-basis. This is realized when the atomic interaction performs a controlled-\\(Z\\) operation during the free evolution. As seen before, this is implemented with the <code>AnalogInteraction</code> and <code>AnalogRY</code> blocks together with appropriate parameters.</p> <pre><code>from qadence import AnalogRY, chain, AnalogInteraction\n\n# Custom entanglement operation.\ndef my_entanglement(duration):\n    return chain(\n        AnalogRY(-PI / 2),\n        AnalogInteraction(duration)\n    )\n\nprotocol = chain(\n   my_entanglement(\"t\"),\n   RY(0, \"y\"),\n)\n\nregister = Register.line(2, spacing = 8.0)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\n\nparams = {\n    \"t\": torch.tensor([500]),  # ns\n    \"y\": torch.tensor([PI / 2]),\n}\n\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> 2024-09-20T08:34:39.169690 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#digital-analog-qnn-circuit","title":"Digital-analog QNN circuit","text":"<p>Finally, let's put all together by constructing a digital-analog version of a quantum neural network circuit with feature map and variational ansatz.</p> <pre><code>from qadence import kron, feature_map, BasisSet\nfrom qadence.operations import RX, RY, AnalogRX\n\nhea_one_layer = chain(\n    kron(RY(0, \"th00\"), RY(1, \"th01\")),\n    kron(RX(0, \"th10\"), RX(1, \"th11\")),\n    kron(RY(0, \"th20\"), RY(1, \"th21\")),\n    entangle(\"t\", qubit_support=(0,1)),\n)\n\nprotocol = chain(\n    feature_map(1, param=\"x\", fm_type=BasisSet.FOURIER),\n    hea_one_layer,\n    AnalogRX(PI/4)\n)\n\nregister = Register.line(2, spacing=8.0)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\n\nparams = {\n    \"x\": torch.tensor([0.8]), # rad\n    \"t\": torch.tensor([900]), # ns\n    \"th00\":  torch.rand(1), # rad\n    \"th01\":  torch.rand(1), # rad\n    \"th10\":  torch.rand(1), # rad\n    \"th11\":  torch.rand(1), # rad\n    \"th20\":  torch.rand(1), # rad\n    \"th21\":  torch.rand(1), # rad\n}\n\nmodel.assign_parameters(params).draw(draw_phase_area=True, show=False)\n</code></pre> 2024-09-20T08:34:39.285943 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/digital_analog_qc/pulser-basic/#references","title":"References","text":"<ol> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> </ol>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/","title":"Restricted local addressability","text":""},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#physics-behind-semi-local-addressing-patterns","title":"Physics behind semi-local addressing patterns","text":"<p>Recall that in Qadence the general neutral-atom Hamiltonian for a set of \\(n\\) interacting qubits is given by expression</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm drive} + \\mathcal{H}_{\\rm int} = \\sum_{i=0}^{n-1}\\left(\\mathcal{H}^\\text{d}_{i}(t) + \\sum_{j&lt;i}\\mathcal{H}^\\text{int}_{ij}\\right) \\] <p>as is described in detail in the analog interface basics documentation.</p> <p>The driving Hamiltonian term in priciple can model any local single-qubit rotation by addressing each qubit individually. However, some neutral-atom devices offer restricted local addressability using devices called spatial light modulators (SLMs).</p> <p>We refer to this regime as semi-local addressability. In this regime, the individual qubit addressing is restricted to a pattern of targeted qubits which is kept fixed during the execution of the quantum circuit. More formally, the addressing pattern appears as an additional term in the neutral-atom Hamiltonian:</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm drive} + \\mathcal{H}_{\\rm int} + \\mathcal{H}_{\\rm local} \\] <p>where \\(\\mathcal{H}_{\\rm pattern}\\) is given by</p> \\[ \\mathcal{H}_{\\rm local} = \\sum_{i=0}^{n-1}\\left(-\\Delta w_i^{\\rm det} \\hat{n}_i + \\Gamma w_i^{\\rm drive} \\hat{\\sigma}^x_i\\right). \\] <p>Here \\(\\Delta\\) specifies the maximal negative detuning that each qubit in the register can be exposed to. The weight \\(w_i^{\\rm det}\\in [0, 1]\\) determines the actual value of detuning that \\(i\\)-th qubit feels and this way the detuning pattern is emulated. Similarly, for the amplitude pattern \\(\\Gamma\\) determines the maximal additional positive drive that acts on qubits. In this case the corresponding weights \\(w_i^{\\rm drive}\\) can vary in the interval \\([0, 1]\\).</p> <p>Using the detuning and amplitude patterns described above one can modify the behavior of a selected set of qubits, thus achieving semi-local addressing.</p> <p>Qadence implements semi-local addressing in two different flavors of increasing complexity: either as a circuit constructor or directly as a pattern added to the general evolution Hamiltonian described by the circuit.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#using-circuit-constructors","title":"Using circuit constructors","text":"<p>The <code>rydberg_hea</code> constructor routine allows to build a circuit instance implementing a basic version of the Hamiltonian evolution described above where both \\(\\Delta\\) and \\(\\tilde{\\Omega}\\) coefficients are considered constants. Furthemore, no global drive and detuning are explicitly added to the Hamiltonian. Therefore, the final Hamiltonian generator of the circuit reads as follows:</p> \\[ \\mathcal{H} = \\mathcal{H}_{\\rm local}(w^{\\rm drive}, w^{\\rm det}) + \\mathcal{H}_{\\textrm{int}} \\] <p>This implementation does not perform any checks on the weights normalization, thus making it not realistic. This implies that global drive and detuning can be retrieved by appropriately choosing the weights.</p> <p>You can easily create a Rydberg hardware efficient ansatz implementing multiple layers of the evolution generated by the local addressing Hamiltonian:</p> \\[ \\mathcal{H}_{\\rm evo} = \\sum_j \\mathcal{H}_{\\textrm{local}}(w_{j}^{\\rm drive}, w_{j}^{\\rm det}) \\] <p>Notice that in real-device implementation, one layer only is usually achievable.</p> <pre><code>import qadence as qd\nfrom qadence import rydberg_hea, rydberg_hea_layer\n\nn_qubits = 4\nn_layers = 2\nregister = qd.Register.line(n_qubits)\n\n# ansatz constructor\n# the evolution time is parametrized for each layer of the evolution\nansatz = rydberg_hea(\n    register,\n    n_layers=n_layers,  # number of subsequent layers of Hamiltonian evolution\n    addressable_detuning=True,  # make the local detuning weights w_i^{det} as variational parameters\n    addressable_drive=True, # make the local drive weights w_i^{drv} as variational parameters\n    tunable_phase=True, # make the phase \\phi as a variational parameter\n)\n\n# alternatively, a single ansatz layer can also be created for\n# better flexibility\n\n# these can be variational parameters\ntevo_drive = 1.0  # evolution time for the locally addressed drive term\ntevo_det = 1.0 # evolution time for the locally addressed detuning term\ntevo_int = 1.0  # evolution time for the interaction term\n\n# these can be list of variational parameters\nweights_drive = [0.0, 0.25, 0.5, 0.25]\nweights_det = [0.0, 0.0, 0.5, 0.5]\n\nansatz_layer = rydberg_hea_layer(\n    register,\n    tevo_det,\n    tevo_drive,\n    tevo_int,\n    detunings=weights_det,\n    drives=weights_drive,\n)\n</code></pre> <pre><code>\n</code></pre> <p>This circuit constructor is meant to be used with fully differentiable backends such as <code>pyqtorch</code> and mainly for quick experimentation with neutral atom compatible ansatze.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#using-addressing-patterns","title":"Using addressing patterns","text":"<p>In Qadence semi-local addressing patterns can be created by either specifying fixed values for the weights of the qubits being addressed or defining them as trainable parameters that can be optimized later in some training loop. Semi-local addressing patterns can be defined with the <code>AddressingPattern</code> dataclass.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#fixed-weights","title":"Fixed weights","text":"<p>With fixed weights, detuning/amplitude addressing patterns can be defined in the following way:</p> <pre><code>import torch\nfrom qadence.analog import AddressingPattern\n\nn_qubits = 3\n\nw_det = {0: 0.9, 1: 0.5, 2: 1.0}\nw_amp = {0: 0.1, 1: 0.4, 2: 0.8}\ndet = 9.0\namp = 6.5\npattern = AddressingPattern(\n    n_qubits=n_qubits,\n    det=det,\n    amp=amp,\n    weights_det=w_det,\n    weights_amp=w_amp,\n)\n</code></pre> <p>If only detuning or amplitude pattern is needed - the corresponding weights for all qubits can be set to 0.</p> <p>The created addressing pattern can now be passed as an argument to any Qadence device class, or to the <code>IdealDevice</code> or <code>RealisticDevice</code> to make use of the pre-defined options in those devices,</p> <pre><code>import torch\nfrom qadence import (\n    AnalogRX,\n    AnalogRY,\n    BackendName,\n    DiffMode,\n    Parameter,\n    QuantumCircuit,\n    QuantumModel,\n    Register,\n    chain,\n    total_magnetization,\n    IdealDevice,\n    PI\n)\n\n# define register and circuit\nspacing = 8.0\nx = Parameter(\"x\")\nblock = chain(AnalogRX(3 * x), AnalogRY(0.5 * x))\n\ndevice_specs = IdealDevice(pattern = pattern)\n\nreg = Register.line(\n    n_qubits,\n    spacing=spacing,\n    device_specs=device_specs,\n)\n\ncirc = QuantumCircuit(reg, block)\n\nobs = total_magnetization(n_qubits)\n\nmodel_pyq = QuantumModel(\n    circuit=circ, observable=obs, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD\n)\n\n# calculate expectation value of the circuit for random input value\nvalue = {\"x\": 1.0 + torch.rand(1)}\nexpval_pyq = model_pyq.expectation(values = value)\n</code></pre>   Expectation value on PyQ:  tensor([2.1087])     <p>The same configuration can also be seamlessly used to create a model with the Pulser backend.</p> <pre><code>model_pulser = QuantumModel(\n    circuit=circ,\n    observable=obs,\n    backend=BackendName.PULSER,\n    diff_mode=DiffMode.GPSR\n)\n\n# calculate expectation value of the circuit for same random input value\nexpval_pulser = model_pulser.expectation(values = value)\n</code></pre>   Expectation value on Pulser:  tensor([2.1068])     <p>Note that by default the addressing pattern terms are added to every analog operation in the circuit. However, it is possible to turn the addressing pattern off for specific operations by passing <code>add_pattern=False</code> in the operation. For example <code>AnalogRX(pi)</code> will get the extra addressing pattern term, but <code>AnalogRX(pi, add_pattern=False)</code> will not. This is currently only implemented for the PyQTorch backend. If an addressing pattern is specified for the Pulser backend, it will be added to all the blocks.</p>"},{"location":"tutorials/digital_analog_qc/semi-local-addressing/#trainable-weights","title":"Trainable weights","text":"<p>Note</p> <p>Trainable parameters currently are supported only by <code>pyqtorch</code> backend.</p> <p>Since both the maximum detuning/amplitude value of the addressing pattern and the corresponding weights can be user specified, they can be variationally used in some QML setting. This can be achieved by defining pattern weights as trainable <code>Parameter</code> instances or strings specifying weight names.</p> <pre><code>n_qubits = 3\nreg = Register.line(n_qubits, spacing=8.0)\n\n# some random target function value\nf_value = torch.rand(1)\n\n# define trainable addressing pattern\nw_amp = {i: f\"w_amp{i}\" for i in range(n_qubits)}\nw_det = {i: f\"w_det{i}\" for i in range(n_qubits)}\namp = \"max_amp\"\ndet = \"max_det\"\n\npattern = AddressingPattern(\n    n_qubits=n_qubits,\n    det=det,\n    amp=amp,\n    weights_det=w_det,\n    weights_amp=w_amp,\n)\n\n# some fixed analog operation\nblock = AnalogRX(PI)\n\ndevice_specs = IdealDevice(pattern = pattern)\n\nreg = Register.line(\n    n_qubits,\n    spacing=spacing,\n    device_specs=device_specs,\n)\n\ncirc = QuantumCircuit(reg, block)\n\n# define quantum model\nobs = total_magnetization(n_qubits)\nmodel = QuantumModel(circuit=circ, observable=obs, backend=BackendName.PYQTORCH)\n\n# prepare for training\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nloss_criterion = torch.nn.MSELoss()\nn_epochs = 200\nloss_save = []\n\n# train model\nfor _ in range(n_epochs):\n    optimizer.zero_grad()\n    out = model.expectation()\n    loss = loss_criterion(f_value, out)\n    loss.backward()\n    optimizer.step()\n    loss_save.append(loss.item())\n\n# get final results\nf_value_model = model.expectation().detach()\n\nassert torch.isclose(f_value, f_value_model, atol=0.01)\n</code></pre>   The target function value:  tensor([0.9294]) The trained function value:  tensor([[0.9294]])    <p>Here, the expectation value of the circuit is fitted by varying the parameters of the addressing pattern.</p>"},{"location":"tutorials/qml/","title":"Variational quantum algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML)[^1] in particular are one of the main target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> (see here for more details) and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Furthermore, Qadence offers a wide range of utilities for helping building and researching quantum machine learning algorithms, including:</p> <ul> <li>a set of constructors for circuits commonly used in quantum machine learning such as feature maps and ansatze</li> <li>a set of tools for training and optimizing quantum neural networks and loading classical data into a QML algorithm</li> </ul>"},{"location":"tutorials/qml/#some-simple-examples","title":"Some simple examples","text":"<p>Qadence symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\n\nn_qubits = 4\n\n# Example feature map, also directly available with the `feature_map` function\nfp = qd.FeatureParameter(\"phi\")\nfm = qd.kron(RX(i, acos(fp)) for i in range(n_qubits))\n\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(fm, values=inputs)\n</code></pre> <pre><code>samples = Counter({'0000': 50, '0001': 13, '0010': 12, '0100': 11, '1000': 7, '0011': 2, '1010': 2, '1100': 2, '1011': 1})\n</code></pre> <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle. This function will be further demonstrated in the QML constructors tutorial.</p> <p>Furthermore, Qadence is natively integrated with PyTorch automatic differentiation engine thus Qadence quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansatz (also explained here) and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, fm, ansatz)\nobservable = qd.kron(X(0), X(1))\n\nmodel = qd.QNN(circuit, observable)\n\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>True\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\n\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre> <pre><code>Quantum model output: \ntensor([[0.4671],\n        [0.3024],\n        [0.6485],\n        [0.6509],\n        [0.5098],\n        [0.5514],\n        [0.5457],\n        [0.5759],\n        [0.3510],\n        [0.1197]], grad_fn=&lt;CatBackward0&gt;)\n\nFirst-order derivative w.r.t. the feature parameter: \ntensor([-1.0793, -1.4651, -0.1807, -0.1383, -0.9465, -0.7953, -0.8175,  0.5882,\n        -1.3675, -1.7343], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>To run QML on real devices, Qadence offers generalized parameter shift rules (GPSR) <sup>1</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qd.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\n\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n</code></pre> <pre><code>First-order derivative w.r.t. the feature parameter: \ntensor([-1.0793, -1.4651, -0.1807, -0.1383, -0.9465, -0.7953, -0.8175,  0.5882,\n        -1.3675, -1.7343], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>See here for more details on how the parameter shift rules implementation works in Qadence.</p>"},{"location":"tutorials/qml/#references","title":"References","text":"<p>[^1] Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)</p> <ol> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/config_qnn/","title":"Configuring a QNN","text":"<p>In <code>qadence</code>, the <code>QNN</code> is a variational quantum model that can potentially take multi-dimensional input.</p> <p>The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>The circuit has two parts, the feature map and the ansatz. The feature map is responsible for encoding the input data into the quantum state, while the ansatz is responsible for the variational part of the model. In addition, a third part of the QNN is the observables, which is (a list of) operators that are measured at the end of the circuit.</p> <p>In QML Constructors we have seen how to construct the feature map and the ansatz. In this tutorial, we will see how to do the same using configs.</p> <p>One convenient way to construct these three parts of the model is to use the config classes, namely, <code>ObservableConfig</code>, <code>FeatureMapConfig</code>, <code>AnsatzConfig</code>. These classes allow you to specify the type of circuit and the parameters of the circuit in a structured way.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-observable","title":"Defining the Observable","text":"<p>The model output is the expectation value of the defined observable(s). We use the <code>ObservableConfig</code> class to specify the observable.</p> <p>We can specify any Hamiltonian that we want to measure at the end of the circuit. Let us say we want to measure the \\(Z\\) operator.</p> <pre><code>from qadence import observable_from_config, ObservableConfig, Z\n\nobservable_config = ObservableConfig(\n    detuning=Z,\n    scale=3.0,\n    shift=-1.0,\n)\n\nobservable = observable_from_config(register=4, config=observable_config)\n</code></pre> %3 cluster_7907d3080a6e4b6ead2b9c3a7553eeaa 2596829d04f24868a5d35595d34bdaa0 0 ee3c71f86be746e2a862912181fa3816 2596829d04f24868a5d35595d34bdaa0--ee3c71f86be746e2a862912181fa3816 081489e8a6554d23b86fc5f24d3f6444 1 8a4c1b8e6934421bba999f0ed02590d8 ee3c71f86be746e2a862912181fa3816--8a4c1b8e6934421bba999f0ed02590d8 1eb72caa88f44c40a09b038c85665b4d 76a70e4b5e624d32bec212073201b457 AddBlock 081489e8a6554d23b86fc5f24d3f6444--76a70e4b5e624d32bec212073201b457 68fc56286c0a4476ba9efdb7434251fc 2 76a70e4b5e624d32bec212073201b457--1eb72caa88f44c40a09b038c85665b4d f21ac171bd3245bc90b955a76eeedd43 e0a2d2ffe47c4b93b4f9aa08e22ae2e5 68fc56286c0a4476ba9efdb7434251fc--e0a2d2ffe47c4b93b4f9aa08e22ae2e5 2f693bdda63c4d60a5283d8e95bd6838 3 e0a2d2ffe47c4b93b4f9aa08e22ae2e5--f21ac171bd3245bc90b955a76eeedd43 be12ce14e1674079be22e60c70a863b5 cbdab11db55249d18a7d786202b5ccb4 2f693bdda63c4d60a5283d8e95bd6838--cbdab11db55249d18a7d786202b5ccb4 cbdab11db55249d18a7d786202b5ccb4--be12ce14e1674079be22e60c70a863b5 <p>We have specified the observable Hamiltonian to be one with \\(Z\\)-detuning. The result is linearly scaled by 3.0 and shifted by -1.0. These parameters can optionally also be FeatureParameter or VariationalParameter</p> <p>One can also specify the observable as a list of observables, in which case the QNN will output a list of values.</p> <p>For full details on the <code>ObservableConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-feature-map","title":"Defining the Feature Map","text":"<p>Let us say we want to build a 4-qubit QNN that takes two inputs, namely, the \\(x\\) and the \\(y\\) coordinates of a point in the plane. We can use the <code>FeatureMapConfig</code> class to specify the feature map.</p> <pre><code>from qadence import BasisSet, chain, create_fm_blocks, FeatureMapConfig, ReuploadScaling\n\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs = [\"x\", \"y\"],\n    basis_set=BasisSet.CHEBYSHEV,\n    reupload_scaling=ReuploadScaling.TOWER,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\n\nfm_blocks = create_fm_blocks(register=4, config=fm_config)\nfeature_map = chain(*fm_blocks)\n</code></pre> %3 cluster_f5093eb17a9f4fe99a2c08913180ce9d Tower Chebyshev FM cluster_47fa4bb6101441fbbaa16bf41ec91c72 Tower Chebyshev FM 8f57775742214d86aa8c3ebb0dabd565 0 031b85d21c664f459efdcedc48b1f872 RX(1.0*acos(x)) 8f57775742214d86aa8c3ebb0dabd565--031b85d21c664f459efdcedc48b1f872 442b03b696e945b48628a84c03f394fa 1 736f85c8a70844b8a2d7e991df426065 031b85d21c664f459efdcedc48b1f872--736f85c8a70844b8a2d7e991df426065 baa7418f298944fc9fc529b6d9647e4a c299d42d848e4a1b9a41193c6783ed0d RX(2.0*acos(x)) 442b03b696e945b48628a84c03f394fa--c299d42d848e4a1b9a41193c6783ed0d 27e5629015f340ed98cf73930ad001d3 2 c299d42d848e4a1b9a41193c6783ed0d--baa7418f298944fc9fc529b6d9647e4a 01f391acb25e4f6d936aa6fec67d1cf0 ea53444d76264f27a0d1cb103f3874fc RX(1.0*acos(2.0*y - 1.0)) 27e5629015f340ed98cf73930ad001d3--ea53444d76264f27a0d1cb103f3874fc 29434cd33f9143529e956fe68f85791c 3 ea53444d76264f27a0d1cb103f3874fc--01f391acb25e4f6d936aa6fec67d1cf0 99b477df51a7476d9e4ad22e7e982637 9054f76b09954e3e8b2aff781751fc02 RX(2.0*acos(2.0*y - 1.0)) 29434cd33f9143529e956fe68f85791c--9054f76b09954e3e8b2aff781751fc02 9054f76b09954e3e8b2aff781751fc02--99b477df51a7476d9e4ad22e7e982637 <p>We have specified that the feature map should take two features, and have named the <code>FeatureParameter</code> \"x\" and \"y\" respectively. Both these parameters are encoded using the Chebyshev basis set, and the reupload scaling is set to <code>ReuploadScaling.TOWER</code>. One can optionally add the basis and the reupload scaling for each parameter separately.</p> <p>The <code>feature_range</code> parameter is a dictionary that specifies the range of values that each feature comes from. This is useful for scaling the input data to the range that the encoding function can handle. In default case, this range is mapped to the target range of the Chebyshev basis set which is \\([-1, 1]\\). One can also specify the target range for each feature separately.</p> <p>For full details on the <code>FeatureMapConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-ansatz","title":"Defining the Ansatz","text":"<p>The next part of the QNN is the ansatz. We use <code>AnsatzConfig</code> class to specify the type of ansatz.</p> <p>Let us say, we want to follow this feature map with 2 layers of hardware efficient ansatz.</p> <pre><code>from qadence import AnsatzConfig, AnsatzType, create_ansatz, Strategy\n\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nansatz = create_ansatz(register=4, config=ansatz_config)\n</code></pre> %3 85399d14ba604db09e93a98655089a82 0 6c56ffd16b0e4b42a4767294f260b5a2 RX(theta\u2080) 85399d14ba604db09e93a98655089a82--6c56ffd16b0e4b42a4767294f260b5a2 5a18fe40aa69459e906e15e41fd494bd 1 d575e1e8c2a74f3d847265cb1892cb35 RY(theta\u2084) 6c56ffd16b0e4b42a4767294f260b5a2--d575e1e8c2a74f3d847265cb1892cb35 cf5ec3fd5cfd4c6bab4964a8e22b2a50 RX(theta\u2088) d575e1e8c2a74f3d847265cb1892cb35--cf5ec3fd5cfd4c6bab4964a8e22b2a50 d699c847a8524a4db7735cbb21c4c257 cf5ec3fd5cfd4c6bab4964a8e22b2a50--d699c847a8524a4db7735cbb21c4c257 b1e4e7b7230c4ce7952366046a164c00 d699c847a8524a4db7735cbb21c4c257--b1e4e7b7230c4ce7952366046a164c00 424ffebd34a243908fe6e554d19571fc RX(theta\u2081\u2082) b1e4e7b7230c4ce7952366046a164c00--424ffebd34a243908fe6e554d19571fc 06db0d06b876447e942019f9824f38c1 RY(theta\u2081\u2086) 424ffebd34a243908fe6e554d19571fc--06db0d06b876447e942019f9824f38c1 2a1a8b632d22470eaaa83363fa410b2f RX(theta\u2082\u2080) 06db0d06b876447e942019f9824f38c1--2a1a8b632d22470eaaa83363fa410b2f 641ae6ed4a464489a483535b09d6b3d3 2a1a8b632d22470eaaa83363fa410b2f--641ae6ed4a464489a483535b09d6b3d3 0aff7d6c84164ae8ac906d0f858156be 641ae6ed4a464489a483535b09d6b3d3--0aff7d6c84164ae8ac906d0f858156be b12c039a378f460d85c25f2c2a243115 0aff7d6c84164ae8ac906d0f858156be--b12c039a378f460d85c25f2c2a243115 a8502dbeeb2645a8a37231d5f71a2c6f 2f0e628c916042229a48e3bcaba4dc5b RX(theta\u2081) 5a18fe40aa69459e906e15e41fd494bd--2f0e628c916042229a48e3bcaba4dc5b a5483a82c5764d779578ba83e7325b05 2 21c4e410c6084df18d54999a3d35039f RY(theta\u2085) 2f0e628c916042229a48e3bcaba4dc5b--21c4e410c6084df18d54999a3d35039f 412a0e53712741229aebae9934cdb86c RX(theta\u2089) 21c4e410c6084df18d54999a3d35039f--412a0e53712741229aebae9934cdb86c 38b404f1603c48bd86d53baca6bc7d92 X 412a0e53712741229aebae9934cdb86c--38b404f1603c48bd86d53baca6bc7d92 38b404f1603c48bd86d53baca6bc7d92--d699c847a8524a4db7735cbb21c4c257 a7874c00fc1544ccb987797e683fc9d1 38b404f1603c48bd86d53baca6bc7d92--a7874c00fc1544ccb987797e683fc9d1 833392a4c8fe4d5fae83d2f3fd874b4e RX(theta\u2081\u2083) a7874c00fc1544ccb987797e683fc9d1--833392a4c8fe4d5fae83d2f3fd874b4e f8a2ba2047fb4f41ad8271f6036a6ca7 RY(theta\u2081\u2087) 833392a4c8fe4d5fae83d2f3fd874b4e--f8a2ba2047fb4f41ad8271f6036a6ca7 86221752a9e64c638e3f52ddc1ba024f RX(theta\u2082\u2081) f8a2ba2047fb4f41ad8271f6036a6ca7--86221752a9e64c638e3f52ddc1ba024f d0241ec1cf3f485597cb2c817d142cc0 X 86221752a9e64c638e3f52ddc1ba024f--d0241ec1cf3f485597cb2c817d142cc0 d0241ec1cf3f485597cb2c817d142cc0--641ae6ed4a464489a483535b09d6b3d3 ffaa954beeed45d2879a9a93a5cf15d4 d0241ec1cf3f485597cb2c817d142cc0--ffaa954beeed45d2879a9a93a5cf15d4 ffaa954beeed45d2879a9a93a5cf15d4--a8502dbeeb2645a8a37231d5f71a2c6f 694414263e3e4492bc46c31ea06b039c f4fe4e527bd5403191574ab37cef5304 RX(theta\u2082) a5483a82c5764d779578ba83e7325b05--f4fe4e527bd5403191574ab37cef5304 a4945b59d93c47e7ab80996087b5a1ed 3 60c841fffbfd43c990d5d92d25e7365c RY(theta\u2086) f4fe4e527bd5403191574ab37cef5304--60c841fffbfd43c990d5d92d25e7365c 5cda0cd246e14f1ea7e618c236ddecd8 RX(theta\u2081\u2080) 60c841fffbfd43c990d5d92d25e7365c--5cda0cd246e14f1ea7e618c236ddecd8 26c5ecb3b632470ea9b21b90bbde190f 5cda0cd246e14f1ea7e618c236ddecd8--26c5ecb3b632470ea9b21b90bbde190f 0fa3d49d735a41c8b5d1b2312b31fde0 X 26c5ecb3b632470ea9b21b90bbde190f--0fa3d49d735a41c8b5d1b2312b31fde0 0fa3d49d735a41c8b5d1b2312b31fde0--a7874c00fc1544ccb987797e683fc9d1 871dc7cf1ffc426ba630259c8425fca4 RX(theta\u2081\u2084) 0fa3d49d735a41c8b5d1b2312b31fde0--871dc7cf1ffc426ba630259c8425fca4 6f0f68c02ca744e7a1e679bd2322e562 RY(theta\u2081\u2088) 871dc7cf1ffc426ba630259c8425fca4--6f0f68c02ca744e7a1e679bd2322e562 bca2cf808e81431fa1d13d17d746cc7d RX(theta\u2082\u2082) 6f0f68c02ca744e7a1e679bd2322e562--bca2cf808e81431fa1d13d17d746cc7d 34a96e8e94824b7da5cbc51c0f841b5d bca2cf808e81431fa1d13d17d746cc7d--34a96e8e94824b7da5cbc51c0f841b5d bb518ccce9c4489fb0f444ec605e4cdd X 34a96e8e94824b7da5cbc51c0f841b5d--bb518ccce9c4489fb0f444ec605e4cdd bb518ccce9c4489fb0f444ec605e4cdd--ffaa954beeed45d2879a9a93a5cf15d4 bb518ccce9c4489fb0f444ec605e4cdd--694414263e3e4492bc46c31ea06b039c 1fd8337b46eb4e089f0fca11ae14e6fb 960fd07dcee44600bd00ee70b669be76 RX(theta\u2083) a4945b59d93c47e7ab80996087b5a1ed--960fd07dcee44600bd00ee70b669be76 74cec4856983404489635f818c3b0060 RY(theta\u2087) 960fd07dcee44600bd00ee70b669be76--74cec4856983404489635f818c3b0060 0de5054bd202491e8bab5dbdac58da57 RX(theta\u2081\u2081) 74cec4856983404489635f818c3b0060--0de5054bd202491e8bab5dbdac58da57 4b94da7e927343778b4f769733d39f09 X 0de5054bd202491e8bab5dbdac58da57--4b94da7e927343778b4f769733d39f09 4b94da7e927343778b4f769733d39f09--26c5ecb3b632470ea9b21b90bbde190f c4a42a65a7714878924f0a05870df39c 4b94da7e927343778b4f769733d39f09--c4a42a65a7714878924f0a05870df39c c25764faf33b4f2c976fd8c00d46c2d7 RX(theta\u2081\u2085) c4a42a65a7714878924f0a05870df39c--c25764faf33b4f2c976fd8c00d46c2d7 dd1d0f10d6804077ad66c8e24e178c1a RY(theta\u2081\u2089) c25764faf33b4f2c976fd8c00d46c2d7--dd1d0f10d6804077ad66c8e24e178c1a 1f1f94eb49e646199b91e389dd219d3a RX(theta\u2082\u2083) dd1d0f10d6804077ad66c8e24e178c1a--1f1f94eb49e646199b91e389dd219d3a 04063482efd94f4db950948972be70f1 X 1f1f94eb49e646199b91e389dd219d3a--04063482efd94f4db950948972be70f1 04063482efd94f4db950948972be70f1--34a96e8e94824b7da5cbc51c0f841b5d 35c58d6ced464431bee89f8e6742db83 04063482efd94f4db950948972be70f1--35c58d6ced464431bee89f8e6742db83 35c58d6ced464431bee89f8e6742db83--1fd8337b46eb4e089f0fca11ae14e6fb <p>We have specified that the ansatz should have a depth of 2, and the ansatz type is \"hea\" (Hardware Efficient Ansatz). The ansatz strategy is set to \"digital\", which means digital gates are being used. One could alternatively use \"analog\" or \"rydberg\" as the ansatz strategy.</p> <p>For full details on the <code>AnsatzConfig</code> class, see the API documentation.</p>"},{"location":"tutorials/qml/config_qnn/#defining-the-qnn-from-the-configs","title":"Defining the QNN from the Configs","text":"<p>To build the QNN, we can now use the <code>QNN</code> class as a <code>QuantumModel</code> subtype. In addition to the feature map, ansatz and the observable configs, we can also specify options such as the <code>backend</code>, <code>diff_mode</code>, etc. For full details on the <code>QNN</code> class, see the API documentation or the documentation on the config constructor here.</p> <pre><code>from qadence import BackendName, DiffMode, QNN\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.AD,\n)\n</code></pre> %3 cluster_9aa6cb3e23944901bc305bf0bd01ecb6 Obs. cluster_06e43352f4e44046ac546e75c6654a37 cluster_c909c379d80141dca6ef5569c396cd68 Tower Chebyshev FM cluster_ed8b7f384417423fb2f311fe6e56b3dd Tower Chebyshev FM cluster_e48f48efbc754e648ff6ac4316ab9bc9 HEA 4a41c79f3fdd491da90b0decfda824d7 0 7345ff801da74d1a8008a85406b0810f RX(1.0*acos(x)) 4a41c79f3fdd491da90b0decfda824d7--7345ff801da74d1a8008a85406b0810f 28666bd15f8f4c1e80edd218a006ca56 1 320c1f06a1994bd7ac63cdf87fb84873 RX(theta\u2080) 7345ff801da74d1a8008a85406b0810f--320c1f06a1994bd7ac63cdf87fb84873 f2f9260de7494d64b3d32e738a6eee30 RY(theta\u2084) 320c1f06a1994bd7ac63cdf87fb84873--f2f9260de7494d64b3d32e738a6eee30 19267e5c31a144e1b99ad066186c2f1d RX(theta\u2088) f2f9260de7494d64b3d32e738a6eee30--19267e5c31a144e1b99ad066186c2f1d a196aa0db4f045199213d6a1306a69d3 19267e5c31a144e1b99ad066186c2f1d--a196aa0db4f045199213d6a1306a69d3 44be7bab45074e15accfe7c4dfa48842 a196aa0db4f045199213d6a1306a69d3--44be7bab45074e15accfe7c4dfa48842 4b27e454987b45ae9b0f4c823d561071 RX(theta\u2081\u2082) 44be7bab45074e15accfe7c4dfa48842--4b27e454987b45ae9b0f4c823d561071 ee2d4df2e20d4339a060bd374f463547 RY(theta\u2081\u2086) 4b27e454987b45ae9b0f4c823d561071--ee2d4df2e20d4339a060bd374f463547 b66a327f4d54452aa4f59962bccfaa41 RX(theta\u2082\u2080) ee2d4df2e20d4339a060bd374f463547--b66a327f4d54452aa4f59962bccfaa41 8a58e93f50e341e2a90bf22e3e9ea05c b66a327f4d54452aa4f59962bccfaa41--8a58e93f50e341e2a90bf22e3e9ea05c f9e3a74467da4dae842b8514fd9af785 8a58e93f50e341e2a90bf22e3e9ea05c--f9e3a74467da4dae842b8514fd9af785 f89be34a12d64670b478fb384a603b64 f9e3a74467da4dae842b8514fd9af785--f89be34a12d64670b478fb384a603b64 7c8ccf6bda1542b5bef2b19dca1612e6 f89be34a12d64670b478fb384a603b64--7c8ccf6bda1542b5bef2b19dca1612e6 1b3a625b0a7b4a1c912dbeeafd31d1e1 ebf7a746760c492ebb38c405bad6702f RX(2.0*acos(x)) 28666bd15f8f4c1e80edd218a006ca56--ebf7a746760c492ebb38c405bad6702f 4d30c525d3a141729851645075839c08 2 0bee3ea59bd2488c9ba43adb54dba8d4 RX(theta\u2081) ebf7a746760c492ebb38c405bad6702f--0bee3ea59bd2488c9ba43adb54dba8d4 a3b6504e652f439dba770d1586bc64c1 RY(theta\u2085) 0bee3ea59bd2488c9ba43adb54dba8d4--a3b6504e652f439dba770d1586bc64c1 3de4d3ec0efb418a9e34d59f9c7fc606 RX(theta\u2089) a3b6504e652f439dba770d1586bc64c1--3de4d3ec0efb418a9e34d59f9c7fc606 5ee5a3812b814d75b10bd034a1a7600a X 3de4d3ec0efb418a9e34d59f9c7fc606--5ee5a3812b814d75b10bd034a1a7600a 5ee5a3812b814d75b10bd034a1a7600a--a196aa0db4f045199213d6a1306a69d3 229c9925c3c947f5b3faa14e3430a0de 5ee5a3812b814d75b10bd034a1a7600a--229c9925c3c947f5b3faa14e3430a0de d0cfe28b0c3d411ca80d6d60dfd14703 RX(theta\u2081\u2083) 229c9925c3c947f5b3faa14e3430a0de--d0cfe28b0c3d411ca80d6d60dfd14703 79606d4acb1a4f9783f4701748d4fb13 RY(theta\u2081\u2087) d0cfe28b0c3d411ca80d6d60dfd14703--79606d4acb1a4f9783f4701748d4fb13 c24a4ed6548443e29042a7bd23e3730a RX(theta\u2082\u2081) 79606d4acb1a4f9783f4701748d4fb13--c24a4ed6548443e29042a7bd23e3730a 4777b8d6fa36414b9a6ef51c0d24b933 X c24a4ed6548443e29042a7bd23e3730a--4777b8d6fa36414b9a6ef51c0d24b933 4777b8d6fa36414b9a6ef51c0d24b933--8a58e93f50e341e2a90bf22e3e9ea05c 9653894d0c5340cb8461705b2f977bb0 4777b8d6fa36414b9a6ef51c0d24b933--9653894d0c5340cb8461705b2f977bb0 d8b3bf75fdf04aceb4c3be137afe4d65 AddBlock 9653894d0c5340cb8461705b2f977bb0--d8b3bf75fdf04aceb4c3be137afe4d65 d8b3bf75fdf04aceb4c3be137afe4d65--1b3a625b0a7b4a1c912dbeeafd31d1e1 419ea11b55814386b817fdaf0af72f17 a8a7bc70f74b4ccea5c2adbc875f4dc4 RX(1.0*acos(2.0*y - 1.0)) 4d30c525d3a141729851645075839c08--a8a7bc70f74b4ccea5c2adbc875f4dc4 14586e4156fa401abe911789b7c130a1 3 82349aa283774a0393dcd09204bfca59 RX(theta\u2082) a8a7bc70f74b4ccea5c2adbc875f4dc4--82349aa283774a0393dcd09204bfca59 cf24482c962f4ad7910dec4dd78c74f4 RY(theta\u2086) 82349aa283774a0393dcd09204bfca59--cf24482c962f4ad7910dec4dd78c74f4 e30f01303e824ddcbded5e8bdb0f32f2 RX(theta\u2081\u2080) cf24482c962f4ad7910dec4dd78c74f4--e30f01303e824ddcbded5e8bdb0f32f2 ac072fa3bbc749be961e729671b84f1e e30f01303e824ddcbded5e8bdb0f32f2--ac072fa3bbc749be961e729671b84f1e 2cb2be31708c4a6d9cc4668d7e784d1e X ac072fa3bbc749be961e729671b84f1e--2cb2be31708c4a6d9cc4668d7e784d1e 2cb2be31708c4a6d9cc4668d7e784d1e--229c9925c3c947f5b3faa14e3430a0de 25448ada93404808832f62033e6cf22c RX(theta\u2081\u2084) 2cb2be31708c4a6d9cc4668d7e784d1e--25448ada93404808832f62033e6cf22c 49dfa0f5cdf0451db91c87611dc86070 RY(theta\u2081\u2088) 25448ada93404808832f62033e6cf22c--49dfa0f5cdf0451db91c87611dc86070 06cb6f81d4f94a97b4cafbf59dcf45ff RX(theta\u2082\u2082) 49dfa0f5cdf0451db91c87611dc86070--06cb6f81d4f94a97b4cafbf59dcf45ff dbf63d4bc80a454dbe339084c63616de 06cb6f81d4f94a97b4cafbf59dcf45ff--dbf63d4bc80a454dbe339084c63616de ac77ea14837742019ba42b08cab03bc3 X dbf63d4bc80a454dbe339084c63616de--ac77ea14837742019ba42b08cab03bc3 ac77ea14837742019ba42b08cab03bc3--9653894d0c5340cb8461705b2f977bb0 04df885f776c42e58661a05015f7ff1e ac77ea14837742019ba42b08cab03bc3--04df885f776c42e58661a05015f7ff1e 04df885f776c42e58661a05015f7ff1e--419ea11b55814386b817fdaf0af72f17 3219296be33b4205ae9e41123768be6d acdcac4a05c24566b97849abf34aef26 RX(2.0*acos(2.0*y - 1.0)) 14586e4156fa401abe911789b7c130a1--acdcac4a05c24566b97849abf34aef26 1fd447ab24a64457b99cb2a09ab4a0a7 RX(theta\u2083) acdcac4a05c24566b97849abf34aef26--1fd447ab24a64457b99cb2a09ab4a0a7 0ea1c77cd9b9448c85680c76e3b7aee1 RY(theta\u2087) 1fd447ab24a64457b99cb2a09ab4a0a7--0ea1c77cd9b9448c85680c76e3b7aee1 e878eca5b90c4edd9450a748dfed79c3 RX(theta\u2081\u2081) 0ea1c77cd9b9448c85680c76e3b7aee1--e878eca5b90c4edd9450a748dfed79c3 6a54019bd7f743dba5785cd87a904020 X e878eca5b90c4edd9450a748dfed79c3--6a54019bd7f743dba5785cd87a904020 6a54019bd7f743dba5785cd87a904020--ac072fa3bbc749be961e729671b84f1e bda609c1c4054cf29df95365dc7b182b 6a54019bd7f743dba5785cd87a904020--bda609c1c4054cf29df95365dc7b182b 5ddf09fd72cf49fb9c5702861aa6ebe5 RX(theta\u2081\u2085) bda609c1c4054cf29df95365dc7b182b--5ddf09fd72cf49fb9c5702861aa6ebe5 7d5bfcd0ec174822a37740eb745b3aaa RY(theta\u2081\u2089) 5ddf09fd72cf49fb9c5702861aa6ebe5--7d5bfcd0ec174822a37740eb745b3aaa f69c252acf38475d83ea48a1076fd8d4 RX(theta\u2082\u2083) 7d5bfcd0ec174822a37740eb745b3aaa--f69c252acf38475d83ea48a1076fd8d4 e9ccbd3e68e845d695f37df4701255f4 X f69c252acf38475d83ea48a1076fd8d4--e9ccbd3e68e845d695f37df4701255f4 e9ccbd3e68e845d695f37df4701255f4--dbf63d4bc80a454dbe339084c63616de 9a66cec28f3645dbaf2d0fcf32faac22 e9ccbd3e68e845d695f37df4701255f4--9a66cec28f3645dbaf2d0fcf32faac22 e52cd5a9960a425aafb9b9e28c367e38 9a66cec28f3645dbaf2d0fcf32faac22--e52cd5a9960a425aafb9b9e28c367e38 e52cd5a9960a425aafb9b9e28c367e38--3219296be33b4205ae9e41123768be6d"},{"location":"tutorials/qml/dqc_1d/","title":"Solving a 1D ODE","text":"<p>In this tutorial we will show how to use Qadence to solve a basic 1D Ordinary Differential Equation (ODE) with a QNN using Differentiable Quantum Circuits (DQC) <sup>1</sup>.</p> <p>Consider the following non-linear ODE and boundary condition:</p> \\[ \\frac{df}{dx}= 5\\times(4x^3+x^2-2x-\\frac12), \\qquad f(0)=0 \\] <p>It admits an exact solution:</p> \\[ f(x)=5\\times(x^4+\\frac13x^3-x^2-\\frac12x) \\] <p>Our goal will be to find this solution for \\(x\\in[-1, 1]\\).</p> <pre><code>import torch\n\ndef dfdx_equation(x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Derivative as per the equation.\"\"\"\n    return 5*(4*x**3 + x**2 - 2*x - 0.5)\n</code></pre> <p>For the purpose of this tutorial, we will compute the derivative of the circuit using <code>torch.autograd</code>. The point of the DQC algorithm is to use differentiable circuits with parameter shift rules. In Qadence, PSR is implemented directly as custom overrides of the derivative function in the autograd engine, and thus we can later change the derivative method for the model itself if we wish.</p> <pre><code>def calc_deriv(outputs: torch.Tensor, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Compute a derivative of model that learns f(x), computes df/dx using torch.autograd.\"\"\"\n    grad = torch.autograd.grad(\n        outputs=outputs,\n        inputs=inputs,\n        grad_outputs = torch.ones_like(inputs),\n        create_graph = True,\n        retain_graph = True,\n    )[0]\n    return grad\n</code></pre>"},{"location":"tutorials/qml/dqc_1d/#defining-the-loss-function","title":"Defining the loss function","text":"<p>The essential part of solving this problem is to define the right loss function to represent our goal. In this case, we want to define a model that has the capacity to learn the target solution, and we want to minimize: - The derivative of this model in comparison with the exact derivative in the equation; - The output of the model at the boundary in comparison with the value for the boundary condition;</p> <p>We can write it like so:</p> <pre><code># Mean-squared error as the comparison criterion\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Loss function encoding the problem to solve.\"\"\"\n    # Equation loss\n    model_output = model(inputs)\n    deriv_model = calc_deriv(model_output, inputs)\n    deriv_exact = dfdx_equation(inputs)\n    ode_loss = criterion(deriv_model, deriv_exact)\n\n    # Boundary loss, f(0) = 0\n    boundary_model = model(torch.tensor([[0.0]]))\n    boundary_exact = torch.tensor([[0.0]])\n    boundary_loss = criterion(boundary_model, boundary_exact)\n\n    return ode_loss + boundary_loss\n</code></pre> <p>Different loss criterions could be considered, and we could also play with the balance between the sum of the two loss terms. For now, let's proceed with the definition above.</p> <p>Note that so far we have not used any quantum specific assumption, and we could in principle use the same loss function with a classical neural network.</p>"},{"location":"tutorials/qml/dqc_1d/#defining-a-qnn-with-qadence","title":"Defining a QNN with Qadence","text":"<p>Now, we can finally use Qadence to write a QNN. We will use a feature map to encode the input values, a trainable ansatz circuit, and an observable to measure as the output.</p> <pre><code>from qadence import feature_map, hea, chain\nfrom qadence import QNN, QuantumCircuit, Z\nfrom qadence.types import BasisSet, ReuploadScaling\n\nn_qubits = 3\ndepth = 3\n\n# Feature map\nfm = feature_map(\n    n_qubits = n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Ansatz\nansatz = hea(n_qubits = n_qubits, depth = depth)\n\n# Observable\nobservable = Z(0)\n\ncircuit = QuantumCircuit(n_qubits, chain(fm, ansatz))\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n</code></pre> <p>We used a Chebyshev feature map with a tower-like scaling of the input reupload, and a standard hardware-efficient ansatz. You can check the qml constructors tutorial to see how you can customize these components. In the observable, for now we consider the simple case of measuring the magnetization of the first qubit.</p> <pre><code>from qadence.draw import display\n\n# display(circuit)\n</code></pre> %3 cluster_aa4391ab49664ec8a2b20f9c259a8d2b HEA cluster_65ab37f9b6c149768aefbed44201e365 Tower Chebyshev FM 54327e1c3aee42be9ae99ff376a4224b 0 97f0806149dc42f8836d904d9dea4743 RX(1.0*acos(x)) 54327e1c3aee42be9ae99ff376a4224b--97f0806149dc42f8836d904d9dea4743 a5b203f27e8446d08c4c11e185174e1a 1 7ed2347e180d4036a59cad50463edde0 RX(theta\u2080) 97f0806149dc42f8836d904d9dea4743--7ed2347e180d4036a59cad50463edde0 7f405cb6e4f84a4ca6b0f98e0685dd91 RY(theta\u2083) 7ed2347e180d4036a59cad50463edde0--7f405cb6e4f84a4ca6b0f98e0685dd91 7c3592bf098d4a1795939e64b82dc5dc RX(theta\u2086) 7f405cb6e4f84a4ca6b0f98e0685dd91--7c3592bf098d4a1795939e64b82dc5dc a80271816a2f49819abd54c55e6009cb 7c3592bf098d4a1795939e64b82dc5dc--a80271816a2f49819abd54c55e6009cb 961d96f5ca5c4f24849b0797ec8ad769 a80271816a2f49819abd54c55e6009cb--961d96f5ca5c4f24849b0797ec8ad769 a8cc659ef5404e5e9b2b643e8ce075d9 RX(theta\u2089) 961d96f5ca5c4f24849b0797ec8ad769--a8cc659ef5404e5e9b2b643e8ce075d9 7020f11a8c8f474c922b783c6808d178 RY(theta\u2081\u2082) a8cc659ef5404e5e9b2b643e8ce075d9--7020f11a8c8f474c922b783c6808d178 78344131aaf749f7b83ad6fcbcdd8d0a RX(theta\u2081\u2085) 7020f11a8c8f474c922b783c6808d178--78344131aaf749f7b83ad6fcbcdd8d0a 6ee690e1aee44107bede64df4e6264f7 78344131aaf749f7b83ad6fcbcdd8d0a--6ee690e1aee44107bede64df4e6264f7 6bc124ca802c4946bc4778a475198835 6ee690e1aee44107bede64df4e6264f7--6bc124ca802c4946bc4778a475198835 0cfafd21b68b4bddab316b3a246e0fba RX(theta\u2081\u2088) 6bc124ca802c4946bc4778a475198835--0cfafd21b68b4bddab316b3a246e0fba 910203ddf99f4baca2800fd6a475c865 RY(theta\u2082\u2081) 0cfafd21b68b4bddab316b3a246e0fba--910203ddf99f4baca2800fd6a475c865 e1d7b457381d48eebe7642023a3bccdd RX(theta\u2082\u2084) 910203ddf99f4baca2800fd6a475c865--e1d7b457381d48eebe7642023a3bccdd a5824f43dde7430582fefa45d00f5285 e1d7b457381d48eebe7642023a3bccdd--a5824f43dde7430582fefa45d00f5285 a5f84edcf3dd47c88947c94852aa6e36 a5824f43dde7430582fefa45d00f5285--a5f84edcf3dd47c88947c94852aa6e36 87a0f22f29cd46659b55c43701b94560 a5f84edcf3dd47c88947c94852aa6e36--87a0f22f29cd46659b55c43701b94560 036ad712810c452ebb311547b5369527 8c4d9ec0e8bf4198b933a9789f27ddf6 RX(2.0*acos(x)) a5b203f27e8446d08c4c11e185174e1a--8c4d9ec0e8bf4198b933a9789f27ddf6 73d0ad19d19347fb9199ccf88cd091d2 2 3e66a7719dc14d238beecca2ad4ab0dd RX(theta\u2081) 8c4d9ec0e8bf4198b933a9789f27ddf6--3e66a7719dc14d238beecca2ad4ab0dd efc6dee40df94e74a3858ed3b30cd27f RY(theta\u2084) 3e66a7719dc14d238beecca2ad4ab0dd--efc6dee40df94e74a3858ed3b30cd27f 19ef5d6b181e413984a7f65bb6137f4d RX(theta\u2087) efc6dee40df94e74a3858ed3b30cd27f--19ef5d6b181e413984a7f65bb6137f4d 7288220ca86f45e59bdd301cfd68d887 X 19ef5d6b181e413984a7f65bb6137f4d--7288220ca86f45e59bdd301cfd68d887 7288220ca86f45e59bdd301cfd68d887--a80271816a2f49819abd54c55e6009cb 50e914dfb47641209d63b99e0410e37a 7288220ca86f45e59bdd301cfd68d887--50e914dfb47641209d63b99e0410e37a 544c48c14455407f89078f5dfa80e42c RX(theta\u2081\u2080) 50e914dfb47641209d63b99e0410e37a--544c48c14455407f89078f5dfa80e42c d7d6519643e74b179c59978fa381ed12 RY(theta\u2081\u2083) 544c48c14455407f89078f5dfa80e42c--d7d6519643e74b179c59978fa381ed12 f70b6316e0054e5aa4ae040b23175e90 RX(theta\u2081\u2086) d7d6519643e74b179c59978fa381ed12--f70b6316e0054e5aa4ae040b23175e90 702fc7f1695347a4ac510aa43e3978ab X f70b6316e0054e5aa4ae040b23175e90--702fc7f1695347a4ac510aa43e3978ab 702fc7f1695347a4ac510aa43e3978ab--6ee690e1aee44107bede64df4e6264f7 78c4f52ce5f64016bd0a45e4d44331e1 702fc7f1695347a4ac510aa43e3978ab--78c4f52ce5f64016bd0a45e4d44331e1 d7b405b1832c46fd9b5014cb392e397f RX(theta\u2081\u2089) 78c4f52ce5f64016bd0a45e4d44331e1--d7b405b1832c46fd9b5014cb392e397f 3afdd6319a5c4bc1a1e64a527485057d RY(theta\u2082\u2082) d7b405b1832c46fd9b5014cb392e397f--3afdd6319a5c4bc1a1e64a527485057d 6ccd29e7f4f04575bc0eb34991759cf2 RX(theta\u2082\u2085) 3afdd6319a5c4bc1a1e64a527485057d--6ccd29e7f4f04575bc0eb34991759cf2 7938451810d649fbb9a767a6a52c3f11 X 6ccd29e7f4f04575bc0eb34991759cf2--7938451810d649fbb9a767a6a52c3f11 7938451810d649fbb9a767a6a52c3f11--a5824f43dde7430582fefa45d00f5285 df99d4aa06a649a29d5319b65b1fa55a 7938451810d649fbb9a767a6a52c3f11--df99d4aa06a649a29d5319b65b1fa55a df99d4aa06a649a29d5319b65b1fa55a--036ad712810c452ebb311547b5369527 4d4c42027bc549079477117f2354a092 e7a81bad91544585a95742d66013b66f RX(3.0*acos(x)) 73d0ad19d19347fb9199ccf88cd091d2--e7a81bad91544585a95742d66013b66f 52e73e9c658646f69dbe496c8ea931d0 RX(theta\u2082) e7a81bad91544585a95742d66013b66f--52e73e9c658646f69dbe496c8ea931d0 30873f975ceb4e39b7494b2cba330e94 RY(theta\u2085) 52e73e9c658646f69dbe496c8ea931d0--30873f975ceb4e39b7494b2cba330e94 3f845e03ae0945cf8fad0f7dc57e84d0 RX(theta\u2088) 30873f975ceb4e39b7494b2cba330e94--3f845e03ae0945cf8fad0f7dc57e84d0 60a8342159024d7a87f18e9adeb56176 3f845e03ae0945cf8fad0f7dc57e84d0--60a8342159024d7a87f18e9adeb56176 c07f3e812bca41b2a1aee722daee6ea7 X 60a8342159024d7a87f18e9adeb56176--c07f3e812bca41b2a1aee722daee6ea7 c07f3e812bca41b2a1aee722daee6ea7--50e914dfb47641209d63b99e0410e37a b59b665276544baa911fbc137448fce7 RX(theta\u2081\u2081) c07f3e812bca41b2a1aee722daee6ea7--b59b665276544baa911fbc137448fce7 f6f96c785a2f471aaee6ad2be1f70be0 RY(theta\u2081\u2084) b59b665276544baa911fbc137448fce7--f6f96c785a2f471aaee6ad2be1f70be0 f0bd3fd756e640f4bc208aac774dfce2 RX(theta\u2081\u2087) f6f96c785a2f471aaee6ad2be1f70be0--f0bd3fd756e640f4bc208aac774dfce2 bb5c625eae9046e8b18846fb95afabb3 f0bd3fd756e640f4bc208aac774dfce2--bb5c625eae9046e8b18846fb95afabb3 d099cee7e08e400e8deaae9c7d4a097c X bb5c625eae9046e8b18846fb95afabb3--d099cee7e08e400e8deaae9c7d4a097c d099cee7e08e400e8deaae9c7d4a097c--78c4f52ce5f64016bd0a45e4d44331e1 9bffe541f1f74f0da5de7de1e0dbb99e RX(theta\u2082\u2080) d099cee7e08e400e8deaae9c7d4a097c--9bffe541f1f74f0da5de7de1e0dbb99e 86811a0fdb374d9e8fdf484477e662cf RY(theta\u2082\u2083) 9bffe541f1f74f0da5de7de1e0dbb99e--86811a0fdb374d9e8fdf484477e662cf 202d293e4eb446e18d1f97d67990c0eb RX(theta\u2082\u2086) 86811a0fdb374d9e8fdf484477e662cf--202d293e4eb446e18d1f97d67990c0eb 7456d108361f4c7aa6244e908d386321 202d293e4eb446e18d1f97d67990c0eb--7456d108361f4c7aa6244e908d386321 b954547162ba4e73ae2beae1037414d8 X 7456d108361f4c7aa6244e908d386321--b954547162ba4e73ae2beae1037414d8 b954547162ba4e73ae2beae1037414d8--df99d4aa06a649a29d5319b65b1fa55a b954547162ba4e73ae2beae1037414d8--4d4c42027bc549079477117f2354a092"},{"location":"tutorials/qml/dqc_1d/#training-the-model","title":"Training the model","text":"<p>Now that the model is defined we can proceed with the training. the <code>QNN</code> class can be used like any other <code>torch.nn.Module</code>. Here we write a simple training loop, but you can also look at the ml tools tutorial to use the convenience training functions that Qadence provides.</p> <p>To train the model, we will select a random set of collocation points uniformly distributed within \\(-1.0&lt; x &lt;1.0\\) and compute the loss function for those points.</p> <pre><code>n_epochs = 200\nn_points = 10\n\nxmin = -0.99\nxmax = 0.99\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data. We unsqueeze essentially making each batch have a single x value.\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>Note the values of \\(x\\) are only picked from \\(x\\in[-0.99, 0.99]\\) since we are using a Chebyshev feature map, and derivative of \\(\\text{acos}(x)\\) diverges at \\(-1\\) and \\(1\\).</p>"},{"location":"tutorials/qml/dqc_1d/#plotting-the-results","title":"Plotting the results","text":"<pre><code>import matplotlib.pyplot as plt\n\ndef f_exact(x: torch.Tensor) -&gt; torch.Tensor:\n    return 5*(x**4 + (1/3)*x**3 - x**2 - 0.5*x)\n\nx_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \" Trained model\")\n</code></pre> 2024-09-20T08:35:00.959652 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/ <p>Clearly, the result is not optimal.</p>"},{"location":"tutorials/qml/dqc_1d/#improving-the-solution","title":"Improving the solution","text":"<p>One point to consider when defining the QNN is the possible output range, which is bounded by the spectrum of the chosen observable. For the magnetization of a single qubit, this means that the output is bounded between -1 and 1, which we can clearly see in the plot.</p> <p>One option would be to define the observable as the total magnetization over all qubits, which would allow a range of -3 to 3.</p> <pre><code>from qadence import add\n\nobservable = add(Z(i) for i in range(n_qubits))\n\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And we again plot the result:</p> <pre><code>x_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \"Trained model\")\n</code></pre> 2024-09-20T08:35:08.900190 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/qml/dqc_1d/#references","title":"References","text":"<ol> <li> <p>Kyriienko et al., Solving nonlinear differential equations with differentiable quantum circuits. \u21a9</p> </li> </ol>"},{"location":"tutorials/qml/ml_tools/","title":"Training tools","text":""},{"location":"tutorials/qml/ml_tools/#dataloaders","title":"Dataloaders","text":"<p>When using Qadence, you can supply classical data to a quantum machine learning algorithm by using a standard PyTorch <code>DataLoader</code> instance. Qadence also provides the <code>DictDataLoader</code> convenience class which allows to build dictionaries of <code>DataLoader</code>s instances and easily iterate over them.</p> <pre><code>import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import DictDataLoader, to_dataloader\n\n\ndef dataloader(data_size: int = 25, batch_size: int = 5, infinite: bool = False) -&gt; DataLoader:\n    x = torch.linspace(0, 1, data_size).reshape(-1, 1)\n    y = torch.sin(x)\n    return to_dataloader(x, y, batch_size=batch_size, infinite=infinite)\n\n\ndef dictdataloader(data_size: int = 25, batch_size: int = 5) -&gt; DictDataLoader:\n    dls = {}\n    for k in [\"y1\", \"y2\"]:\n        x = torch.rand(data_size, 1)\n        y = torch.sin(x)\n        dls[k] = to_dataloader(x, y, batch_size=batch_size, infinite=True)\n    return DictDataLoader(dls)\n\n\n# iterate over standard DataLoader\nfor (x,y) in dataloader(data_size=6, batch_size=2):\n    print(f\"Standard {x = }\")\n\n# construct an infinite dataset which will keep sampling indefinitely\nn_epochs = 5\ndl = iter(dataloader(data_size=6, batch_size=2, infinite=True))\nfor _ in range(n_epochs):\n    (x, y) = next(dl)\n    print(f\"Infinite {x = }\")\n\n# iterate over DictDataLoader\nddl = dictdataloader()\ndata = next(iter(ddl))\nprint(f\"{data = }\")\n</code></pre> <pre><code>Standard x = tensor([[0.0000],\n        [0.2000]])\nStandard x = tensor([[0.4000],\n        [0.6000]])\nStandard x = tensor([[0.8000],\n        [1.0000]])\nInfinite x = tensor([[0.0000],\n        [0.2000]])\nInfinite x = tensor([[0.4000],\n        [0.6000]])\nInfinite x = tensor([[0.8000],\n        [1.0000]])\nInfinite x = tensor([[0.0000],\n        [0.2000]])\nInfinite x = tensor([[0.4000],\n        [0.6000]])\ndata = {'y1': [tensor([[0.9914],\n        [0.1202],\n        [0.9460],\n        [0.7041],\n        [0.2477]]), tensor([[0.8368],\n        [0.1199],\n        [0.8111],\n        [0.6474],\n        [0.2452]])], 'y2': [tensor([[0.5858],\n        [0.3664],\n        [0.8248],\n        [0.6879],\n        [0.0721]]), tensor([[0.5528],\n        [0.3582],\n        [0.7344],\n        [0.6349],\n        [0.0720]])]}\n</code></pre>"},{"location":"tutorials/qml/ml_tools/#optimization-routines","title":"Optimization routines","text":"<p>For training QML models, Qadence also offers a few out-of-the-box routines for optimizing differentiable models, e.g. <code>QNN</code>s and <code>QuantumModel</code>, containing either trainable and/or non-trainable parameters (see the parameters tutorial for detailed information about parameter types):</p> <ul> <li><code>train_with_grad</code> for gradient-based optimization using PyTorch native optimizers</li> <li><code>train_gradient_free</code> for gradient-free optimization using the Nevergrad library.</li> </ul> <p>These routines performs training, logging/printing loss metrics and storing intermediate checkpoints of models. In the following, we use <code>train_with_grad</code> as example but the code can be used directly with the gradient-free routine.</p> <p>As every other training routine commonly used in Machine Learning, it requires <code>model</code>, <code>data</code> and an <code>optimizer</code> as input arguments. However, in addition, it requires a <code>loss_fn</code> and a <code>TrainConfig</code>. A <code>loss_fn</code> is required to be a function which expects both a model and data and returns a tuple of (loss, metrics: <code>&lt;dict&gt;</code>, ...), where <code>metrics</code> is a dict of scalars which can be customized too. It can optionally also return additional values which are utilised by the corresponding user-provided <code>optimize_step</code> function inside <code>train_with_grad</code>.</p> <pre><code>import torch\nfrom itertools import count\ncnt = count()\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    x, y = data[0], data[1]\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n</code></pre> <p>The <code>TrainConfig</code> tells <code>train_with_grad</code> what batch_size should be used, how many epochs to train, in which intervals to print/log metrics and how often to store intermediate checkpoints. It is also possible to provide custom callback functions by instantiating a <code>Callback</code> with a function <code>callback</code> that only accept as argument an instance of <code>OptimizeResult</code> created within the <code>train</code> functions. One can also provide a <code>callback_condition</code> function, also only accepting an instance of <code>OptimizeResult</code>, which returns True if <code>callback</code> should be called. If no <code>callback_condition</code> is provided, <code>callback</code> is called at every x epochs (specified by <code>Callback</code>'s <code>called_every</code> argument). We can also specify in which part of the training function the <code>Callback</code> will be applied. Note that if you need it, you can modify the instance of <code>OptimizeResult</code> created in the train functions by specifying <code>Callback</code>'s <code>modify_optimize_result</code> (as a function or a dictionary). For instance, we could add inputs to the <code>extra</code> field of <code>OptimizeResult</code> to be used within <code>callback</code>. An example code is shown below.</p> <pre><code>from qadence.ml_tools import OptimizeResult, TrainConfig, Callback\n\nbatch_size = 5\nn_epochs = 100\n\nprint_parameters = lambda opt_res: print(opt_res.model.parameters())\ncondition_print = lambda opt_res: opt_res.loss &lt; 1.0e-03\nmodify_extra_opt_res = {\"n_epochs\": n_epochs}\ncustom_callback = Callback(print_parameters, callback_condition=condition_print, modify_optimize_result=modify_extra_opt_res, called_every=10, call_end_epoch=True)\n\nconfig = TrainConfig(\n    folder=\"some_path/\",\n    max_iter=n_epochs,\n    checkpoint_every=100,\n    write_every=100,\n    batch_size=batch_size,\n    callbacks = [custom_callback]\n)\n</code></pre> <p>If it is desired to only the save the \"best\" checkpoint, the following must be ensured:</p> <p>(a) <code>checkpoint_best_only = True</code> is used while creating the configuration through <code>TrainConfig</code>, (b) <code>val_every</code> is set to a valid integer value (for example, <code>val_every = 10</code>) which controls the no. of iterations after which the validation data should be used to evaluate the model during training, which can also be set through <code>TrainConfig</code>, (c) a validation criterion is provided through the <code>validation_criterion</code>, set through <code>TrainConfig</code> to quantify the definition of \"best\", and (d) the dataloader passed to <code>train_grad</code> is of type <code>DictDataLoader</code>. In this case, it is expected that a validation dataloader is also provided along with the train dataloader since the validation data will be used to decide the \"best\" checkpoint. The dataloaders must be accessible with specific keys: \"train\" and \"val\".</p> <p>The criterion used to decide the \"best\" checkpoint can be customized by <code>validation_criterion</code>, which should be a function that can take any number of arguments and return a boolean value (True or False) indicating whether some validation metric is satisfied or not. Typical choices are to return True when the validation loss (accuracy) has decreased (increased) compared to smallest (largest) value from previous iterations at which a validation check was performed.</p> <p>Let's see it in action with a simple example.</p>"},{"location":"tutorials/qml/ml_tools/#fitting-a-funtion-with-a-qnn-using-ml_tools","title":"Fitting a funtion with a QNN using <code>ml_tools</code>","text":"<p>In Quantum Machine Learning, the general consensus is to use <code>complex128</code> precision for states and operators and <code>float64</code> precision for parameters. This is also the convention which is used in <code>qadence</code>. However, for specific usecases, lower precision can greatly speed up training and reduce memory consumption. When using the <code>pyqtorch</code> backend, <code>qadence</code> offers the option to move a <code>QuantumModel</code> instance to a specific precision using the torch <code>to</code> syntax.</p> <p>Let's look at a complete example of how to use <code>train_with_grad</code> now. Here we perform a validation check during training and use a validation criterion that checks whether the validation loss in the current iteration has decreased compared to the lowest validation loss from all previous iterations. For demonstration, the train and the validation data are kept the same here. However, it is beneficial and encouraged to keep them distinct in practice to understand model's generalization capabilities.</p> <pre><code>from pathlib import Path\nimport torch\nfrom functools import reduce\nfrom operator import add\nfrom itertools import count\nimport matplotlib.pyplot as plt\n\nfrom qadence import Parameter, QuantumCircuit, Z\nfrom qadence import hamiltonian_factory, hea, feature_map, chain\nfrom qadence import QNN\nfrom qadence.ml_tools import  TrainConfig, train_with_grad, to_dataloader, DictDataLoader\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nDTYPE = torch.complex64\nn_qubits = 4\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\n\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 100\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    x, y = data[0], data[1]\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ndef validation_criterion(\n    current_validation_loss: float, current_best_validation_loss: float, val_epsilon: float\n) -&gt; bool:\n    return current_validation_loss &lt;= current_best_validation_loss - val_epsilon\n\nn_epochs = 300\n\nconfig = TrainConfig(\n    max_iter=n_epochs,\n    batch_size=batch_size,\n    checkpoint_best_only=True,\n    val_every=10,  # The model will be run on the validation data after every `val_every` epochs.\n    validation_criterion=validation_criterion\n)\n\nfn = lambda x, degree: .05 * reduce(add, (torch.cos(i*x) + torch.sin(i*x) for i in range(degree)), 0.)\nx = torch.linspace(0, 10, batch_size, dtype=torch.float32).reshape(-1, 1)\ny = fn(x, 5)\n\ndata = DictDataLoader(\n    {\n        \"train\": to_dataloader(x, y, batch_size=batch_size, infinite=True),\n        \"val\": to_dataloader(x, y, batch_size=batch_size, infinite=True),\n    }\n)\n\ntrain_with_grad(model, data, optimizer, config, loss_fn=loss_fn,device=DEVICE, dtype=DTYPE)\n\nplt.clf()\nplt.plot(x.numpy(), y.numpy(), label='truth')\nplt.plot(x.numpy(), model(x).detach().numpy(), \"--\", label=\"final\", linewidth=3)\nplt.legend()\n</code></pre> 2024-09-20T08:35:17.122599 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/ <p>For users who want to use the low-level API of <code>qadence</code>, here an example written without <code>train_with_grad</code>.</p>"},{"location":"tutorials/qml/ml_tools/#fitting-a-function-low-level-api","title":"Fitting a function - Low-level API","text":"<pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence import QNN\nfrom qadence.ml_tools import TrainConfig\n\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\n\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nn_epochs=50\ncnt = count()\n\ntmp_path = Path(\"/tmp\")\n\nconfig = TrainConfig(\n    folder=tmp_path,\n    max_iter=n_epochs,\n    checkpoint_every=100,\n    write_every=100,\n    batch_size=batch_size,\n)\n\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\n\nfor i in range(n_epochs):\n    out = model(x)\n    loss = criterion(out, y)\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"tutorials/qml/ml_tools/#custom-train-loop","title":"Custom <code>train</code> loop","text":"<p>If you need custom training functionality that goes beyond what is available in <code>qadence.ml_tools.train_with_grad</code> and <code>qadence.ml_tools.train_gradient_free</code> you can write your own training loop based on the building blocks that are available in Qadence.</p> <p>A simplified version of Qadence's train loop is defined below. Feel free to copy it and modify at will.</p> <pre><code>from typing import Callable, Union\n\nfrom torch.nn import Module\nfrom torch.optim import Optimizer\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom qadence.ml_tools.config import TrainConfig\nfrom qadence.ml_tools.data import DictDataLoader, data_to_device\nfrom qadence.ml_tools.optimize_step import optimize_step\nfrom qadence.ml_tools.printing import print_metrics, write_tensorboard\nfrom qadence.ml_tools.saveload import load_checkpoint, write_checkpoint\n\n\ndef train(\n    model: Module,\n    data: DataLoader,\n    optimizer: Optimizer,\n    config: TrainConfig,\n    loss_fn: Callable,\n    device: str = \"cpu\",\n    optimize_step: Callable = optimize_step,\n    write_tensorboard: Callable = write_tensorboard,\n) -&gt; tuple[Module, Optimizer]:\n\n    # Move model to device before optimizer is loaded\n    model = model.to(device)\n\n    # load available checkpoint\n    init_iter = 0\n    if config.folder:\n        model, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\n\n    # initialize tensorboard\n    writer = SummaryWriter(config.folder, purge_step=init_iter)\n\n    dl_iter = iter(dataloader)\n\n    # outer epoch loop\n    for iteration in range(init_iter, init_iter + config.max_iter):\n        data = data_to_device(next(dl_iter), device)\n        loss, metrics = optimize_step(model, optimizer, loss_fn, data)\n\n        if iteration % config.print_every == 0 and config.verbose:\n            print_metrics(loss, metrics, iteration)\n\n        if iteration % config.write_every == 0:\n            write_tensorboard(writer, loss, metrics, iteration)\n\n        if config.folder:\n            if iteration % config.checkpoint_every == 0:\n                write_checkpoint(config.folder, model, optimizer, iteration)\n\n    # Final writing and checkpointing\n    if config.folder:\n        write_checkpoint(config.folder, model, optimizer, iteration)\n    write_tensorboard(writer, loss, metrics, iteration)\n    writer.close()\n\n    return model, optimizer\n</code></pre>"},{"location":"tutorials/qml/ml_tools/#experiment-tracking-with-mlflow","title":"Experiment tracking with mlflow","text":"<p>Qadence allows to track runs and log hyperparameters, models and plots with tensorboard and mlflow. In the following, we demonstrate the integration with mlflow.</p>"},{"location":"tutorials/qml/ml_tools/#mlflow-configuration","title":"mlflow configuration","text":"<p>We have control over our tracking configuration by setting environment variables. First, let's look at the tracking URI. For the purpose of this demo we will be working with a local database, in a similar fashion as described here, <pre><code>export MLFLOW_TRACKING_URI=sqlite:///mlruns.db\n</code></pre></p> <p>Qadence can also read the following two environment variables to define the mlflow experiment name and run name <pre><code>export MLFLOW_EXPERIMENT=test_experiment\nexport MLFLOW_RUN_NAME=run_0\n</code></pre></p> <p>If no tracking URI is provided, mlflow stores run information and artifacts in the local <code>./mlflow</code> directory and if no names are defined, the experiment and run will be named with random UUIDs.</p>"},{"location":"tutorials/qml/ml_tools/#setup","title":"Setup","text":"<p>Let's do the necessary imports and declare a <code>DataLoader</code>. We can already define some hyperparameters here, including the seed for random number generators. mlflow can log hyperparameters with arbitrary types, for example the observable that we want to monitor (<code>Z</code> in this case, which has a <code>qadence.Operation</code> type).</p> <pre><code>import random\nfrom itertools import count\n\nimport numpy as np\nimport torch\nfrom matplotlib import pyplot as plt\nfrom matplotlib.figure import Figure\nfrom torch.nn import Module\nfrom torch.utils.data import DataLoader\n\nfrom qadence import hea, QuantumCircuit, Z\nfrom qadence.constructors import feature_map, hamiltonian_factory\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nfrom qadence.ml_tools.data import to_dataloader\nfrom qadence.ml_tools.utils import rand_featureparameters\nfrom qadence.models import QNN, QuantumModel\nfrom qadence.types import ExperimentTrackingTool\n\nhyperparams = {\n    \"seed\": 42,\n    \"batch_size\": 10,\n    \"n_qubits\": 2,\n    \"ansatz_depth\": 1,\n    \"observable\": Z,\n}\n\nnp.random.seed(hyperparams[\"seed\"])\ntorch.manual_seed(hyperparams[\"seed\"])\nrandom.seed(hyperparams[\"seed\"])\n\n\ndef dataloader(batch_size: int = 25) -&gt; DataLoader:\n    x = torch.linspace(0, 1, batch_size).reshape(-1, 1)\n    y = torch.cos(x)\n    return to_dataloader(x, y, batch_size=batch_size, infinite=True)\n</code></pre> <p>We continue with the regular QNN definition, together with the loss function and optimizer.</p> <pre><code>obs = hamiltonian_factory(register=hyperparams[\"n_qubits\"], detuning=hyperparams[\"observable\"])\n\ndata = dataloader(hyperparams[\"batch_size\"])\nfm = feature_map(hyperparams[\"n_qubits\"], param=\"x\")\n\nmodel = QNN(\n    QuantumCircuit(\n        hyperparams[\"n_qubits\"], fm, hea(hyperparams[\"n_qubits\"], hyperparams[\"ansatz_depth\"])\n    ),\n    observable=obs,\n    inputs=[\"x\"],\n)\n\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n\ninputs = rand_featureparameters(model, 1)\n\ndef loss_fn(model: QuantumModel, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n    next(cnt)\n    out = model.expectation(inputs)\n    loss = criterion(out, torch.rand(1))\n    return loss, {}\n</code></pre>"},{"location":"tutorials/qml/ml_tools/#trainconfig-specifications","title":"<code>TrainConfig</code> specifications","text":"<p>Qadence offers different tracking options via <code>TrainConfig</code>. Here we use the <code>ExperimentTrackingTool</code> type to specify that we want to track the experiment with mlflow. Tracking with tensorboard is also possible. We can then indicate what and how often we want to track or log. <code>write_every</code> controls the number of epochs after which the loss values is logged. Thanks to the <code>plotting_functions</code> and <code>plot_every</code>arguments, we are also able to plot model-related quantities throughout training. Notice that arbitrary plotting functions can be passed, as long as the signature is the same as <code>plot_fn</code> below. Finally, the trained model can be logged by setting <code>log_model=True</code>. Here is an example of plotting function and training configuration</p> <pre><code>def plot_fn(model: Module, iteration: int) -&gt; tuple[str, Figure]:\n    descr = f\"ufa_prediction_epoch_{iteration}.png\"\n    fig, ax = plt.subplots()\n    x = torch.linspace(0, 1, 100).reshape(-1, 1)\n    out = model.expectation(x)\n    ax.plot(x.detach().numpy(), out.detach().numpy())\n    return descr, fig\n\n\nconfig = TrainConfig(\n    folder=\"mlflow_demonstration\",\n    max_iter=10,\n    checkpoint_every=1,\n    plot_every=2,\n    write_every=1,\n    log_model=True,\n    tracking_tool=ExperimentTrackingTool.MLFLOW,\n    hyperparams=hyperparams,\n    plotting_functions=(plot_fn,),\n)\n</code></pre>"},{"location":"tutorials/qml/ml_tools/#training-and-inspecting","title":"Training and inspecting","text":"<p>Model training happens as usual <pre><code>train_with_grad(model, data, optimizer, config, loss_fn=loss_fn)\n</code></pre></p> <p>After training , we can inspect our experiment via the mlflow UI <pre><code>mlflow ui --port 8080 --backend-store-uri sqlite:///mlruns.db\n</code></pre> In this case, since we're running on a local server, we can access the mlflow UI by navigating to http://localhost:8080/.</p>"},{"location":"tutorials/qml/qaoa/","title":"Solving MaxCut with QAOA","text":"<p>This tutorial shows how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA), first introduced by Farhi et al. in 2014 <sup>1</sup>.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a graph cut which partitions the nodes into two disjoint sets, such that the number of edges in the cut is maximized. This is a very common combinatorial optimization problem known to be computationally hard (NP-hard).</p> <p>The graph used for this tutorial is an unweighted graph randomly generated using the <code>networkx</code> library with a certain probability \\(p\\) of having an edge between two arbitrary nodes (known as Erd\u0151s\u2013R\u00e9nyi graph).</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\n\n# ensure reproducibility\nseed = 42\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Create random graph\nn_nodes = 4\nedge_prob = 0.8\ngraph = nx.gnp_random_graph(n_nodes, edge_prob)\n\nnx.draw(graph)\n</code></pre> 2024-09-20T08:35:17.798208 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[\\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p)\\] <p>where \\(p\\) is a given cut of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\). We will represent a cut \\(p\\) as a bitstring of length \\(N\\), where \\(N\\) is the number of nodes, and where the bit in position \\(i\\) shows to which partition node \\(i\\) belongs. We assign value 0 to one of the partitions defined by the cut and 1 to the other. Since this choice is arbitrary, every cut is represented by two bitstrings, e.g. \"0011\" and \"1100\" are equivalent.</p> <p>Since in this tutorial we are only dealing with small graphs, we can find the maximum cut by brute force to make sure QAOA works as intended. <pre><code># Function to calculate the cost associated with a cut\ndef calculate_cost(cut: str, graph: nx.graph) -&gt; float:\n    \"\"\"Returns the cost of a given cut (represented by a bitstring)\"\"\"\n    cost = 0\n    for edge in graph.edges():\n        (i, j) = edge\n        if cut[i] != cut[j]:\n            cost += 1\n    return cost\n\n\n# Function to get a binary representation of an int\nget_binary = lambda x, n: format(x, \"b\").zfill(n)\n\n# List of all possible cuts\nall_possible_cuts = [bin(k)[2:].rjust(n_nodes, \"0\") for k in range(2**n_nodes)]\n\n# List with the costs associated to each cut\nall_costs = [calculate_cost(cut, graph) for cut in all_possible_cuts]\n\n# Get the maximum cost\nmaxcost = max(all_costs)\n\n# Get all cuts that correspond to the maximum cost\nmaxcuts = [get_binary(i, n_nodes) for i, j in enumerate(all_costs) if j == maxcost]\nprint(f\"The maximum cut is represented by the bitstrings {maxcuts}, with a cost of {maxcost}\")\n</code></pre> <pre><code>The maximum cut is represented by the bitstrings ['0011', '0101', '0110', '1001', '1010', '1100'], with a cost of 4\n</code></pre> </p>"},{"location":"tutorials/qml/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>The Max-Cut problem can be solved by using the QAOA algorithm. QAOA belongs to the class of Variational Quantum Algorithms (VQAs), which means that its quantum circuit contains a certain number of parametrized quantum gates that need to be optimized with a classical optimizer. The QAOA circuit is composed of two operators:</p> <ul> <li>The cost operator \\(U_c\\): a circuit generated by the cost Hamiltonian which encodes the cost function described above into a quantum circuit. The solution to the optimization problem is encoded in the ground state of the cost Hamiltonian \\(H_c\\). The cost operator  is simply the evolution of the cost Hamiltonian parametrized by a variational parameter \\(\\gamma\\) so that \\(U_c = e^{i\\gamma H_c}.\\)</li> <li>The mixing operator \\(U_b\\): a simple set of single-qubit rotations with adjustable   angles which are tuned during the classical optimization loop to minimize the cost</li> </ul> <p>The cost Hamiltonian of the MaxCut problem can be written as:</p> \\[H_c = \\frac12 \\sum_{\\langle i,j\\rangle} (\\mathbb{1} - Z_iZ_j)\\] <p>where \\(\\langle i,j\\rangle\\) represents the edge between nodes \\(i\\) and \\(j\\). The solution of the MaxCut problem is encoded in the ground state of the above Hamiltonian.</p> <p>The QAOA quantum circuit consists of a number of layers, each layer containing a cost and a mixing operator. Below, the QAOA quantum circuit is defined using <code>qadence</code> operations. First, a layer of Hadamard gates is applied to all qubits to prepare the initial state \\(|+\\rangle ^{\\otimes n}\\). The cost operator of each layer can be built \"manually\", implementing the \\(e^{iZZ\\gamma}\\) terms with CNOTs and a \\(\\rm{RZ}(2\\gamma)\\) rotation, or it can also be automatically decomposed into digital single and two-qubits operations via the <code>.digital_decomposition()</code> method. The decomposition is exact since the Hamiltonian generator is diagonal.</p> <pre><code>from qadence import tag, kron, chain, RX, RZ, Z, H, CNOT, I, add\nfrom qadence import HamEvo, QuantumCircuit, Parameter\n\nn_qubits = graph.number_of_nodes()\nn_edges = graph.number_of_edges()\nn_layers = 6\n\n# Generate the cost Hamiltonian\nzz_ops = add(Z(edge[0]) @ Z(edge[1]) for edge in graph.edges)\ncost_ham = 0.5 * (n_edges * kron(I(i) for i in range(n_qubits)) - zz_ops)\n\n\n# QAOA circuit\ndef build_qaoa_circuit(n_qubits, n_layers, graph):\n    layers = []\n    # Layer of Hadamards\n    initial_layer = kron(H(i) for i in range(n_qubits))\n    layers.append(initial_layer)\n    for layer in range(n_layers):\n\n        # cost layer with digital decomposition\n        # cost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition(approximation=\"basic\")\n        cost_layer = []\n        for edge in graph.edges():\n            (q0, q1) = edge\n            zz_term = chain(\n                CNOT(q0, q1),\n                RZ(q1, Parameter(f\"g{layer}\")),\n                CNOT(q0, q1),\n            )\n            cost_layer.append(zz_term)\n        cost_layer = chain(*cost_layer)\n        cost_layer = tag(cost_layer, \"cost\")\n\n        # mixing layer with single qubit rotations\n        mixing_layer = kron(RX(i, f\"b{layer}\") for i in range(n_qubits))\n        mixing_layer = tag(mixing_layer, \"mixing\")\n\n        # putting all together in a single ChainBlock\n        layers.append(chain(cost_layer, mixing_layer))\n\n    final_b = chain(*layers)\n    return QuantumCircuit(n_qubits, final_b)\n\n\ncircuit = build_qaoa_circuit(n_qubits, n_layers, graph)\n\n# Print a single layer of the circuit\n</code></pre> %3 cluster_9a047520f86b4922a646b3cc1a34c04a mixing cluster_55f39f9de1d4434dab79b9fde38ccc72 cost aba71dc5a1c345f3be365308c3953ba8 0 80f77a372132450f8e5077710b8f8296 H aba71dc5a1c345f3be365308c3953ba8--80f77a372132450f8e5077710b8f8296 5cbd44834f7a4291b592129a26bbb83f 1 7575c508567f4bbf8795545217b6610f 80f77a372132450f8e5077710b8f8296--7575c508567f4bbf8795545217b6610f c364d561f0c84ff0a4ee9a8b2da7757c 7575c508567f4bbf8795545217b6610f--c364d561f0c84ff0a4ee9a8b2da7757c 333e3115b29f4882bb3023773f7aadf4 c364d561f0c84ff0a4ee9a8b2da7757c--333e3115b29f4882bb3023773f7aadf4 86d3c949fc644b4e9f868c4d772ecdd1 333e3115b29f4882bb3023773f7aadf4--86d3c949fc644b4e9f868c4d772ecdd1 a6adcc52018845e9bd4be182654ad155 86d3c949fc644b4e9f868c4d772ecdd1--a6adcc52018845e9bd4be182654ad155 0133092d5e814ea085df4412c0dbb532 a6adcc52018845e9bd4be182654ad155--0133092d5e814ea085df4412c0dbb532 8947bb61384e4c4c800b55a43485738d 0133092d5e814ea085df4412c0dbb532--8947bb61384e4c4c800b55a43485738d 3980ae44901e4e82ac547f51515005c1 8947bb61384e4c4c800b55a43485738d--3980ae44901e4e82ac547f51515005c1 a4af0a9de93b4c739dd0f5ea1f84c5bc 3980ae44901e4e82ac547f51515005c1--a4af0a9de93b4c739dd0f5ea1f84c5bc baa45786ed3c4d90a4b3cad7dda9fcd7 a4af0a9de93b4c739dd0f5ea1f84c5bc--baa45786ed3c4d90a4b3cad7dda9fcd7 1b03c873d25040bab34c6c88d49d8e0b baa45786ed3c4d90a4b3cad7dda9fcd7--1b03c873d25040bab34c6c88d49d8e0b 6a389b64c05b439aadc816e2ee6ab225 1b03c873d25040bab34c6c88d49d8e0b--6a389b64c05b439aadc816e2ee6ab225 34e378ae20754907aba9b99f36c96e57 6a389b64c05b439aadc816e2ee6ab225--34e378ae20754907aba9b99f36c96e57 f00af454504640d6834f9043eec33880 34e378ae20754907aba9b99f36c96e57--f00af454504640d6834f9043eec33880 950355f462bd44e395ea3d1a6bf4d370 f00af454504640d6834f9043eec33880--950355f462bd44e395ea3d1a6bf4d370 4e2094362c43462caa3d0744da3ee1aa 950355f462bd44e395ea3d1a6bf4d370--4e2094362c43462caa3d0744da3ee1aa 98d5c8c30f2f40328005684c1302856f 4e2094362c43462caa3d0744da3ee1aa--98d5c8c30f2f40328005684c1302856f dc135df147be4ca1bebec4232f686121 98d5c8c30f2f40328005684c1302856f--dc135df147be4ca1bebec4232f686121 47d7905d1abe44048984674583d87cee RX(b0) dc135df147be4ca1bebec4232f686121--47d7905d1abe44048984674583d87cee df8d661c43864514a4f9dd8ea82aa51a 47d7905d1abe44048984674583d87cee--df8d661c43864514a4f9dd8ea82aa51a bae7246548424e958192e689fec3836c e06308b6a4ad4c41972c4a4371ea9232 H 5cbd44834f7a4291b592129a26bbb83f--e06308b6a4ad4c41972c4a4371ea9232 223b8fbc96e64876aeafacaf32cd86cc 2 75a29b3408c04cf5ba1e45136e03f0f5 X e06308b6a4ad4c41972c4a4371ea9232--75a29b3408c04cf5ba1e45136e03f0f5 75a29b3408c04cf5ba1e45136e03f0f5--7575c508567f4bbf8795545217b6610f 6dd4502ecd374a7bbd00557e72c54c96 RZ(g0) 75a29b3408c04cf5ba1e45136e03f0f5--6dd4502ecd374a7bbd00557e72c54c96 0a0b2cc6f38e44e0b2a814522cf542c6 X 6dd4502ecd374a7bbd00557e72c54c96--0a0b2cc6f38e44e0b2a814522cf542c6 0a0b2cc6f38e44e0b2a814522cf542c6--333e3115b29f4882bb3023773f7aadf4 761ea6678a744894846c9e8b4bd2d568 0a0b2cc6f38e44e0b2a814522cf542c6--761ea6678a744894846c9e8b4bd2d568 ddbdca3802f543278bdc4859063aa8a6 761ea6678a744894846c9e8b4bd2d568--ddbdca3802f543278bdc4859063aa8a6 ec91224a7ded420194ce5db4425c28ac ddbdca3802f543278bdc4859063aa8a6--ec91224a7ded420194ce5db4425c28ac 1a849ff9a3ad447bb63f25a0d5d67edb ec91224a7ded420194ce5db4425c28ac--1a849ff9a3ad447bb63f25a0d5d67edb d568548644c747d8bcf8dd3ec8d2ba90 1a849ff9a3ad447bb63f25a0d5d67edb--d568548644c747d8bcf8dd3ec8d2ba90 361c49114adf40aaa680a6cec3f046a0 d568548644c747d8bcf8dd3ec8d2ba90--361c49114adf40aaa680a6cec3f046a0 2e8243722249462696c3c586d20e0da5 361c49114adf40aaa680a6cec3f046a0--2e8243722249462696c3c586d20e0da5 1fdf35fbc71540e1a555ab86e9f3689d 2e8243722249462696c3c586d20e0da5--1fdf35fbc71540e1a555ab86e9f3689d ef7571479f0c4798aaa776f7a7d08461 1fdf35fbc71540e1a555ab86e9f3689d--ef7571479f0c4798aaa776f7a7d08461 2cea9bb8d6bb4ec8a3b747715a8be685 ef7571479f0c4798aaa776f7a7d08461--2cea9bb8d6bb4ec8a3b747715a8be685 830c8f5797024f84af571f95b66cd350 2cea9bb8d6bb4ec8a3b747715a8be685--830c8f5797024f84af571f95b66cd350 1e96ab373ffe4bf59bedaaac646855a1 830c8f5797024f84af571f95b66cd350--1e96ab373ffe4bf59bedaaac646855a1 d9fde22c0b874352a7bc28d4d973ee0e 1e96ab373ffe4bf59bedaaac646855a1--d9fde22c0b874352a7bc28d4d973ee0e fd68d1ebb7ca4f63a2df240a5914dcc9 d9fde22c0b874352a7bc28d4d973ee0e--fd68d1ebb7ca4f63a2df240a5914dcc9 1aaefcd25b8143dabb3f5685e8b48354 fd68d1ebb7ca4f63a2df240a5914dcc9--1aaefcd25b8143dabb3f5685e8b48354 a554282dc3604db78b0108854250119c RX(b0) 1aaefcd25b8143dabb3f5685e8b48354--a554282dc3604db78b0108854250119c a554282dc3604db78b0108854250119c--bae7246548424e958192e689fec3836c 9d602e4bef2849e48f4d405d67889259 d1d24cb068204e699117f122de691608 H 223b8fbc96e64876aeafacaf32cd86cc--d1d24cb068204e699117f122de691608 0e7d035105584f32b57c28bc6df914d3 3 0fe5abddf91d44018769039168a6a049 d1d24cb068204e699117f122de691608--0fe5abddf91d44018769039168a6a049 b4a3136752ce46aca3427f743ad11e9a 0fe5abddf91d44018769039168a6a049--b4a3136752ce46aca3427f743ad11e9a 8c5f184c319b467c997a578fc648a734 b4a3136752ce46aca3427f743ad11e9a--8c5f184c319b467c997a578fc648a734 e510f1057514466b8144c62f995e446f X 8c5f184c319b467c997a578fc648a734--e510f1057514466b8144c62f995e446f e510f1057514466b8144c62f995e446f--86d3c949fc644b4e9f868c4d772ecdd1 83298ed2d3994ff382624961576c5bce RZ(g0) e510f1057514466b8144c62f995e446f--83298ed2d3994ff382624961576c5bce aa087829446440748c154656419d036c X 83298ed2d3994ff382624961576c5bce--aa087829446440748c154656419d036c aa087829446440748c154656419d036c--0133092d5e814ea085df4412c0dbb532 e0936ef87bbe4c00ad3ac7772287959d aa087829446440748c154656419d036c--e0936ef87bbe4c00ad3ac7772287959d e6198640dfaf4e5fb499772d644c2055 e0936ef87bbe4c00ad3ac7772287959d--e6198640dfaf4e5fb499772d644c2055 0ffc59efee034dae97e375cf9fb507f4 e6198640dfaf4e5fb499772d644c2055--0ffc59efee034dae97e375cf9fb507f4 d8c7665da6e443d6a1fab0a0898b5349 X 0ffc59efee034dae97e375cf9fb507f4--d8c7665da6e443d6a1fab0a0898b5349 d8c7665da6e443d6a1fab0a0898b5349--2e8243722249462696c3c586d20e0da5 b57db81686424333801e1d39ec81ede9 RZ(g0) d8c7665da6e443d6a1fab0a0898b5349--b57db81686424333801e1d39ec81ede9 74891d8265d044a2a0f5fd895df178c7 X b57db81686424333801e1d39ec81ede9--74891d8265d044a2a0f5fd895df178c7 74891d8265d044a2a0f5fd895df178c7--ef7571479f0c4798aaa776f7a7d08461 5b6a6f25a62249bf91a7ed678bc85f5f 74891d8265d044a2a0f5fd895df178c7--5b6a6f25a62249bf91a7ed678bc85f5f 11ec92dd5dd04768be59e8187dfd1887 5b6a6f25a62249bf91a7ed678bc85f5f--11ec92dd5dd04768be59e8187dfd1887 52d77b994da04b86bbd433423f11d41b 11ec92dd5dd04768be59e8187dfd1887--52d77b994da04b86bbd433423f11d41b 539bae843d8549bebdcd08a6cf8e4834 52d77b994da04b86bbd433423f11d41b--539bae843d8549bebdcd08a6cf8e4834 04ed054f77414675b8dd027a294f4c92 539bae843d8549bebdcd08a6cf8e4834--04ed054f77414675b8dd027a294f4c92 3d14c75a752e481b80c9174e90175217 04ed054f77414675b8dd027a294f4c92--3d14c75a752e481b80c9174e90175217 525d55c30ea94893b15e38e8b18d9776 RX(b0) 3d14c75a752e481b80c9174e90175217--525d55c30ea94893b15e38e8b18d9776 525d55c30ea94893b15e38e8b18d9776--9d602e4bef2849e48f4d405d67889259 08f259011521493191c7bc3d5155bcb7 7d7fe58fda06417b8b55c7ff3dcabfca H 0e7d035105584f32b57c28bc6df914d3--7d7fe58fda06417b8b55c7ff3dcabfca 1c15e2266d2a48faa3399ee97ce1e793 7d7fe58fda06417b8b55c7ff3dcabfca--1c15e2266d2a48faa3399ee97ce1e793 5d1f2703f32f43898361021fd7e637c8 1c15e2266d2a48faa3399ee97ce1e793--5d1f2703f32f43898361021fd7e637c8 1f115c58637749649b04b4897f900433 5d1f2703f32f43898361021fd7e637c8--1f115c58637749649b04b4897f900433 11fba74746dc44578ca604455a73c0eb 1f115c58637749649b04b4897f900433--11fba74746dc44578ca604455a73c0eb 0e4784fff2964e1083fdbdf2a116fd5d 11fba74746dc44578ca604455a73c0eb--0e4784fff2964e1083fdbdf2a116fd5d 1ae70b50ed634c14a7ab859d4c4309f6 0e4784fff2964e1083fdbdf2a116fd5d--1ae70b50ed634c14a7ab859d4c4309f6 bb5da3739e3d4cee96781fc419531940 X 1ae70b50ed634c14a7ab859d4c4309f6--bb5da3739e3d4cee96781fc419531940 bb5da3739e3d4cee96781fc419531940--8947bb61384e4c4c800b55a43485738d f6441e3d995e43b3863a3420b84718c9 RZ(g0) bb5da3739e3d4cee96781fc419531940--f6441e3d995e43b3863a3420b84718c9 1eced17ab4f748b2b62bd854e88a1adb X f6441e3d995e43b3863a3420b84718c9--1eced17ab4f748b2b62bd854e88a1adb 1eced17ab4f748b2b62bd854e88a1adb--a4af0a9de93b4c739dd0f5ea1f84c5bc 9075d055a0a545b7b3cb6dc27729a9d7 1eced17ab4f748b2b62bd854e88a1adb--9075d055a0a545b7b3cb6dc27729a9d7 28ddb6d4e3bd45898b8cdd0ee72810b8 9075d055a0a545b7b3cb6dc27729a9d7--28ddb6d4e3bd45898b8cdd0ee72810b8 ed810d028d1047d28a8ddce31331bc67 28ddb6d4e3bd45898b8cdd0ee72810b8--ed810d028d1047d28a8ddce31331bc67 e4cc168b3e0e418a93b1f7198358075c X ed810d028d1047d28a8ddce31331bc67--e4cc168b3e0e418a93b1f7198358075c e4cc168b3e0e418a93b1f7198358075c--2cea9bb8d6bb4ec8a3b747715a8be685 a8911956a2844aea8c146e950e4d0daa RZ(g0) e4cc168b3e0e418a93b1f7198358075c--a8911956a2844aea8c146e950e4d0daa 56f0bc0b7c0649c982fbd5f26e41ec8c X a8911956a2844aea8c146e950e4d0daa--56f0bc0b7c0649c982fbd5f26e41ec8c 56f0bc0b7c0649c982fbd5f26e41ec8c--1e96ab373ffe4bf59bedaaac646855a1 7b29886695cf4699bc4f1c3e095e9b85 X 56f0bc0b7c0649c982fbd5f26e41ec8c--7b29886695cf4699bc4f1c3e095e9b85 7b29886695cf4699bc4f1c3e095e9b85--539bae843d8549bebdcd08a6cf8e4834 62e43d3cc190470a980c87f43ea965b1 RZ(g0) 7b29886695cf4699bc4f1c3e095e9b85--62e43d3cc190470a980c87f43ea965b1 846c6ba8cd2f4b2093074c708273e826 X 62e43d3cc190470a980c87f43ea965b1--846c6ba8cd2f4b2093074c708273e826 846c6ba8cd2f4b2093074c708273e826--3d14c75a752e481b80c9174e90175217 cc1a1e6f882046759312e2e5e6905c88 RX(b0) 846c6ba8cd2f4b2093074c708273e826--cc1a1e6f882046759312e2e5e6905c88 cc1a1e6f882046759312e2e5e6905c88--08f259011521493191c7bc3d5155bcb7"},{"location":"tutorials/qml/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Given the QAOA circuit above, one can construct the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization.</p> <p>The loss function to be minimized reads:</p> \\[\\mathcal{L} =-\\langle \\psi | H_c| \\psi \\rangle= -\\frac12 \\sum_{\\langle i,j\\rangle}  \\left(1 - \\langle \\psi | Z_i Z_j | \\psi \\rangle \\right)\\] <p>where \\(|\\psi\\rangle(\\beta, \\gamma)\\) is the wavefunction obtained by running the QAQA quantum circuit and the sum runs over the edges of the graph \\(\\langle i,j\\rangle\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\n\ntorch.manual_seed(seed)\n\n\ndef loss_function(model: QuantumModel):\n    # The loss corresponds to the expectation\n    # value of the cost Hamiltonian\n    return -1.0 * model.expectation().squeeze()\n\n\n# initialize the parameters to random values\nmodel = QuantumModel(circuit, observable=cost_ham)\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n\n# train the model\nn_epochs = 100\nlr = 0.1\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_function(model)\n    loss.backward()\n    optimizer.step()\n    if (i + 1) % (n_epochs // 10) == 0:\n        print(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -2.1782381363858794\nMaxCut cost at iteration 10: 3.7470706807026417\nMaxCut cost at iteration 20: 3.8378810288930216\nMaxCut cost at iteration 30: 3.9424197899236133\nMaxCut cost at iteration 40: 3.9981256255766002\nMaxCut cost at iteration 50: 3.996470528508214\nMaxCut cost at iteration 60: 3.9991374608876606\nMaxCut cost at iteration 70: 3.9994678542919555\nMaxCut cost at iteration 80: 3.999872558672829\nMaxCut cost at iteration 90: 3.9999475834121063\nMaxCut cost at iteration 100: 3.9999793311641003\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p>"},{"location":"tutorials/qml/qaoa/#results","title":"Results","text":"<p>Given the trained quantum model, one needs to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph.</p> <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\n\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\n    colors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\n    labels[node] = \"A\" if int(b) == 0 else \"B\"\n\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 1001  2024-09-20T08:35:22.447697 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/qml/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/qml/qcl/","title":"Quantum circuit learning","text":"<p>This tutorial shows how to apply <code>qadence</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning<sup>1</sup> (QCL) algorithm.</p> <p>QCL is a supervised quantum machine learning algorithm that uses a parametrized quantum neural network to learn the behavior of an arbitrary mathematical function using a set of function values as training data. This tutorial shows how to fit the \\(\\sin(x)\\) function in the \\([-1, 1]\\) domain.</p> <p>In the following, train and test data are defined.</p> <pre><code>import torch\nfrom torch.utils.data import random_split\n\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndef qcl_training_data(\n    domain: tuple = (0, 2*torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n\n    start, end = domain\n\n    x_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\n    y_rand = torch.sin(x_rand)\n\n    return x_rand, y_rand\n\nx, y = qcl_training_data()\n\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\n\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre>"},{"location":"tutorials/qml/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>Total qubit magnetization is used as observable:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <p>In the following the observable, quantum circuit and corresponding QNN model are constructed.</p> <pre><code>import qadence as qd\n\nn_qubits = 4\n\n# create a simple feature map to encode the input data\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(qd.RX(i, feature_param) for i in range(n_qubits))\nfeature_map = qd.tag(feature_map, \"feature_map\")\n\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits)\nansatz = qd.tag(ansatz, \"ansatz\")\n\n# total qubit magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning=qd.Z)\n\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qd.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\n</code></pre> <pre><code>tensor([[ 0.0092],\n        [-0.0207],\n        [-0.4616],\n        [-0.1845],\n        [-0.3761],\n        [-0.1463],\n        [-0.4563],\n        [-0.0016],\n        [-0.3436],\n        [-0.4252]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable universal function approximator. Standard PyTorch code is used for training the QNN using a mean-square error loss, Adam optimizer. Training is performend on the GPU if available:</p> <pre><code>n_epochs = 100\nlr = 0.25\n\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\n\nprint(f\"Initial loss: {mse_loss(model(values=x_train), y_train)}\")\ny_pred_initial = model(values=x_test)\n\nfor i in range(n_epochs):\n\n    optimizer.zero_grad()\n\n    # given a `n_batch` number of input points and a `n_observables`\n    # number of input observables to measure, the QNN returns\n    # an output of the following shape: [n_batch x n_observables]\n    # given that there is only one observable, a squeeze is applied to get\n    # a 1-dimensional tensor\n    loss = mse_loss(model(values=x_train).squeeze(), y_train)\n    loss.backward()\n    optimizer.step()\n\n    if (i+1) % 20 == 0:\n        print(f\"Epoch {i+1} - Loss: {loss.item()}\")\n\nassert loss.item() &lt; 1e-3\n</code></pre> <pre><code>Initial loss: 0.6272721767455237\nEpoch 20 - Loss: 0.008173087377230498\nEpoch 40 - Loss: 0.0011247726222838813\nEpoch 60 - Loss: 0.0001415308609619855\nEpoch 80 - Loss: 2.3606578815826947e-05\nEpoch 100 - Loss: 2.503287372853267e-06\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p> <p>The quantum model is now trained on the training data points. To determine the quality of the results, one can check to see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\n\ny_pred = model({\"phi\": x_test})\n\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_test_np = y_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\n\nfig, _ = plt.subplots()\nplt.scatter(x_test_np, y_test_np, label=\"Test points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2024-09-20T08:35:26.968129 image/svg+xml Matplotlib v3.7.5, https://matplotlib.org/"},{"location":"tutorials/qml/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"tutorials/realistic_sims/","title":"Realistic simulations","text":"<p>This section describes how to perform realistic simulations in Qadence.</p>"},{"location":"tutorials/realistic_sims/measurements/","title":"Measurement protocols","text":"<p>Sample-based measurement protocols are fundamental tools for the prediction and estimation of a quantum state as the result of NISQ programs executions. Their resource efficient implementation is a current and active research field. Qadence offers two main measurement protocols: quantum state tomography and classical shadows.</p>"},{"location":"tutorials/realistic_sims/measurements/#quantum-state-tomography","title":"Quantum state tomography","text":"<p>The fundamental task of quantum state tomography is to learn an approximate classical description of an output quantum state described by a density matrix \\(\\rho\\), from repeated measurements of copies on a chosen basis. To do so, \\(\\rho\\) is expanded in a basis of observables (the tomography step) and for a given observable \\(\\hat{\\mathcal{O}}\\), the expectation value is calculated with \\(\\langle \\hat{\\mathcal{O}} \\rangle=\\textrm{Tr}(\\hat{\\mathcal{O}}\\rho)\\). A number of measurement repetitions in a suitable basis is then required to estimate \\(\\langle \\hat{\\mathcal{O}} \\rangle\\).</p> <p>The main drawback is the scaling in measurements for the retrieval of the classical expression for a \\(n\\)-qubit quantum state as \\(2^n \\times 2^n\\), together with a large amount of classical post-processing.</p> <p>For an observable expressed as a Pauli string \\(\\hat{\\mathcal{P}}\\), the expectation value for a state \\(|\\psi \\rangle\\) can be derived as:</p> \\[ \\langle \\hat{\\mathcal{P}} \\rangle=\\langle \\psi | \\hat{\\mathcal{P}} |\\psi \\rangle=\\langle \\psi | \\hat{\\mathcal{R}}^\\dagger \\hat{\\mathcal{D}} \\hat{\\mathcal{R}} |\\psi \\rangle \\] <p>The operator \\(\\hat{\\mathcal{R}}\\) diagonalizes \\(\\hat{\\mathcal{P}}\\) and rotates the state into an eigenstate in the computational basis. Therefore, \\(\\hat{\\mathcal{R}}|\\psi \\rangle=\\sum\\limits_{z}a_z|z\\rangle\\) and the expectation value can finally be expressed as:</p> \\[ \\langle \\hat{\\mathcal{P}} \\rangle=\\sum_{z,z'}\\langle z |\\bar{a}_z\\hat{\\mathcal{D}}a_{z'}|z'\\rangle = \\sum_{z}|a_z|^2(-1)^{\\phi_z(\\hat{\\mathcal{P}})} \\] <p>In Qadence, running a tomographical experiment is made simple by defining a <code>Measurements</code> object that captures all options for execution:</p> <pre><code>from torch import tensor\nfrom qadence import hamiltonian_factory, BackendName, DiffMode\nfrom qadence import Parameter, chain, kron, RX, RY, Z, QuantumCircuit, QuantumModel\nfrom qadence.measurements import Measurements\n\n# Define parameters for a circuit.\ntheta1 = Parameter(\"theta1\", trainable=False)\ntheta2 = Parameter(\"theta2\", trainable=False)\ntheta3 = Parameter(\"theta3\", trainable=False)\ntheta4 = Parameter(\"theta4\", trainable=False)\n\nblocks = chain(\n    kron(RX(0, theta1), RY(1, theta2)),\n    kron(RX(0, theta3), RY(1, theta4)),\n)\n\nvalues = {\n    \"theta1\": tensor([0.5]),\n    \"theta2\": tensor([1.5]),\n    \"theta3\": tensor([2.0]),\n    \"theta4\": tensor([2.5]),\n}\n\n# Create a circuit and an observable.\ncircuit = QuantumCircuit(2, blocks)\nobservable = hamiltonian_factory(2, detuning=Z)\n\n# Create a model.\nmodel = QuantumModel(\n    circuit=circuit,\n    observable=observable,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.GPSR,\n)\n\n# Define a measurement protocol by passing the shot budget as an option.\ntomo_options = {\"n_shots\": 100000}\ntomo_measurement = Measurements(protocol=Measurements.TOMOGRAPHY, options=tomo_options)\n\n# Get the exact expectation value.\nexact_values = model.expectation(\n    values=values,\n)\n\n# Run the tomography experiment.\nestimated_values_tomo = model.expectation(\n    values=values,\n    measurement=tomo_measurement,\n)\n</code></pre> <pre><code>Exact expectation value = tensor([[-1.4548]])\nEstimated expectation value tomo = tensor([[-1.4584]])\n</code></pre>"},{"location":"tutorials/realistic_sims/measurements/#classical-shadows","title":"Classical shadows","text":"<p>Recently, a much less resource demanding protocol based on classical shadows has been proposed<sup>1</sup>. It combines ideas from shadow tomography<sup>2</sup> and randomized measurement protocols capable of learning a classical shadow of an unknown quantum state \\(\\rho\\). It relies on deliberately discarding the full classical characterization of the quantum state, and instead focuses on accurately predicting a restricted set of properties that provide efficient protocols for the study of the system.</p> <p>A random measurement consists of applying random unitary rotations before a fixed measurement on each copy of a state. Appropriately averaging over these measurements produces an efficient estimator for the expectation value of an observable. This protocol therefore creates a robust classical representation of the quantum state or classical shadow. The captured measurement information is then reuseable for multiple purposes, i.e. any observable expected value and available for noise mitigation postprocessing.</p> <p>A classical shadow is therefore an unbiased estimator of a quantum state \\(\\rho\\). Such an estimator is obtained with the following procedure<sup>1</sup>: first, apply a random unitary gate \\(U\\) to rotate the state: \\(\\rho \\rightarrow U \\rho U^\\dagger\\) and then perform a basis measurement to obtain a \\(n\\)-bit measurement \\(|\\hat{b}\\rangle \\in \\{0, 1\\}^n\\). Both unitary gates \\(U\\) and the measurement outcomes \\(|\\hat{b}\\rangle\\) are stored on a classical computer for postprocessing v \\(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U\\), a classical snapshot of the state \\(\\rho\\). The whole procedure can be seen as a quantum channel \\(\\mathcal{M}\\) that maps the initial unknown quantum state \\(\\rho\\) to the average result of the measurement protocol:</p> \\[ \\mathbb{E}[U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U] = \\mathcal{M}(\\rho) \\Rightarrow \\rho = \\mathbb{E}[\\mathcal{M}^{-1}(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U)] \\] <p>It is worth noting that the single classical snapshot \\(\\hat{\\rho}=\\mathcal{M}^{-1}(U^\\dagger |\\hat{b}\\rangle\\langle \\hat{b}|U)\\) equals \\(\\rho\\) in expectation: \\(\\mathbb{E}[\\hat{\\rho}]=\\rho\\) despite \\(\\mathcal{M}^{-1}\\) not being a completely positive map. Repeating this procedure \\(N\\) times results in an array of \\(N\\) independent, classical snapshots of \\(\\rho\\) called the classical shadow:</p> \\[ S(\\rho, N) = \\{ \\hat{\\rho}_1=\\mathcal{M}^{-1}(U_1^\\dagger |\\hat{b}_1\\rangle\\langle \\hat{b}_1|U_1),\\cdots,\\hat{\\rho}_N=\\mathcal{M}^{-1}(U_N^\\dagger |\\hat{b}_N\\rangle\\langle \\hat{b}_N|U_N)\\} \\] <p>Along the same lines as the example before, estimating the expectation value using classical shadows in Qadence only requires to pass the right set of parameters to the <code>Measurements</code> object:</p> <pre><code># Classical shadows are defined up to some accuracy and confidence.\nshadow_options = {\"accuracy\": 0.1, \"confidence\": 0.1}  # Shadow size N=54400.\nshadow_measurement = Measurements(protocol=Measurements.SHADOW, options=shadow_options)\n\n# Run the experiment with classical shadows.\nestimated_values_shadow = model.expectation(\n    values=values,\n    measurement=shadow_measurement,\n)\n</code></pre> <pre><code>Estimated expectation value shadow = tensor([[-1.4365]])\n</code></pre>"},{"location":"tutorials/realistic_sims/measurements/#references","title":"References","text":"<ol> <li> <p>Hsin-Yuan Huang, Richard Kueng and John Preskill, Predicting Many Properties of a Quantum System from Very Few Measurements (2020) \u21a9\u21a9</p> </li> <li> <p>S. Aaronson. Shadow tomography of quantum states. In Proceedings of the 50th Annual A ACM SIGACT Symposium on Theory of Computing, STOC 2018, pages 325\u2013338, New York, NY, USA, 2018. ACM\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/realistic_sims/mitigation/","title":"Error mitigation","text":"<p>Beyond running noisy simulations, Qadence offers a number of noise mitigation techniques to achieve better accuracy of simulation outputs. Currently, mitigation addresses readout errors and depolarizing and dephasing noise for analog blocks.</p>"},{"location":"tutorials/realistic_sims/mitigation/#readout-error-mitigation","title":"Readout error mitigation","text":"<p>The complete implementation of the mitigation technique is to measure \\(T\\) and classically apply \\(T^{\u22121}\\) to measured probability distributions. However there are several limitations of this approach:</p> <ul> <li>The complete implementation requires \\(2^n\\) characterization experiments (probability measurements), which is not scalable. The classical processing of the calibration data is also inefficient.</li> <li>The matrix \\(T\\) may become singular for large \\(n\\), preventing direct inversion.</li> <li>The inverse \\(T^{\u22121}\\) might not be a stochastic matrix, meaning that it can produce negative corrected probabilities.</li> <li>The correction is not rigorously justified, so we cannot be sure that we are only removing SPAM errors and not otherwise corrupting an estimated probability distribution.</li> </ul> <p>Qadence relies on the assumption of uncorrelated readout errors:</p> \\[ T=T_1\\otimes T_2\\otimes \\dots \\otimes T_n \\] <p>for which the inversion is straightforward:</p> \\[ T^{-1}=T_1^{-1}\\otimes T_2^{-1}\\otimes \\dots \\otimes T_n^{-1} \\] <p>However, even for a reduced \\(n\\) the third limitation holds. This can be avoided by reformulating into a minimization problem<sup>1</sup>:</p> \\[ \\lVert Tp_{\\textrm{corr}}-p_{\\textrm{raw}}\\rVert_{2}^{2} \\] <p>subjected to physicality constraints \\(0 \\leq p_{corr}(x) \\leq 1\\) and \\(\\lVert p_{corr} \\rVert = 1\\). At this point, two methods are implemented to solve this problem. The first one relies on solving using standard optimization tools, the second on Maximum-Likelihood Estimation<sup>2</sup>. In Qadence, this can be user defined using the mitigation protocol:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\nfrom qadence.noise import Noise\nfrom qadence.mitigations import Mitigations\nfrom qadence.types import ReadOutOptimization\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use:\nnoise = Noise(protocol=Noise.READOUT)\n# Define the mitigation method solving the minimization problem:\noptions={\"optimization_type\": ReadOutOptimization.CONSTRAINED}  # ReadOutOptimization.MLE for the alternative method.\nmitigation = Mitigations(protocol=Mitigations.READOUT, options=options)\n\n# Run noiseless, noisy and mitigated simulations.\nn_shots = 100\nnoiseless_samples = model.sample(n_shots=n_shots)\nnoisy_samples = model.sample(noise=noise, n_shots=n_shots)\nmitigated_samples = model.sample(\n    noise=noise, mitigation=mitigation, n_shots=n_shots\n)\n\nprint(f\"noiseless {noiseless_samples}\")\nprint(f\"noisy {noisy_samples}\")\nprint(f\"mitigated {mitigated_samples}\")\n</code></pre> <pre><code>noiseless [Counter({'10': 51, '00': 49})]\nnoisy [Counter({'00': 47, '10': 47, '01': 3, '11': 3})]\nmitigated [Counter({'10': 45, '00': 43, '01': 7, '11': 5})]\n</code></pre>"},{"location":"tutorials/realistic_sims/mitigation/#wip-zero-noise-extrapolation-for-analog-blocks","title":"[WIP] Zero-noise extrapolation for analog blocks","text":"<p>Zero-noise extrapolation (ZNE) is an error mitigation technique in which an expectation value is computed at different noise levels and, as a second step, the ideal expectation value is inferred by extrapolating the measured results to the zero-noise limit. In digital computing, this is typically implemented by \"folding\" the circuit and its dagger to artificially increase the noise through sequences of identities<sup>3</sup>. In the analog ZNE variation, analog blocks are time stretched to again artificially increase noise<sup>3</sup>.</p>"},{"location":"tutorials/realistic_sims/mitigation/#references","title":"References","text":"<ol> <li> <p>Michael R. Geller and Mingyu Sun, Efficient correction of multiqubit measurement errors, (2020) \u21a9</p> </li> <li> <p>Smolin et al., Maximum Likelihood, Minimum Effort, (2011) \u21a9</p> </li> <li> <p>Mitiq: What's the theory behind ZNE? \u21a9\u21a9</p> </li> </ol>"},{"location":"tutorials/realistic_sims/noise/","title":"Simulated errors","text":"<p>Running programs on NISQ devices often leads to partially useful results due to the presence of noise. In order to perform realistic simulations, a number of noise models are supported in Qadence and corresponding error mitigation techniques whenever possible.</p>"},{"location":"tutorials/realistic_sims/noise/#readout-errors","title":"Readout errors","text":"<p>State Preparation and Measurement (SPAM) in the hardware is a major source of noise in the execution of quantum programs. They are typically described using confusion matrices of the form:</p> \\[ T(x|x')=\\delta_{xx'} \\] <p>Qadence offers to simulate readout errors with the <code>Noise</code> protocol to corrupt the output samples of a simulation, through execution via a <code>QuantumModel</code>:</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, kron, H, Z\nfrom qadence import hamiltonian_factory\nfrom qadence.noise import Noise\n\n# Simple circuit and observable construction.\nblock = kron(H(0), Z(1))\ncircuit = QuantumCircuit(2, block)\nobservable = hamiltonian_factory(circuit.n_qubits, detuning=Z)\n\n# Construct a quantum model.\nmodel = QuantumModel(circuit=circuit, observable=observable)\n\n# Define a noise model to use.\nnoise = Noise(protocol=Noise.READOUT)\n\n# Run noiseless and noisy simulations.\nnoiseless_samples = model.sample(n_shots=100)\nnoisy_samples = model.sample(noise=noise, n_shots=100)\n</code></pre> <pre><code>noiseless = [Counter({'00': 52, '10': 48})]\nnoisy = [Counter({'10': 48, '00': 44, '11': 5, '01': 3})]\n</code></pre> <p>It is possible to pass options to the noise model. In the previous example, a noise matrix is implicitly computed from a uniform distribution. The <code>option</code> dictionary argument accepts the following options:</p> <ul> <li><code>seed</code>: defaulted to <code>None</code>, for reproducibility purposes</li> <li><code>error_probability</code>: defaulted to 0.1, a bit flip probability</li> <li><code>noise_distribution</code>: defaulted to <code>WhiteNoise.UNIFORM</code>, for non-uniform noise distributions</li> <li><code>noise_matrix</code>: defaulted to <code>None</code>, if the noise matrix is known from third-party experiments, i.e. hardware calibration.</li> </ul> <p>Noisy simulations go hand-in-hand with measurement protocols discussed in the previous section, to assess the impact of noise on expectation values. In this case, both measurement and noise protocols have to be defined appropriately. Please note that a noise protocol without a measurement protocol will be ignored for expectation values computations.</p> <pre><code>from qadence.measurements import Measurements\n\n# Define a noise model with options.\noptions = {\"error_probability\": 0.01}\nnoise = Noise(protocol=Noise.READOUT, options=options)\n\n# Define a tomographical measurement protocol with options.\noptions = {\"n_shots\": 10000}\nmeasurement = Measurements(protocol=Measurements.TOMOGRAPHY, options=options)\n\n# Run noiseless and noisy simulations.\nnoiseless_exp = model.expectation(measurement=measurement)\nnoisy_exp = model.expectation(measurement=measurement, noise=noise)\n</code></pre> <pre><code>noiseless = tensor([[1.0040]], grad_fn=&lt;TransposeBackward0&gt;)\nnoisy = tensor([[0.9772]], grad_fn=&lt;TransposeBackward0&gt;)\n</code></pre>"}]}